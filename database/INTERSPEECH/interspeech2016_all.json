{"John Makhoul": [0, ["A 50-Year Retrospective on Speech and Language Processing", ["John Makhoul"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/3001.html", 1, "interspeech", 2016]], "Ivan Medennikov": [0, ["Improving English Conversational Telephone Speech Recognition", ["Ivan Medennikov", "Alexey Prudnikov", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2016-473", 5, "interspeech", 2016]], "Alexey Prudnikov": [0, ["Improving English Conversational Telephone Speech Recognition", ["Ivan Medennikov", "Alexey Prudnikov", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2016-473", 5, "interspeech", 2016]], "Alexander Zatvornitskiy": [0, ["Improving English Conversational Telephone Speech Recognition", ["Ivan Medennikov", "Alexey Prudnikov", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2016-473", 5, "interspeech", 2016]], "George Saon": [0, ["The IBM 2016 English Conversational Telephone Speech Recognition System", ["George Saon", "Tom Sercu", "Steven J. Rennie", "Hong-Kwang Jeff Kuo"], "https://doi.org/10.21437/Interspeech.2016-1460", 5, "interspeech", 2016], ["Domain Adaptation of CNN Based Acoustic Models Under Limited Resource Settings", ["Masayuki Suzuki", "Ryuki Tachibana", "Samuel Thomas", "Bhuvana Ramabhadran", "George Saon"], "https://doi.org/10.21437/Interspeech.2016-1161", 5, "interspeech", 2016]], "Tom Sercu": [0, ["The IBM 2016 English Conversational Telephone Speech Recognition System", ["George Saon", "Tom Sercu", "Steven J. Rennie", "Hong-Kwang Jeff Kuo"], "https://doi.org/10.21437/Interspeech.2016-1460", 5, "interspeech", 2016], ["Advances in Very Deep Convolutional Neural Networks for LVCSR", ["Tom Sercu", "Vaibhava Goel"], "https://doi.org/10.21437/Interspeech.2016-1033", 5, "interspeech", 2016]], "Steven J. Rennie": [0, ["The IBM 2016 English Conversational Telephone Speech Recognition System", ["George Saon", "Tom Sercu", "Steven J. Rennie", "Hong-Kwang Jeff Kuo"], "https://doi.org/10.21437/Interspeech.2016-1460", 5, "interspeech", 2016]], "Hong-Kwang Jeff Kuo": [0, ["The IBM 2016 English Conversational Telephone Speech Recognition System", ["George Saon", "Tom Sercu", "Steven J. Rennie", "Hong-Kwang Jeff Kuo"], "https://doi.org/10.21437/Interspeech.2016-1460", 5, "interspeech", 2016]], "Liang Lu": [0, ["Small-Footprint Deep Neural Networks with Highway Connections for Speech Recognition", ["Liang Lu", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-39", 5, "interspeech", 2016], ["Segmental Recurrent Neural Networks for End-to-End Speech Recognition", ["Liang Lu", "Lingpeng Kong", "Chris Dyer", "Noah A. Smith", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-40", 5, "interspeech", 2016]], "Steve Renals": [0, ["Small-Footprint Deep Neural Networks with Highway Connections for Speech Recognition", ["Liang Lu", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-39", 5, "interspeech", 2016], ["Segmental Recurrent Neural Networks for End-to-End Speech Recognition", ["Liang Lu", "Lingpeng Kong", "Chris Dyer", "Noah A. Smith", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-40", 5, "interspeech", 2016], ["Improving Children's Speech Recognition Through Out-of-Domain Data Augmentation", ["Joachim Fainberg", "Peter Bell", "Mike Lincoln", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-1348", 5, "interspeech", 2016], ["Unsupervised Adaptation of Recurrent Neural Network Language Models", ["Siva Reddy Gangireddy", "Pawel Swietojanski", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-1342", 5, "interspeech", 2016], ["Automatic Dialect Detection in Arabic Broadcast Speech", ["Ahmed M. Ali", "Najim Dehak", "Patrick Cardinal", "Sameer Khurana", "Sree Harsha Yella", "James R. Glass", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-1297", 5, "interspeech", 2016]], "Dong Yu": [0.19732904434204102, ["Deep Convolutional Neural Networks with Layer-Wise Context Expansion and Attention", ["Dong Yu", "Wayne Xiong", "Jasha Droppo", "Andreas Stolcke", "Guoli Ye", "Jinyu Li", "Geoffrey Zweig"], "https://doi.org/10.21437/Interspeech.2016-251", 5, "interspeech", 2016]], "Wayne Xiong": [0, ["Deep Convolutional Neural Networks with Layer-Wise Context Expansion and Attention", ["Dong Yu", "Wayne Xiong", "Jasha Droppo", "Andreas Stolcke", "Guoli Ye", "Jinyu Li", "Geoffrey Zweig"], "https://doi.org/10.21437/Interspeech.2016-251", 5, "interspeech", 2016]], "Jasha Droppo": [0, ["Deep Convolutional Neural Networks with Layer-Wise Context Expansion and Attention", ["Dong Yu", "Wayne Xiong", "Jasha Droppo", "Andreas Stolcke", "Guoli Ye", "Jinyu Li", "Geoffrey Zweig"], "https://doi.org/10.21437/Interspeech.2016-251", 5, "interspeech", 2016]], "Andreas Stolcke": [0, ["Deep Convolutional Neural Networks with Layer-Wise Context Expansion and Attention", ["Dong Yu", "Wayne Xiong", "Jasha Droppo", "Andreas Stolcke", "Guoli Ye", "Jinyu Li", "Geoffrey Zweig"], "https://doi.org/10.21437/Interspeech.2016-251", 5, "interspeech", 2016]], "Guoli Ye": [0.0019077393226325512, ["Deep Convolutional Neural Networks with Layer-Wise Context Expansion and Attention", ["Dong Yu", "Wayne Xiong", "Jasha Droppo", "Andreas Stolcke", "Guoli Ye", "Jinyu Li", "Geoffrey Zweig"], "https://doi.org/10.21437/Interspeech.2016-251", 5, "interspeech", 2016]], "Jinyu Li": [0, ["Deep Convolutional Neural Networks with Layer-Wise Context Expansion and Attention", ["Dong Yu", "Wayne Xiong", "Jasha Droppo", "Andreas Stolcke", "Guoli Ye", "Jinyu Li", "Geoffrey Zweig"], "https://doi.org/10.21437/Interspeech.2016-251", 5, "interspeech", 2016]], "Geoffrey Zweig": [0, ["Deep Convolutional Neural Networks with Layer-Wise Context Expansion and Attention", ["Dong Yu", "Wayne Xiong", "Jasha Droppo", "Andreas Stolcke", "Guoli Ye", "Jinyu Li", "Geoffrey Zweig"], "https://doi.org/10.21437/Interspeech.2016-251", 5, "interspeech", 2016]], "Golan Pundak": [0, ["Lower Frame Rate Neural Network Acoustic Models", ["Golan Pundak", "Tara N. Sainath"], "https://doi.org/10.21437/Interspeech.2016-275", 5, "interspeech", 2016]], "Tara N. Sainath": [0, ["Lower Frame Rate Neural Network Acoustic Models", ["Golan Pundak", "Tara N. Sainath"], "https://doi.org/10.21437/Interspeech.2016-275", 5, "interspeech", 2016], ["Complex Linear Projection (CLP): A Discriminative Approach to Joint Feature Extraction and Acoustic Modeling", ["Ehsan Variani", "Tara N. Sainath", "Izhak Shafran", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2016-1459", 5, "interspeech", 2016], ["Modeling Time-Frequency Patterns with LSTM vs. Convolutional Architectures for LVCSR Tasks", ["Tara N. Sainath", "Bo Li"], "https://doi.org/10.21437/Interspeech.2016-84", 5, "interspeech", 2016], ["Reducing the Computational Complexity of Multimicrophone Acoustic Models with Integrated Feature Extraction", ["Tara N. Sainath", "Arun Narayanan", "Ron J. Weiss", "Ehsan Variani", "Kevin W. Wilson", "Michiel Bacchiani", "Izhak Shafran"], "https://doi.org/10.21437/Interspeech.2016-92", 5, "interspeech", 2016], ["Neural Network Adaptive Beamforming for Robust Multichannel Speech Recognition", ["Bo Li", "Tara N. Sainath", "Ron J. Weiss", "Kevin W. Wilson", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2016-173", 5, "interspeech", 2016], ["Feature Learning with Raw-Waveform CLDNNs for Voice Activity Detection", ["Ruben Zazo", "Tara N. Sainath", "Gabor Simko", "Carolina Parada"], "https://doi.org/10.21437/Interspeech.2016-268", 5, "interspeech", 2016]], "Gakuto Kurata": [0, ["Improved Neural Network Initialization by Grouping Context-Dependent Targets for Acoustic Modeling", ["Gakuto Kurata", "Brian Kingsbury"], "https://doi.org/10.21437/Interspeech.2016-725", 5, "interspeech", 2016], ["Labeled Data Generation with Encoder-Decoder LSTM for Semantic Slot Filling", ["Gakuto Kurata", "Bing Xiang", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2016-727", 5, "interspeech", 2016]], "Brian Kingsbury": [0, ["Improved Neural Network Initialization by Grouping Context-Dependent Targets for Acoustic Modeling", ["Gakuto Kurata", "Brian Kingsbury"], "https://doi.org/10.21437/Interspeech.2016-725", 5, "interspeech", 2016], ["Multilingual Data Selection for Low Resource Speech Recognition", ["Samuel Thomas", "Kartik Audhkhasi", "Jia Cui", "Brian Kingsbury", "Bhuvana Ramabhadran"], "https://doi.org/10.21437/Interspeech.2016-598", 5, "interspeech", 2016]], "Lei Chen": [0, ["Automatic Scoring of Monologue Video Interviews Using Multimodal Cues", ["Lei Chen", "Gary Feng", "Michelle Martin-Raugh", "Chee Wee Leong", "Christopher Kitchen", "Su-Youn Yoon", "Blair Lehman", "Harrison Kell", "Chong Min Lee"], "https://doi.org/10.21437/Interspeech.2016-1453", 5, "interspeech", 2016], ["DNN Online with iVectors Acoustic Modeling and Doc2Vec Distributed Representations for Improving Automated Speech Scoring", ["Jidong Tao", "Lei Chen", "Chong Min Lee"], "https://doi.org/10.21437/Interspeech.2016-1457", 5, "interspeech", 2016]], "Gary Feng": [0, ["Automatic Scoring of Monologue Video Interviews Using Multimodal Cues", ["Lei Chen", "Gary Feng", "Michelle Martin-Raugh", "Chee Wee Leong", "Christopher Kitchen", "Su-Youn Yoon", "Blair Lehman", "Harrison Kell", "Chong Min Lee"], "https://doi.org/10.21437/Interspeech.2016-1453", 5, "interspeech", 2016]], "Michelle Martin-Raugh": [0, ["Automatic Scoring of Monologue Video Interviews Using Multimodal Cues", ["Lei Chen", "Gary Feng", "Michelle Martin-Raugh", "Chee Wee Leong", "Christopher Kitchen", "Su-Youn Yoon", "Blair Lehman", "Harrison Kell", "Chong Min Lee"], "https://doi.org/10.21437/Interspeech.2016-1453", 5, "interspeech", 2016]], "Chee Wee Leong": [0, ["Automatic Scoring of Monologue Video Interviews Using Multimodal Cues", ["Lei Chen", "Gary Feng", "Michelle Martin-Raugh", "Chee Wee Leong", "Christopher Kitchen", "Su-Youn Yoon", "Blair Lehman", "Harrison Kell", "Chong Min Lee"], "https://doi.org/10.21437/Interspeech.2016-1453", 5, "interspeech", 2016]], "Christopher Kitchen": [0, ["Automatic Scoring of Monologue Video Interviews Using Multimodal Cues", ["Lei Chen", "Gary Feng", "Michelle Martin-Raugh", "Chee Wee Leong", "Christopher Kitchen", "Su-Youn Yoon", "Blair Lehman", "Harrison Kell", "Chong Min Lee"], "https://doi.org/10.21437/Interspeech.2016-1453", 5, "interspeech", 2016]], "Su-Youn Yoon": [0.9995113462209702, ["Automatic Scoring of Monologue Video Interviews Using Multimodal Cues", ["Lei Chen", "Gary Feng", "Michelle Martin-Raugh", "Chee Wee Leong", "Christopher Kitchen", "Su-Youn Yoon", "Blair Lehman", "Harrison Kell", "Chong Min Lee"], "https://doi.org/10.21437/Interspeech.2016-1453", 5, "interspeech", 2016]], "Blair Lehman": [0, ["Automatic Scoring of Monologue Video Interviews Using Multimodal Cues", ["Lei Chen", "Gary Feng", "Michelle Martin-Raugh", "Chee Wee Leong", "Christopher Kitchen", "Su-Youn Yoon", "Blair Lehman", "Harrison Kell", "Chong Min Lee"], "https://doi.org/10.21437/Interspeech.2016-1453", 5, "interspeech", 2016]], "Harrison Kell": [0, ["Automatic Scoring of Monologue Video Interviews Using Multimodal Cues", ["Lei Chen", "Gary Feng", "Michelle Martin-Raugh", "Chee Wee Leong", "Christopher Kitchen", "Su-Youn Yoon", "Blair Lehman", "Harrison Kell", "Chong Min Lee"], "https://doi.org/10.21437/Interspeech.2016-1453", 5, "interspeech", 2016]], "Chong Min Lee": [0.05315091647207737, ["Automatic Scoring of Monologue Video Interviews Using Multimodal Cues", ["Lei Chen", "Gary Feng", "Michelle Martin-Raugh", "Chee Wee Leong", "Christopher Kitchen", "Su-Youn Yoon", "Blair Lehman", "Harrison Kell", "Chong Min Lee"], "https://doi.org/10.21437/Interspeech.2016-1453", 5, "interspeech", 2016], ["DNN Online with iVectors Acoustic Modeling and Doc2Vec Distributed Representations for Improving Automated Speech Scoring", ["Jidong Tao", "Lei Chen", "Chong Min Lee"], "https://doi.org/10.21437/Interspeech.2016-1457", 5, "interspeech", 2016]], "Chee Seng Chong": [0.9921252578496933, ["The Sound of Disgust: How Facial Expression May Influence Speech Production", ["Chee Seng Chong", "Jeesun Kim", "Chris Davis"], "https://doi.org/10.21437/Interspeech.2016-1463", 5, "interspeech", 2016]], "Jeesun Kim": [0.9742622375488281, ["The Sound of Disgust: How Facial Expression May Influence Speech Production", ["Chee Seng Chong", "Jeesun Kim", "Chris Davis"], "https://doi.org/10.21437/Interspeech.2016-1463", 5, "interspeech", 2016], ["The Consistency and Stability of Acoustic and Visual Cues for Different Prosodic Attitudes", ["Jeesun Kim", "Chris Davis"], "https://doi.org/10.21437/Interspeech.2016-1505", 5, "interspeech", 2016], ["Introduction to Poster Presentation of Part II", ["Jeesun Kim", "Gerard Bailly"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs1.html", 0, "interspeech", 2016]], "Chris Davis": [0, ["The Sound of Disgust: How Facial Expression May Influence Speech Production", ["Chee Seng Chong", "Jeesun Kim", "Chris Davis"], "https://doi.org/10.21437/Interspeech.2016-1463", 5, "interspeech", 2016], ["The Consistency and Stability of Acoustic and Visual Cues for Different Prosodic Attitudes", ["Jeesun Kim", "Chris Davis"], "https://doi.org/10.21437/Interspeech.2016-1505", 5, "interspeech", 2016], ["The Influence of Modality and Speaking Style on the Assimilation Type and Categorization Consistency of Non-Native Speech", ["Sarah E. Fenwick", "Catherine T. Best", "Chris Davis", "Michael D. Tyler"], "https://doi.org/10.21437/Interspeech.2016-611", 5, "interspeech", 2016]], "Zhaojun Yang": [1.6324977369919225e-08, ["Analyzing Temporal Dynamics of Dyadic Synchrony in Affective Interactions", ["Zhaojun Yang", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-158", 5, "interspeech", 2016]], "Shrikanth S. Narayanan": [0, ["Analyzing Temporal Dynamics of Dyadic Synchrony in Affective Interactions", ["Zhaojun Yang", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-158", 5, "interspeech", 2016], ["Sensitivity of Quantitative RT-MRI Metrics of Vocal Tract Dynamics to Image Reconstruction Settings", ["Johannes Toger", "Yongwan Lim", "Sajan Goud Lingala", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-168", 5, "interspeech", 2016], ["L2 Acquisition and Production of the English Rhotic Pharyngeal Gesture", ["Sarah Harper", "Louis Goldstein", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-658", 5, "interspeech", 2016], ["Investigation of Speed-Accuracy Tradeoffs in Speech Production Using Real-Time Magnetic Resonance Imaging", ["Adam C. Lammert", "Christine H. Shadle", "Shrikanth S. Narayanan", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2016-157", 5, "interspeech", 2016], ["Characterizing Vocal Tract Dynamics Across Speakers Using Real-Time MRI", ["Tanner Sorensen", "Asterios Toutios", "Louis Goldstein", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-583", 5, "interspeech", 2016], ["State-of-the-Art MRI Protocol for Comprehensive Assessment of Vocal Tract Structure and Function", ["Sajan Goud Lingala", "Asterios Toutios", "Johannes Toger", "Yongwan Lim", "Yinghua Zhu", "Yoon-Chul Kim", "Colin Vaz", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-559", 5, "interspeech", 2016], ["Laughter Valence Prediction in Motivational Interviewing Based on Lexical and Acoustic Cues", ["Rahul Gupta", "Nishant Nath", "Taruna Agrawal", "Panayiotis G. Georgiou", "David C. Atkins", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-184", 5, "interspeech", 2016], ["Complexity in Prosody: A Nonlinear Dynamical Systems Approach for Dyadic Conversations; Behavior and Outcomes in Couples Therapy", ["Md. Nasir", "Brian R. Baucom", "Shrikanth S. Narayanan", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2016-1367", 5, "interspeech", 2016], ["Behavioral Coding of Therapist Language in Addiction Counseling Using Recurrent Neural Networks", ["Bo Xiao", "Dogan Can", "James Gibson", "Zac E. Imel", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1560", 5, "interspeech", 2016], ["Convex Hull Convolutive Non-Negative Matrix Factorization for Uncovering Temporal Patterns in Multivariate Time-Series Data", ["Colin Vaz", "Asterios Toutios", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-571", 5, "interspeech", 2016], ["Velum Control for Oral Sounds", ["Reed Blaylock", "Louis Goldstein", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1408", 5, "interspeech", 2016], ["Acoustic-Prosodic and Turn-Taking Features in Interactions with Children with Neurodevelopmental Disorders", ["Daniel Bone", "Somer Bishop", "Rahul Gupta", "Sungbok Lee", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1073", 5, "interspeech", 2016], ["Attention Assisted Discovery of Sub-Utterance Structure in Speech Emotion Recognition", ["Che-Wei Huang", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-448", 5, "interspeech", 2016], ["Predicting Affective Dimensions Based on Self Assessed Depression Severity", ["Rahul Gupta", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-187", 5, "interspeech", 2016], ["A Deep Learning Approach to Modeling Empathy in Addiction Counseling", ["James Gibson", "Dogan Can", "Bo Xiao", "Zac E. Imel", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-554", 5, "interspeech", 2016], ["Articulatory Synthesis Based on Real-Time Magnetic Resonance Imaging Data", ["Asterios Toutios", "Tanner Sorensen", "Krishna Somandepalli", "Rachel Alexander", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-596", 5, "interspeech", 2016], ["An Expectation Maximization Approach to Joint Modeling of Multidimensional Ratings Derived from Multiple Annotators", ["Anil Ramakrishna", "Rahul Gupta", "Ruth B. Grossman", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-270", 5, "interspeech", 2016], ["Improved Depiction of Tissue Boundaries in Vocal Tract Real-Time MRI Using Automatic Off-Resonance Correction", ["Yongwan Lim", "Sajan Goud Lingala", "Asterios Toutios", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-664", 5, "interspeech", 2016], ["Automatic Estimation of Perceived Sincerity from Spoken Language", ["Brandon M. Booth", "Rahul Gupta", "Pavlos Papadopoulos", "Ruchir Travadi", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1537", 5, "interspeech", 2016], ["Robust Multichannel Gender Classification from Speech in Movie Audio", ["Naveen Kumar", "Md. Nasir", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-540", 5, "interspeech", 2016], ["Illustrating the Production of the International Phonetic Alphabet Sounds Using Fast Real-Time Magnetic Resonance Imaging", ["Asterios Toutios", "Sajan Goud Lingala", "Colin Vaz", "Jangwon Kim", "John H. Esling", "Patricia A. Keating", "Matthew Gordon", "Dani Byrd", "Louis Goldstein", "Krishna S. Nayak", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-605", 5, "interspeech", 2016], ["Perceptual Lateralization of Coda Rhotic Production in Puerto Rican Spanish", ["Mairym Llorens Monteserin", "Shrikanth S. Narayanan", "Louis Goldstein"], "https://doi.org/10.21437/Interspeech.2016-1498", 5, "interspeech", 2016], ["Objective Language Feature Analysis in Children with Neurodevelopmental Disorders During Autism Assessment", ["Manoj Kumar", "Rahul Gupta", "Daniel Bone", "Nikolaos Malandrakis", "Somer Bishop", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-563", 5, "interspeech", 2016], ["Noise Aware and Combined Noise Models for Speech Denoising in Unknown Noise Conditions", ["Pavlos Papadopoulos", "Colin Vaz", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-501", 4, "interspeech", 2016], ["Non-Iterative Parameter Estimation for Total Variability Model Using Randomized Singular Value Decomposition", ["Ruchir Travadi", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-293", 5, "interspeech", 2016]], "Attigodu C. Ganesh": [0, ["Audiovisual Speech Scene Analysis in the Context of Competing Sources", ["Attigodu C. Ganesh", "Frederic Berthommier", "Jean-Luc Schwartz"], "https://doi.org/10.21437/Interspeech.2016-62", 5, "interspeech", 2016]], "Frederic Berthommier": [0, ["Audiovisual Speech Scene Analysis in the Context of Competing Sources", ["Attigodu C. Ganesh", "Frederic Berthommier", "Jean-Luc Schwartz"], "https://doi.org/10.21437/Interspeech.2016-62", 5, "interspeech", 2016]], "Jean-Luc Schwartz": [0, ["Audiovisual Speech Scene Analysis in the Context of Competing Sources", ["Attigodu C. Ganesh", "Frederic Berthommier", "Jean-Luc Schwartz"], "https://doi.org/10.21437/Interspeech.2016-62", 5, "interspeech", 2016], ["Assessing Idiosyncrasies in a Bayesian Model of Speech Communication", ["Marie-Lou Barnaud", "Julien Diard", "Pierre Bessiere", "Jean-Luc Schwartz"], "https://doi.org/10.21437/Interspeech.2016-396", 5, "interspeech", 2016], ["Does Auditory-Motor Learning of Speech Transfer from the CV Syllable to the CVCV Word?", ["Tiphaine Caudrelier", "Pascal Perrier", "Jean-Luc Schwartz", "Amelie Rochet-Capellan"], "https://doi.org/10.21437/Interspeech.2016-262", 5, "interspeech", 2016]], "Najmeh Sadoughi": [0, ["Head Motion Generation with Synthetic Speech: A Data Driven Approach", ["Najmeh Sadoughi", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2016-419", 5, "interspeech", 2016]], "Carlos Busso": [0, ["Head Motion Generation with Synthetic Speech: A Data Driven Approach", ["Najmeh Sadoughi", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2016-419", 5, "interspeech", 2016], ["A Portable Automatic PA-TA-KA Syllable Detection System to Derive Biomarkers for Neurological Disorders", ["Fei Tao", "Louis Daudet", "Christian Poellabauer", "Sandra L. Schneider", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2016-789", 5, "interspeech", 2016], ["Retrieving Categorical Emotions Using a Probabilistic Framework to Define Preference Learning Samples", ["Reza Lotfian", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2016-1052", 5, "interspeech", 2016], ["Improving Boundary Estimation in Audiovisual Speech Activity Detection Using Bayesian Information Criterion", ["Fei Tao", "John H. L. Hansen", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2016-406", 5, "interspeech", 2016], ["Defining Emotionally Salient Regions Using Qualitative Agreement Method", ["Srinivas Parthasarathy", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2016-429", 5, "interspeech", 2016]], "Gerard Bailly": [0, ["Introduction to Poster Presentation of Part II", ["Jeesun Kim", "Gerard Bailly"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs1.html", 0, "interspeech", 2016], ["Characterization of Audiovisual Dramatic Attitudes", ["Adela Barbulescu", "Remi Ronfard", "Gerard Bailly"], "https://doi.org/10.21437/Interspeech.2016-75", 5, "interspeech", 2016], ["Adaptive Latency for Part-of-Speech Tagging in Incremental Text-to-Speech Synthesis", ["Mael Pouget", "Olha Nahorna", "Thomas Hueber", "Gerard Bailly"], "https://doi.org/10.21437/Interspeech.2016-165", 5, "interspeech", 2016], ["Quantitative Analysis of Backchannels Uttered by an Interviewer During Neuropsychological Tests", ["Gerard Bailly", "Frederic Elisei", "Alexandra Juphard", "Olivier Moreaud"], "https://doi.org/10.21437/Interspeech.2016-22", 5, "interspeech", 2016]], "Irene Vogel": [0, ["The Unit of Speech Encoding: The Case of Romanian", ["Irene Vogel", "Laura Spinu"], "https://doi.org/10.21437/Interspeech.2016-1601", 5, "interspeech", 2016], ["The Acoustic Manifestation of Prominence in Stressless Languages", ["Angeliki Athanasopoulou", "Irene Vogel"], "https://doi.org/10.21437/Interspeech.2016-1424", 5, "interspeech", 2016]], "Laura Spinu": [0, ["The Unit of Speech Encoding: The Case of Romanian", ["Irene Vogel", "Laura Spinu"], "https://doi.org/10.21437/Interspeech.2016-1601", 5, "interspeech", 2016]], "Jeanin Jugler": [0, ["The Perceptual Effect of L1 Prosody Transplantation on L2 Speech: The Case of French Accented German", ["Jeanin Jugler", "Frank Zimmerer", "Jurgen Trouvain", "Bernd Mobius"], "https://doi.org/10.21437/Interspeech.2016-1268", 5, "interspeech", 2016], ["Evaluation of Phonatory Behavior of German and French Speakers in Native and Non-Native Speech", ["Manfred Putzer", "Frank Zimmerer", "Wolfgang Wokurek", "Jeanin Jugler"], "https://doi.org/10.21437/Interspeech.2016-49", 5, "interspeech", 2016]], "Frank Zimmerer": [0, ["The Perceptual Effect of L1 Prosody Transplantation on L2 Speech: The Case of French Accented German", ["Jeanin Jugler", "Frank Zimmerer", "Jurgen Trouvain", "Bernd Mobius"], "https://doi.org/10.21437/Interspeech.2016-1268", 5, "interspeech", 2016], ["Evaluation of Phonatory Behavior of German and French Speakers in Native and Non-Native Speech", ["Manfred Putzer", "Frank Zimmerer", "Wolfgang Wokurek", "Jeanin Jugler"], "https://doi.org/10.21437/Interspeech.2016-49", 5, "interspeech", 2016]], "Jurgen Trouvain": [0, ["The Perceptual Effect of L1 Prosody Transplantation on L2 Speech: The Case of French Accented German", ["Jeanin Jugler", "Frank Zimmerer", "Jurgen Trouvain", "Bernd Mobius"], "https://doi.org/10.21437/Interspeech.2016-1268", 5, "interspeech", 2016], ["Inter-Speech Clicks in an Interspeech Keynote", ["Jurgen Trouvain", "Zofia Malisz"], "https://doi.org/10.21437/Interspeech.2016-1064", 5, "interspeech", 2016]], "Bernd Mobius": [0, ["The Perceptual Effect of L1 Prosody Transplantation on L2 Speech: The Case of French Accented German", ["Jeanin Jugler", "Frank Zimmerer", "Jurgen Trouvain", "Bernd Mobius"], "https://doi.org/10.21437/Interspeech.2016-1268", 5, "interspeech", 2016]], "Bijun Ling": [0, ["Organizing Syllables into Sandhi Domains - Evidence from F0 and Duration Patterns in Shanghai Chinese", ["Bijun Ling", "Jie Liang"], "https://doi.org/10.21437/Interspeech.2016-631", 5, "interspeech", 2016]], "Jie Liang": [0, ["Organizing Syllables into Sandhi Domains - Evidence from F0 and Duration Patterns in Shanghai Chinese", ["Bijun Ling", "Jie Liang"], "https://doi.org/10.21437/Interspeech.2016-631", 5, "interspeech", 2016]], "Neville Ryant": [0, ["Automatic Analysis of Phonetic Speech Style Dimensions", ["Neville Ryant", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2016-1355", 5, "interspeech", 2016]], "Mark Liberman": [0, ["Automatic Analysis of Phonetic Speech Style Dimensions", ["Neville Ryant", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2016-1355", 5, "interspeech", 2016], ["The Rhythmic Constraint on Prosodic Boundaries in Mandarin Chinese Based on Corpora of Silent Reading and Speech Perception", ["Wei Lai", "Jiahong Yuan", "Ya Li", "Xiaoying Xu", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2016-607", 5, "interspeech", 2016], ["Pitch-Range Perception: The Dynamic Interaction Between Voice Quality and Fundamental Frequency", ["Jianjing Kuang", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2016-1483", 5, "interspeech", 2016], ["Phoneme, Phone Boundary, and Tone in Automatic Scoring of Mandarin Proficiency", ["Jiahong Yuan", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2016-510", 5, "interspeech", 2016]], "Angeliki Athanasopoulou": [0, ["The Acoustic Manifestation of Prominence in Stressless Languages", ["Angeliki Athanasopoulou", "Irene Vogel"], "https://doi.org/10.21437/Interspeech.2016-1424", 5, "interspeech", 2016]], "Wei Lai": [0, ["The Rhythmic Constraint on Prosodic Boundaries in Mandarin Chinese Based on Corpora of Silent Reading and Speech Perception", ["Wei Lai", "Jiahong Yuan", "Ya Li", "Xiaoying Xu", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2016-607", 5, "interspeech", 2016]], "Jiahong Yuan": [0, ["The Rhythmic Constraint on Prosodic Boundaries in Mandarin Chinese Based on Corpora of Silent Reading and Speech Perception", ["Wei Lai", "Jiahong Yuan", "Ya Li", "Xiaoying Xu", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2016-607", 5, "interspeech", 2016], ["Phoneme, Phone Boundary, and Tone in Automatic Scoring of Mandarin Proficiency", ["Jiahong Yuan", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2016-510", 5, "interspeech", 2016]], "Ya Li": [0, ["The Rhythmic Constraint on Prosodic Boundaries in Mandarin Chinese Based on Corpora of Silent Reading and Speech Perception", ["Wei Lai", "Jiahong Yuan", "Ya Li", "Xiaoying Xu", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2016-607", 5, "interspeech", 2016], ["The Parameterized Phoneme Identity Feature as a Continuous Real-Valued Vector for Neural Network Based Speech Synthesis", ["Zhengqi Wen", "Ya Li", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2016-222", 5, "interspeech", 2016], ["Improving Prosodic Boundaries Prediction for Mandarin Speech Synthesis by Using Enhanced Embedding Feature and Model Fusion Approach", ["Yibin Zheng", "Ya Li", "Zhengqi Wen", "Xingguang Ding", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2016-1060", 5, "interspeech", 2016]], "Xiaoying Xu": [0, ["The Rhythmic Constraint on Prosodic Boundaries in Mandarin Chinese Based on Corpora of Silent Reading and Speech Perception", ["Wei Lai", "Jiahong Yuan", "Ya Li", "Xiaoying Xu", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2016-607", 5, "interspeech", 2016]], "Fu-Sheng Tsai": [0, ["Toward Development and Evaluation of Pain Level-Rating Scale for Emergency Triage based on Vocal Characteristics and Facial Expressions", ["Fu-Sheng Tsai", "Ya-Ling Hsu", "Wei-Chen Chen", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2016-408", 5, "interspeech", 2016]], "Ya-Ling Hsu": [0, ["Toward Development and Evaluation of Pain Level-Rating Scale for Emergency Triage based on Vocal Characteristics and Facial Expressions", ["Fu-Sheng Tsai", "Ya-Ling Hsu", "Wei-Chen Chen", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2016-408", 5, "interspeech", 2016]], "Wei-Chen Chen": [0, ["Toward Development and Evaluation of Pain Level-Rating Scale for Emergency Triage based on Vocal Characteristics and Facial Expressions", ["Fu-Sheng Tsai", "Ya-Ling Hsu", "Wei-Chen Chen", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2016-408", 5, "interspeech", 2016], ["Minimization of Regression and Ranking Losses with Shallow Neural Networks on Automatic Sincerity Evaluation", ["Hung-Shin Lee", "Yu Tsao", "Chi-Chun Lee", "Hsin-Min Wang", "Wei-Cheng Lin", "Wei-Chen Chen", "Shan-Wen Hsiao", "Shyh-Kang Jeng"], "https://doi.org/10.21437/Interspeech.2016-756", 5, "interspeech", 2016]], "Yi-Ming Weng": [0, ["Toward Development and Evaluation of Pain Level-Rating Scale for Emergency Triage based on Vocal Characteristics and Facial Expressions", ["Fu-Sheng Tsai", "Ya-Ling Hsu", "Wei-Chen Chen", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2016-408", 5, "interspeech", 2016]], "Chip-Jin Ng": [0, ["Toward Development and Evaluation of Pain Level-Rating Scale for Emergency Triage based on Vocal Characteristics and Facial Expressions", ["Fu-Sheng Tsai", "Ya-Ling Hsu", "Wei-Chen Chen", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2016-408", 5, "interspeech", 2016]], "Chi-Chun Lee": [0.29328782111406326, ["Toward Development and Evaluation of Pain Level-Rating Scale for Emergency Triage based on Vocal Characteristics and Facial Expressions", ["Fu-Sheng Tsai", "Ya-Ling Hsu", "Wei-Chen Chen", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2016-408", 5, "interspeech", 2016], ["Enhancement of Automatic Oral Presentation Assessment System Using Latent N-Grams Word Representation and Part-of-Speech Information", ["Wen-Yu Huang", "Shan-Wen Hsiao", "Hung-Ching Sun", "Ming-Chuan Hsieh", "Ming-Hsueh Tsai", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2016-400", 5, "interspeech", 2016], ["Minimization of Regression and Ranking Losses with Shallow Neural Networks on Automatic Sincerity Evaluation", ["Hung-Shin Lee", "Yu Tsao", "Chi-Chun Lee", "Hsin-Min Wang", "Wei-Cheng Lin", "Wei-Chen Chen", "Shan-Wen Hsiao", "Shyh-Kang Jeng"], "https://doi.org/10.21437/Interspeech.2016-756", 5, "interspeech", 2016]], "Tan Lee": [0.0017472007311880589, ["Predicting Severity of Voice Disorder from DNN-HMM Acoustic Posteriors", ["Tan Lee", "Yuanyuan Liu", "Yu Ting Yeung", "Thomas K. T. Law", "Kathy Y. S. Lee"], "https://doi.org/10.21437/Interspeech.2016-1098", 5, "interspeech", 2016], ["Hybrid Accelerated Optimization for Speech Recognition", ["Jen-Tzung Chien", "Pei-Wen Huang", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2016-192", 5, "interspeech", 2016]], "Yuanyuan Liu": [0, ["Predicting Severity of Voice Disorder from DNN-HMM Acoustic Posteriors", ["Tan Lee", "Yuanyuan Liu", "Yu Ting Yeung", "Thomas K. T. Law", "Kathy Y. S. Lee"], "https://doi.org/10.21437/Interspeech.2016-1098", 5, "interspeech", 2016]], "Yu Ting Yeung": [0, ["Predicting Severity of Voice Disorder from DNN-HMM Acoustic Posteriors", ["Tan Lee", "Yuanyuan Liu", "Yu Ting Yeung", "Thomas K. T. Law", "Kathy Y. S. Lee"], "https://doi.org/10.21437/Interspeech.2016-1098", 5, "interspeech", 2016]], "Thomas K. T. Law": [0, ["Predicting Severity of Voice Disorder from DNN-HMM Acoustic Posteriors", ["Tan Lee", "Yuanyuan Liu", "Yu Ting Yeung", "Thomas K. T. Law", "Kathy Y. S. Lee"], "https://doi.org/10.21437/Interspeech.2016-1098", 5, "interspeech", 2016]], "Kathy Y. S. Lee": [4.8862796475646064e-08, ["Predicting Severity of Voice Disorder from DNN-HMM Acoustic Posteriors", ["Tan Lee", "Yuanyuan Liu", "Yu Ting Yeung", "Thomas K. T. Law", "Kathy Y. S. Lee"], "https://doi.org/10.21437/Interspeech.2016-1098", 5, "interspeech", 2016]], "Klaske E. van Sluis": [0, ["Long-Term Stability of Tracheoesophageal Voices", ["Klaske E. van Sluis", "Michiel W. M. van den Brekel", "Frans J. M. Hilgers", "Rob J. J. H. van Son"], "https://doi.org/10.21437/Interspeech.2016-114", 5, "interspeech", 2016]], "Michiel W. M. van den Brekel": [0, ["Long-Term Stability of Tracheoesophageal Voices", ["Klaske E. van Sluis", "Michiel W. M. van den Brekel", "Frans J. M. Hilgers", "Rob J. J. H. van Son"], "https://doi.org/10.21437/Interspeech.2016-114", 5, "interspeech", 2016]], "Frans J. M. Hilgers": [0, ["Long-Term Stability of Tracheoesophageal Voices", ["Klaske E. van Sluis", "Michiel W. M. van den Brekel", "Frans J. M. Hilgers", "Rob J. J. H. van Son"], "https://doi.org/10.21437/Interspeech.2016-114", 5, "interspeech", 2016]], "Rob J. J. H. van Son": [1.6504738908906802e-08, ["Long-Term Stability of Tracheoesophageal Voices", ["Klaske E. van Sluis", "Michiel W. M. van den Brekel", "Frans J. M. Hilgers", "Rob J. J. H. van Son"], "https://doi.org/10.21437/Interspeech.2016-114", 5, "interspeech", 2016]], "Gabor Gosztolya": [0, ["Detecting Mild Cognitive Impairment from Spontaneous Speech by Correlation-Based Phonetic Feature Selection", ["Gabor Gosztolya", "Laszlo Toth", "Tamas Grosz", "Veronika Vincze", "Ildiko Hoffmann", "Greta Szatloczki", "Magdolna Pakaski", "Janos Kalman"], "https://doi.org/10.21437/Interspeech.2016-384", 5, "interspeech", 2016], ["Estimating the Sincerity of Apologies in Speech by DNN Rank Learning and Prosodic Analysis", ["Gabor Gosztolya", "Tamas Grosz", "Gyorgy Szaszak", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2016-956", 5, "interspeech", 2016], ["Determining Native Language and Deception Using Phonetic Features and Classifier Combination", ["Gabor Gosztolya", "Tamas Grosz", "Robert Busa-Fekete", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2016-962", 5, "interspeech", 2016], ["GMM-Free Flat Start Sequence-Discriminative DNN Training", ["Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2016-391", 5, "interspeech", 2016]], "Laszlo Toth": [0, ["Detecting Mild Cognitive Impairment from Spontaneous Speech by Correlation-Based Phonetic Feature Selection", ["Gabor Gosztolya", "Laszlo Toth", "Tamas Grosz", "Veronika Vincze", "Ildiko Hoffmann", "Greta Szatloczki", "Magdolna Pakaski", "Janos Kalman"], "https://doi.org/10.21437/Interspeech.2016-384", 5, "interspeech", 2016], ["Estimating the Sincerity of Apologies in Speech by DNN Rank Learning and Prosodic Analysis", ["Gabor Gosztolya", "Tamas Grosz", "Gyorgy Szaszak", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2016-956", 5, "interspeech", 2016], ["Determining Native Language and Deception Using Phonetic Features and Classifier Combination", ["Gabor Gosztolya", "Tamas Grosz", "Robert Busa-Fekete", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2016-962", 5, "interspeech", 2016], ["GMM-Free Flat Start Sequence-Discriminative DNN Training", ["Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2016-391", 5, "interspeech", 2016]], "Tamas Grosz": [0, ["Detecting Mild Cognitive Impairment from Spontaneous Speech by Correlation-Based Phonetic Feature Selection", ["Gabor Gosztolya", "Laszlo Toth", "Tamas Grosz", "Veronika Vincze", "Ildiko Hoffmann", "Greta Szatloczki", "Magdolna Pakaski", "Janos Kalman"], "https://doi.org/10.21437/Interspeech.2016-384", 5, "interspeech", 2016], ["Estimating the Sincerity of Apologies in Speech by DNN Rank Learning and Prosodic Analysis", ["Gabor Gosztolya", "Tamas Grosz", "Gyorgy Szaszak", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2016-956", 5, "interspeech", 2016], ["Determining Native Language and Deception Using Phonetic Features and Classifier Combination", ["Gabor Gosztolya", "Tamas Grosz", "Robert Busa-Fekete", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2016-962", 5, "interspeech", 2016], ["GMM-Free Flat Start Sequence-Discriminative DNN Training", ["Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2016-391", 5, "interspeech", 2016]], "Veronika Vincze": [0, ["Detecting Mild Cognitive Impairment from Spontaneous Speech by Correlation-Based Phonetic Feature Selection", ["Gabor Gosztolya", "Laszlo Toth", "Tamas Grosz", "Veronika Vincze", "Ildiko Hoffmann", "Greta Szatloczki", "Magdolna Pakaski", "Janos Kalman"], "https://doi.org/10.21437/Interspeech.2016-384", 5, "interspeech", 2016]], "Ildiko Hoffmann": [0, ["Detecting Mild Cognitive Impairment from Spontaneous Speech by Correlation-Based Phonetic Feature Selection", ["Gabor Gosztolya", "Laszlo Toth", "Tamas Grosz", "Veronika Vincze", "Ildiko Hoffmann", "Greta Szatloczki", "Magdolna Pakaski", "Janos Kalman"], "https://doi.org/10.21437/Interspeech.2016-384", 5, "interspeech", 2016]], "Greta Szatloczki": [0, ["Detecting Mild Cognitive Impairment from Spontaneous Speech by Correlation-Based Phonetic Feature Selection", ["Gabor Gosztolya", "Laszlo Toth", "Tamas Grosz", "Veronika Vincze", "Ildiko Hoffmann", "Greta Szatloczki", "Magdolna Pakaski", "Janos Kalman"], "https://doi.org/10.21437/Interspeech.2016-384", 5, "interspeech", 2016]], "Magdolna Pakaski": [0, ["Detecting Mild Cognitive Impairment from Spontaneous Speech by Correlation-Based Phonetic Feature Selection", ["Gabor Gosztolya", "Laszlo Toth", "Tamas Grosz", "Veronika Vincze", "Ildiko Hoffmann", "Greta Szatloczki", "Magdolna Pakaski", "Janos Kalman"], "https://doi.org/10.21437/Interspeech.2016-384", 5, "interspeech", 2016]], "Janos Kalman": [0, ["Detecting Mild Cognitive Impairment from Spontaneous Speech by Correlation-Based Phonetic Feature Selection", ["Gabor Gosztolya", "Laszlo Toth", "Tamas Grosz", "Veronika Vincze", "Ildiko Hoffmann", "Greta Szatloczki", "Magdolna Pakaski", "Janos Kalman"], "https://doi.org/10.21437/Interspeech.2016-384", 5, "interspeech", 2016]], "Jen J. Gong": [0.0012277985515538603, ["Towards an Automated Screening Tool for Developmental Speech and Language Impairments", ["Jen J. Gong", "Maryann Gong", "Dina Levy-Lambert", "Jordan R. Green", "Tiffany P. Hogan", "John V. Guttag"], "https://doi.org/10.21437/Interspeech.2016-549", 5, "interspeech", 2016]], "Maryann Gong": [1.2880986943741846e-08, ["Towards an Automated Screening Tool for Developmental Speech and Language Impairments", ["Jen J. Gong", "Maryann Gong", "Dina Levy-Lambert", "Jordan R. Green", "Tiffany P. Hogan", "John V. Guttag"], "https://doi.org/10.21437/Interspeech.2016-549", 5, "interspeech", 2016]], "Dina Levy-Lambert": [0, ["Towards an Automated Screening Tool for Developmental Speech and Language Impairments", ["Jen J. Gong", "Maryann Gong", "Dina Levy-Lambert", "Jordan R. Green", "Tiffany P. Hogan", "John V. Guttag"], "https://doi.org/10.21437/Interspeech.2016-549", 5, "interspeech", 2016]], "Jordan R. Green": [0, ["Towards an Automated Screening Tool for Developmental Speech and Language Impairments", ["Jen J. Gong", "Maryann Gong", "Dina Levy-Lambert", "Jordan R. Green", "Tiffany P. Hogan", "John V. Guttag"], "https://doi.org/10.21437/Interspeech.2016-549", 5, "interspeech", 2016], ["Differential Effects of Velopharyngeal Dysfunction on Speech Intelligibility During Early and Late Stages of Amyotrophic Lateral Sclerosis", ["Panying Rong", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2016-1524", 5, "interspeech", 2016], ["Relation of Automatically Extracted Formant Trajectories with Intelligibility Loss and Speaking Rate Decline in Amyotrophic Lateral Sclerosis", ["Rachelle L. Horwitz-Martin", "Thomas F. Quatieri", "Adam C. Lammert", "James R. Williamson", "Yana Yunusova", "Elizabeth Godoy", "Daryush D. Mehta", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2016-403", 5, "interspeech", 2016]], "Tiffany P. Hogan": [0, ["Towards an Automated Screening Tool for Developmental Speech and Language Impairments", ["Jen J. Gong", "Maryann Gong", "Dina Levy-Lambert", "Jordan R. Green", "Tiffany P. Hogan", "John V. Guttag"], "https://doi.org/10.21437/Interspeech.2016-549", 5, "interspeech", 2016]], "John V. Guttag": [0, ["Towards an Automated Screening Tool for Developmental Speech and Language Impairments", ["Jen J. Gong", "Maryann Gong", "Dina Levy-Lambert", "Jordan R. Green", "Tiffany P. Hogan", "John V. Guttag"], "https://doi.org/10.21437/Interspeech.2016-549", 5, "interspeech", 2016]], "Vikram C. M.": [0, ["Spectral Enhancement of Cleft Lip and Palate Speech", ["Vikram C. M.", "Nagaraj Adiga", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2016-842", 5, "interspeech", 2016]], "Nagaraj Adiga": [0, ["Spectral Enhancement of Cleft Lip and Palate Speech", ["Vikram C. M.", "Nagaraj Adiga", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2016-842", 5, "interspeech", 2016]], "S. R. Mahadeva Prasanna": [0, ["Spectral Enhancement of Cleft Lip and Palate Speech", ["Vikram C. M.", "Nagaraj Adiga", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2016-842", 5, "interspeech", 2016], ["Speech Synthesis in Noisy Environment by Enhancing Strength of Excitation and Formant Prominence", ["Bidisha Sharma", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2016-1005", 5, "interspeech", 2016], ["Exploring Session Variability and Template Aging in Speaker Verification for Fixed Phrase Short Utterances", ["Rohan Kumar Das", "Sarfaraz Jelil", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2016-1001", 5, "interspeech", 2016], ["Analysis of Glottal Stop in Assam Sora Language", ["Sishir Kalita", "Luke Horo", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2016-877", 5, "interspeech", 2016]], "Tian Guan": [0, ["Assessing Level-Dependent Segmental Contribution to the Intelligibility of Speech Processed by Single-Channel Noise-Suppression Algorithms", ["Tian Guan", "Guangxing Chu", "Fei Chen", "Feng Yang"], "https://doi.org/10.21437/Interspeech.2016-43", 4, "interspeech", 2016]], "Guangxing Chu": [2.3680567923234364e-11, ["Assessing Level-Dependent Segmental Contribution to the Intelligibility of Speech Processed by Single-Channel Noise-Suppression Algorithms", ["Tian Guan", "Guangxing Chu", "Fei Chen", "Feng Yang"], "https://doi.org/10.21437/Interspeech.2016-43", 4, "interspeech", 2016]], "Fei Chen": [0, ["Assessing Level-Dependent Segmental Contribution to the Intelligibility of Speech Processed by Single-Channel Noise-Suppression Algorithms", ["Tian Guan", "Guangxing Chu", "Fei Chen", "Feng Yang"], "https://doi.org/10.21437/Interspeech.2016-43", 4, "interspeech", 2016], ["Relative Contributions of Amplitude and Phase to the Intelligibility Advantage of Ideal Binary Masked Sentences", ["Lei Wang", "Shufeng Zhu", "Diliang Chen", "Yong Feng", "Fei Chen"], "https://doi.org/10.21437/Interspeech.2016-18", 4, "interspeech", 2016], ["Development of Mandarin Onset-Rime Detection in Relation to Age and Pinyin Instruction", ["Fei Chen", "Nan Yan", "Xunan Huang", "Hao Zhang", "Lan Wang", "Gang Peng"], "https://doi.org/10.21437/Interspeech.2016-895", 5, "interspeech", 2016], ["Impaired Categorical Perception of Mandarin Tones and its Relationship to Language Ability in Autism Spectrum Disorders", ["Fei Chen", "Nan Yan", "Xiaojie Pan", "Feng Yang", "Zhuanzhuan Ji", "Lan Wang", "Gang Peng"], "https://doi.org/10.21437/Interspeech.2016-1133", 5, "interspeech", 2016], ["The Influence of Language Experience on the Categorical Perception of Vowels: Evidence from Mandarin and Korean", ["Hao Zhang", "Fei Chen", "Nan Yan", "Lan Wang", "Feng Shi", "Manwa L. Ng"], "https://doi.org/10.21437/Interspeech.2016-887", 5, "interspeech", 2016], ["Comparing the Contributions of Amplitude and Phase to Speech Intelligibility in a Vocoder-Based Speech Synthesis Model", ["Fei Chen", "Benson C. L. Chiao"], "https://doi.org/10.21437/Interspeech.2016-66", 4, "interspeech", 2016], ["Modeling Noise Influence to Speech Intelligibility Non-Intrusively by Reduced Speech Dynamic Range", ["Fei Chen"], "https://doi.org/10.21437/Interspeech.2016-9", 4, "interspeech", 2016], ["Vowel Fundamental and Formant Frequency Contributions to English and Mandarin Sentence Intelligibility", ["Daniel Fogerty", "Fei Chen"], "https://doi.org/10.21437/Interspeech.2016-28", 5, "interspeech", 2016], ["Understanding Periodically Interrupted Mandarin Speech", ["Jing Liu", "Rosanna H. N. Tong", "Fei Chen"], "https://doi.org/10.21437/Interspeech.2016-176", 5, "interspeech", 2016], ["Factors Affecting the Intelligibility of Sine-Wave Speech", ["Fei Chen", "Daniel Fogerty"], "https://doi.org/10.21437/Interspeech.2016-4", 4, "interspeech", 2016]], "Feng Yang": [0.0002190577652072534, ["Assessing Level-Dependent Segmental Contribution to the Intelligibility of Speech Processed by Single-Channel Noise-Suppression Algorithms", ["Tian Guan", "Guangxing Chu", "Fei Chen", "Feng Yang"], "https://doi.org/10.21437/Interspeech.2016-43", 4, "interspeech", 2016], ["Impaired Categorical Perception of Mandarin Tones and its Relationship to Language Ability in Autism Spectrum Disorders", ["Fei Chen", "Nan Yan", "Xiaojie Pan", "Feng Yang", "Zhuanzhuan Ji", "Lan Wang", "Gang Peng"], "https://doi.org/10.21437/Interspeech.2016-1133", 5, "interspeech", 2016]], "Tudor-Catalin Zorila": [0, ["Effectiveness of Near-End Speech Enhancement Under Equal-Loudness and Equal-Level Constraints", ["Tudor-Catalin Zorila", "Sheila Flanagan", "Brian C. J. Moore", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2016-594", 5, "interspeech", 2016]], "Sheila Flanagan": [0, ["Effectiveness of Near-End Speech Enhancement Under Equal-Loudness and Equal-Level Constraints", ["Tudor-Catalin Zorila", "Sheila Flanagan", "Brian C. J. Moore", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2016-594", 5, "interspeech", 2016]], "Brian C. J. Moore": [0, ["Effectiveness of Near-End Speech Enhancement Under Equal-Loudness and Equal-Level Constraints", ["Tudor-Catalin Zorila", "Sheila Flanagan", "Brian C. J. Moore", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2016-594", 5, "interspeech", 2016]], "Yannis Stylianou": [0, ["Effectiveness of Near-End Speech Enhancement Under Equal-Loudness and Equal-Level Constraints", ["Tudor-Catalin Zorila", "Sheila Flanagan", "Brian C. J. Moore", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2016-594", 5, "interspeech", 2016], ["Automated Pause Insertion for Improved Intelligibility Under Reverberation", ["Petko N. Petkov", "Norbert Braunschweiler", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2016-960", 5, "interspeech", 2016], ["Modulation Enhancement of Temporal Envelopes for Increasing Speech Intelligibility in Noise", ["Maria Koutsogiannaki", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2016-500", 5, "interspeech", 2016], ["Generalizing Steady State Suppression for Enhanced Intelligibility Under Reverberation", ["Petko N. Petkov", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2016-1026", 5, "interspeech", 2016]], "Bidisha Sharma": [0, ["Speech Synthesis in Noisy Environment by Enhancing Strength of Excitation and Formant Prominence", ["Bidisha Sharma", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2016-1005", 5, "interspeech", 2016]], "Lei Wang": [0.001596404006704688, ["Relative Contributions of Amplitude and Phase to the Intelligibility Advantage of Ideal Binary Masked Sentences", ["Lei Wang", "Shufeng Zhu", "Diliang Chen", "Yong Feng", "Fei Chen"], "https://doi.org/10.21437/Interspeech.2016-18", 4, "interspeech", 2016], ["Rapid Update of Multilingual Deep Neural Network for Low-Resource Keyword Search", ["Chongjia Ni", "Lei Wang", "Cheung-Chi Leung", "Feng Rao", "Li Lu", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-53", 5, "interspeech", 2016], ["Toward High-Performance Language-Independent Query-by-Example Spoken Term Detection for MediaEval 2015: Post-Evaluation Analysis", ["Cheung-Chi Leung", "Lei Wang", "Haihua Xu", "Jingyong Hou", "Van Tung Pham", "Hang Lv", "Lei Xie", "Xiong Xiao", "Chongjia Ni", "Bin Ma", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-691", 5, "interspeech", 2016]], "Shufeng Zhu": [0, ["Relative Contributions of Amplitude and Phase to the Intelligibility Advantage of Ideal Binary Masked Sentences", ["Lei Wang", "Shufeng Zhu", "Diliang Chen", "Yong Feng", "Fei Chen"], "https://doi.org/10.21437/Interspeech.2016-18", 4, "interspeech", 2016]], "Diliang Chen": [0, ["Relative Contributions of Amplitude and Phase to the Intelligibility Advantage of Ideal Binary Masked Sentences", ["Lei Wang", "Shufeng Zhu", "Diliang Chen", "Yong Feng", "Fei Chen"], "https://doi.org/10.21437/Interspeech.2016-18", 4, "interspeech", 2016]], "Yong Feng": [0, ["Relative Contributions of Amplitude and Phase to the Intelligibility Advantage of Ideal Binary Masked Sentences", ["Lei Wang", "Shufeng Zhu", "Diliang Chen", "Yong Feng", "Fei Chen"], "https://doi.org/10.21437/Interspeech.2016-18", 4, "interspeech", 2016]], "Qingju Liu": [0, ["Predicting Binaural Speech Intelligibility from Signals Estimated by a Blind Source Separation Algorithm", ["Qingju Liu", "Yan Tang", "Philip J. B. Jackson", "Wenwu Wang"], "https://doi.org/10.21437/Interspeech.2016-410", 5, "interspeech", 2016]], "Yan Tang": [0, ["Predicting Binaural Speech Intelligibility from Signals Estimated by a Blind Source Separation Algorithm", ["Qingju Liu", "Yan Tang", "Philip J. B. Jackson", "Wenwu Wang"], "https://doi.org/10.21437/Interspeech.2016-410", 5, "interspeech", 2016], ["Glimpse-Based Metrics for Predicting Speech Intelligibility in Additive Noise Conditions", ["Yan Tang", "Martin Cooke"], "https://doi.org/10.21437/Interspeech.2016-14", 5, "interspeech", 2016]], "Philip J. B. Jackson": [0, ["Predicting Binaural Speech Intelligibility from Signals Estimated by a Blind Source Separation Algorithm", ["Qingju Liu", "Yan Tang", "Philip J. B. Jackson", "Wenwu Wang"], "https://doi.org/10.21437/Interspeech.2016-410", 5, "interspeech", 2016]], "Wenwu Wang": [0.02055400237441063, ["Predicting Binaural Speech Intelligibility from Signals Estimated by a Blind Source Separation Algorithm", ["Qingju Liu", "Yan Tang", "Philip J. B. Jackson", "Wenwu Wang"], "https://doi.org/10.21437/Interspeech.2016-410", 5, "interspeech", 2016]], "Petko N. Petkov": [0, ["Automated Pause Insertion for Improved Intelligibility Under Reverberation", ["Petko N. Petkov", "Norbert Braunschweiler", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2016-960", 5, "interspeech", 2016], ["Generalizing Steady State Suppression for Enhanced Intelligibility Under Reverberation", ["Petko N. Petkov", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2016-1026", 5, "interspeech", 2016]], "Norbert Braunschweiler": [0, ["Automated Pause Insertion for Improved Intelligibility Under Reverberation", ["Petko N. Petkov", "Norbert Braunschweiler", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2016-960", 5, "interspeech", 2016], ["Pause Prediction from Text for Speech Synthesis with User-Definable Pause Insertion Likelihood Threshold", ["Norbert Braunschweiler", "Ranniery Maia"], "https://doi.org/10.21437/Interspeech.2016-752", 5, "interspeech", 2016]], "Jean-Luc Rouas": [0, ["Automatic Classification of Phonation Modes in Singing Voice: Towards Singing Style Characterisation and Application to Ethnomusicological Recordings", ["Jean-Luc Rouas", "Leonidas Ioannidis"], "https://doi.org/10.21437/Interspeech.2016-1135", 5, "interspeech", 2016]], "Leonidas Ioannidis": [0, ["Automatic Classification of Phonation Modes in Singing Voice: Towards Singing Style Characterisation and Application to Ethnomusicological Recordings", ["Jean-Luc Rouas", "Leonidas Ioannidis"], "https://doi.org/10.21437/Interspeech.2016-1135", 5, "interspeech", 2016]], "Himanshu N. Bhavsar": [0, ["Novel Nonlinear Prediction Based Features for Spoofed Speech Detection", ["Himanshu N. Bhavsar", "Tanvina B. Patel", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2016-1002", 5, "interspeech", 2016]], "Tanvina B. Patel": [0, ["Novel Nonlinear Prediction Based Features for Spoofed Speech Detection", ["Himanshu N. Bhavsar", "Tanvina B. Patel", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2016-1002", 5, "interspeech", 2016], ["Novel Subband Autoencoder Features for Detection of Spoofed Speech", ["Meet H. Soni", "Tanvina B. Patel", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2016-668", 5, "interspeech", 2016], ["Native Language Identification Using Spectral and Source-Based Features", ["Avni Rajpal", "Tanvina B. Patel", "Hardik B. Sailor", "Maulik C. Madhavi", "Hemant A. Patil", "Hiroya Fujisaki"], "https://doi.org/10.21437/Interspeech.2016-1100", 5, "interspeech", 2016]], "Hemant A. Patil": [0, ["Novel Nonlinear Prediction Based Features for Spoofed Speech Detection", ["Himanshu N. Bhavsar", "Tanvina B. Patel", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2016-1002", 5, "interspeech", 2016], ["Novel Subband Autoencoder Features for Detection of Spoofed Speech", ["Meet H. Soni", "Tanvina B. Patel", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2016-668", 5, "interspeech", 2016], ["Native Language Identification Using Spectral and Source-Based Features", ["Avni Rajpal", "Tanvina B. Patel", "Hardik B. Sailor", "Maulik C. Madhavi", "Hemant A. Patil", "Hiroya Fujisaki"], "https://doi.org/10.21437/Interspeech.2016-1100", 5, "interspeech", 2016], ["Unsupervised Deep Auditory Model Using Stack of Convolutional RBMs for Speech Recognition", ["Hardik B. Sailor", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2016-812", 5, "interspeech", 2016], ["Novel Subband Autoencoder Features for Non-Intrusive Quality Assessment of Noise Suppressed Speech", ["Meet H. Soni", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2016-693", 5, "interspeech", 2016]], "Sri Harsha Dumpala": [0, ["Robust Vowel Landmark Detection Using Epoch-Based Features", ["Sri Harsha Dumpala", "Bhanu Teja Nellore", "Raghu Ram Nevali", "Suryakanth V. Gangashetty", "B. Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2016-1074", 5, "interspeech", 2016], ["Use of Vowels in Discriminating Speech-Laugh from Laughter and Neutral Speech", ["Sri Harsha Dumpala", "P. Gangamohan", "Suryakanth V. Gangashetty", "B. Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2016-1114", 5, "interspeech", 2016]], "Bhanu Teja Nellore": [0, ["Robust Vowel Landmark Detection Using Epoch-Based Features", ["Sri Harsha Dumpala", "Bhanu Teja Nellore", "Raghu Ram Nevali", "Suryakanth V. Gangashetty", "B. Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2016-1074", 5, "interspeech", 2016]], "Raghu Ram Nevali": [0, ["Robust Vowel Landmark Detection Using Epoch-Based Features", ["Sri Harsha Dumpala", "Bhanu Teja Nellore", "Raghu Ram Nevali", "Suryakanth V. Gangashetty", "B. Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2016-1074", 5, "interspeech", 2016]], "Suryakanth V. Gangashetty": [0, ["Robust Vowel Landmark Detection Using Epoch-Based Features", ["Sri Harsha Dumpala", "Bhanu Teja Nellore", "Raghu Ram Nevali", "Suryakanth V. Gangashetty", "B. Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2016-1074", 5, "interspeech", 2016], ["Use of Vowels in Discriminating Speech-Laugh from Laughter and Neutral Speech", ["Sri Harsha Dumpala", "P. Gangamohan", "Suryakanth V. Gangashetty", "B. Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2016-1114", 5, "interspeech", 2016], ["An Investigation of Recurrent Neural Network Architectures Using Word Embeddings for Phrase Break Prediction", ["Anandaswarup Vadapalli", "Suryakanth V. Gangashetty"], "https://doi.org/10.21437/Interspeech.2016-885", 5, "interspeech", 2016], ["An Investigation of Deep Neural Network Architectures for Language Recognition in Indian Languages", ["Mounika K. V.", "Sivanand Achanta", "Lakshmi H. R.", "Suryakanth V. Gangashetty", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2016-910", 4, "interspeech", 2016]], "B. Yegnanarayana": [0, ["Robust Vowel Landmark Detection Using Epoch-Based Features", ["Sri Harsha Dumpala", "Bhanu Teja Nellore", "Raghu Ram Nevali", "Suryakanth V. Gangashetty", "B. Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2016-1074", 5, "interspeech", 2016], ["Use of Vowels in Discriminating Speech-Laugh from Laughter and Neutral Speech", ["Sri Harsha Dumpala", "P. Gangamohan", "Suryakanth V. Gangashetty", "B. Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2016-1114", 5, "interspeech", 2016], ["Robust Estimation of Fundamental Frequency Using Single Frequency Filtering Approach", ["Vishala Pannala", "G. Aneeja", "Sudarsana Reddy Kadiri", "B. Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2016-1401", 5, "interspeech", 2016]], "Johannes Toger": [0, ["Sensitivity of Quantitative RT-MRI Metrics of Vocal Tract Dynamics to Image Reconstruction Settings", ["Johannes Toger", "Yongwan Lim", "Sajan Goud Lingala", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-168", 5, "interspeech", 2016], ["State-of-the-Art MRI Protocol for Comprehensive Assessment of Vocal Tract Structure and Function", ["Sajan Goud Lingala", "Asterios Toutios", "Johannes Toger", "Yongwan Lim", "Yinghua Zhu", "Yoon-Chul Kim", "Colin Vaz", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-559", 5, "interspeech", 2016]], "Yongwan Lim": [0.8646367788314819, ["Sensitivity of Quantitative RT-MRI Metrics of Vocal Tract Dynamics to Image Reconstruction Settings", ["Johannes Toger", "Yongwan Lim", "Sajan Goud Lingala", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-168", 5, "interspeech", 2016], ["State-of-the-Art MRI Protocol for Comprehensive Assessment of Vocal Tract Structure and Function", ["Sajan Goud Lingala", "Asterios Toutios", "Johannes Toger", "Yongwan Lim", "Yinghua Zhu", "Yoon-Chul Kim", "Colin Vaz", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-559", 5, "interspeech", 2016], ["Improved Depiction of Tissue Boundaries in Vocal Tract Real-Time MRI Using Automatic Off-Resonance Correction", ["Yongwan Lim", "Sajan Goud Lingala", "Asterios Toutios", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-664", 5, "interspeech", 2016]], "Sajan Goud Lingala": [0, ["Sensitivity of Quantitative RT-MRI Metrics of Vocal Tract Dynamics to Image Reconstruction Settings", ["Johannes Toger", "Yongwan Lim", "Sajan Goud Lingala", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-168", 5, "interspeech", 2016], ["State-of-the-Art MRI Protocol for Comprehensive Assessment of Vocal Tract Structure and Function", ["Sajan Goud Lingala", "Asterios Toutios", "Johannes Toger", "Yongwan Lim", "Yinghua Zhu", "Yoon-Chul Kim", "Colin Vaz", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-559", 5, "interspeech", 2016], ["Improved Depiction of Tissue Boundaries in Vocal Tract Real-Time MRI Using Automatic Off-Resonance Correction", ["Yongwan Lim", "Sajan Goud Lingala", "Asterios Toutios", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-664", 5, "interspeech", 2016], ["Illustrating the Production of the International Phonetic Alphabet Sounds Using Fast Real-Time Magnetic Resonance Imaging", ["Asterios Toutios", "Sajan Goud Lingala", "Colin Vaz", "Jangwon Kim", "John H. Esling", "Patricia A. Keating", "Matthew Gordon", "Dani Byrd", "Louis Goldstein", "Krishna S. Nayak", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-605", 5, "interspeech", 2016]], "Krishna S. Nayak": [0, ["Sensitivity of Quantitative RT-MRI Metrics of Vocal Tract Dynamics to Image Reconstruction Settings", ["Johannes Toger", "Yongwan Lim", "Sajan Goud Lingala", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-168", 5, "interspeech", 2016], ["State-of-the-Art MRI Protocol for Comprehensive Assessment of Vocal Tract Structure and Function", ["Sajan Goud Lingala", "Asterios Toutios", "Johannes Toger", "Yongwan Lim", "Yinghua Zhu", "Yoon-Chul Kim", "Colin Vaz", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-559", 5, "interspeech", 2016], ["Improved Depiction of Tissue Boundaries in Vocal Tract Real-Time MRI Using Automatic Off-Resonance Correction", ["Yongwan Lim", "Sajan Goud Lingala", "Asterios Toutios", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-664", 5, "interspeech", 2016], ["Illustrating the Production of the International Phonetic Alphabet Sounds Using Fast Real-Time Magnetic Resonance Imaging", ["Asterios Toutios", "Sajan Goud Lingala", "Colin Vaz", "Jangwon Kim", "John H. Esling", "Patricia A. Keating", "Matthew Gordon", "Dani Byrd", "Louis Goldstein", "Krishna S. Nayak", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-605", 5, "interspeech", 2016]], "Milos Cernak": [0, ["Sound Pattern Matching for Automatic Prosodic Event Detection", ["Milos Cernak", "Afsaneh Asaei", "Pierre-Edouard Honnet", "Philip N. Garner", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-875", 5, "interspeech", 2016], ["PhonVoc: A Phonetic and Phonological Vocoding Toolkit", ["Milos Cernak", "Philip N. Garner"], "https://doi.org/10.21437/Interspeech.2016-235", 5, "interspeech", 2016], ["Phonetic and Phonological Posterior Search Space Hashing Exploiting Class-Specific Sparsity Structures", ["Afsaneh Asaei", "Gil Luyet", "Milos Cernak", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-938", 5, "interspeech", 2016], ["Probabilistic Amplitude Demodulation Features in Speech Synthesis for Improving Prosody", ["Alexandros Lazaridis", "Milos Cernak", "Philip N. Garner"], "https://doi.org/10.21437/Interspeech.2016-258", 5, "interspeech", 2016], ["HMM-Based Non-Native Accent Assessment Using Posterior Features", ["Ramya Rasipuram", "Milos Cernak", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2016-750", 5, "interspeech", 2016]], "Afsaneh Asaei": [0, ["Sound Pattern Matching for Automatic Prosodic Event Detection", ["Milos Cernak", "Afsaneh Asaei", "Pierre-Edouard Honnet", "Philip N. Garner", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-875", 5, "interspeech", 2016], ["Subspace Detection of DNN Posterior Probabilities via Sparse Representation for Query by Example Spoken Term Detection", ["Dhananjay Ram", "Afsaneh Asaei", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-1278", 5, "interspeech", 2016], ["Phonetic and Phonological Posterior Search Space Hashing Exploiting Class-Specific Sparsity Structures", ["Afsaneh Asaei", "Gil Luyet", "Milos Cernak", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-938", 5, "interspeech", 2016], ["Low-Rank Representation of Nearest Neighbor Posterior Probabilities to Enhance DNN Based Acoustic Modeling", ["Gil Luyet", "Pranay Dighe", "Afsaneh Asaei", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-1279", 5, "interspeech", 2016]], "Pierre-Edouard Honnet": [0, ["Sound Pattern Matching for Automatic Prosodic Event Detection", ["Milos Cernak", "Afsaneh Asaei", "Pierre-Edouard Honnet", "Philip N. Garner", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-875", 5, "interspeech", 2016], ["The SIWIS Database: A Multilingual Speech Database with Acted Emphasis", ["Jean-Philippe Goldman", "Pierre-Edouard Honnet", "Robert A. J. Clark", "Philip N. Garner", "Maria Ivanova", "Alexandros Lazaridis", "Hui Liang", "Tiago Macedo", "Beat Pfister", "Manuel Sam Ribeiro", "Eric Wehrli", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1003", 4, "interspeech", 2016]], "Philip N. Garner": [0, ["Sound Pattern Matching for Automatic Prosodic Event Detection", ["Milos Cernak", "Afsaneh Asaei", "Pierre-Edouard Honnet", "Philip N. Garner", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-875", 5, "interspeech", 2016], ["PhonVoc: A Phonetic and Phonological Vocoding Toolkit", ["Milos Cernak", "Philip N. Garner"], "https://doi.org/10.21437/Interspeech.2016-235", 5, "interspeech", 2016], ["The SIWIS Database: A Multilingual Speech Database with Acted Emphasis", ["Jean-Philippe Goldman", "Pierre-Edouard Honnet", "Robert A. J. Clark", "Philip N. Garner", "Maria Ivanova", "Alexandros Lazaridis", "Hui Liang", "Tiago Macedo", "Beat Pfister", "Manuel Sam Ribeiro", "Eric Wehrli", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1003", 4, "interspeech", 2016], ["Probabilistic Amplitude Demodulation Features in Speech Synthesis for Improving Prosody", ["Alexandros Lazaridis", "Milos Cernak", "Philip N. Garner"], "https://doi.org/10.21437/Interspeech.2016-258", 5, "interspeech", 2016]], "Herve Bourlard": [0, ["Sound Pattern Matching for Automatic Prosodic Event Detection", ["Milos Cernak", "Afsaneh Asaei", "Pierre-Edouard Honnet", "Philip N. Garner", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-875", 5, "interspeech", 2016], ["Subspace Detection of DNN Posterior Probabilities via Sparse Representation for Query by Example Spoken Term Detection", ["Dhananjay Ram", "Afsaneh Asaei", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-1278", 5, "interspeech", 2016], ["Inter-Task System Fusion for Speaker Recognition", ["Marc Ferras", "Srikanth R. Madikeri", "Subhadeep Dey", "Petr Motlicek", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-1179", 5, "interspeech", 2016], ["Phonetic and Phonological Posterior Search Space Hashing Exploiting Class-Specific Sparsity Structures", ["Afsaneh Asaei", "Gil Luyet", "Milos Cernak", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-938", 5, "interspeech", 2016], ["Low-Rank Representation of Nearest Neighbor Posterior Probabilities to Enhance DNN Based Acoustic Modeling", ["Gil Luyet", "Pranay Dighe", "Afsaneh Asaei", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-1279", 5, "interspeech", 2016]], "Mostafa Ali Shahin": [0, ["Automatic Classification of Lexical Stress in English and Arabic Languages Using Deep Learning", ["Mostafa Ali Shahin", "Julien Epps", "Beena Ahmed"], "https://doi.org/10.21437/Interspeech.2016-644", 5, "interspeech", 2016]], "Julien Epps": [0, ["Automatic Classification of Lexical Stress in English and Arabic Languages Using Deep Learning", ["Mostafa Ali Shahin", "Julien Epps", "Beena Ahmed"], "https://doi.org/10.21437/Interspeech.2016-644", 5, "interspeech", 2016], ["An Investigation of Emotional Speech in Depression Classification", ["Brian Stasak", "Julien Epps", "Nicholas Cummins", "Roland Goecke"], "https://doi.org/10.21437/Interspeech.2016-867", 5, "interspeech", 2016], ["Cross-Cultural Depression Recognition from Vocal Biomarkers", ["Sharifa Alghowinem", "Roland Goecke", "Julien Epps", "Michael Wagner", "Jeffrey F. Cohn"], "https://doi.org/10.21437/Interspeech.2016-1339", 5, "interspeech", 2016]], "Beena Ahmed": [0, ["Automatic Classification of Lexical Stress in English and Arabic Languages Using Deep Learning", ["Mostafa Ali Shahin", "Julien Epps", "Beena Ahmed"], "https://doi.org/10.21437/Interspeech.2016-644", 5, "interspeech", 2016]], "Nan Yan": [0, ["Development of Mandarin Onset-Rime Detection in Relation to Age and Pinyin Instruction", ["Fei Chen", "Nan Yan", "Xunan Huang", "Hao Zhang", "Lan Wang", "Gang Peng"], "https://doi.org/10.21437/Interspeech.2016-895", 5, "interspeech", 2016], ["Impaired Categorical Perception of Mandarin Tones and its Relationship to Language Ability in Autism Spectrum Disorders", ["Fei Chen", "Nan Yan", "Xiaojie Pan", "Feng Yang", "Zhuanzhuan Ji", "Lan Wang", "Gang Peng"], "https://doi.org/10.21437/Interspeech.2016-1133", 5, "interspeech", 2016], ["The Influence of Language Experience on the Categorical Perception of Vowels: Evidence from Mandarin and Korean", ["Hao Zhang", "Fei Chen", "Nan Yan", "Lan Wang", "Feng Shi", "Manwa L. Ng"], "https://doi.org/10.21437/Interspeech.2016-887", 5, "interspeech", 2016], ["Deep Neural Networks for Voice Quality Assessment Based on the GRBAS Scale", ["Simin Xie", "Nan Yan", "Ping Yu", "Manwa L. Ng", "Lan Wang", "Zhuanzhuan Ji"], "https://doi.org/10.21437/Interspeech.2016-986", 5, "interspeech", 2016]], "Xunan Huang": [0, ["Development of Mandarin Onset-Rime Detection in Relation to Age and Pinyin Instruction", ["Fei Chen", "Nan Yan", "Xunan Huang", "Hao Zhang", "Lan Wang", "Gang Peng"], "https://doi.org/10.21437/Interspeech.2016-895", 5, "interspeech", 2016]], "Hao Zhang": [0, ["Development of Mandarin Onset-Rime Detection in Relation to Age and Pinyin Instruction", ["Fei Chen", "Nan Yan", "Xunan Huang", "Hao Zhang", "Lan Wang", "Gang Peng"], "https://doi.org/10.21437/Interspeech.2016-895", 5, "interspeech", 2016], ["The Influence of Language Experience on the Categorical Perception of Vowels: Evidence from Mandarin and Korean", ["Hao Zhang", "Fei Chen", "Nan Yan", "Lan Wang", "Feng Shi", "Manwa L. Ng"], "https://doi.org/10.21437/Interspeech.2016-887", 5, "interspeech", 2016]], "Lan Wang": [0.007233928190544248, ["Development of Mandarin Onset-Rime Detection in Relation to Age and Pinyin Instruction", ["Fei Chen", "Nan Yan", "Xunan Huang", "Hao Zhang", "Lan Wang", "Gang Peng"], "https://doi.org/10.21437/Interspeech.2016-895", 5, "interspeech", 2016], ["Impaired Categorical Perception of Mandarin Tones and its Relationship to Language Ability in Autism Spectrum Disorders", ["Fei Chen", "Nan Yan", "Xiaojie Pan", "Feng Yang", "Zhuanzhuan Ji", "Lan Wang", "Gang Peng"], "https://doi.org/10.21437/Interspeech.2016-1133", 5, "interspeech", 2016], ["The Influence of Language Experience on the Categorical Perception of Vowels: Evidence from Mandarin and Korean", ["Hao Zhang", "Fei Chen", "Nan Yan", "Lan Wang", "Feng Shi", "Manwa L. Ng"], "https://doi.org/10.21437/Interspeech.2016-887", 5, "interspeech", 2016], ["Deep Neural Network Based Acoustic-to-Articulatory Inversion Using Phone Sequence Information", ["Xurong Xie", "Xunying Liu", "Lan Wang"], "https://doi.org/10.21437/Interspeech.2016-659", 5, "interspeech", 2016], ["Deep Neural Networks for Voice Quality Assessment Based on the GRBAS Scale", ["Simin Xie", "Nan Yan", "Ping Yu", "Manwa L. Ng", "Lan Wang", "Zhuanzhuan Ji"], "https://doi.org/10.21437/Interspeech.2016-986", 5, "interspeech", 2016]], "Gang Peng": [0, ["Development of Mandarin Onset-Rime Detection in Relation to Age and Pinyin Instruction", ["Fei Chen", "Nan Yan", "Xunan Huang", "Hao Zhang", "Lan Wang", "Gang Peng"], "https://doi.org/10.21437/Interspeech.2016-895", 5, "interspeech", 2016], ["Impaired Categorical Perception of Mandarin Tones and its Relationship to Language Ability in Autism Spectrum Disorders", ["Fei Chen", "Nan Yan", "Xiaojie Pan", "Feng Yang", "Zhuanzhuan Ji", "Lan Wang", "Gang Peng"], "https://doi.org/10.21437/Interspeech.2016-1133", 5, "interspeech", 2016], ["Effect of Noise on Lexical Tone Perception in Cantonese-Speaking Amusics", ["Jing Shao", "Caicai Zhang", "Gang Peng", "Yike Yang", "William S.-Y. Wang"], "https://doi.org/10.21437/Interspeech.2016-891", 5, "interspeech", 2016]], "Xinyi Wen": [0, ["Joint Effect of Dialect and Mandarin on English Vowel Production: A Case Study in Changsha EFL Learners", ["Xinyi Wen", "Yuan Jia"], "https://doi.org/10.21437/Interspeech.2016-1022", 5, "interspeech", 2016]], "Yuan Jia": [0, ["Joint Effect of Dialect and Mandarin on English Vowel Production: A Case Study in Changsha EFL Learners", ["Xinyi Wen", "Yuan Jia"], "https://doi.org/10.21437/Interspeech.2016-1022", 5, "interspeech", 2016]], "Tamami Katayama": [0, ["Effects of L1 Phonotactic Constraints on L2 Word Segmentation Strategies", ["Tamami Katayama"], "https://doi.org/10.21437/Interspeech.2016-182", 5, "interspeech", 2016]], "Jane Wottawa": [0, ["Putting German [\u0283] and [\u00e7] in Two Different Boxes: Native German vs L2 German of French Learners", ["Jane Wottawa", "Martine Adda-Decker", "Frederic Isel"], "https://doi.org/10.21437/Interspeech.2016-457", 5, "interspeech", 2016]], "Martine Adda-Decker": [0, ["Putting German [\u0283] and [\u00e7] in Two Different Boxes: Native German vs L2 German of French Learners", ["Jane Wottawa", "Martine Adda-Decker", "Frederic Isel"], "https://doi.org/10.21437/Interspeech.2016-457", 5, "interspeech", 2016], ["Lig-Aikuma: A Mobile App to Collect Parallel Speech for Under-Resourced Language Studies", ["Elodie Gauthier", "David Blachon", "Laurent Besacier", "Guy-Noel Kouarata", "Martine Adda-Decker", "Annie Rialland", "Gilles Adda", "Gregoire Bachman"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2003.html", 2, "interspeech", 2016], ["Preliminary Experiments on Unsupervised Word Discovery in Mboshi", ["Pierre Godard", "Gilles Adda", "Martine Adda-Decker", "Alexandre Allauzen", "Laurent Besacier", "Helene Bonneau-Maynard", "Guy-Noel Kouarata", "Kevin Loser", "Annie Rialland", "Francois Yvon"], "https://doi.org/10.21437/Interspeech.2016-886", 5, "interspeech", 2016]], "Frederic Isel": [0, ["Putting German [\u0283] and [\u00e7] in Two Different Boxes: Native German vs L2 German of French Learners", ["Jane Wottawa", "Martine Adda-Decker", "Frederic Isel"], "https://doi.org/10.21437/Interspeech.2016-457", 5, "interspeech", 2016]], "Dean Luo": [0, ["Naturalness Judgement of L2 English Through Dubbing Practice", ["Dean Luo", "Ruxin Luo", "Lixin Wang"], "https://doi.org/10.21437/Interspeech.2016-623", 4, "interspeech", 2016]], "Ruxin Luo": [0, ["Naturalness Judgement of L2 English Through Dubbing Practice", ["Dean Luo", "Ruxin Luo", "Lixin Wang"], "https://doi.org/10.21437/Interspeech.2016-623", 4, "interspeech", 2016]], "Lixin Wang": [8.110532405680715e-07, ["Naturalness Judgement of L2 English Through Dubbing Practice", ["Dean Luo", "Ruxin Luo", "Lixin Wang"], "https://doi.org/10.21437/Interspeech.2016-623", 4, "interspeech", 2016]], "Yasuaki Shinohara": [0, ["Audiovisual Training Effects for Japanese Children Learning English /r/-/l/", ["Yasuaki Shinohara"], "https://doi.org/10.21437/Interspeech.2016-641", 4, "interspeech", 2016]], "Sarah Harper": [0, ["L2 Acquisition and Production of the English Rhotic Pharyngeal Gesture", ["Sarah Harper", "Louis Goldstein", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-658", 5, "interspeech", 2016]], "Louis Goldstein": [0, ["L2 Acquisition and Production of the English Rhotic Pharyngeal Gesture", ["Sarah Harper", "Louis Goldstein", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-658", 5, "interspeech", 2016], ["Characterizing Vocal Tract Dynamics Across Speakers Using Real-Time MRI", ["Tanner Sorensen", "Asterios Toutios", "Louis Goldstein", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-583", 5, "interspeech", 2016], ["Velum Control for Oral Sounds", ["Reed Blaylock", "Louis Goldstein", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1408", 5, "interspeech", 2016], ["Illustrating the Production of the International Phonetic Alphabet Sounds Using Fast Real-Time Magnetic Resonance Imaging", ["Asterios Toutios", "Sajan Goud Lingala", "Colin Vaz", "Jangwon Kim", "John H. Esling", "Patricia A. Keating", "Matthew Gordon", "Dani Byrd", "Louis Goldstein", "Krishna S. Nayak", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-605", 5, "interspeech", 2016], ["Perceptual Lateralization of Coda Rhotic Production in Puerto Rican Spanish", ["Mairym Llorens Monteserin", "Shrikanth S. Narayanan", "Louis Goldstein"], "https://doi.org/10.21437/Interspeech.2016-1498", 5, "interspeech", 2016], ["A New Model of Speech Motor Control Based on Task Dynamics and State Feedback", ["Vikram Ramanarayanan", "Benjamin Parrell", "Louis Goldstein", "Srikantan S. Nagarajan", "John F. Houde"], "https://doi.org/10.21437/Interspeech.2016-1499", 5, "interspeech", 2016]], "Alexandre Hennequin": [0, ["Auditory-Visual Perception of VCVs Produced by People with Down Syndrome: Preliminary Results", ["Alexandre Hennequin", "Amelie Rochet-Capellan", "Marion Dohen"], "https://doi.org/10.21437/Interspeech.2016-1198", 5, "interspeech", 2016]], "Amelie Rochet-Capellan": [0, ["Auditory-Visual Perception of VCVs Produced by People with Down Syndrome: Preliminary Results", ["Alexandre Hennequin", "Amelie Rochet-Capellan", "Marion Dohen"], "https://doi.org/10.21437/Interspeech.2016-1198", 5, "interspeech", 2016], ["Does Auditory-Motor Learning of Speech Transfer from the CV Syllable to the CVCV Word?", ["Tiphaine Caudrelier", "Pascal Perrier", "Jean-Luc Schwartz", "Amelie Rochet-Capellan"], "https://doi.org/10.21437/Interspeech.2016-262", 5, "interspeech", 2016]], "Marion Dohen": [0, ["Auditory-Visual Perception of VCVs Produced by People with Down Syndrome: Preliminary Results", ["Alexandre Hennequin", "Amelie Rochet-Capellan", "Marion Dohen"], "https://doi.org/10.21437/Interspeech.2016-1198", 5, "interspeech", 2016]], "Emre Yilmaz": [0, ["Combining Non-Pathological Data of Different Language Varieties to Improve DNN-HMM Performance on Pathological Speech", ["Emre Yilmaz", "Mario Ganzeboom", "Catia Cucchiarini", "Helmer Strik"], "https://doi.org/10.21437/Interspeech.2016-109", 5, "interspeech", 2016], ["Open Source Speech and Language Resources for Frisian", ["Emre Yilmaz", "Henk van den Heuvel", "Jelske Dijkstra", "Hans Van de Velde", "Frederik Kampstra", "Jouke Algra", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2016-48", 5, "interspeech", 2016]], "Mario Ganzeboom": [0, ["Combining Non-Pathological Data of Different Language Varieties to Improve DNN-HMM Performance on Pathological Speech", ["Emre Yilmaz", "Mario Ganzeboom", "Catia Cucchiarini", "Helmer Strik"], "https://doi.org/10.21437/Interspeech.2016-109", 5, "interspeech", 2016], ["Intelligibility of Disordered Speech: Global and Detailed Scores", ["Mario Ganzeboom", "Marjoke Bakker", "Catia Cucchiarini", "Helmer Strik"], "https://doi.org/10.21437/Interspeech.2016-1448", 5, "interspeech", 2016]], "Catia Cucchiarini": [0, ["Combining Non-Pathological Data of Different Language Varieties to Improve DNN-HMM Performance on Pathological Speech", ["Emre Yilmaz", "Mario Ganzeboom", "Catia Cucchiarini", "Helmer Strik"], "https://doi.org/10.21437/Interspeech.2016-109", 5, "interspeech", 2016], ["Intelligibility of Disordered Speech: Global and Detailed Scores", ["Mario Ganzeboom", "Marjoke Bakker", "Catia Cucchiarini", "Helmer Strik"], "https://doi.org/10.21437/Interspeech.2016-1448", 5, "interspeech", 2016]], "Helmer Strik": [0, ["Combining Non-Pathological Data of Different Language Varieties to Improve DNN-HMM Performance on Pathological Speech", ["Emre Yilmaz", "Mario Ganzeboom", "Catia Cucchiarini", "Helmer Strik"], "https://doi.org/10.21437/Interspeech.2016-109", 5, "interspeech", 2016], ["Intelligibility of Disordered Speech: Global and Detailed Scores", ["Mario Ganzeboom", "Marjoke Bakker", "Catia Cucchiarini", "Helmer Strik"], "https://doi.org/10.21437/Interspeech.2016-1448", 5, "interspeech", 2016]], "Imed Laaridh": [0, ["Evaluation of a Phone-Based Anomaly Detection Approach for Dysarthric Speech", ["Imed Laaridh", "Corinne Fredouille", "Christine Meunier"], "https://doi.org/10.21437/Interspeech.2016-1077", 5, "interspeech", 2016]], "Corinne Fredouille": [0, ["Evaluation of a Phone-Based Anomaly Detection Approach for Dysarthric Speech", ["Imed Laaridh", "Corinne Fredouille", "Christine Meunier"], "https://doi.org/10.21437/Interspeech.2016-1077", 5, "interspeech", 2016]], "Christine Meunier": [0, ["Evaluation of a Phone-Based Anomaly Detection Approach for Dysarthric Speech", ["Imed Laaridh", "Corinne Fredouille", "Christine Meunier"], "https://doi.org/10.21437/Interspeech.2016-1077", 5, "interspeech", 2016]], "Chitralekha Bhat": [0, ["Recognition of Dysarthric Speech Using Voice Parameters for Speaker Adaptation and Multi-Taper Spectral Estimation", ["Chitralekha Bhat", "Bhavik Vachhani", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2016-1085", 5, "interspeech", 2016]], "Bhavik Vachhani": [0, ["Recognition of Dysarthric Speech Using Voice Parameters for Speaker Adaptation and Multi-Taper Spectral Estimation", ["Chitralekha Bhat", "Bhavik Vachhani", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2016-1085", 5, "interspeech", 2016]], "Sunil Kumar Kopparapu": [0, ["Recognition of Dysarthric Speech Using Voice Parameters for Speaker Adaptation and Multi-Taper Spectral Estimation", ["Chitralekha Bhat", "Bhavik Vachhani", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2016-1085", 5, "interspeech", 2016]], "Xiaojie Pan": [0, ["Impaired Categorical Perception of Mandarin Tones and its Relationship to Language Ability in Autism Spectrum Disorders", ["Fei Chen", "Nan Yan", "Xiaojie Pan", "Feng Yang", "Zhuanzhuan Ji", "Lan Wang", "Gang Peng"], "https://doi.org/10.21437/Interspeech.2016-1133", 5, "interspeech", 2016]], "Zhuanzhuan Ji": [2.951430780208992e-18, ["Impaired Categorical Perception of Mandarin Tones and its Relationship to Language Ability in Autism Spectrum Disorders", ["Fei Chen", "Nan Yan", "Xiaojie Pan", "Feng Yang", "Zhuanzhuan Ji", "Lan Wang", "Gang Peng"], "https://doi.org/10.21437/Interspeech.2016-1133", 5, "interspeech", 2016], ["Deep Neural Networks for Voice Quality Assessment Based on the GRBAS Scale", ["Simin Xie", "Nan Yan", "Ping Yu", "Manwa L. Ng", "Lan Wang", "Zhuanzhuan Ji"], "https://doi.org/10.21437/Interspeech.2016-986", 5, "interspeech", 2016]], "Kathleen F. Nagle": [0, ["Perceived Naturalness of Electrolaryngeal Speech Produced Using sEMG-Controlled vs. Manual Pitch Modulation", ["Kathleen F. Nagle", "James T. Heaton"], "https://doi.org/10.21437/Interspeech.2016-1476", 5, "interspeech", 2016]], "James T. Heaton": [0, ["Perceived Naturalness of Electrolaryngeal Speech Produced Using sEMG-Controlled vs. Manual Pitch Modulation", ["Kathleen F. Nagle", "James T. Heaton"], "https://doi.org/10.21437/Interspeech.2016-1476", 5, "interspeech", 2016]], "Shamima Najnin": [0, ["Identifying Hearing Loss from Learned Speech Kernels", ["Shamima Najnin", "Bonny Banerjee", "Lisa Lucks Mendel", "Masoumeh Heidari Kapourchali", "Jayanta Kumar Dutta", "Sungmin Lee", "Chhayakanta Patro", "Monique Pousson"], "https://doi.org/10.21437/Interspeech.2016-1488", 5, "interspeech", 2016], ["Emergence of Vocal Developmental Sequences in a Predictive Coding Model of Speech Acquisition", ["Shamima Najnin", "Bonny Banerjee"], "https://doi.org/10.21437/Interspeech.2016-1126", 5, "interspeech", 2016]], "Bonny Banerjee": [0, ["Identifying Hearing Loss from Learned Speech Kernels", ["Shamima Najnin", "Bonny Banerjee", "Lisa Lucks Mendel", "Masoumeh Heidari Kapourchali", "Jayanta Kumar Dutta", "Sungmin Lee", "Chhayakanta Patro", "Monique Pousson"], "https://doi.org/10.21437/Interspeech.2016-1488", 5, "interspeech", 2016], ["Emergence of Vocal Developmental Sequences in a Predictive Coding Model of Speech Acquisition", ["Shamima Najnin", "Bonny Banerjee"], "https://doi.org/10.21437/Interspeech.2016-1126", 5, "interspeech", 2016]], "Lisa Lucks Mendel": [0, ["Identifying Hearing Loss from Learned Speech Kernels", ["Shamima Najnin", "Bonny Banerjee", "Lisa Lucks Mendel", "Masoumeh Heidari Kapourchali", "Jayanta Kumar Dutta", "Sungmin Lee", "Chhayakanta Patro", "Monique Pousson"], "https://doi.org/10.21437/Interspeech.2016-1488", 5, "interspeech", 2016]], "Masoumeh Heidari Kapourchali": [0, ["Identifying Hearing Loss from Learned Speech Kernels", ["Shamima Najnin", "Bonny Banerjee", "Lisa Lucks Mendel", "Masoumeh Heidari Kapourchali", "Jayanta Kumar Dutta", "Sungmin Lee", "Chhayakanta Patro", "Monique Pousson"], "https://doi.org/10.21437/Interspeech.2016-1488", 5, "interspeech", 2016]], "Jayanta Kumar Dutta": [0, ["Identifying Hearing Loss from Learned Speech Kernels", ["Shamima Najnin", "Bonny Banerjee", "Lisa Lucks Mendel", "Masoumeh Heidari Kapourchali", "Jayanta Kumar Dutta", "Sungmin Lee", "Chhayakanta Patro", "Monique Pousson"], "https://doi.org/10.21437/Interspeech.2016-1488", 5, "interspeech", 2016]], "Sungmin Lee": [0.6420749425888062, ["Identifying Hearing Loss from Learned Speech Kernels", ["Shamima Najnin", "Bonny Banerjee", "Lisa Lucks Mendel", "Masoumeh Heidari Kapourchali", "Jayanta Kumar Dutta", "Sungmin Lee", "Chhayakanta Patro", "Monique Pousson"], "https://doi.org/10.21437/Interspeech.2016-1488", 5, "interspeech", 2016]], "Chhayakanta Patro": [0, ["Identifying Hearing Loss from Learned Speech Kernels", ["Shamima Najnin", "Bonny Banerjee", "Lisa Lucks Mendel", "Masoumeh Heidari Kapourchali", "Jayanta Kumar Dutta", "Sungmin Lee", "Chhayakanta Patro", "Monique Pousson"], "https://doi.org/10.21437/Interspeech.2016-1488", 5, "interspeech", 2016]], "Monique Pousson": [0, ["Identifying Hearing Loss from Learned Speech Kernels", ["Shamima Najnin", "Bonny Banerjee", "Lisa Lucks Mendel", "Masoumeh Heidari Kapourchali", "Jayanta Kumar Dutta", "Sungmin Lee", "Chhayakanta Patro", "Monique Pousson"], "https://doi.org/10.21437/Interspeech.2016-1488", 5, "interspeech", 2016]], "Panying Rong": [0, ["Differential Effects of Velopharyngeal Dysfunction on Speech Intelligibility During Early and Late Stages of Amyotrophic Lateral Sclerosis", ["Panying Rong", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2016-1524", 5, "interspeech", 2016]], "Yana Yunusova": [0, ["Differential Effects of Velopharyngeal Dysfunction on Speech Intelligibility During Early and Late Stages of Amyotrophic Lateral Sclerosis", ["Panying Rong", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2016-1524", 5, "interspeech", 2016], ["Relation of Automatically Extracted Formant Trajectories with Intelligibility Loss and Speaking Rate Decline in Amyotrophic Lateral Sclerosis", ["Rachelle L. Horwitz-Martin", "Thomas F. Quatieri", "Adam C. Lammert", "James R. Williamson", "Yana Yunusova", "Elizabeth Godoy", "Daryush D. Mehta", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2016-403", 5, "interspeech", 2016]], "Veronique Delvaux": [0, ["The Production of Intervocalic Glides in Non Dysarthric Parkinsonian Speech", ["Veronique Delvaux", "V. Roland", "Kathy Huet", "Myriam Piccaluga", "M. C. Haelewyck", "Bernard Harmegnies"], "https://doi.org/10.21437/Interspeech.2016-349", 4, "interspeech", 2016]], "V. Roland": [0, ["The Production of Intervocalic Glides in Non Dysarthric Parkinsonian Speech", ["Veronique Delvaux", "V. Roland", "Kathy Huet", "Myriam Piccaluga", "M. C. Haelewyck", "Bernard Harmegnies"], "https://doi.org/10.21437/Interspeech.2016-349", 4, "interspeech", 2016]], "Kathy Huet": [0, ["The Production of Intervocalic Glides in Non Dysarthric Parkinsonian Speech", ["Veronique Delvaux", "V. Roland", "Kathy Huet", "Myriam Piccaluga", "M. C. Haelewyck", "Bernard Harmegnies"], "https://doi.org/10.21437/Interspeech.2016-349", 4, "interspeech", 2016]], "Myriam Piccaluga": [0, ["The Production of Intervocalic Glides in Non Dysarthric Parkinsonian Speech", ["Veronique Delvaux", "V. Roland", "Kathy Huet", "Myriam Piccaluga", "M. C. Haelewyck", "Bernard Harmegnies"], "https://doi.org/10.21437/Interspeech.2016-349", 4, "interspeech", 2016]], "M. C. Haelewyck": [0, ["The Production of Intervocalic Glides in Non Dysarthric Parkinsonian Speech", ["Veronique Delvaux", "V. Roland", "Kathy Huet", "Myriam Piccaluga", "M. C. Haelewyck", "Bernard Harmegnies"], "https://doi.org/10.21437/Interspeech.2016-349", 4, "interspeech", 2016]], "Bernard Harmegnies": [0, ["The Production of Intervocalic Glides in Non Dysarthric Parkinsonian Speech", ["Veronique Delvaux", "V. Roland", "Kathy Huet", "Myriam Piccaluga", "M. C. Haelewyck", "Bernard Harmegnies"], "https://doi.org/10.21437/Interspeech.2016-349", 4, "interspeech", 2016]], "Yang Feng": [0, ["Auditory Processing Impairments Under Background Noise in Children with Non-Syndromic Cleft Lip and/or Palate", ["Yang Feng", "Zhang Lu"], "https://doi.org/10.21437/Interspeech.2016-38", 5, "interspeech", 2016]], "Zhang Lu": [0, ["Auditory Processing Impairments Under Background Noise in Children with Non-Syndromic Cleft Lip and/or Palate", ["Yang Feng", "Zhang Lu"], "https://doi.org/10.21437/Interspeech.2016-38", 5, "interspeech", 2016]], "Zhi Zhu": [0, ["Modulation Spectral Features for Predicting Vocal Emotion Recognition by Simulated Cochlear Implants", ["Zhi Zhu", "Ryota Miyauchi", "Yukiko Araki", "Masashi Unoki"], "https://doi.org/10.21437/Interspeech.2016-737", 5, "interspeech", 2016]], "Ryota Miyauchi": [0, ["Modulation Spectral Features for Predicting Vocal Emotion Recognition by Simulated Cochlear Implants", ["Zhi Zhu", "Ryota Miyauchi", "Yukiko Araki", "Masashi Unoki"], "https://doi.org/10.21437/Interspeech.2016-737", 5, "interspeech", 2016]], "Yukiko Araki": [0, ["Modulation Spectral Features for Predicting Vocal Emotion Recognition by Simulated Cochlear Implants", ["Zhi Zhu", "Ryota Miyauchi", "Yukiko Araki", "Masashi Unoki"], "https://doi.org/10.21437/Interspeech.2016-737", 5, "interspeech", 2016]], "Masashi Unoki": [0, ["Modulation Spectral Features for Predicting Vocal Emotion Recognition by Simulated Cochlear Implants", ["Zhi Zhu", "Ryota Miyauchi", "Yukiko Araki", "Masashi Unoki"], "https://doi.org/10.21437/Interspeech.2016-737", 5, "interspeech", 2016]], "Keiko Ochi": [0, ["Automatic Discrimination of Soft Voice Onset Using Acoustic Features of Breathy Voicing", ["Keiko Ochi", "Koichi Mori", "Naomi Sakai", "Nobutaka Ono"], "https://doi.org/10.21437/Interspeech.2016-765", 5, "interspeech", 2016], ["Multi-Talker Speech Recognition Based on Blind Source Separation with ad hoc Microphone Array Using Smartphones and Cloud Storage", ["Keiko Ochi", "Nobutaka Ono", "Shigeki Miyabe", "Shoji Makino"], "https://doi.org/10.21437/Interspeech.2016-758", 5, "interspeech", 2016]], "Koichi Mori": [0, ["Automatic Discrimination of Soft Voice Onset Using Acoustic Features of Breathy Voicing", ["Keiko Ochi", "Koichi Mori", "Naomi Sakai", "Nobutaka Ono"], "https://doi.org/10.21437/Interspeech.2016-765", 5, "interspeech", 2016]], "Naomi Sakai": [0, ["Automatic Discrimination of Soft Voice Onset Using Acoustic Features of Breathy Voicing", ["Keiko Ochi", "Koichi Mori", "Naomi Sakai", "Nobutaka Ono"], "https://doi.org/10.21437/Interspeech.2016-765", 5, "interspeech", 2016]], "Nobutaka Ono": [0, ["Automatic Discrimination of Soft Voice Onset Using Acoustic Features of Breathy Voicing", ["Keiko Ochi", "Koichi Mori", "Naomi Sakai", "Nobutaka Ono"], "https://doi.org/10.21437/Interspeech.2016-765", 5, "interspeech", 2016], ["Multi-Talker Speech Recognition Based on Blind Source Separation with ad hoc Microphone Array Using Smartphones and Cloud Storage", ["Keiko Ochi", "Nobutaka Ono", "Shigeki Miyabe", "Shoji Makino"], "https://doi.org/10.21437/Interspeech.2016-758", 5, "interspeech", 2016]], "Jing Shao": [0, ["Effect of Noise on Lexical Tone Perception in Cantonese-Speaking Amusics", ["Jing Shao", "Caicai Zhang", "Gang Peng", "Yike Yang", "William S.-Y. Wang"], "https://doi.org/10.21437/Interspeech.2016-891", 5, "interspeech", 2016]], "Caicai Zhang": [0, ["Effect of Noise on Lexical Tone Perception in Cantonese-Speaking Amusics", ["Jing Shao", "Caicai Zhang", "Gang Peng", "Yike Yang", "William S.-Y. Wang"], "https://doi.org/10.21437/Interspeech.2016-891", 5, "interspeech", 2016]], "Yike Yang": [0.00010171237590839155, ["Effect of Noise on Lexical Tone Perception in Cantonese-Speaking Amusics", ["Jing Shao", "Caicai Zhang", "Gang Peng", "Yike Yang", "William S.-Y. Wang"], "https://doi.org/10.21437/Interspeech.2016-891", 5, "interspeech", 2016]], "William S.-Y. Wang": [4.4470897326965675e-15, ["Effect of Noise on Lexical Tone Perception in Cantonese-Speaking Amusics", ["Jing Shao", "Caicai Zhang", "Gang Peng", "Yike Yang", "William S.-Y. Wang"], "https://doi.org/10.21437/Interspeech.2016-891", 5, "interspeech", 2016]], "Yuki Takashima": [0, ["Audio-Visual Speech Recognition Using Bimodal-Trained Bottleneck Features for a Person with Severe Hearing Loss", ["Yuki Takashima", "Ryo Aihara", "Tetsuya Takiguchi", "Yasuo Ariki", "Nobuyuki Mitani", "Kiyohiro Omori", "Kaoru Nakazono"], "https://doi.org/10.21437/Interspeech.2016-721", 5, "interspeech", 2016]], "Ryo Aihara": [0, ["Audio-Visual Speech Recognition Using Bimodal-Trained Bottleneck Features for a Person with Severe Hearing Loss", ["Yuki Takashima", "Ryo Aihara", "Tetsuya Takiguchi", "Yasuo Ariki", "Nobuyuki Mitani", "Kiyohiro Omori", "Kaoru Nakazono"], "https://doi.org/10.21437/Interspeech.2016-721", 5, "interspeech", 2016], ["Parallel Dictionary Learning for Voice Conversion Using Discriminative Graph-Embedded Non-Negative Matrix Factorization", ["Ryo Aihara", "Tetsuya Takiguchi", "Yasuo Ariki"], "https://doi.org/10.21437/Interspeech.2016-227", 5, "interspeech", 2016]], "Tetsuya Takiguchi": [0, ["Audio-Visual Speech Recognition Using Bimodal-Trained Bottleneck Features for a Person with Severe Hearing Loss", ["Yuki Takashima", "Ryo Aihara", "Tetsuya Takiguchi", "Yasuo Ariki", "Nobuyuki Mitani", "Kiyohiro Omori", "Kaoru Nakazono"], "https://doi.org/10.21437/Interspeech.2016-721", 5, "interspeech", 2016], ["Parallel Dictionary Learning for Voice Conversion Using Discriminative Graph-Embedded Non-Negative Matrix Factorization", ["Ryo Aihara", "Tetsuya Takiguchi", "Yasuo Ariki"], "https://doi.org/10.21437/Interspeech.2016-227", 5, "interspeech", 2016]], "Yasuo Ariki": [0, ["Audio-Visual Speech Recognition Using Bimodal-Trained Bottleneck Features for a Person with Severe Hearing Loss", ["Yuki Takashima", "Ryo Aihara", "Tetsuya Takiguchi", "Yasuo Ariki", "Nobuyuki Mitani", "Kiyohiro Omori", "Kaoru Nakazono"], "https://doi.org/10.21437/Interspeech.2016-721", 5, "interspeech", 2016], ["Parallel Dictionary Learning for Voice Conversion Using Discriminative Graph-Embedded Non-Negative Matrix Factorization", ["Ryo Aihara", "Tetsuya Takiguchi", "Yasuo Ariki"], "https://doi.org/10.21437/Interspeech.2016-227", 5, "interspeech", 2016]], "Nobuyuki Mitani": [0, ["Audio-Visual Speech Recognition Using Bimodal-Trained Bottleneck Features for a Person with Severe Hearing Loss", ["Yuki Takashima", "Ryo Aihara", "Tetsuya Takiguchi", "Yasuo Ariki", "Nobuyuki Mitani", "Kiyohiro Omori", "Kaoru Nakazono"], "https://doi.org/10.21437/Interspeech.2016-721", 5, "interspeech", 2016]], "Kiyohiro Omori": [0, ["Audio-Visual Speech Recognition Using Bimodal-Trained Bottleneck Features for a Person with Severe Hearing Loss", ["Yuki Takashima", "Ryo Aihara", "Tetsuya Takiguchi", "Yasuo Ariki", "Nobuyuki Mitani", "Kiyohiro Omori", "Kaoru Nakazono"], "https://doi.org/10.21437/Interspeech.2016-721", 5, "interspeech", 2016]], "Kaoru Nakazono": [0, ["Audio-Visual Speech Recognition Using Bimodal-Trained Bottleneck Features for a Person with Severe Hearing Loss", ["Yuki Takashima", "Ryo Aihara", "Tetsuya Takiguchi", "Yasuo Ariki", "Nobuyuki Mitani", "Kiyohiro Omori", "Kaoru Nakazono"], "https://doi.org/10.21437/Interspeech.2016-721", 5, "interspeech", 2016]], "Yuling Gu": [0.0008847196586430073, ["Perception of Tone in Whispered Mandarin Sentences: The Case for Singapore Mandarin", ["Yuling Gu", "Boon Pang Lim", "Nancy F. Chen"], "https://doi.org/10.21437/Interspeech.2016-297", 5, "interspeech", 2016]], "Boon Pang Lim": [0.9906302392482758, ["Perception of Tone in Whispered Mandarin Sentences: The Case for Singapore Mandarin", ["Yuling Gu", "Boon Pang Lim", "Nancy F. Chen"], "https://doi.org/10.21437/Interspeech.2016-297", 5, "interspeech", 2016], ["Transfer Learning with Bottleneck Feature Networks for Whispered Speech Recognition", ["Boon Pang Lim", "Faith Wong", "Yuyao Li", "Jia Wei Bay"], "https://doi.org/10.21437/Interspeech.2016-250", 5, "interspeech", 2016], ["Analysis of Mismatched Transcriptions Generated by Humans and Machines for Under-Resourced Languages", ["Van Hai Do", "Nancy F. Chen", "Boon Pang Lim", "Mark Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2016-736", 5, "interspeech", 2016]], "Nancy F. Chen": [0, ["Perception of Tone in Whispered Mandarin Sentences: The Case for Singapore Mandarin", ["Yuling Gu", "Boon Pang Lim", "Nancy F. Chen"], "https://doi.org/10.21437/Interspeech.2016-297", 5, "interspeech", 2016], ["Rescoring Hypothesized Detections of Out-of-Vocabulary Keywords Using Subword Samples", ["Van Tung Pham", "Haihua Xu", "Xiong Xiao", "Nancy F. Chen", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-646", 5, "interspeech", 2016], ["SingaKids-Mandarin: Speech Corpus of Singaporean Children Speaking Mandarin Chinese", ["Nancy F. Chen", "Rong Tong", "Darren Wee", "Pei Xuan Lee", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-139", 5, "interspeech", 2016], ["Context Aware Mispronunciation Detection for Mandarin Pronunciation Training", ["Rong Tong", "Nancy F. Chen", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-289", 5, "interspeech", 2016], ["Detecting Mispronunciations of L2 Learners and Providing Corrective Feedback Using Knowledge-Guided and Data-Driven Decision Trees", ["Wei Li", "Kehuang Li", "Sabato Marco Siniscalchi", "Nancy F. Chen", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2016-517", 5, "interspeech", 2016], ["Analysis of Mismatched Transcriptions Generated by Humans and Machines for Under-Resourced Languages", ["Van Hai Do", "Nancy F. Chen", "Boon Pang Lim", "Mark Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2016-736", 5, "interspeech", 2016]], "Feng-Long Xie": [0, ["A KL Divergence and DNN-Based Approach to Voice Conversion without Parallel Training Sentences", ["Feng-Long Xie", "Frank K. Soong", "Haifeng Li"], "https://doi.org/10.21437/Interspeech.2016-116", 5, "interspeech", 2016]], "Frank K. Soong": [0, ["A KL Divergence and DNN-Based Approach to Voice Conversion without Parallel Training Sentences", ["Feng-Long Xie", "Frank K. Soong", "Haifeng Li"], "https://doi.org/10.21437/Interspeech.2016-116", 5, "interspeech", 2016], ["Improved Time-Frequency Trajectory Excitation Vocoder for DNN-Based Speech Synthesis", ["Eunwoo Song", "Frank K. Soong", "Hong-Goo Kang"], "https://doi.org/10.21437/Interspeech.2016-230", 5, "interspeech", 2016]], "Haifeng Li": [0, ["A KL Divergence and DNN-Based Approach to Voice Conversion without Parallel Training Sentences", ["Feng-Long Xie", "Frank K. Soong", "Haifeng Li"], "https://doi.org/10.21437/Interspeech.2016-116", 5, "interspeech", 2016]], "Yu Gu": [0.002284143352881074, ["Speech Bandwidth Extension Using Bottleneck Features and Deep Recurrent Neural Networks", ["Yu Gu", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-678", 5, "interspeech", 2016]], "Zhen-Hua Ling": [0, ["Speech Bandwidth Extension Using Bottleneck Features and Deep Recurrent Neural Networks", ["Yu Gu", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-678", 5, "interspeech", 2016], ["Articulatory-to-Acoustic Conversion with Cascaded Prediction of Spectral and Excitation Features Using Neural Networks", ["Zheng-Chen Liu", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-715", 5, "interspeech", 2016], ["The USTC System for Voice Conversion Challenge 2016: Neural Network Based Approaches for Spectrum, Aperiodicity and F0 Conversion", ["Ling-Hui Chen", "Li-Juan Liu", "Zhen-Hua Ling", "Yuan Jiang", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-456", 5, "interspeech", 2016]], "Li-Rong Dai": [0, ["Speech Bandwidth Extension Using Bottleneck Features and Deep Recurrent Neural Networks", ["Yu Gu", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-678", 5, "interspeech", 2016], ["Articulatory-to-Acoustic Conversion with Cascaded Prediction of Spectral and Excitation Features Using Neural Networks", ["Zheng-Chen Liu", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-715", 5, "interspeech", 2016], ["The USTC System for Voice Conversion Challenge 2016: Neural Network Based Approaches for Spectrum, Aperiodicity and F0 Conversion", ["Ling-Hui Chen", "Li-Juan Liu", "Zhen-Hua Ling", "Yuan Jiang", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-456", 5, "interspeech", 2016], ["RNN-BLSTM Based Multi-Pitch Estimation", ["Jianshu Zhang", "Jian Tang", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-117", 5, "interspeech", 2016], ["Compact Feedforward Sequential Memory Networks for Large Vocabulary Continuous Speech Recognition", ["Shiliang Zhang", "Hui Jiang", "Shifu Xiong", "Si Wei", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-121", 5, "interspeech", 2016], ["Future Context Attention for Unidirectional LSTM Based Acoustic Model", ["Jian Tang", "Shiliang Zhang", "Si Wei", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-185", 5, "interspeech", 2016], ["SNR-Based Progressive Learning of Deep Neural Network for Speech Enhancement", ["Tian Gao", "Jun Du", "Li-Rong Dai", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2016-224", 5, "interspeech", 2016]], "Yi Yang": [0.00034603855601744726, ["Voice Conversion Based on Matrix Variate Gaussian Mixture Model Using Multiple Frame Features", ["Yi Yang", "Hidetsugu Uchida", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2016-705", 5, "interspeech", 2016]], "Hidetsugu Uchida": [0, ["Voice Conversion Based on Matrix Variate Gaussian Mixture Model Using Multiple Frame Features", ["Yi Yang", "Hidetsugu Uchida", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2016-705", 5, "interspeech", 2016], ["Prediction of the Articulatory Movements of Unseen Phonemes of a Speaker Using the Speech Structure of Another Speaker", ["Hidetsugu Uchida", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2016-1138", 5, "interspeech", 2016]], "Daisuke Saito": [0, ["Voice Conversion Based on Matrix Variate Gaussian Mixture Model Using Multiple Frame Features", ["Yi Yang", "Hidetsugu Uchida", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2016-705", 5, "interspeech", 2016], ["Prediction of the Articulatory Movements of Unseen Phonemes of a Speaker Using the Speech Structure of Another Speaker", ["Hidetsugu Uchida", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2016-1138", 5, "interspeech", 2016], ["The Voice Conversion Challenge 2016", ["Tomoki Toda", "Ling-Hui Chen", "Daisuke Saito", "Fernando Villavicencio", "Mirjam Wester", "Zhizheng Wu", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1066", 5, "interspeech", 2016], ["Speaker Representations for Speaker Adaptation in Multiple Speakers' BLSTM-RNN-Based Speech Synthesis", ["Yi Zhao", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2016-506", 5, "interspeech", 2016], ["Automatic Assessment and Error Detection of Shadowing Speech: Case of English Spoken by Japanese Learners", ["Shuju Shi", "Yosuke Kashiwagi", "Shohei Toyama", "Junwei Yue", "Yutaka Yamauchi", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2016-915", 5, "interspeech", 2016]], "Nobuaki Minematsu": [0, ["Voice Conversion Based on Matrix Variate Gaussian Mixture Model Using Multiple Frame Features", ["Yi Yang", "Hidetsugu Uchida", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2016-705", 5, "interspeech", 2016], ["Prediction of the Articulatory Movements of Unseen Phonemes of a Speaker Using the Speech Structure of Another Speaker", ["Hidetsugu Uchida", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2016-1138", 5, "interspeech", 2016], ["Speaker Representations for Speaker Adaptation in Multiple Speakers' BLSTM-RNN-Based Speech Synthesis", ["Yi Zhao", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2016-506", 5, "interspeech", 2016], ["Automatic Assessment and Error Detection of Shadowing Speech: Case of English Spoken by Japanese Learners", ["Shuju Shi", "Yosuke Kashiwagi", "Shohei Toyama", "Junwei Yue", "Yutaka Yamauchi", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2016-915", 5, "interspeech", 2016]], "Naoki Hosaka": [0, ["Voice Conversion Based on Trajectory Model Training of Neural Networks Considering Global Variance", ["Naoki Hosaka", "Kei Hashimoto", "Keiichiro Oura", "Yoshihiko Nankaku", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-1035", 5, "interspeech", 2016]], "Kei Hashimoto": [0, ["Voice Conversion Based on Trajectory Model Training of Neural Networks Considering Global Variance", ["Naoki Hosaka", "Kei Hashimoto", "Keiichiro Oura", "Yoshihiko Nankaku", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-1035", 5, "interspeech", 2016], ["Singing Voice Synthesis Based on Deep Neural Networks", ["Masanari Nishimura", "Kei Hashimoto", "Keiichiro Oura", "Yoshihiko Nankaku", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-1027", 5, "interspeech", 2016], ["Redefining the Linguistic Context Feature Set for HMM and DNN TTS Through Position and Parsing", ["Rasmus Dall", "Kei Hashimoto", "Keiichiro Oura", "Yoshihiko Nankaku", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-399", 5, "interspeech", 2016]], "Keiichiro Oura": [0, ["Voice Conversion Based on Trajectory Model Training of Neural Networks Considering Global Variance", ["Naoki Hosaka", "Kei Hashimoto", "Keiichiro Oura", "Yoshihiko Nankaku", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-1035", 5, "interspeech", 2016], ["Singing Voice Synthesis Based on Deep Neural Networks", ["Masanari Nishimura", "Kei Hashimoto", "Keiichiro Oura", "Yoshihiko Nankaku", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-1027", 5, "interspeech", 2016], ["Redefining the Linguistic Context Feature Set for HMM and DNN TTS Through Position and Parsing", ["Rasmus Dall", "Kei Hashimoto", "Keiichiro Oura", "Yoshihiko Nankaku", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-399", 5, "interspeech", 2016]], "Yoshihiko Nankaku": [0, ["Voice Conversion Based on Trajectory Model Training of Neural Networks Considering Global Variance", ["Naoki Hosaka", "Kei Hashimoto", "Keiichiro Oura", "Yoshihiko Nankaku", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-1035", 5, "interspeech", 2016], ["Singing Voice Synthesis Based on Deep Neural Networks", ["Masanari Nishimura", "Kei Hashimoto", "Keiichiro Oura", "Yoshihiko Nankaku", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-1027", 5, "interspeech", 2016], ["Redefining the Linguistic Context Feature Set for HMM and DNN TTS Through Position and Parsing", ["Rasmus Dall", "Kei Hashimoto", "Keiichiro Oura", "Yoshihiko Nankaku", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-399", 5, "interspeech", 2016]], "Keiichi Tokuda": [0, ["Voice Conversion Based on Trajectory Model Training of Neural Networks Considering Global Variance", ["Naoki Hosaka", "Kei Hashimoto", "Keiichiro Oura", "Yoshihiko Nankaku", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-1035", 5, "interspeech", 2016], ["A Hierarchical Predictor of Synthetic Speech Naturalness Using Neural Networks", ["Takenori Yoshimura", "Gustav Eje Henter", "Oliver Watts", "Mirjam Wester", "Junichi Yamagishi", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-847", 5, "interspeech", 2016], ["Singing Voice Synthesis Based on Deep Neural Networks", ["Masanari Nishimura", "Kei Hashimoto", "Keiichiro Oura", "Yoshihiko Nankaku", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-1027", 5, "interspeech", 2016], ["Redefining the Linguistic Context Feature Set for HMM and DNN TTS Through Position and Parsing", ["Rasmus Dall", "Kei Hashimoto", "Keiichiro Oura", "Yoshihiko Nankaku", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-399", 5, "interspeech", 2016]], "Sandesh Aryal": [0, ["Comparing Articulatory and Acoustic Strategies for Reducing Non-Native Accents", ["Sandesh Aryal", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2016-1131", 5, "interspeech", 2016]], "Ricardo Gutierrez-Osuna": [0, ["Comparing Articulatory and Acoustic Strategies for Reducing Non-Native Accents", ["Sandesh Aryal", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2016-1131", 5, "interspeech", 2016], ["Generating Gestural Scores from Acoustics Through a Sparse Anchor-Based Representation of Speech", ["Christopher Liberatore", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2016-1336", 5, "interspeech", 2016]], "Seyyed Saeed Sarfjoo": [0, ["Cross-Lingual Speaker Adaptation for Statistical Speech Synthesis Using Limited Data", ["Seyyed Saeed Sarfjoo", "Cenk Demiroglu"], "https://doi.org/10.21437/Interspeech.2016-345", 5, "interspeech", 2016]], "Cenk Demiroglu": [0, ["Cross-Lingual Speaker Adaptation for Statistical Speech Synthesis Using Limited Data", ["Seyyed Saeed Sarfjoo", "Cenk Demiroglu"], "https://doi.org/10.21437/Interspeech.2016-345", 5, "interspeech", 2016]], "Lifa Sun": [0.00882017333060503, ["Personalized, Cross-Lingual TTS Using Phonetic Posteriorgrams", ["Lifa Sun", "Hao Wang", "Shiyin Kang", "Kun Li", "Helen M. Meng"], "https://doi.org/10.21437/Interspeech.2016-1043", 5, "interspeech", 2016]], "Hao Wang": [0.05930126644670963, ["Personalized, Cross-Lingual TTS Using Phonetic Posteriorgrams", ["Lifa Sun", "Hao Wang", "Shiyin Kang", "Kun Li", "Helen M. Meng"], "https://doi.org/10.21437/Interspeech.2016-1043", 5, "interspeech", 2016]], "Shiyin Kang": [1.3562754759277595e-06, ["Personalized, Cross-Lingual TTS Using Phonetic Posteriorgrams", ["Lifa Sun", "Hao Wang", "Shiyin Kang", "Kun Li", "Helen M. Meng"], "https://doi.org/10.21437/Interspeech.2016-1043", 5, "interspeech", 2016]], "Kun Li": [0, ["Personalized, Cross-Lingual TTS Using Phonetic Posteriorgrams", ["Lifa Sun", "Hao Wang", "Shiyin Kang", "Kun Li", "Helen M. Meng"], "https://doi.org/10.21437/Interspeech.2016-1043", 5, "interspeech", 2016]], "Helen M. Meng": [0, ["Personalized, Cross-Lingual TTS Using Phonetic Posteriorgrams", ["Lifa Sun", "Hao Wang", "Shiyin Kang", "Kun Li", "Helen M. Meng"], "https://doi.org/10.21437/Interspeech.2016-1043", 5, "interspeech", 2016], ["Analysis on Gated Recurrent Unit Based Question Detection Approach", ["Yaodong Tang", "Zhiyong Wu", "Helen M. Meng", "Mingxing Xu", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-964", 5, "interspeech", 2016], ["Combining CNN and BLSTM to Extract Textual and Acoustic Features for Recognizing Stances in Mandarin Ideological Debate Competition", ["Linchuan Li", "Zhiyong Wu", "Mingxing Xu", "Helen M. Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-324", 5, "interspeech", 2016], ["Phoneme Embedding and its Application to Speech Driven Talking Avatar Synthesis", ["Xu Li", "Zhiyong Wu", "Helen M. Meng", "Jia Jia", "Xiaoyan Lou", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-363", 5, "interspeech", 2016], ["Expressive Speech Driven Talking Avatar Synthesis with DBLSTM Using Limited Amount of Emotional Bimodal Data", ["Xu Li", "Zhiyong Wu", "Helen M. Meng", "Jia Jia", "Xiaoyan Lou", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-364", 5, "interspeech", 2016]], "Anusha Prakash": [0, ["Acoustic Analysis of Syllables Across Indian Languages", ["Anusha Prakash", "Jeena J. Prakash", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2016-1127", 5, "interspeech", 2016]], "Jeena J. Prakash": [0, ["Acoustic Analysis of Syllables Across Indian Languages", ["Anusha Prakash", "Jeena J. Prakash", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2016-1127", 5, "interspeech", 2016]], "Hema A. Murthy": [0, ["Acoustic Analysis of Syllables Across Indian Languages", ["Anusha Prakash", "Jeena J. Prakash", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2016-1127", 5, "interspeech", 2016], ["Two-Pass IB Based Speaker Diarization System Using Meeting-Specific ANN Based Features", ["Nauman Dawalatabad", "Srikanth R. Madikeri", "C. Chandra Sekhar", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2016-714", 5, "interspeech", 2016]], "Teng Zhang": [0, ["Objective Evaluation Methods for Chinese Text-To-Speech Systems", ["Teng Zhang", "Zhipeng Chen", "Ji Wu", "Sam Lai", "Wenhui Lei", "Carsten Isert"], "https://doi.org/10.21437/Interspeech.2016-421", 5, "interspeech", 2016]], "Zhipeng Chen": [0, ["Objective Evaluation Methods for Chinese Text-To-Speech Systems", ["Teng Zhang", "Zhipeng Chen", "Ji Wu", "Sam Lai", "Wenhui Lei", "Carsten Isert"], "https://doi.org/10.21437/Interspeech.2016-421", 5, "interspeech", 2016], ["Improving the Probabilistic Framework for Representing Dialogue Systems with User Response Model", ["Miao Li", "Zhipeng Chen", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2016-810", 5, "interspeech", 2016]], "Ji Wu": [0.005666725337505341, ["Objective Evaluation Methods for Chinese Text-To-Speech Systems", ["Teng Zhang", "Zhipeng Chen", "Ji Wu", "Sam Lai", "Wenhui Lei", "Carsten Isert"], "https://doi.org/10.21437/Interspeech.2016-421", 5, "interspeech", 2016], ["Improving the Probabilistic Framework for Representing Dialogue Systems with User Response Model", ["Miao Li", "Zhipeng Chen", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2016-810", 5, "interspeech", 2016], ["Target-Based State and Tracking Algorithm for Spoken Dialogue System", ["Miao Li", "Zhiyang He", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2016-800", 5, "interspeech", 2016]], "Sam Lai": [0, ["Objective Evaluation Methods for Chinese Text-To-Speech Systems", ["Teng Zhang", "Zhipeng Chen", "Ji Wu", "Sam Lai", "Wenhui Lei", "Carsten Isert"], "https://doi.org/10.21437/Interspeech.2016-421", 5, "interspeech", 2016]], "Wenhui Lei": [0, ["Objective Evaluation Methods for Chinese Text-To-Speech Systems", ["Teng Zhang", "Zhipeng Chen", "Ji Wu", "Sam Lai", "Wenhui Lei", "Carsten Isert"], "https://doi.org/10.21437/Interspeech.2016-421", 5, "interspeech", 2016]], "Carsten Isert": [0, ["Objective Evaluation Methods for Chinese Text-To-Speech Systems", ["Teng Zhang", "Zhipeng Chen", "Ji Wu", "Sam Lai", "Wenhui Lei", "Carsten Isert"], "https://doi.org/10.21437/Interspeech.2016-421", 5, "interspeech", 2016]], "Yusuke Ijima": [0, ["Objective Evaluation Using Association Between Dimensions Within Spectral Features for Statistical Parametric Speech Synthesis", ["Yusuke Ijima", "Taichi Asami", "Hideyuki Mizuno"], "https://doi.org/10.21437/Interspeech.2016-584", 5, "interspeech", 2016], ["An Investigation of DNN-Based Speech Synthesis Using Speaker Codes", ["Nobukatsu Hojo", "Yusuke Ijima", "Hideyuki Mizuno"], "https://doi.org/10.21437/Interspeech.2016-589", 5, "interspeech", 2016]], "Taichi Asami": [0, ["Objective Evaluation Using Association Between Dimensions Within Spectral Features for Statistical Parametric Speech Synthesis", ["Yusuke Ijima", "Taichi Asami", "Hideyuki Mizuno"], "https://doi.org/10.21437/Interspeech.2016-584", 5, "interspeech", 2016], ["Recurrent Out-of-Vocabulary Word Detection Using Distribution of Features", ["Taichi Asami", "Ryo Masumura", "Yushi Aono", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2016-562", 5, "interspeech", 2016], ["Language Identification Based on Generative Modeling of Posteriorgram Sequences Extracted from Frame-by-Frame DNNs and LSTM-RNNs", ["Ryo Masumura", "Taichi Asami", "Hirokazu Masataki", "Yushi Aono", "Sumitaka Sakauchi"], "https://doi.org/10.21437/Interspeech.2016-719", 5, "interspeech", 2016]], "Hideyuki Mizuno": [0, ["Objective Evaluation Using Association Between Dimensions Within Spectral Features for Statistical Parametric Speech Synthesis", ["Yusuke Ijima", "Taichi Asami", "Hideyuki Mizuno"], "https://doi.org/10.21437/Interspeech.2016-584", 5, "interspeech", 2016], ["An Investigation of DNN-Based Speech Synthesis Using Speaker Codes", ["Nobukatsu Hojo", "Yusuke Ijima", "Hideyuki Mizuno"], "https://doi.org/10.21437/Interspeech.2016-589", 5, "interspeech", 2016]], "Takenori Yoshimura": [0, ["A Hierarchical Predictor of Synthetic Speech Naturalness Using Neural Networks", ["Takenori Yoshimura", "Gustav Eje Henter", "Oliver Watts", "Mirjam Wester", "Junichi Yamagishi", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-847", 5, "interspeech", 2016]], "Gustav Eje Henter": [0, ["A Hierarchical Predictor of Synthetic Speech Naturalness Using Neural Networks", ["Takenori Yoshimura", "Gustav Eje Henter", "Oliver Watts", "Mirjam Wester", "Junichi Yamagishi", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-847", 5, "interspeech", 2016], ["A Template-Based Approach for Speech Synthesis Intonation Generation Using LSTMs", ["Srikanth Ronanki", "Gustav Eje Henter", "Zhizheng Wu", "Simon King"], "https://doi.org/10.21437/Interspeech.2016-96", 5, "interspeech", 2016]], "Oliver Watts": [0, ["A Hierarchical Predictor of Synthetic Speech Naturalness Using Neural Networks", ["Takenori Yoshimura", "Gustav Eje Henter", "Oliver Watts", "Mirjam Wester", "Junichi Yamagishi", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-847", 5, "interspeech", 2016], ["Syllable-Level Representations of Suprasegmental Features for DNN-Based Text-to-Speech Synthesis", ["Manuel Sam Ribeiro", "Oliver Watts", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1034", 5, "interspeech", 2016]], "Mirjam Wester": [0, ["A Hierarchical Predictor of Synthetic Speech Naturalness Using Neural Networks", ["Takenori Yoshimura", "Gustav Eje Henter", "Oliver Watts", "Mirjam Wester", "Junichi Yamagishi", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-847", 5, "interspeech", 2016], ["The Voice Conversion Challenge 2016", ["Tomoki Toda", "Ling-Hui Chen", "Daisuke Saito", "Fernando Villavicencio", "Mirjam Wester", "Zhizheng Wu", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1066", 5, "interspeech", 2016], ["Analysis of the Voice Conversion Challenge 2016 Evaluation Results", ["Mirjam Wester", "Zhizheng Wu", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1331", 5, "interspeech", 2016]], "Junichi Yamagishi": [0, ["A Hierarchical Predictor of Synthetic Speech Naturalness Using Neural Networks", ["Takenori Yoshimura", "Gustav Eje Henter", "Oliver Watts", "Mirjam Wester", "Junichi Yamagishi", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-847", 5, "interspeech", 2016], ["Speech Enhancement for a Noise-Robust Text-to-Speech Synthesis System Using Deep Recurrent Neural Networks", ["Cassia Valentini-Botinhao", "Xin Wang", "Shinji Takaki", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-159", 5, "interspeech", 2016], ["Majorisation-Minimisation Based Optimisation of the Composite Autoregressive System with Application to Glottal Inverse Filtering", ["Lauri Juvela", "Hirokazu Kameoka", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-735", 5, "interspeech", 2016], ["The SIWIS Database: A Multilingual Speech Database with Acted Emphasis", ["Jean-Philippe Goldman", "Pierre-Edouard Honnet", "Robert A. J. Clark", "Philip N. Garner", "Maria Ivanova", "Alexandros Lazaridis", "Hui Liang", "Tiago Macedo", "Beat Pfister", "Manuel Sam Ribeiro", "Eric Wehrli", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1003", 4, "interspeech", 2016], ["The Voice Conversion Challenge 2016", ["Tomoki Toda", "Ling-Hui Chen", "Daisuke Saito", "Fernando Villavicencio", "Mirjam Wester", "Zhizheng Wu", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1066", 5, "interspeech", 2016], ["Analysis of the Voice Conversion Challenge 2016 Evaluation Results", ["Mirjam Wester", "Zhizheng Wu", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1331", 5, "interspeech", 2016], ["Applying Spectral Normalisation and Efficient Envelope Estimation and Statistical Transformation for the Voice Conversion Challenge 2016", ["Fernando Villavicencio", "Junichi Yamagishi", "Jordi Bonada", "Felipe Espic"], "https://doi.org/10.21437/Interspeech.2016-305", 5, "interspeech", 2016], ["Using Text and Acoustic Features in Predicting Glottal Excitation Waveforms for Parametric Speech Synthesis with Recurrent Neural Networks", ["Lauri Juvela", "Xin Wang", "Shinji Takaki", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-712", 5, "interspeech", 2016], ["Enhance the Word Vector with Prosodic Information for the Recurrent Neural Network Based TTS System", ["Xin Wang", "Shinji Takaki", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-390", 5, "interspeech", 2016], ["Syllable-Level Representations of Suprasegmental Features for DNN-Based Text-to-Speech Synthesis", ["Manuel Sam Ribeiro", "Oliver Watts", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1034", 5, "interspeech", 2016]], "Monika Podsiadlo": [0, ["Text-to-Speech for Individuals with Vision Loss: A User Study", ["Monika Podsiadlo", "Shweta Chahar"], "https://doi.org/10.21437/Interspeech.2016-1376", 5, "interspeech", 2016]], "Shweta Chahar": [0, ["Text-to-Speech for Individuals with Vision Loss: A User Study", ["Monika Podsiadlo", "Shweta Chahar"], "https://doi.org/10.21437/Interspeech.2016-1376", 5, "interspeech", 2016]], "Cassia Valentini-Botinhao": [0, ["Speech Enhancement for a Noise-Robust Text-to-Speech Synthesis System Using Deep Recurrent Neural Networks", ["Cassia Valentini-Botinhao", "Xin Wang", "Shinji Takaki", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-159", 5, "interspeech", 2016], ["Waveform Generation Based on Signal Reshaping for Statistical Parametric Speech Synthesis", ["Felipe Espic", "Cassia Valentini-Botinhao", "Zhizheng Wu", "Simon King"], "https://doi.org/10.21437/Interspeech.2016-487", 5, "interspeech", 2016]], "Xin Wang": [0.00010220255353488028, ["Speech Enhancement for a Noise-Robust Text-to-Speech Synthesis System Using Deep Recurrent Neural Networks", ["Cassia Valentini-Botinhao", "Xin Wang", "Shinji Takaki", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-159", 5, "interspeech", 2016], ["Using Text and Acoustic Features in Predicting Glottal Excitation Waveforms for Parametric Speech Synthesis with Recurrent Neural Networks", ["Lauri Juvela", "Xin Wang", "Shinji Takaki", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-712", 5, "interspeech", 2016], ["Enhance the Word Vector with Prosodic Information for the Recurrent Neural Network Based TTS System", ["Xin Wang", "Shinji Takaki", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-390", 5, "interspeech", 2016]], "Shinji Takaki": [0, ["Speech Enhancement for a Noise-Robust Text-to-Speech Synthesis System Using Deep Recurrent Neural Networks", ["Cassia Valentini-Botinhao", "Xin Wang", "Shinji Takaki", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-159", 5, "interspeech", 2016], ["Using Text and Acoustic Features in Predicting Glottal Excitation Waveforms for Parametric Speech Synthesis with Recurrent Neural Networks", ["Lauri Juvela", "Xin Wang", "Shinji Takaki", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-712", 5, "interspeech", 2016], ["Enhance the Word Vector with Prosodic Information for the Recurrent Neural Network Based TTS System", ["Xin Wang", "Shinji Takaki", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-390", 5, "interspeech", 2016]], "Erica Cooper": [0, ["Data Selection and Adaptation for Naturalness in HMM-Based Speech Synthesis", ["Erica Cooper", "Alison Chang", "Yocheved Levitan", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-502", 5, "interspeech", 2016]], "Alison Chang": [2.7239328659334205e-07, ["Data Selection and Adaptation for Naturalness in HMM-Based Speech Synthesis", ["Erica Cooper", "Alison Chang", "Yocheved Levitan", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-502", 5, "interspeech", 2016]], "Yocheved Levitan": [0, ["Data Selection and Adaptation for Naturalness in HMM-Based Speech Synthesis", ["Erica Cooper", "Alison Chang", "Yocheved Levitan", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-502", 5, "interspeech", 2016]], "Julia Hirschberg": [0, ["Data Selection and Adaptation for Naturalness in HMM-Based Speech Synthesis", ["Erica Cooper", "Alison Chang", "Yocheved Levitan", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-502", 5, "interspeech", 2016], ["Implementing Acoustic-Prosodic Entrainment in a Conversational Avatar", ["Rivka Levitan", "Stefan Benus", "Ramiro H. Galvez", "Agustin Gravano", "Florencia Savoretti", "Marian Trnka", "Andreas Weise", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-985", 5, "interspeech", 2016], ["Automatically Classifying Self-Rated Personality Scores from Speech", ["Guozhen An", "Sarah Ita Levitan", "Rivka Levitan", "Andrew Rosenberg", "Michelle Levine", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-1328", 5, "interspeech", 2016], ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: Deception, Sincerity & Native Language", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "https://doi.org/10.21437/Interspeech.2016-129", 5, "interspeech", 2016], ["The Deception Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs5.html", 0, "interspeech", 2016], ["Combining Acoustic-Prosodic, Lexical, and Phonotactic Features for Automatic Deception Detection", ["Sarah Ita Levitan", "Guozhen An", "Min Ma", "Rivka Levitan", "Andrew Rosenberg", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-1519", 5, "interspeech", 2016], ["The Sincerity Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs6.html", 0, "interspeech", 2016], ["The Native Language Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs11.html", 0, "interspeech", 2016], ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: A Summary of Results", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs12.html", 0, "interspeech", 2016], ["Discussion", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs13.html", 0, "interspeech", 2016], ["Computational Approaches to Linguistic Code Switching", ["Mona T. Diab", "Pascale Fung", "Julia Hirschberg", "Thamar Solorio"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs16.html", 0, "interspeech", 2016]], "Fei Tao": [0, ["A Portable Automatic PA-TA-KA Syllable Detection System to Derive Biomarkers for Neurological Disorders", ["Fei Tao", "Louis Daudet", "Christian Poellabauer", "Sandra L. Schneider", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2016-789", 5, "interspeech", 2016], ["Improving Boundary Estimation in Audiovisual Speech Activity Detection Using Bayesian Information Criterion", ["Fei Tao", "John H. L. Hansen", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2016-406", 5, "interspeech", 2016]], "Louis Daudet": [0, ["A Portable Automatic PA-TA-KA Syllable Detection System to Derive Biomarkers for Neurological Disorders", ["Fei Tao", "Louis Daudet", "Christian Poellabauer", "Sandra L. Schneider", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2016-789", 5, "interspeech", 2016]], "Christian Poellabauer": [0, ["A Portable Automatic PA-TA-KA Syllable Detection System to Derive Biomarkers for Neurological Disorders", ["Fei Tao", "Louis Daudet", "Christian Poellabauer", "Sandra L. Schneider", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2016-789", 5, "interspeech", 2016]], "Sandra L. Schneider": [0, ["A Portable Automatic PA-TA-KA Syllable Detection System to Derive Biomarkers for Neurological Disorders", ["Fei Tao", "Louis Daudet", "Christian Poellabauer", "Sandra L. Schneider", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2016-789", 5, "interspeech", 2016]], "Omid Ghahabi": [0, ["Deep Neural Networks for i-Vector Language Identification of Short Utterances in Cars", ["Omid Ghahabi", "Antonio Bonafonte", "Javier Hernando", "Asuncion Moreno"], "https://doi.org/10.21437/Interspeech.2016-1045", 5, "interspeech", 2016]], "Antonio Bonafonte": [0, ["Deep Neural Networks for i-Vector Language Identification of Short Utterances in Cars", ["Omid Ghahabi", "Antonio Bonafonte", "Javier Hernando", "Asuncion Moreno"], "https://doi.org/10.21437/Interspeech.2016-1045", 5, "interspeech", 2016], ["Direct Expressive Voice Training Based on Semantic Selection", ["Igor Jauk", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2016-979", 5, "interspeech", 2016]], "Javier Hernando": [0, ["Deep Neural Networks for i-Vector Language Identification of Short Utterances in Cars", ["Omid Ghahabi", "Antonio Bonafonte", "Javier Hernando", "Asuncion Moreno"], "https://doi.org/10.21437/Interspeech.2016-1045", 5, "interspeech", 2016], ["Improving i-Vector and PLDA Based Speaker Clustering with Long-Term Features", ["Abraham Woubie", "Jordi Luque", "Javier Hernando"], "https://doi.org/10.21437/Interspeech.2016-339", 5, "interspeech", 2016]], "Asuncion Moreno": [0, ["Deep Neural Networks for i-Vector Language Identification of Short Utterances in Cars", ["Omid Ghahabi", "Antonio Bonafonte", "Javier Hernando", "Asuncion Moreno"], "https://doi.org/10.21437/Interspeech.2016-1045", 5, "interspeech", 2016]], "Abraham Woubie": [0, ["Improving i-Vector and PLDA Based Speaker Clustering with Long-Term Features", ["Abraham Woubie", "Jordi Luque", "Javier Hernando"], "https://doi.org/10.21437/Interspeech.2016-339", 5, "interspeech", 2016]], "Jordi Luque": [0, ["Improving i-Vector and PLDA Based Speaker Clustering with Long-Term Features", ["Abraham Woubie", "Jordi Luque", "Javier Hernando"], "https://doi.org/10.21437/Interspeech.2016-339", 5, "interspeech", 2016]], "Aaron Lawson": [0, ["Open Language Interface for Voice Exploitation (OLIVE)", ["Aaron Lawson", "Mitchell McLaren", "Harry Bratt", "Martin Graciarena", "Horacio Franco", "Christopher George", "Allen R. Stauffer", "Chris Bartels", "Julien van Hout"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2000.html", 2, "interspeech", 2016], ["The Speakers in the Wild (SITW) Speaker Recognition Database", ["Mitchell McLaren", "Luciana Ferrer", "Diego Castan", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2016-1129", 5, "interspeech", 2016], ["The 2016 Speakers in the Wild Speaker Recognition Evaluation", ["Mitchell McLaren", "Luciana Ferrer", "Diego Castan", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2016-1137", 5, "interspeech", 2016], ["On the Issue of Calibration in DNN-Based Speaker Recognition Systems", ["Mitchell McLaren", "Diego Castan", "Luciana Ferrer", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2016-1134", 5, "interspeech", 2016]], "Mitchell McLaren": [0, ["Open Language Interface for Voice Exploitation (OLIVE)", ["Aaron Lawson", "Mitchell McLaren", "Harry Bratt", "Martin Graciarena", "Horacio Franco", "Christopher George", "Allen R. Stauffer", "Chris Bartels", "Julien van Hout"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2000.html", 2, "interspeech", 2016], ["The Speakers in the Wild (SITW) Speaker Recognition Database", ["Mitchell McLaren", "Luciana Ferrer", "Diego Castan", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2016-1129", 5, "interspeech", 2016], ["The 2016 Speakers in the Wild Speaker Recognition Evaluation", ["Mitchell McLaren", "Luciana Ferrer", "Diego Castan", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2016-1137", 5, "interspeech", 2016], ["On the Issue of Calibration in DNN-Based Speaker Recognition Systems", ["Mitchell McLaren", "Diego Castan", "Luciana Ferrer", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2016-1134", 5, "interspeech", 2016]], "Harry Bratt": [0, ["Open Language Interface for Voice Exploitation (OLIVE)", ["Aaron Lawson", "Mitchell McLaren", "Harry Bratt", "Martin Graciarena", "Horacio Franco", "Christopher George", "Allen R. Stauffer", "Chris Bartels", "Julien van Hout"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2000.html", 2, "interspeech", 2016], ["Privacy-Preserving Speech Analytics for Automatic Assessment of Student Collaboration", ["Nikoletta Bassiou", "Andreas Tsiartas", "Jennifer Smith", "Harry Bratt", "Colleen Richey", "Elizabeth Shriberg", "Cynthia DAngelo", "Nonye Alozie"], "https://doi.org/10.21437/Interspeech.2016-1569", 5, "interspeech", 2016], ["The SRI Speech-Based Collaborative Learning Corpus", ["Colleen Richey", "Cynthia DAngelo", "Nonye Alozie", "Harry Bratt", "Elizabeth Shriberg"], "https://doi.org/10.21437/Interspeech.2016-1541", 5, "interspeech", 2016]], "Martin Graciarena": [0, ["Open Language Interface for Voice Exploitation (OLIVE)", ["Aaron Lawson", "Mitchell McLaren", "Harry Bratt", "Martin Graciarena", "Horacio Franco", "Christopher George", "Allen R. Stauffer", "Chris Bartels", "Julien van Hout"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2000.html", 2, "interspeech", 2016], ["Minimizing Annotation Effort for Adaptation of Speech-Activity Detection Systems", ["Luciana Ferrer", "Martin Graciarena"], "https://doi.org/10.21437/Interspeech.2016-247", 5, "interspeech", 2016], ["The SRI System for the NIST OpenSAD 2015 Speech Activity Detection Evaluation", ["Martin Graciarena", "Luciana Ferrer", "Vikramjit Mitra"], "https://doi.org/10.21437/Interspeech.2016-550", 5, "interspeech", 2016]], "Horacio Franco": [0, ["Open Language Interface for Voice Exploitation (OLIVE)", ["Aaron Lawson", "Mitchell McLaren", "Harry Bratt", "Martin Graciarena", "Horacio Franco", "Christopher George", "Allen R. Stauffer", "Chris Bartels", "Julien van Hout"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2000.html", 2, "interspeech", 2016], ["Unsupervised Learning of Acoustic Units Using Autoencoders and Kohonen Nets", ["Vikramjit Mitra", "Dimitra Vergyri", "Horacio Franco"], "https://doi.org/10.21437/Interspeech.2016-1374", 5, "interspeech", 2016], ["Fusion Strategies for Robust Speech Recognition and Keyword Spotting for Channel- and Noise-Degraded Speech", ["Vikramjit Mitra", "Julien van Hout", "Wen Wang", "Chris Bartels", "Horacio Franco", "Dimitra Vergyri", "Abeer Alwan", "Adam Janin", "John H. L. Hansen", "Richard M. Stern", "Abhijeet Sangwan", "Nelson Morgan"], "https://doi.org/10.21437/Interspeech.2016-279", 5, "interspeech", 2016], ["Coping with Unseen Data Conditions: Investigating Neural Net Architectures, Robust Features, and Information Fusion for Robust Speech Recognition", ["Vikramjit Mitra", "Horacio Franco"], "https://doi.org/10.21437/Interspeech.2016-966", 5, "interspeech", 2016]], "Christopher George": [0, ["Open Language Interface for Voice Exploitation (OLIVE)", ["Aaron Lawson", "Mitchell McLaren", "Harry Bratt", "Martin Graciarena", "Horacio Franco", "Christopher George", "Allen R. Stauffer", "Chris Bartels", "Julien van Hout"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2000.html", 2, "interspeech", 2016]], "Allen R. Stauffer": [0, ["Open Language Interface for Voice Exploitation (OLIVE)", ["Aaron Lawson", "Mitchell McLaren", "Harry Bratt", "Martin Graciarena", "Horacio Franco", "Christopher George", "Allen R. Stauffer", "Chris Bartels", "Julien van Hout"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2000.html", 2, "interspeech", 2016]], "Chris Bartels": [0, ["Open Language Interface for Voice Exploitation (OLIVE)", ["Aaron Lawson", "Mitchell McLaren", "Harry Bratt", "Martin Graciarena", "Horacio Franco", "Christopher George", "Allen R. Stauffer", "Chris Bartels", "Julien van Hout"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2000.html", 2, "interspeech", 2016], ["Fusion Strategies for Robust Speech Recognition and Keyword Spotting for Channel- and Noise-Degraded Speech", ["Vikramjit Mitra", "Julien van Hout", "Wen Wang", "Chris Bartels", "Horacio Franco", "Dimitra Vergyri", "Abeer Alwan", "Adam Janin", "John H. L. Hansen", "Richard M. Stern", "Abhijeet Sangwan", "Nelson Morgan"], "https://doi.org/10.21437/Interspeech.2016-279", 5, "interspeech", 2016]], "Julien van Hout": [0, ["Open Language Interface for Voice Exploitation (OLIVE)", ["Aaron Lawson", "Mitchell McLaren", "Harry Bratt", "Martin Graciarena", "Horacio Franco", "Christopher George", "Allen R. Stauffer", "Chris Bartels", "Julien van Hout"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2000.html", 2, "interspeech", 2016], ["Fusion Strategies for Robust Speech Recognition and Keyword Spotting for Channel- and Noise-Degraded Speech", ["Vikramjit Mitra", "Julien van Hout", "Wen Wang", "Chris Bartels", "Horacio Franco", "Dimitra Vergyri", "Abeer Alwan", "Adam Janin", "John H. L. Hansen", "Richard M. Stern", "Abhijeet Sangwan", "Nelson Morgan"], "https://doi.org/10.21437/Interspeech.2016-279", 5, "interspeech", 2016]], "Lubos Smidl": [0, ["A Multimodal Dialogue System for Air Traffic Control Trainees Based on Discrete-Event Simulation", ["Lubos Smidl", "Adam Chylek", "Jan Svec"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2002.html", 2, "interspeech", 2016], ["An Automatic Training Tool for Air Traffic Control Training", ["Petr Stanislav", "Lubos Smidl", "Jan Svec"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2007.html", 2, "interspeech", 2016]], "Adam Chylek": [0, ["A Multimodal Dialogue System for Air Traffic Control Trainees Based on Discrete-Event Simulation", ["Lubos Smidl", "Adam Chylek", "Jan Svec"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2002.html", 2, "interspeech", 2016]], "Jan Svec": [0, ["A Multimodal Dialogue System for Air Traffic Control Trainees Based on Discrete-Event Simulation", ["Lubos Smidl", "Adam Chylek", "Jan Svec"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2002.html", 2, "interspeech", 2016], ["An Automatic Training Tool for Air Traffic Control Training", ["Petr Stanislav", "Lubos Smidl", "Jan Svec"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2007.html", 2, "interspeech", 2016], ["An Engine for Online Video Search in Large Archives of the Holocaust Testimonies", ["Petr Stanislav", "Jan Svec", "Pavel Ircing"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2016.html", 2, "interspeech", 2016]], "Elodie Gauthier": [0, ["Lig-Aikuma: A Mobile App to Collect Parallel Speech for Under-Resourced Language Studies", ["Elodie Gauthier", "David Blachon", "Laurent Besacier", "Guy-Noel Kouarata", "Martine Adda-Decker", "Annie Rialland", "Gilles Adda", "Gregoire Bachman"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2003.html", 2, "interspeech", 2016], ["Speed Perturbation and Vowel Duration Modeling for ASR in Hausa and Wolof Languages", ["Elodie Gauthier", "Laurent Besacier", "Sylvie Voisin"], "https://doi.org/10.21437/Interspeech.2016-461", 5, "interspeech", 2016]], "David Blachon": [0, ["Lig-Aikuma: A Mobile App to Collect Parallel Speech for Under-Resourced Language Studies", ["Elodie Gauthier", "David Blachon", "Laurent Besacier", "Guy-Noel Kouarata", "Martine Adda-Decker", "Annie Rialland", "Gilles Adda", "Gregoire Bachman"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2003.html", 2, "interspeech", 2016]], "Laurent Besacier": [0, ["Lig-Aikuma: A Mobile App to Collect Parallel Speech for Under-Resourced Language Studies", ["Elodie Gauthier", "David Blachon", "Laurent Besacier", "Guy-Noel Kouarata", "Martine Adda-Decker", "Annie Rialland", "Gilles Adda", "Gregoire Bachman"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2003.html", 2, "interspeech", 2016], ["Better Evaluation of ASR in Speech Translation Context Using Word Embeddings", ["Ngoc-Tien Le", "Christophe Servan", "Benjamin Lecouteux", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2016-464", 5, "interspeech", 2016], ["Speed Perturbation and Vowel Duration Modeling for ASR in Hausa and Wolof Languages", ["Elodie Gauthier", "Laurent Besacier", "Sylvie Voisin"], "https://doi.org/10.21437/Interspeech.2016-461", 5, "interspeech", 2016], ["Preliminary Experiments on Unsupervised Word Discovery in Mboshi", ["Pierre Godard", "Gilles Adda", "Martine Adda-Decker", "Alexandre Allauzen", "Laurent Besacier", "Helene Bonneau-Maynard", "Guy-Noel Kouarata", "Kevin Loser", "Annie Rialland", "Francois Yvon"], "https://doi.org/10.21437/Interspeech.2016-886", 5, "interspeech", 2016]], "Guy-Noel Kouarata": [0, ["Lig-Aikuma: A Mobile App to Collect Parallel Speech for Under-Resourced Language Studies", ["Elodie Gauthier", "David Blachon", "Laurent Besacier", "Guy-Noel Kouarata", "Martine Adda-Decker", "Annie Rialland", "Gilles Adda", "Gregoire Bachman"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2003.html", 2, "interspeech", 2016], ["Preliminary Experiments on Unsupervised Word Discovery in Mboshi", ["Pierre Godard", "Gilles Adda", "Martine Adda-Decker", "Alexandre Allauzen", "Laurent Besacier", "Helene Bonneau-Maynard", "Guy-Noel Kouarata", "Kevin Loser", "Annie Rialland", "Francois Yvon"], "https://doi.org/10.21437/Interspeech.2016-886", 5, "interspeech", 2016]], "Annie Rialland": [0, ["Lig-Aikuma: A Mobile App to Collect Parallel Speech for Under-Resourced Language Studies", ["Elodie Gauthier", "David Blachon", "Laurent Besacier", "Guy-Noel Kouarata", "Martine Adda-Decker", "Annie Rialland", "Gilles Adda", "Gregoire Bachman"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2003.html", 2, "interspeech", 2016], ["Preliminary Experiments on Unsupervised Word Discovery in Mboshi", ["Pierre Godard", "Gilles Adda", "Martine Adda-Decker", "Alexandre Allauzen", "Laurent Besacier", "Helene Bonneau-Maynard", "Guy-Noel Kouarata", "Kevin Loser", "Annie Rialland", "Francois Yvon"], "https://doi.org/10.21437/Interspeech.2016-886", 5, "interspeech", 2016]], "Gilles Adda": [0, ["Lig-Aikuma: A Mobile App to Collect Parallel Speech for Under-Resourced Language Studies", ["Elodie Gauthier", "David Blachon", "Laurent Besacier", "Guy-Noel Kouarata", "Martine Adda-Decker", "Annie Rialland", "Gilles Adda", "Gregoire Bachman"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2003.html", 2, "interspeech", 2016], ["Preliminary Experiments on Unsupervised Word Discovery in Mboshi", ["Pierre Godard", "Gilles Adda", "Martine Adda-Decker", "Alexandre Allauzen", "Laurent Besacier", "Helene Bonneau-Maynard", "Guy-Noel Kouarata", "Kevin Loser", "Annie Rialland", "Francois Yvon"], "https://doi.org/10.21437/Interspeech.2016-886", 5, "interspeech", 2016]], "Gregoire Bachman": [0, ["Lig-Aikuma: A Mobile App to Collect Parallel Speech for Under-Resourced Language Studies", ["Elodie Gauthier", "David Blachon", "Laurent Besacier", "Guy-Noel Kouarata", "Martine Adda-Decker", "Annie Rialland", "Gilles Adda", "Gregoire Bachman"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2003.html", 2, "interspeech", 2016]], "Martin Gruber": [0, ["ARET - Automatic Reading of Educational Texts for Visually Impaired Students", ["Martin Gruber", "Jindrich Matousek", "Zdenek Hanzlicek", "Zdenek Krnoul", "Zbynek Zajic"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2004.html", 2, "interspeech", 2016]], "Jindrich Matousek": [0, ["ARET - Automatic Reading of Educational Texts for Visually Impaired Students", ["Martin Gruber", "Jindrich Matousek", "Zdenek Hanzlicek", "Zdenek Krnoul", "Zbynek Zajic"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2004.html", 2, "interspeech", 2016], ["Voting Detector: A Combination of Anomaly Detectors to Reveal Annotation Errors in TTS Corpora", ["Jindrich Matousek", "Daniel Tihelka"], "https://doi.org/10.21437/Interspeech.2016-442", 5, "interspeech", 2016]], "Zdenek Hanzlicek": [0, ["ARET - Automatic Reading of Educational Texts for Visually Impaired Students", ["Martin Gruber", "Jindrich Matousek", "Zdenek Hanzlicek", "Zdenek Krnoul", "Zbynek Zajic"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2004.html", 2, "interspeech", 2016]], "Zdenek Krnoul": [0, ["ARET - Automatic Reading of Educational Texts for Visually Impaired Students", ["Martin Gruber", "Jindrich Matousek", "Zdenek Hanzlicek", "Zdenek Krnoul", "Zbynek Zajic"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2004.html", 2, "interspeech", 2016]], "Zbynek Zajic": [0, ["ARET - Automatic Reading of Educational Texts for Visually Impaired Students", ["Martin Gruber", "Jindrich Matousek", "Zdenek Hanzlicek", "Zdenek Krnoul", "Zbynek Zajic"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2004.html", 2, "interspeech", 2016]], "Lingpeng Kong": [1.1730736174109246e-10, ["Segmental Recurrent Neural Networks for End-to-End Speech Recognition", ["Liang Lu", "Lingpeng Kong", "Chris Dyer", "Noah A. Smith", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-40", 5, "interspeech", 2016]], "Chris Dyer": [0, ["Segmental Recurrent Neural Networks for End-to-End Speech Recognition", ["Liang Lu", "Lingpeng Kong", "Chris Dyer", "Noah A. Smith", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-40", 5, "interspeech", 2016]], "Noah A. Smith": [0, ["Segmental Recurrent Neural Networks for End-to-End Speech Recognition", ["Liang Lu", "Lingpeng Kong", "Chris Dyer", "Noah A. Smith", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-40", 5, "interspeech", 2016]], "Markus Nussbaum-Thom": [0, ["Acoustic Modeling Using Bidirectional Gated Recurrent Convolutional Units", ["Markus Nussbaum-Thom", "Jia Cui", "Bhuvana Ramabhadran", "Vaibhava Goel"], "https://doi.org/10.21437/Interspeech.2016-212", 5, "interspeech", 2016]], "Jia Cui": [0, ["Acoustic Modeling Using Bidirectional Gated Recurrent Convolutional Units", ["Markus Nussbaum-Thom", "Jia Cui", "Bhuvana Ramabhadran", "Vaibhava Goel"], "https://doi.org/10.21437/Interspeech.2016-212", 5, "interspeech", 2016], ["Multilingual Data Selection for Low Resource Speech Recognition", ["Samuel Thomas", "Kartik Audhkhasi", "Jia Cui", "Brian Kingsbury", "Bhuvana Ramabhadran"], "https://doi.org/10.21437/Interspeech.2016-598", 5, "interspeech", 2016]], "Bhuvana Ramabhadran": [0, ["Acoustic Modeling Using Bidirectional Gated Recurrent Convolutional Units", ["Markus Nussbaum-Thom", "Jia Cui", "Bhuvana Ramabhadran", "Vaibhava Goel"], "https://doi.org/10.21437/Interspeech.2016-212", 5, "interspeech", 2016], ["Domain Adaptation of CNN Based Acoustic Models Under Limited Resource Settings", ["Masayuki Suzuki", "Ryuki Tachibana", "Samuel Thomas", "Bhuvana Ramabhadran", "George Saon"], "https://doi.org/10.21437/Interspeech.2016-1161", 5, "interspeech", 2016], ["Multilingual Data Selection for Low Resource Speech Recognition", ["Samuel Thomas", "Kartik Audhkhasi", "Jia Cui", "Brian Kingsbury", "Bhuvana Ramabhadran"], "https://doi.org/10.21437/Interspeech.2016-598", 5, "interspeech", 2016]], "Vaibhava Goel": [0, ["Acoustic Modeling Using Bidirectional Gated Recurrent Convolutional Units", ["Markus Nussbaum-Thom", "Jia Cui", "Bhuvana Ramabhadran", "Vaibhava Goel"], "https://doi.org/10.21437/Interspeech.2016-212", 5, "interspeech", 2016], ["Advances in Very Deep Convolutional Neural Networks for LVCSR", ["Tom Sercu", "Vaibhava Goel"], "https://doi.org/10.21437/Interspeech.2016-1033", 5, "interspeech", 2016]], "Wei-Ning Hsu": [0, ["Exploiting Depth and Highway Connections in Convolutional Recurrent Deep Neural Networks for Speech Recognition", ["Wei-Ning Hsu", "Yu Zhang", "Ann Lee", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2016-515", 5, "interspeech", 2016]], "Yu Zhang": [0, ["Exploiting Depth and Highway Connections in Convolutional Recurrent Deep Neural Networks for Speech Recognition", ["Wei-Ning Hsu", "Yu Zhang", "Ann Lee", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2016-515", 5, "interspeech", 2016]], "Ann Lee": [0.010210834443569183, ["Exploiting Depth and Highway Connections in Convolutional Recurrent Deep Neural Networks for Speech Recognition", ["Wei-Ning Hsu", "Yu Zhang", "Ann Lee", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2016-515", 5, "interspeech", 2016]], "James R. Glass": [0, ["Exploiting Depth and Highway Connections in Convolutional Recurrent Deep Neural Networks for Speech Recognition", ["Wei-Ning Hsu", "Yu Zhang", "Ann Lee", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2016-515", 5, "interspeech", 2016], ["Memory-Efficient Modeling and Search Techniques for Hardware ASR Decoders", ["Michael Price", "Anantha Chandrakasan", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2016-287", 5, "interspeech", 2016], ["Automatic Dialect Detection in Arabic Broadcast Speech", ["Ahmed M. Ali", "Najim Dehak", "Patrick Cardinal", "Sameer Khurana", "Sree Harsha Yella", "James R. Glass", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-1297", 5, "interspeech", 2016]], "Chunyang Wu": [0.13471154496073723, ["Stimulated Deep Neural Network for Speech Recognition", ["Chunyang Wu", "Penny Karanasou", "Mark J. F. Gales", "Khe Chai Sim"], "https://doi.org/10.21437/Interspeech.2016-580", 5, "interspeech", 2016]], "Penny Karanasou": [0, ["Stimulated Deep Neural Network for Speech Recognition", ["Chunyang Wu", "Penny Karanasou", "Mark J. F. Gales", "Khe Chai Sim"], "https://doi.org/10.21437/Interspeech.2016-580", 5, "interspeech", 2016], ["Selection of Multi-Genre Broadcast Data for the Training of Automatic Speech Recognition Systems", ["Pierre Lanchantin", "Mark J. F. Gales", "Penny Karanasou", "X. Liu", "Y. Qian", "L. Wang", "Philip C. Woodland", "C. Zhang"], "https://doi.org/10.21437/Interspeech.2016-462", 5, "interspeech", 2016]], "Mark J. F. Gales": [0, ["Stimulated Deep Neural Network for Speech Recognition", ["Chunyang Wu", "Penny Karanasou", "Mark J. F. Gales", "Khe Chai Sim"], "https://doi.org/10.21437/Interspeech.2016-580", 5, "interspeech", 2016], ["Log-Linear System Combination Using Structured Support Vector Machines", ["Jingzhou Yang", "Anton Ragni", "Mark J. F. Gales", "Kate M. Knill"], "https://doi.org/10.21437/Interspeech.2016-377", 5, "interspeech", 2016], ["Incorporating a Generative Front-End Layer to Deep Neural Network for Noise Robust Automatic Speech Recognition", ["Souvik Kundu", "Khe Chai Sim", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2016-760", 5, "interspeech", 2016], ["Sequence Student-Teacher Training of Deep Neural Networks", ["Jeremy H. M. Wong", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2016-911", 5, "interspeech", 2016], ["Multi-Language Neural Network Language Models", ["Anton Ragni", "Edgar Dakin", "Xie Chen", "Mark J. F. Gales", "Kate M. Knill"], "https://doi.org/10.21437/Interspeech.2016-371", 5, "interspeech", 2016], ["Selection of Multi-Genre Broadcast Data for the Training of Automatic Speech Recognition Systems", ["Pierre Lanchantin", "Mark J. F. Gales", "Penny Karanasou", "X. Liu", "Y. Qian", "L. Wang", "Philip C. Woodland", "C. Zhang"], "https://doi.org/10.21437/Interspeech.2016-462", 5, "interspeech", 2016]], "Khe Chai Sim": [1.1623291811702074e-05, ["Stimulated Deep Neural Network for Speech Recognition", ["Chunyang Wu", "Penny Karanasou", "Mark J. F. Gales", "Khe Chai Sim"], "https://doi.org/10.21437/Interspeech.2016-580", 5, "interspeech", 2016], ["Subspace LHUC for Fast Adaptation of Deep Neural Network Acoustic Models", ["Lahiru Samarakoon", "Khe Chai Sim"], "https://doi.org/10.21437/Interspeech.2016-1249", 5, "interspeech", 2016], ["Incorporating a Generative Front-End Layer to Deep Neural Network for Noise Robust Automatic Speech Recognition", ["Souvik Kundu", "Khe Chai Sim", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2016-760", 5, "interspeech", 2016], ["Multi-Attribute Factorized Hidden Layer Adaptation for DNN Acoustic Models", ["Lahiru Samarakoon", "Khe Chai Sim"], "https://doi.org/10.21437/Interspeech.2016-1233", 5, "interspeech", 2016], ["Microphone Distance Adaptation Using Cluster Adaptive Training for Robust Far Field Speech Recognition", ["Animesh Prasad", "Khe Chai Sim"], "https://doi.org/10.21437/Interspeech.2016-738", 5, "interspeech", 2016]], "Leonardo Badino": [0, ["Phonetic Context Embeddings for DNN-HMM Phone Recognition", ["Leonardo Badino"], "https://doi.org/10.21437/Interspeech.2016-1036", 5, "interspeech", 2016]], "Ying Zhang": [0, ["Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks", ["Ying Zhang", "Mohammad Pezeshki", "Philemon Brakel", "Saizheng Zhang", "Cesar Laurent", "Yoshua Bengio", "Aaron C. Courville"], "https://doi.org/10.21437/Interspeech.2016-1446", 5, "interspeech", 2016]], "Mohammad Pezeshki": [0, ["Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks", ["Ying Zhang", "Mohammad Pezeshki", "Philemon Brakel", "Saizheng Zhang", "Cesar Laurent", "Yoshua Bengio", "Aaron C. Courville"], "https://doi.org/10.21437/Interspeech.2016-1446", 5, "interspeech", 2016]], "Philemon Brakel": [0, ["Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks", ["Ying Zhang", "Mohammad Pezeshki", "Philemon Brakel", "Saizheng Zhang", "Cesar Laurent", "Yoshua Bengio", "Aaron C. Courville"], "https://doi.org/10.21437/Interspeech.2016-1446", 5, "interspeech", 2016]], "Saizheng Zhang": [0, ["Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks", ["Ying Zhang", "Mohammad Pezeshki", "Philemon Brakel", "Saizheng Zhang", "Cesar Laurent", "Yoshua Bengio", "Aaron C. Courville"], "https://doi.org/10.21437/Interspeech.2016-1446", 5, "interspeech", 2016]], "Cesar Laurent": [0, ["Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks", ["Ying Zhang", "Mohammad Pezeshki", "Philemon Brakel", "Saizheng Zhang", "Cesar Laurent", "Yoshua Bengio", "Aaron C. Courville"], "https://doi.org/10.21437/Interspeech.2016-1446", 5, "interspeech", 2016]], "Yoshua Bengio": [0, ["Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks", ["Ying Zhang", "Mohammad Pezeshki", "Philemon Brakel", "Saizheng Zhang", "Cesar Laurent", "Yoshua Bengio", "Aaron C. Courville"], "https://doi.org/10.21437/Interspeech.2016-1446", 5, "interspeech", 2016]], "Aaron C. Courville": [0, ["Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks", ["Ying Zhang", "Mohammad Pezeshki", "Philemon Brakel", "Saizheng Zhang", "Cesar Laurent", "Yoshua Bengio", "Aaron C. Courville"], "https://doi.org/10.21437/Interspeech.2016-1446", 5, "interspeech", 2016]], "Guangsen Wang": [6.218036219252099e-08, ["Joint Speaker and Lexical Modeling for Short-Term Characterization of Speaker", ["Guangsen Wang", "Kong-Aik Lee", "Trung Hieu Nguyen", "Hanwu Sun", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2016-929", 5, "interspeech", 2016], ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016]], "Kong-Aik Lee": [2.7774487989518093e-06, ["Joint Speaker and Lexical Modeling for Short-Term Characterization of Speaker", ["Guangsen Wang", "Kong-Aik Lee", "Trung Hieu Nguyen", "Hanwu Sun", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2016-929", 5, "interspeech", 2016], ["Twin Model G-PLDA for Duration Mismatch Compensation in Text-Independent Speaker Verification", ["Jianbo Ma", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah", "Kong-Aik Lee"], "https://doi.org/10.21437/Interspeech.2016-683", 5, "interspeech", 2016], ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016]], "Trung Hieu Nguyen": [0, ["Joint Speaker and Lexical Modeling for Short-Term Characterization of Speaker", ["Guangsen Wang", "Kong-Aik Lee", "Trung Hieu Nguyen", "Hanwu Sun", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2016-929", 5, "interspeech", 2016], ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016]], "Hanwu Sun": [0.775729775428772, ["Joint Speaker and Lexical Modeling for Short-Term Characterization of Speaker", ["Guangsen Wang", "Kong-Aik Lee", "Trung Hieu Nguyen", "Hanwu Sun", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2016-929", 5, "interspeech", 2016], ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016]], "Bin Ma": [0, ["Joint Speaker and Lexical Modeling for Short-Term Characterization of Speaker", ["Guangsen Wang", "Kong-Aik Lee", "Trung Hieu Nguyen", "Hanwu Sun", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2016-929", 5, "interspeech", 2016], ["Learning Neural Network Representations Using Cross-Lingual Bottleneck Features with Word-Pair Information", ["Yougen Yuan", "Cheung-Chi Leung", "Lei Xie", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-317", 5, "interspeech", 2016], ["Unsupervised Bottleneck Features for Low-Resource Query-by-Example Spoken Term Detection", ["Hongjie Chen", "Cheung-Chi Leung", "Lei Xie", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-313", 5, "interspeech", 2016], ["SingaKids-Mandarin: Speech Corpus of Singaporean Children Speaking Mandarin Chinese", ["Nancy F. Chen", "Rong Tong", "Darren Wee", "Pei Xuan Lee", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-139", 5, "interspeech", 2016], ["Context Aware Mispronunciation Detection for Mandarin Pronunciation Training", ["Rong Tong", "Nancy F. Chen", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-289", 5, "interspeech", 2016], ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016], ["Rapid Update of Multilingual Deep Neural Network for Low-Resource Keyword Search", ["Chongjia Ni", "Lei Wang", "Cheung-Chi Leung", "Feng Rao", "Li Lu", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-53", 5, "interspeech", 2016], ["Toward High-Performance Language-Independent Query-by-Example Spoken Term Detection for MediaEval 2015: Post-Evaluation Analysis", ["Cheung-Chi Leung", "Lei Wang", "Haihua Xu", "Jingyong Hou", "Van Tung Pham", "Hang Lv", "Lei Xie", "Xiong Xiao", "Chongjia Ni", "Bin Ma", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-691", 5, "interspeech", 2016]], "Md. Jahangir Alam": [0, ["Tandem Features for Text-Dependent Speaker Verification on the RedDots Corpus", ["Md. Jahangir Alam", "Patrick Kenny", "Vishwa Gupta"], "https://doi.org/10.21437/Interspeech.2016-1465", 5, "interspeech", 2016]], "Patrick Kenny": [0, ["Tandem Features for Text-Dependent Speaker Verification on the RedDots Corpus", ["Md. Jahangir Alam", "Patrick Kenny", "Vishwa Gupta"], "https://doi.org/10.21437/Interspeech.2016-1465", 5, "interspeech", 2016]], "Vishwa Gupta": [0, ["Tandem Features for Text-Dependent Speaker Verification on the RedDots Corpus", ["Md. Jahangir Alam", "Patrick Kenny", "Vishwa Gupta"], "https://doi.org/10.21437/Interspeech.2016-1465", 5, "interspeech", 2016]], "Achintya Kumar Sarkar": [0, ["Text Dependent Speaker Verification Using Un-Supervised HMM-UBM and Temporal GMM-UBM", ["Achintya Kumar Sarkar", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-362", 5, "interspeech", 2016], ["Utterance Verification for Text-Dependent Speaker Recognition: A Comparative Assessment Using the RedDots Corpus", ["Tomi Kinnunen", "Md. Sahidullah", "Ivan Kukanov", "Hector Delgado", "Massimiliano Todisco", "Achintya Kumar Sarkar", "Nicolai Baek Thomsen", "Ville Hautamaki", "Nicholas W. D. Evans", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1125", 5, "interspeech", 2016]], "Zheng-Hua Tan": [0, ["Text Dependent Speaker Verification Using Un-Supervised HMM-UBM and Temporal GMM-UBM", ["Achintya Kumar Sarkar", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-362", 5, "interspeech", 2016], ["Utterance Verification for Text-Dependent Speaker Recognition: A Comparative Assessment Using the RedDots Corpus", ["Tomi Kinnunen", "Md. Sahidullah", "Ivan Kukanov", "Hector Delgado", "Massimiliano Todisco", "Achintya Kumar Sarkar", "Nicolai Baek Thomsen", "Ville Hautamaki", "Nicholas W. D. Evans", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1125", 5, "interspeech", 2016], ["Integrated Spoofing Countermeasures and Automatic Speaker Verification: An Evaluation on ASVspoof 2015", ["Md. Sahidullah", "Hector Delgado", "Massimiliano Todisco", "Hong Yu", "Tomi Kinnunen", "Nicholas W. D. Evans", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1280", 5, "interspeech", 2016], ["Robust Speaker Recognition with Combined Use of Acoustic and Throat Microphone Speech", ["Md. Sahidullah", "Rosa Gonzalez Hautamaki", "Dennis Alexander Lehmann Thomsen", "Tomi Kinnunen", "Zheng-Hua Tan", "Ville Hautamaki", "Robert Parts", "Martti Pitkanen"], "https://doi.org/10.21437/Interspeech.2016-1153", 5, "interspeech", 2016], ["Speaker-Dependent Dictionary-Based Speech Enhancement for Text-Dependent Speaker Verification", ["Nicolai Baek Thomsen", "Dennis Alexander Lehmann Thomsen", "Zheng-Hua Tan", "Borge Lindberg", "Soren Holdt Jensen"], "https://doi.org/10.21437/Interspeech.2016-763", 5, "interspeech", 2016], ["HAPPY Team Entry to NIST OpenSAD Challenge: A Fusion of Short-Term Unsupervised and Segment i-Vector Based Speech Activity Detectors", ["Tomi Kinnunen", "Alexey Sholokhov", "Elie el Khoury", "Dennis Alexander Lehmann Thomsen", "Md. Sahidullah", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1281", 5, "interspeech", 2016]], "Tomi Kinnunen": [0, ["Utterance Verification for Text-Dependent Speaker Recognition: A Comparative Assessment Using the RedDots Corpus", ["Tomi Kinnunen", "Md. Sahidullah", "Ivan Kukanov", "Hector Delgado", "Massimiliano Todisco", "Achintya Kumar Sarkar", "Nicolai Baek Thomsen", "Ville Hautamaki", "Nicholas W. D. Evans", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1125", 5, "interspeech", 2016], ["Integrated Spoofing Countermeasures and Automatic Speaker Verification: An Evaluation on ASVspoof 2015", ["Md. Sahidullah", "Hector Delgado", "Massimiliano Todisco", "Hong Yu", "Tomi Kinnunen", "Nicholas W. D. Evans", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1280", 5, "interspeech", 2016], ["Robust Speaker Recognition with Combined Use of Acoustic and Throat Microphone Speech", ["Md. Sahidullah", "Rosa Gonzalez Hautamaki", "Dennis Alexander Lehmann Thomsen", "Tomi Kinnunen", "Zheng-Hua Tan", "Ville Hautamaki", "Robert Parts", "Martti Pitkanen"], "https://doi.org/10.21437/Interspeech.2016-1153", 5, "interspeech", 2016], ["HAPPY Team Entry to NIST OpenSAD Challenge: A Fusion of Short-Term Unsupervised and Segment i-Vector Based Speech Activity Detectors", ["Tomi Kinnunen", "Alexey Sholokhov", "Elie el Khoury", "Dennis Alexander Lehmann Thomsen", "Md. Sahidullah", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1281", 5, "interspeech", 2016]], "Md. Sahidullah": [0, ["Utterance Verification for Text-Dependent Speaker Recognition: A Comparative Assessment Using the RedDots Corpus", ["Tomi Kinnunen", "Md. Sahidullah", "Ivan Kukanov", "Hector Delgado", "Massimiliano Todisco", "Achintya Kumar Sarkar", "Nicolai Baek Thomsen", "Ville Hautamaki", "Nicholas W. D. Evans", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1125", 5, "interspeech", 2016], ["Integrated Spoofing Countermeasures and Automatic Speaker Verification: An Evaluation on ASVspoof 2015", ["Md. Sahidullah", "Hector Delgado", "Massimiliano Todisco", "Hong Yu", "Tomi Kinnunen", "Nicholas W. D. Evans", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1280", 5, "interspeech", 2016], ["Robust Speaker Recognition with Combined Use of Acoustic and Throat Microphone Speech", ["Md. Sahidullah", "Rosa Gonzalez Hautamaki", "Dennis Alexander Lehmann Thomsen", "Tomi Kinnunen", "Zheng-Hua Tan", "Ville Hautamaki", "Robert Parts", "Martti Pitkanen"], "https://doi.org/10.21437/Interspeech.2016-1153", 5, "interspeech", 2016], ["HAPPY Team Entry to NIST OpenSAD Challenge: A Fusion of Short-Term Unsupervised and Segment i-Vector Based Speech Activity Detectors", ["Tomi Kinnunen", "Alexey Sholokhov", "Elie el Khoury", "Dennis Alexander Lehmann Thomsen", "Md. Sahidullah", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1281", 5, "interspeech", 2016]], "Ivan Kukanov": [0, ["Utterance Verification for Text-Dependent Speaker Recognition: A Comparative Assessment Using the RedDots Corpus", ["Tomi Kinnunen", "Md. Sahidullah", "Ivan Kukanov", "Hector Delgado", "Massimiliano Todisco", "Achintya Kumar Sarkar", "Nicolai Baek Thomsen", "Ville Hautamaki", "Nicholas W. D. Evans", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1125", 5, "interspeech", 2016], ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016]], "Hector Delgado": [0, ["Utterance Verification for Text-Dependent Speaker Recognition: A Comparative Assessment Using the RedDots Corpus", ["Tomi Kinnunen", "Md. Sahidullah", "Ivan Kukanov", "Hector Delgado", "Massimiliano Todisco", "Achintya Kumar Sarkar", "Nicolai Baek Thomsen", "Ville Hautamaki", "Nicholas W. D. Evans", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1125", 5, "interspeech", 2016], ["Integrated Spoofing Countermeasures and Automatic Speaker Verification: An Evaluation on ASVspoof 2015", ["Md. Sahidullah", "Hector Delgado", "Massimiliano Todisco", "Hong Yu", "Tomi Kinnunen", "Nicholas W. D. Evans", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1280", 5, "interspeech", 2016], ["Articulation Rate Filtering of CQCC Features for Automatic Speaker Verification", ["Massimiliano Todisco", "Hector Delgado", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2016-1140", 5, "interspeech", 2016]], "Massimiliano Todisco": [0, ["Utterance Verification for Text-Dependent Speaker Recognition: A Comparative Assessment Using the RedDots Corpus", ["Tomi Kinnunen", "Md. Sahidullah", "Ivan Kukanov", "Hector Delgado", "Massimiliano Todisco", "Achintya Kumar Sarkar", "Nicolai Baek Thomsen", "Ville Hautamaki", "Nicholas W. D. Evans", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1125", 5, "interspeech", 2016], ["Integrated Spoofing Countermeasures and Automatic Speaker Verification: An Evaluation on ASVspoof 2015", ["Md. Sahidullah", "Hector Delgado", "Massimiliano Todisco", "Hong Yu", "Tomi Kinnunen", "Nicholas W. D. Evans", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1280", 5, "interspeech", 2016], ["Articulation Rate Filtering of CQCC Features for Automatic Speaker Verification", ["Massimiliano Todisco", "Hector Delgado", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2016-1140", 5, "interspeech", 2016]], "Nicolai Baek Thomsen": [0, ["Utterance Verification for Text-Dependent Speaker Recognition: A Comparative Assessment Using the RedDots Corpus", ["Tomi Kinnunen", "Md. Sahidullah", "Ivan Kukanov", "Hector Delgado", "Massimiliano Todisco", "Achintya Kumar Sarkar", "Nicolai Baek Thomsen", "Ville Hautamaki", "Nicholas W. D. Evans", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1125", 5, "interspeech", 2016], ["Speaker-Dependent Dictionary-Based Speech Enhancement for Text-Dependent Speaker Verification", ["Nicolai Baek Thomsen", "Dennis Alexander Lehmann Thomsen", "Zheng-Hua Tan", "Borge Lindberg", "Soren Holdt Jensen"], "https://doi.org/10.21437/Interspeech.2016-763", 5, "interspeech", 2016]], "Ville Hautamaki": [0, ["Utterance Verification for Text-Dependent Speaker Recognition: A Comparative Assessment Using the RedDots Corpus", ["Tomi Kinnunen", "Md. Sahidullah", "Ivan Kukanov", "Hector Delgado", "Massimiliano Todisco", "Achintya Kumar Sarkar", "Nicolai Baek Thomsen", "Ville Hautamaki", "Nicholas W. D. Evans", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1125", 5, "interspeech", 2016], ["Robust Speaker Recognition with Combined Use of Acoustic and Throat Microphone Speech", ["Md. Sahidullah", "Rosa Gonzalez Hautamaki", "Dennis Alexander Lehmann Thomsen", "Tomi Kinnunen", "Zheng-Hua Tan", "Ville Hautamaki", "Robert Parts", "Martti Pitkanen"], "https://doi.org/10.21437/Interspeech.2016-1153", 5, "interspeech", 2016], ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016], ["Variation in Spoken North Sami Language", ["Kristiina Jokinen", "Trung Ngo Trong", "Ville Hautamaki"], "https://doi.org/10.21437/Interspeech.2016-1438", 5, "interspeech", 2016]], "Nicholas W. D. Evans": [0, ["Utterance Verification for Text-Dependent Speaker Recognition: A Comparative Assessment Using the RedDots Corpus", ["Tomi Kinnunen", "Md. Sahidullah", "Ivan Kukanov", "Hector Delgado", "Massimiliano Todisco", "Achintya Kumar Sarkar", "Nicolai Baek Thomsen", "Ville Hautamaki", "Nicholas W. D. Evans", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1125", 5, "interspeech", 2016], ["Integrated Spoofing Countermeasures and Automatic Speaker Verification: An Evaluation on ASVspoof 2015", ["Md. Sahidullah", "Hector Delgado", "Massimiliano Todisco", "Hong Yu", "Tomi Kinnunen", "Nicholas W. D. Evans", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1280", 5, "interspeech", 2016], ["On the Influence of Text Content on Pass-Phrase Strength for Short-Duration Text-Dependent Automatic Speaker Authentication", ["Giacomo Valenti", "Adrien Daniel", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2016-1115", 5, "interspeech", 2016], ["Articulation Rate Filtering of CQCC Features for Automatic Speaker Verification", ["Massimiliano Todisco", "Hector Delgado", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2016-1140", 5, "interspeech", 2016]], "Jianbo Ma": [0, ["Parallel Speaker and Content Modelling for Text-Dependent Speaker Verification", ["Jianbo Ma", "Saad Irtza", "Kaavya Sriskandaraja", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2016-825", 5, "interspeech", 2016], ["Twin Model G-PLDA for Duration Mismatch Compensation in Text-Independent Speaker Verification", ["Jianbo Ma", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah", "Kong-Aik Lee"], "https://doi.org/10.21437/Interspeech.2016-683", 5, "interspeech", 2016]], "Saad Irtza": [0, ["Parallel Speaker and Content Modelling for Text-Dependent Speaker Verification", ["Jianbo Ma", "Saad Irtza", "Kaavya Sriskandaraja", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2016-825", 5, "interspeech", 2016], ["Out of Set Language Modelling in Hierarchical Language Identification", ["Saad Irtza", "Vidhyasaharan Sethu", "Sarith Fernando", "Eliathamby Ambikairajah", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-558", 5, "interspeech", 2016]], "Kaavya Sriskandaraja": [0, ["Parallel Speaker and Content Modelling for Text-Dependent Speaker Verification", ["Jianbo Ma", "Saad Irtza", "Kaavya Sriskandaraja", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2016-825", 5, "interspeech", 2016], ["Investigation of Sub-Band Discriminative Information Between Spoofed and Genuine Speech", ["Kaavya Sriskandaraja", "Vidhyasaharan Sethu", "Phu Ngoc Le", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2016-844", 5, "interspeech", 2016]], "Vidhyasaharan Sethu": [0, ["Parallel Speaker and Content Modelling for Text-Dependent Speaker Verification", ["Jianbo Ma", "Saad Irtza", "Kaavya Sriskandaraja", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2016-825", 5, "interspeech", 2016], ["Factor Analysis Based Speaker Normalisation for Continuous Emotion Prediction", ["Ting Dang", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2016-880", 5, "interspeech", 2016], ["Investigation of Sub-Band Discriminative Information Between Spoofed and Genuine Speech", ["Kaavya Sriskandaraja", "Vidhyasaharan Sethu", "Phu Ngoc Le", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2016-844", 5, "interspeech", 2016], ["Twin Model G-PLDA for Duration Mismatch Compensation in Text-Independent Speaker Verification", ["Jianbo Ma", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah", "Kong-Aik Lee"], "https://doi.org/10.21437/Interspeech.2016-683", 5, "interspeech", 2016], ["A Feature Normalisation Technique for PLLR Based Language Identification Systems", ["Sarith Fernando", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2016-560", 5, "interspeech", 2016], ["Out of Set Language Modelling in Hierarchical Language Identification", ["Saad Irtza", "Vidhyasaharan Sethu", "Sarith Fernando", "Eliathamby Ambikairajah", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-558", 5, "interspeech", 2016]], "Eliathamby Ambikairajah": [0, ["Parallel Speaker and Content Modelling for Text-Dependent Speaker Verification", ["Jianbo Ma", "Saad Irtza", "Kaavya Sriskandaraja", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2016-825", 5, "interspeech", 2016], ["Factor Analysis Based Speaker Normalisation for Continuous Emotion Prediction", ["Ting Dang", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2016-880", 5, "interspeech", 2016], ["Investigation of Sub-Band Discriminative Information Between Spoofed and Genuine Speech", ["Kaavya Sriskandaraja", "Vidhyasaharan Sethu", "Phu Ngoc Le", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2016-844", 5, "interspeech", 2016], ["Twin Model G-PLDA for Duration Mismatch Compensation in Text-Independent Speaker Verification", ["Jianbo Ma", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah", "Kong-Aik Lee"], "https://doi.org/10.21437/Interspeech.2016-683", 5, "interspeech", 2016], ["A Feature Normalisation Technique for PLLR Based Language Identification Systems", ["Sarith Fernando", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2016-560", 5, "interspeech", 2016], ["Out of Set Language Modelling in Hierarchical Language Identification", ["Saad Irtza", "Vidhyasaharan Sethu", "Sarith Fernando", "Eliathamby Ambikairajah", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-558", 5, "interspeech", 2016]], "Hossein Zeinali": [0, ["i-Vector/HMM Based Text-Dependent Speaker Verification System for RedDots Challenge", ["Hossein Zeinali", "Hossein Sameti", "Lukas Burget", "Jan Cernocky", "Nooshin Maghsoodi", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2016-1174", 5, "interspeech", 2016]], "Hossein Sameti": [0, ["i-Vector/HMM Based Text-Dependent Speaker Verification System for RedDots Challenge", ["Hossein Zeinali", "Hossein Sameti", "Lukas Burget", "Jan Cernocky", "Nooshin Maghsoodi", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2016-1174", 5, "interspeech", 2016]], "Lukas Burget": [0, ["i-Vector/HMM Based Text-Dependent Speaker Verification System for RedDots Challenge", ["Hossein Zeinali", "Hossein Sameti", "Lukas Burget", "Jan Cernocky", "Nooshin Maghsoodi", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2016-1174", 5, "interspeech", 2016], ["Learning Document Representations Using Subspace Multinomial Model", ["Santosh Kesiraju", "Lukas Burget", "Igor Szoke", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-1634", 5, "interspeech", 2016], ["Analysis of Speaker Recognition Systems in Realistic Scenarios of the SITW 2016 Challenge", ["Ondrej Novotny", "Pavel Matejka", "Oldrich Plchot", "Ondrej Glembek", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-981", 5, "interspeech", 2016], ["Data Selection by Sequence Summarizing Neural Network in Mismatch Condition Training", ["Katerina Zmolikova", "Martin Karafiat", "Karel Vesely", "Marc Delcroix", "Shinji Watanabe", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-741", 5, "interspeech", 2016], ["Exploiting Hidden-Layer Responses of Deep Neural Networks for Language Recognition", ["Ruizhi Li", "Sri Harish Reddy Mallidi", "Lukas Burget", "Oldrich Plchot", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2016-1584", 5, "interspeech", 2016], ["Sequence Summarizing Neural Networks for Spoken Language Recognition", ["Jan Pesan", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-764", 4, "interspeech", 2016]], "Jan Cernocky": [0, ["i-Vector/HMM Based Text-Dependent Speaker Verification System for RedDots Challenge", ["Hossein Zeinali", "Hossein Sameti", "Lukas Burget", "Jan Cernocky", "Nooshin Maghsoodi", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2016-1174", 5, "interspeech", 2016], ["Learning Document Representations Using Subspace Multinomial Model", ["Santosh Kesiraju", "Lukas Burget", "Igor Szoke", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-1634", 5, "interspeech", 2016], ["Analysis of Speaker Recognition Systems in Realistic Scenarios of the SITW 2016 Challenge", ["Ondrej Novotny", "Pavel Matejka", "Oldrich Plchot", "Ondrej Glembek", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-981", 5, "interspeech", 2016], ["Data Selection by Sequence Summarizing Neural Network in Mismatch Condition Training", ["Katerina Zmolikova", "Martin Karafiat", "Karel Vesely", "Marc Delcroix", "Shinji Watanabe", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-741", 5, "interspeech", 2016], ["Sequence Summarizing Neural Networks for Spoken Language Recognition", ["Jan Pesan", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-764", 4, "interspeech", 2016]], "Nooshin Maghsoodi": [0, ["i-Vector/HMM Based Text-Dependent Speaker Verification System for RedDots Challenge", ["Hossein Zeinali", "Hossein Sameti", "Lukas Burget", "Jan Cernocky", "Nooshin Maghsoodi", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2016-1174", 5, "interspeech", 2016]], "Pavel Matejka": [0, ["i-Vector/HMM Based Text-Dependent Speaker Verification System for RedDots Challenge", ["Hossein Zeinali", "Hossein Sameti", "Lukas Burget", "Jan Cernocky", "Nooshin Maghsoodi", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2016-1174", 5, "interspeech", 2016], ["Analysis of Speaker Recognition Systems in Realistic Scenarios of the SITW 2016 Challenge", ["Ondrej Novotny", "Pavel Matejka", "Oldrich Plchot", "Ondrej Glembek", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-981", 5, "interspeech", 2016], ["Enhancing Multilingual Recognition of Emotion in Speech by Language Identification", ["Hesam Sagha", "Pavel Matejka", "Maryna Gavryukova", "Filip Povolny", "Erik Marchi", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-333", 5, "interspeech", 2016]], "Rohan Kumar Das": [0, ["Exploring Session Variability and Template Aging in Speaker Verification for Fixed Phrase Short Utterances", ["Rohan Kumar Das", "Sarfaraz Jelil", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2016-1001", 5, "interspeech", 2016]], "Sarfaraz Jelil": [0, ["Exploring Session Variability and Template Aging in Speaker Verification for Fixed Phrase Short Utterances", ["Rohan Kumar Das", "Sarfaraz Jelil", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2016-1001", 5, "interspeech", 2016]], "Ganesh Sivaraman": [0, ["Vocal Tract Length Normalization for Speaker Independent Acoustic-to-Articulatory Speech Inversion", ["Ganesh Sivaraman", "Vikramjit Mitra", "Hosung Nam", "Mark K. Tiede", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2016-1399", 5, "interspeech", 2016]], "Vikramjit Mitra": [0, ["Vocal Tract Length Normalization for Speaker Independent Acoustic-to-Articulatory Speech Inversion", ["Ganesh Sivaraman", "Vikramjit Mitra", "Hosung Nam", "Mark K. Tiede", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2016-1399", 5, "interspeech", 2016], ["Unsupervised Learning of Acoustic Units Using Autoencoders and Kohonen Nets", ["Vikramjit Mitra", "Dimitra Vergyri", "Horacio Franco"], "https://doi.org/10.21437/Interspeech.2016-1374", 5, "interspeech", 2016], ["Automatic Speech Transcription for Low-Resource Languages - The Case of Yolox\u00f3chitl Mixtec (Mexico)", ["Vikramjit Mitra", "Andreas Kathol", "Jonathan D. Amith", "Rey Castillo Garcia"], "https://doi.org/10.21437/Interspeech.2016-546", 5, "interspeech", 2016], ["The SRI System for the NIST OpenSAD 2015 Speech Activity Detection Evaluation", ["Martin Graciarena", "Luciana Ferrer", "Vikramjit Mitra"], "https://doi.org/10.21437/Interspeech.2016-550", 5, "interspeech", 2016], ["Fusion Strategies for Robust Speech Recognition and Keyword Spotting for Channel- and Noise-Degraded Speech", ["Vikramjit Mitra", "Julien van Hout", "Wen Wang", "Chris Bartels", "Horacio Franco", "Dimitra Vergyri", "Abeer Alwan", "Adam Janin", "John H. L. Hansen", "Richard M. Stern", "Abhijeet Sangwan", "Nelson Morgan"], "https://doi.org/10.21437/Interspeech.2016-279", 5, "interspeech", 2016], ["Coping with Unseen Data Conditions: Investigating Neural Net Architectures, Robust Features, and Information Fusion for Robust Speech Recognition", ["Vikramjit Mitra", "Horacio Franco"], "https://doi.org/10.21437/Interspeech.2016-966", 5, "interspeech", 2016]], "Hosung Nam": [0.7784548997879028, ["Vocal Tract Length Normalization for Speaker Independent Acoustic-to-Articulatory Speech Inversion", ["Ganesh Sivaraman", "Vikramjit Mitra", "Hosung Nam", "Mark K. Tiede", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2016-1399", 5, "interspeech", 2016]], "Mark K. Tiede": [0, ["Vocal Tract Length Normalization for Speaker Independent Acoustic-to-Articulatory Speech Inversion", ["Ganesh Sivaraman", "Vikramjit Mitra", "Hosung Nam", "Mark K. Tiede", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2016-1399", 5, "interspeech", 2016]], "Carol Y. Espy-Wilson": [0, ["Vocal Tract Length Normalization for Speaker Independent Acoustic-to-Articulatory Speech Inversion", ["Ganesh Sivaraman", "Vikramjit Mitra", "Hosung Nam", "Mark K. Tiede", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2016-1399", 5, "interspeech", 2016], ["Speech Features for Depression Detection", ["Saurabh Sahu", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2016-1566", 5, "interspeech", 2016]], "Adam C. Lammert": [0, ["Investigation of Speed-Accuracy Tradeoffs in Speech Production Using Real-Time Magnetic Resonance Imaging", ["Adam C. Lammert", "Christine H. Shadle", "Shrikanth S. Narayanan", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2016-157", 5, "interspeech", 2016], ["Relation of Automatically Extracted Formant Trajectories with Intelligibility Loss and Speaking Rate Decline in Amyotrophic Lateral Sclerosis", ["Rachelle L. Horwitz-Martin", "Thomas F. Quatieri", "Adam C. Lammert", "James R. Williamson", "Yana Yunusova", "Elizabeth Godoy", "Daryush D. Mehta", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2016-403", 5, "interspeech", 2016]], "Christine H. Shadle": [0, ["Investigation of Speed-Accuracy Tradeoffs in Speech Production Using Real-Time Magnetic Resonance Imaging", ["Adam C. Lammert", "Christine H. Shadle", "Shrikanth S. Narayanan", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2016-157", 5, "interspeech", 2016]], "Thomas F. Quatieri": [0, ["Investigation of Speed-Accuracy Tradeoffs in Speech Production Using Real-Time Magnetic Resonance Imaging", ["Adam C. Lammert", "Christine H. Shadle", "Shrikanth S. Narayanan", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2016-157", 5, "interspeech", 2016], ["Relating Estimated Cyclic Spectral Peak Frequency to Measured Epilarynx Length Using Magnetic Resonance Imaging", ["Elizabeth Godoy", "Andrew Dumas", "Jennifer Melot", "Nicolas Malyska", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2016-1362", 5, "interspeech", 2016], ["Neurophysiological Vocal Source Modeling for Biomarkers of Disease", ["Gregory Ciccarelli", "Thomas F. Quatieri", "Satrajit S. Ghosh"], "https://doi.org/10.21437/Interspeech.2016-292", 5, "interspeech", 2016], ["Relation of Automatically Extracted Formant Trajectories with Intelligibility Loss and Speaking Rate Decline in Amyotrophic Lateral Sclerosis", ["Rachelle L. Horwitz-Martin", "Thomas F. Quatieri", "Adam C. Lammert", "James R. Williamson", "Yana Yunusova", "Elizabeth Godoy", "Daryush D. Mehta", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2016-403", 5, "interspeech", 2016], ["A Framework for Automated Marmoset Vocalization Detection and Classification", ["Alan Wisler", "Laura J. Brattain", "Rogier Landman", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2016-1410", 5, "interspeech", 2016]], "Tanner Sorensen": [0, ["Characterizing Vocal Tract Dynamics Across Speakers Using Real-Time MRI", ["Tanner Sorensen", "Asterios Toutios", "Louis Goldstein", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-583", 5, "interspeech", 2016], ["Articulatory Synthesis Based on Real-Time Magnetic Resonance Imaging Data", ["Asterios Toutios", "Tanner Sorensen", "Krishna Somandepalli", "Rachel Alexander", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-596", 5, "interspeech", 2016]], "Asterios Toutios": [0, ["Characterizing Vocal Tract Dynamics Across Speakers Using Real-Time MRI", ["Tanner Sorensen", "Asterios Toutios", "Louis Goldstein", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-583", 5, "interspeech", 2016], ["State-of-the-Art MRI Protocol for Comprehensive Assessment of Vocal Tract Structure and Function", ["Sajan Goud Lingala", "Asterios Toutios", "Johannes Toger", "Yongwan Lim", "Yinghua Zhu", "Yoon-Chul Kim", "Colin Vaz", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-559", 5, "interspeech", 2016], ["Convex Hull Convolutive Non-Negative Matrix Factorization for Uncovering Temporal Patterns in Multivariate Time-Series Data", ["Colin Vaz", "Asterios Toutios", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-571", 5, "interspeech", 2016], ["Articulatory Synthesis Based on Real-Time Magnetic Resonance Imaging Data", ["Asterios Toutios", "Tanner Sorensen", "Krishna Somandepalli", "Rachel Alexander", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-596", 5, "interspeech", 2016], ["Improved Depiction of Tissue Boundaries in Vocal Tract Real-Time MRI Using Automatic Off-Resonance Correction", ["Yongwan Lim", "Sajan Goud Lingala", "Asterios Toutios", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-664", 5, "interspeech", 2016], ["Illustrating the Production of the International Phonetic Alphabet Sounds Using Fast Real-Time Magnetic Resonance Imaging", ["Asterios Toutios", "Sajan Goud Lingala", "Colin Vaz", "Jangwon Kim", "John H. Esling", "Patricia A. Keating", "Matthew Gordon", "Dani Byrd", "Louis Goldstein", "Krishna S. Nayak", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-605", 5, "interspeech", 2016]], "Mathieu Labrunie": [0, ["Tracking Contours of Orofacial Articulators from Real-Time MRI of Speech", ["Mathieu Labrunie", "Pierre Badin", "Dirk Voit", "Arun A. Joseph", "Laurent Lamalle", "Coriandre Vilain", "Louis-Jean Boe", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2016-78", 5, "interspeech", 2016]], "Pierre Badin": [0, ["Tracking Contours of Orofacial Articulators from Real-Time MRI of Speech", ["Mathieu Labrunie", "Pierre Badin", "Dirk Voit", "Arun A. Joseph", "Laurent Lamalle", "Coriandre Vilain", "Louis-Jean Boe", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2016-78", 5, "interspeech", 2016], ["Using a Biomechanical Model and Articulatory Data for the Numerical Production of Vowels", ["Saeed Dabbaghchian", "Marc Arnela", "Olov Engwall", "Oriol Guasch", "Ian Stavness", "Pierre Badin"], "https://doi.org/10.21437/Interspeech.2016-1500", 5, "interspeech", 2016]], "Dirk Voit": [0, ["Tracking Contours of Orofacial Articulators from Real-Time MRI of Speech", ["Mathieu Labrunie", "Pierre Badin", "Dirk Voit", "Arun A. Joseph", "Laurent Lamalle", "Coriandre Vilain", "Louis-Jean Boe", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2016-78", 5, "interspeech", 2016]], "Arun A. Joseph": [0, ["Tracking Contours of Orofacial Articulators from Real-Time MRI of Speech", ["Mathieu Labrunie", "Pierre Badin", "Dirk Voit", "Arun A. Joseph", "Laurent Lamalle", "Coriandre Vilain", "Louis-Jean Boe", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2016-78", 5, "interspeech", 2016]], "Laurent Lamalle": [0, ["Tracking Contours of Orofacial Articulators from Real-Time MRI of Speech", ["Mathieu Labrunie", "Pierre Badin", "Dirk Voit", "Arun A. Joseph", "Laurent Lamalle", "Coriandre Vilain", "Louis-Jean Boe", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2016-78", 5, "interspeech", 2016]], "Coriandre Vilain": [0, ["Tracking Contours of Orofacial Articulators from Real-Time MRI of Speech", ["Mathieu Labrunie", "Pierre Badin", "Dirk Voit", "Arun A. Joseph", "Laurent Lamalle", "Coriandre Vilain", "Louis-Jean Boe", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2016-78", 5, "interspeech", 2016]], "Louis-Jean Boe": [0, ["Tracking Contours of Orofacial Articulators from Real-Time MRI of Speech", ["Mathieu Labrunie", "Pierre Badin", "Dirk Voit", "Arun A. Joseph", "Laurent Lamalle", "Coriandre Vilain", "Louis-Jean Boe", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2016-78", 5, "interspeech", 2016]], "Jens Frahm": [0, ["Tracking Contours of Orofacial Articulators from Real-Time MRI of Speech", ["Mathieu Labrunie", "Pierre Badin", "Dirk Voit", "Arun A. Joseph", "Laurent Lamalle", "Coriandre Vilain", "Louis-Jean Boe", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2016-78", 5, "interspeech", 2016]], "Yinghua Zhu": [0, ["State-of-the-Art MRI Protocol for Comprehensive Assessment of Vocal Tract Structure and Function", ["Sajan Goud Lingala", "Asterios Toutios", "Johannes Toger", "Yongwan Lim", "Yinghua Zhu", "Yoon-Chul Kim", "Colin Vaz", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-559", 5, "interspeech", 2016]], "Yoon-Chul Kim": [0.9999954402446747, ["State-of-the-Art MRI Protocol for Comprehensive Assessment of Vocal Tract Structure and Function", ["Sajan Goud Lingala", "Asterios Toutios", "Johannes Toger", "Yongwan Lim", "Yinghua Zhu", "Yoon-Chul Kim", "Colin Vaz", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-559", 5, "interspeech", 2016]], "Colin Vaz": [0, ["State-of-the-Art MRI Protocol for Comprehensive Assessment of Vocal Tract Structure and Function", ["Sajan Goud Lingala", "Asterios Toutios", "Johannes Toger", "Yongwan Lim", "Yinghua Zhu", "Yoon-Chul Kim", "Colin Vaz", "Shrikanth S. Narayanan", "Krishna S. Nayak"], "https://doi.org/10.21437/Interspeech.2016-559", 5, "interspeech", 2016], ["Convex Hull Convolutive Non-Negative Matrix Factorization for Uncovering Temporal Patterns in Multivariate Time-Series Data", ["Colin Vaz", "Asterios Toutios", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-571", 5, "interspeech", 2016], ["Illustrating the Production of the International Phonetic Alphabet Sounds Using Fast Real-Time Magnetic Resonance Imaging", ["Asterios Toutios", "Sajan Goud Lingala", "Colin Vaz", "Jangwon Kim", "John H. Esling", "Patricia A. Keating", "Matthew Gordon", "Dani Byrd", "Louis Goldstein", "Krishna S. Nayak", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-605", 5, "interspeech", 2016], ["Noise Aware and Combined Noise Models for Speech Denoising in Unknown Noise Conditions", ["Pavlos Papadopoulos", "Colin Vaz", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-501", 4, "interspeech", 2016]], "Rui Xia": [0, ["DBN-ivector Framework for Acoustic Emotion Recognition", ["Rui Xia", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2016-488", 5, "interspeech", 2016]], "Yang Liu": [0, ["DBN-ivector Framework for Acoustic Emotion Recognition", ["Rui Xia", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2016-488", 5, "interspeech", 2016]], "Brian Stasak": [0, ["An Investigation of Emotional Speech in Depression Classification", ["Brian Stasak", "Julien Epps", "Nicholas Cummins", "Roland Goecke"], "https://doi.org/10.21437/Interspeech.2016-867", 5, "interspeech", 2016]], "Nicholas Cummins": [0, ["An Investigation of Emotional Speech in Depression Classification", ["Brian Stasak", "Julien Epps", "Nicholas Cummins", "Roland Goecke"], "https://doi.org/10.21437/Interspeech.2016-867", 5, "interspeech", 2016]], "Roland Goecke": [0, ["An Investigation of Emotional Speech in Depression Classification", ["Brian Stasak", "Julien Epps", "Nicholas Cummins", "Roland Goecke"], "https://doi.org/10.21437/Interspeech.2016-867", 5, "interspeech", 2016], ["Cross-Cultural Depression Recognition from Vocal Biomarkers", ["Sharifa Alghowinem", "Roland Goecke", "Julien Epps", "Michael Wagner", "Jeffrey F. Cohn"], "https://doi.org/10.21437/Interspeech.2016-1339", 5, "interspeech", 2016]], "Reza Lotfian": [0, ["Retrieving Categorical Emotions Using a Probabilistic Framework to Define Preference Learning Samples", ["Reza Lotfian", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2016-1052", 5, "interspeech", 2016]], "Maximilian Schmitt": [0, ["At the Border of Acoustics and Linguistics: Bag-of-Audio-Words for the Recognition of Emotions in Speech", ["Maximilian Schmitt", "Fabien Ringeval", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-1124", 5, "interspeech", 2016]], "Fabien Ringeval": [0, ["At the Border of Acoustics and Linguistics: Bag-of-Audio-Words for the Recognition of Emotions in Speech", ["Maximilian Schmitt", "Fabien Ringeval", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-1124", 5, "interspeech", 2016], ["Automatic Analysis of Typical and Atypical Encoding of Spontaneous Emotion in the Voice of Children", ["Fabien Ringeval", "Erik Marchi", "Charline Grossard", "Jean Xavier", "Mohamed Chetouani", "David Cohen", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-766", 5, "interspeech", 2016], ["Facing Realism in Spontaneous Emotion Recognition from Speech: Feature Enhancement by Autoencoder with LSTM Neural Networks", ["Zixing Zhang", "Fabien Ringeval", "Jing Han", "Jun Deng", "Erik Marchi", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-998", 5, "interspeech", 2016]], "Bjorn W. Schuller": [0, ["At the Border of Acoustics and Linguistics: Bag-of-Audio-Words for the Recognition of Emotions in Speech", ["Maximilian Schmitt", "Fabien Ringeval", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-1124", 5, "interspeech", 2016], ["Real-Time Tracking of Speakers' Emotions, States, and Traits on Mobile Platforms", ["Erik Marchi", "Florian Eyben", "Gerhard Hagerer", "Bjorn W. Schuller"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2015.html", 2, "interspeech", 2016], ["Automatic Analysis of Typical and Atypical Encoding of Spontaneous Emotion in the Voice of Children", ["Fabien Ringeval", "Erik Marchi", "Charline Grossard", "Jean Xavier", "Mohamed Chetouani", "David Cohen", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-766", 5, "interspeech", 2016], ["Does She Speak RTT? Towards an Earlier Identification of Rett Syndrome Through Intelligent Pre-Linguistic Vocalisation Analysis", ["Florian B. Pokorny", "Peter B. Marschik", "Christa Einspieler", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-520", 5, "interspeech", 2016], ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: Deception, Sincerity & Native Language", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "https://doi.org/10.21437/Interspeech.2016-129", 5, "interspeech", 2016], ["The Deception Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs5.html", 0, "interspeech", 2016], ["Is Deception Emotional? An Emotion-Driven Predictive Approach", ["Shahin Amiriparian", "Jouni Pohjalainen", "Erik Marchi", "Sergey Pugachevskiy", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-565", 5, "interspeech", 2016], ["The Sincerity Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs6.html", 0, "interspeech", 2016], ["Sincerity and Deception in Speech: Two Sides of the Same Coin? A Transfer- and Multi-Task Learning Perspective", ["Yue Zhang", "Felix Weninger", "Zhao Ren", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-1305", 5, "interspeech", 2016], ["The Native Language Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs11.html", 0, "interspeech", 2016], ["Convolutional Neural Networks with Data Augmentation for Classifying Speakers' Native Language", ["Gil Keren", "Jun Deng", "Jouni Pohjalainen", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-261", 5, "interspeech", 2016], ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: A Summary of Results", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs12.html", 0, "interspeech", 2016], ["Discussion", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs13.html", 0, "interspeech", 2016], ["Deep Bidirectional Long Short-Term Memory Recurrent Neural Networks for Grapheme-to-Phoneme Conversion Utilizing Complex Many-to-Many Alignments", ["Amr El-Desoky Mousa", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-1229", 5, "interspeech", 2016], ["Enhancing Multilingual Recognition of Emotion in Speech by Language Identification", ["Hesam Sagha", "Pavel Matejka", "Maryna Gavryukova", "Filip Povolny", "Erik Marchi", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-333", 5, "interspeech", 2016], ["Manual versus Automated: The Challenging Routine of Infant Vocalisation Segmentation in Home Videos to Study Neuro(mal)development", ["Florian B. Pokorny", "Robert Peharz", "Wolfgang Roth", "Matthias Zohrer", "Franz Pernkopf", "Peter B. Marschik", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-1341", 5, "interspeech", 2016], ["Facing Realism in Spontaneous Emotion Recognition from Speech: Feature Enhancement by Autoencoder with LSTM Neural Networks", ["Zixing Zhang", "Fabien Ringeval", "Jing Han", "Jun Deng", "Erik Marchi", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-998", 5, "interspeech", 2016]], "Arodami Chorianopoulou": [0, ["Speech Emotion Recognition Using Affective Saliency", ["Arodami Chorianopoulou", "Polychronis Koutsakis", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2016-1311", 5, "interspeech", 2016], ["Root Cause Analysis of Miscommunication Hotspots in Spoken Dialogue Systems", ["Spiros Georgiladakis", "Georgia Athanasopoulou", "Raveesh Meena", "Jose Lopes", "Arodami Chorianopoulou", "Elisavet Palogiannidi", "Elias Iosif", "Gabriel Skantze", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2016-1273", 5, "interspeech", 2016]], "Polychronis Koutsakis": [0, ["Speech Emotion Recognition Using Affective Saliency", ["Arodami Chorianopoulou", "Polychronis Koutsakis", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2016-1311", 5, "interspeech", 2016]], "Alexandros Potamianos": [0, ["Speech Emotion Recognition Using Affective Saliency", ["Arodami Chorianopoulou", "Polychronis Koutsakis", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2016-1311", 5, "interspeech", 2016], ["Root Cause Analysis of Miscommunication Hotspots in Spoken Dialogue Systems", ["Spiros Georgiladakis", "Georgia Athanasopoulou", "Raveesh Meena", "Jose Lopes", "Arodami Chorianopoulou", "Elisavet Palogiannidi", "Elias Iosif", "Gabriel Skantze", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2016-1273", 5, "interspeech", 2016], ["Audio-Based Distributional Representations of Meaning Using a Fusion of Feature Encodings", ["Giannis Karamanolakis", "Elias Iosif", "Athanasia Zlatintsi", "Aggelos Pikrakis", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2016-839", 5, "interspeech", 2016]], "Rahul Gupta": [0, ["Laughter Valence Prediction in Motivational Interviewing Based on Lexical and Acoustic Cues", ["Rahul Gupta", "Nishant Nath", "Taruna Agrawal", "Panayiotis G. Georgiou", "David C. Atkins", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-184", 5, "interspeech", 2016], ["Acoustic-Prosodic and Turn-Taking Features in Interactions with Children with Neurodevelopmental Disorders", ["Daniel Bone", "Somer Bishop", "Rahul Gupta", "Sungbok Lee", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1073", 5, "interspeech", 2016], ["Predicting Affective Dimensions Based on Self Assessed Depression Severity", ["Rahul Gupta", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-187", 5, "interspeech", 2016], ["An Expectation Maximization Approach to Joint Modeling of Multidimensional Ratings Derived from Multiple Annotators", ["Anil Ramakrishna", "Rahul Gupta", "Ruth B. Grossman", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-270", 5, "interspeech", 2016], ["Automatic Estimation of Perceived Sincerity from Spoken Language", ["Brandon M. Booth", "Rahul Gupta", "Pavlos Papadopoulos", "Ruchir Travadi", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1537", 5, "interspeech", 2016], ["Objective Language Feature Analysis in Children with Neurodevelopmental Disorders During Autism Assessment", ["Manoj Kumar", "Rahul Gupta", "Daniel Bone", "Nikolaos Malandrakis", "Somer Bishop", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-563", 5, "interspeech", 2016]], "Nishant Nath": [0, ["Laughter Valence Prediction in Motivational Interviewing Based on Lexical and Acoustic Cues", ["Rahul Gupta", "Nishant Nath", "Taruna Agrawal", "Panayiotis G. Georgiou", "David C. Atkins", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-184", 5, "interspeech", 2016]], "Taruna Agrawal": [0, ["Laughter Valence Prediction in Motivational Interviewing Based on Lexical and Acoustic Cues", ["Rahul Gupta", "Nishant Nath", "Taruna Agrawal", "Panayiotis G. Georgiou", "David C. Atkins", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-184", 5, "interspeech", 2016]], "Panayiotis G. Georgiou": [0, ["Laughter Valence Prediction in Motivational Interviewing Based on Lexical and Acoustic Cues", ["Rahul Gupta", "Nishant Nath", "Taruna Agrawal", "Panayiotis G. Georgiou", "David C. Atkins", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-184", 5, "interspeech", 2016], ["Complexity in Prosody: A Nonlinear Dynamical Systems Approach for Dyadic Conversations; Behavior and Outcomes in Couples Therapy", ["Md. Nasir", "Brian R. Baucom", "Shrikanth S. Narayanan", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2016-1367", 5, "interspeech", 2016], ["Couples Behavior Modeling and Annotation Using Low-Resource LSTM Language Models", ["Shao-Yen Tseng", "Sandeep Nallan Chakravarthula", "Brian R. Baucom", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2016-1186", 5, "interspeech", 2016], ["Behavioral Coding of Therapist Language in Addiction Counseling Using Recurrent Neural Networks", ["Bo Xiao", "Dogan Can", "James Gibson", "Zac E. Imel", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1560", 5, "interspeech", 2016], ["Sparsely Connected and Disjointly Trained Deep Neural Networks for Low Resource Behavioral Annotation: Acoustic Classification in Couples' Therapy", ["Haoqi Li", "Brian R. Baucom", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2016-1217", 5, "interspeech", 2016], ["A Deep Learning Approach to Modeling Empathy in Addiction Counseling", ["James Gibson", "Dogan Can", "Bo Xiao", "Zac E. Imel", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-554", 5, "interspeech", 2016], ["Robust Multichannel Gender Classification from Speech in Movie Audio", ["Naveen Kumar", "Md. Nasir", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-540", 5, "interspeech", 2016], ["Multimodal Fusion of Multirate Acoustic, Prosodic, and Lexical Speaker Characteristics for Native Language Identification", ["Prashanth Gurunath Shivakumar", "Sandeep Nallan Chakravarthula", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2016-1312", 5, "interspeech", 2016], ["Perception Optimized Deep Denoising AutoEncoders for Speech Enhancement", ["Prashanth Gurunath Shivakumar", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2016-1284", 5, "interspeech", 2016]], "David C. Atkins": [0, ["Laughter Valence Prediction in Motivational Interviewing Based on Lexical and Acoustic Cues", ["Rahul Gupta", "Nishant Nath", "Taruna Agrawal", "Panayiotis G. Georgiou", "David C. Atkins", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-184", 5, "interspeech", 2016], ["Behavioral Coding of Therapist Language in Addiction Counseling Using Recurrent Neural Networks", ["Bo Xiao", "Dogan Can", "James Gibson", "Zac E. Imel", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1560", 5, "interspeech", 2016], ["A Deep Learning Approach to Modeling Empathy in Addiction Counseling", ["James Gibson", "Dogan Can", "Bo Xiao", "Zac E. Imel", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-554", 5, "interspeech", 2016]], "Marcin Wlodarczak": [0, ["Respiratory Belts and Whistles: A Preliminary Study of Breathing Acoustics for Turn-Taking", ["Marcin Wlodarczak", "Mattias Heldner"], "https://doi.org/10.21437/Interspeech.2016-344", 5, "interspeech", 2016], ["Respiratory Turn-Taking Cues", ["Marcin Wlodarczak", "Mattias Heldner"], "https://doi.org/10.21437/Interspeech.2016-346", 5, "interspeech", 2016]], "Mattias Heldner": [0, ["Respiratory Belts and Whistles: A Preliminary Study of Breathing Acoustics for Turn-Taking", ["Marcin Wlodarczak", "Mattias Heldner"], "https://doi.org/10.21437/Interspeech.2016-344", 5, "interspeech", 2016], ["The Acoustics of Lexical Stress in Italian as a Function of Stress Level and Speaking Style", ["Anders Eriksson", "Pier Marco Bertinetto", "Mattias Heldner", "Rosalba Nodari", "Giovanna Lenoci"], "https://doi.org/10.21437/Interspeech.2016-348", 5, "interspeech", 2016], ["Respiratory Turn-Taking Cues", ["Marcin Wlodarczak", "Mattias Heldner"], "https://doi.org/10.21437/Interspeech.2016-346", 5, "interspeech", 2016]], "Constantijn Kaland": [0, ["/r/ as Language Marker in Bilingual Speech Production and Perception", ["Constantijn Kaland", "Vincenzo Galata", "Lorenzo Spreafico", "Alessandro Vietti"], "https://doi.org/10.21437/Interspeech.2016-418", 5, "interspeech", 2016], ["An Acoustic Analysis of /r/ in Tyrolean", ["Vincenzo Galata", "Lorenzo Spreafico", "Alessandro Vietti", "Constantijn Kaland"], "https://doi.org/10.21437/Interspeech.2016-434", 5, "interspeech", 2016]], "Vincenzo Galata": [0, ["/r/ as Language Marker in Bilingual Speech Production and Perception", ["Constantijn Kaland", "Vincenzo Galata", "Lorenzo Spreafico", "Alessandro Vietti"], "https://doi.org/10.21437/Interspeech.2016-418", 5, "interspeech", 2016], ["An Acoustic Analysis of /r/ in Tyrolean", ["Vincenzo Galata", "Lorenzo Spreafico", "Alessandro Vietti", "Constantijn Kaland"], "https://doi.org/10.21437/Interspeech.2016-434", 5, "interspeech", 2016]], "Lorenzo Spreafico": [0, ["/r/ as Language Marker in Bilingual Speech Production and Perception", ["Constantijn Kaland", "Vincenzo Galata", "Lorenzo Spreafico", "Alessandro Vietti"], "https://doi.org/10.21437/Interspeech.2016-418", 5, "interspeech", 2016], ["An Acoustic Analysis of /r/ in Tyrolean", ["Vincenzo Galata", "Lorenzo Spreafico", "Alessandro Vietti", "Constantijn Kaland"], "https://doi.org/10.21437/Interspeech.2016-434", 5, "interspeech", 2016]], "Alessandro Vietti": [0, ["/r/ as Language Marker in Bilingual Speech Production and Perception", ["Constantijn Kaland", "Vincenzo Galata", "Lorenzo Spreafico", "Alessandro Vietti"], "https://doi.org/10.21437/Interspeech.2016-418", 5, "interspeech", 2016], ["An Acoustic Analysis of /r/ in Tyrolean", ["Vincenzo Galata", "Lorenzo Spreafico", "Alessandro Vietti", "Constantijn Kaland"], "https://doi.org/10.21437/Interspeech.2016-434", 5, "interspeech", 2016]], "Manfred Putzer": [0, ["Evaluation of Phonatory Behavior of German and French Speakers in Native and Non-Native Speech", ["Manfred Putzer", "Frank Zimmerer", "Wolfgang Wokurek", "Jeanin Jugler"], "https://doi.org/10.21437/Interspeech.2016-49", 5, "interspeech", 2016]], "Wolfgang Wokurek": [0, ["Evaluation of Phonatory Behavior of German and French Speakers in Native and Non-Native Speech", ["Manfred Putzer", "Frank Zimmerer", "Wolfgang Wokurek", "Jeanin Jugler"], "https://doi.org/10.21437/Interspeech.2016-49", 5, "interspeech", 2016]], "Sofia Strombergsson": [0, ["Today's Most Frequently Used F0 Estimation Methods, and Their Accuracy in Estimating Male and Female Pitch in Clean Speech", ["Sofia Strombergsson"], "https://doi.org/10.21437/Interspeech.2016-240", 5, "interspeech", 2016]], "Lei He": [0, ["A Praat-Based Algorithm to Extract the Amplitude Envelope and Temporal Fine Structure Using the Hilbert Transform", ["Lei He", "Volker Dellwo"], "https://doi.org/10.21437/Interspeech.2016-1447", 5, "interspeech", 2016]], "Volker Dellwo": [0, ["A Praat-Based Algorithm to Extract the Amplitude Envelope and Temporal Fine Structure Using the Hilbert Transform", ["Lei He", "Volker Dellwo"], "https://doi.org/10.21437/Interspeech.2016-1447", 5, "interspeech", 2016]], "Ewald Enzinger": [0, ["Likelihood Ratio Calculation in Acoustic-Phonetic Forensic Voice Comparison: Comparison of Three Statistical Modelling Approaches", ["Ewald Enzinger"], "https://doi.org/10.21437/Interspeech.2016-1611", 5, "interspeech", 2016]], "Xiaoke Qi": [0, ["A Sparse Spherical Harmonic-Based Model in Subbands for Head-Related Transfer Functions", ["Xiaoke Qi", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2016-987", 5, "interspeech", 2016]], "Jianhua Tao": [0, ["A Sparse Spherical Harmonic-Based Model in Subbands for Head-Related Transfer Functions", ["Xiaoke Qi", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2016-987", 5, "interspeech", 2016], ["The Parameterized Phoneme Identity Feature as a Continuous Real-Valued Vector for Neural Network Based Speech Synthesis", ["Zhengqi Wen", "Ya Li", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2016-222", 5, "interspeech", 2016], ["Improving Prosodic Boundaries Prediction for Mandarin Speech Synthesis by Using Enhanced Embedding Feature and Model Fusion Approach", ["Yibin Zheng", "Ya Li", "Zhengqi Wen", "Xingguang Ding", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2016-1060", 5, "interspeech", 2016], ["A Novel Research to Artificial Bandwidth Extension Based on Deep BLSTM Recurrent Neural Networks and Exemplar-Based Sparse Representation", ["Bin Liu", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2016-772", 5, "interspeech", 2016]], "Yusuf Isik": [0, ["Single-Channel Multi-Speaker Separation Using Deep Clustering", ["Yusuf Isik", "Jonathan Le Roux", "Zhuo Chen", "Shinji Watanabe", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2016-1176", 5, "interspeech", 2016]], "Jonathan Le Roux": [0, ["Single-Channel Multi-Speaker Separation Using Deep Clustering", ["Yusuf Isik", "Jonathan Le Roux", "Zhuo Chen", "Shinji Watanabe", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2016-1176", 5, "interspeech", 2016], ["Improved MVDR Beamforming Using Single-Channel Mask Prediction Networks", ["Hakan Erdogan", "John R. Hershey", "Shinji Watanabe", "Michael I. Mandel", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2016-552", 5, "interspeech", 2016]], "Zhuo Chen": [0, ["Single-Channel Multi-Speaker Separation Using Deep Clustering", ["Yusuf Isik", "Jonathan Le Roux", "Zhuo Chen", "Shinji Watanabe", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2016-1176", 5, "interspeech", 2016], ["Adaptation of Neural Networks Constrained by Prior Statistics of Node Co-Activations", ["Tasha Nagamine", "Zhuo Chen", "Nima Mesgarani"], "https://doi.org/10.21437/Interspeech.2016-600", 5, "interspeech", 2016]], "Shinji Watanabe": [0, ["Single-Channel Multi-Speaker Separation Using Deep Clustering", ["Yusuf Isik", "Jonathan Le Roux", "Zhuo Chen", "Shinji Watanabe", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2016-1176", 5, "interspeech", 2016], ["Improved MVDR Beamforming Using Single-Channel Mask Prediction Networks", ["Hakan Erdogan", "John R. Hershey", "Shinji Watanabe", "Michael I. Mandel", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2016-552", 5, "interspeech", 2016], ["Data Selection by Sequence Summarizing Neural Network in Mismatch Condition Training", ["Katerina Zmolikova", "Martin Karafiat", "Karel Vesely", "Marc Delcroix", "Shinji Watanabe", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-741", 5, "interspeech", 2016], ["Context-Sensitive and Role-Dependent Spoken Language Understanding Using Bidirectional and Attention LSTMs", ["Chiori Hori", "Takaaki Hori", "Shinji Watanabe", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2016-1171", 5, "interspeech", 2016]], "John R. Hershey": [0, ["Single-Channel Multi-Speaker Separation Using Deep Clustering", ["Yusuf Isik", "Jonathan Le Roux", "Zhuo Chen", "Shinji Watanabe", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2016-1176", 5, "interspeech", 2016], ["Improved MVDR Beamforming Using Single-Channel Mask Prediction Networks", ["Hakan Erdogan", "John R. Hershey", "Shinji Watanabe", "Michael I. Mandel", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2016-552", 5, "interspeech", 2016], ["Context-Sensitive and Role-Dependent Spoken Language Understanding Using Bidirectional and Attention LSTMs", ["Chiori Hori", "Takaaki Hori", "Shinji Watanabe", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2016-1171", 5, "interspeech", 2016]], "Hao Li": [0, ["Jointly Optimizing Activation Coefficients of Convolutive NMF Using DNN for Speech Separation", ["Hao Li", "Shuai Nie", "Xueliang Zhang", "Hui Zhang"], "https://doi.org/10.21437/Interspeech.2016-120", 5, "interspeech", 2016]], "Shuai Nie": [0, ["Jointly Optimizing Activation Coefficients of Convolutive NMF Using DNN for Speech Separation", ["Hao Li", "Shuai Nie", "Xueliang Zhang", "Hui Zhang"], "https://doi.org/10.21437/Interspeech.2016-120", 5, "interspeech", 2016]], "Xueliang Zhang": [0, ["Jointly Optimizing Activation Coefficients of Convolutive NMF Using DNN for Speech Separation", ["Hao Li", "Shuai Nie", "Xueliang Zhang", "Hui Zhang"], "https://doi.org/10.21437/Interspeech.2016-120", 5, "interspeech", 2016]], "Hui Zhang": [0, ["Jointly Optimizing Activation Coefficients of Convolutive NMF Using DNN for Speech Separation", ["Hao Li", "Shuai Nie", "Xueliang Zhang", "Hui Zhang"], "https://doi.org/10.21437/Interspeech.2016-120", 5, "interspeech", 2016]], "Masood Delfarah": [0, ["A Feature Study for Masking-Based Reverberant Speech Separation", ["Masood Delfarah", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2016-382", 5, "interspeech", 2016]], "DeLiang Wang": [0.0001271418914257083, ["A Feature Study for Masking-Based Reverberant Speech Separation", ["Masood Delfarah", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2016-382", 5, "interspeech", 2016], ["Long Short-Term Memory for Speaker Generalization in Supervised Speech Separation", ["Jitong Chen", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2016-551", 5, "interspeech", 2016]], "Chung-Chien Hsu": [0, ["Discriminative Layered Nonnegative Matrix Factorization for Speech Separation", ["Chung-Chien Hsu", "Tai-Shih Chi", "Jen-Tzung Chien"], "https://doi.org/10.21437/Interspeech.2016-415", 5, "interspeech", 2016]], "Tai-Shih Chi": [0, ["Discriminative Layered Nonnegative Matrix Factorization for Speech Separation", ["Chung-Chien Hsu", "Tai-Shih Chi", "Jen-Tzung Chien"], "https://doi.org/10.21437/Interspeech.2016-415", 5, "interspeech", 2016], ["A Spectral Modulation Sensitivity Weighted Pre-Emphasis Filter for Active Noise Control System", ["Kah-Meng Cheong", "Yuh-Yuan Wang", "Tai-Shih Chi"], "https://doi.org/10.21437/Interspeech.2016-757", 5, "interspeech", 2016]], "Jen-Tzung Chien": [0, ["Discriminative Layered Nonnegative Matrix Factorization for Speech Separation", ["Chung-Chien Hsu", "Tai-Shih Chi", "Jen-Tzung Chien"], "https://doi.org/10.21437/Interspeech.2016-415", 5, "interspeech", 2016], ["Hybrid Accelerated Optimization for Speech Recognition", ["Jen-Tzung Chien", "Pei-Wen Huang", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2016-192", 5, "interspeech", 2016]], "Arpita Gang": [3.9162716038848577e-13, ["On Discriminative Framework for Single Channel Audio Source Separation", ["Arpita Gang", "Pravesh Biyani"], "https://doi.org/10.21437/Interspeech.2016-701", 5, "interspeech", 2016]], "Pravesh Biyani": [0, ["On Discriminative Framework for Single Channel Audio Source Separation", ["Arpita Gang", "Pravesh Biyani"], "https://doi.org/10.21437/Interspeech.2016-701", 5, "interspeech", 2016]], "Qin Jin": [8.872746002452914e-05, ["Generating Natural Video Descriptions via Multimodal Processing", ["Qin Jin", "Junwei Liang", "Xiaozhu Lin"], "https://doi.org/10.21437/Interspeech.2016-380", 5, "interspeech", 2016]], "Junwei Liang": [0, ["Generating Natural Video Descriptions via Multimodal Processing", ["Qin Jin", "Junwei Liang", "Xiaozhu Lin"], "https://doi.org/10.21437/Interspeech.2016-380", 5, "interspeech", 2016]], "Xiaozhu Lin": [0, ["Generating Natural Video Descriptions via Multimodal Processing", ["Qin Jin", "Junwei Liang", "Xiaozhu Lin"], "https://doi.org/10.21437/Interspeech.2016-380", 5, "interspeech", 2016]], "Martin Heckmann": [0, ["Feature-Level Decision Fusion for Audio-Visual Word Prominence Detection", ["Martin Heckmann"], "https://doi.org/10.21437/Interspeech.2016-163", 5, "interspeech", 2016]], "Slim Ouni": [0, ["Acoustic and Visual Analysis of Expressive Speech: A Case Study of French Acted Speech", ["Slim Ouni", "Vincent Colotte", "Sara Dahmani", "Soumaya Azzi"], "https://doi.org/10.21437/Interspeech.2016-730", 5, "interspeech", 2016]], "Vincent Colotte": [0, ["Acoustic and Visual Analysis of Expressive Speech: A Case Study of French Acted Speech", ["Slim Ouni", "Vincent Colotte", "Sara Dahmani", "Soumaya Azzi"], "https://doi.org/10.21437/Interspeech.2016-730", 5, "interspeech", 2016]], "Sara Dahmani": [0, ["Acoustic and Visual Analysis of Expressive Speech: A Case Study of French Acted Speech", ["Slim Ouni", "Vincent Colotte", "Sara Dahmani", "Soumaya Azzi"], "https://doi.org/10.21437/Interspeech.2016-730", 5, "interspeech", 2016]], "Soumaya Azzi": [0, ["Acoustic and Visual Analysis of Expressive Speech: A Case Study of French Acted Speech", ["Slim Ouni", "Vincent Colotte", "Sara Dahmani", "Soumaya Azzi"], "https://doi.org/10.21437/Interspeech.2016-730", 5, "interspeech", 2016]], "Adela Barbulescu": [0, ["Characterization of Audiovisual Dramatic Attitudes", ["Adela Barbulescu", "Remi Ronfard", "Gerard Bailly"], "https://doi.org/10.21437/Interspeech.2016-75", 5, "interspeech", 2016]], "Remi Ronfard": [0, ["Characterization of Audiovisual Dramatic Attitudes", ["Adela Barbulescu", "Remi Ronfard", "Gerard Bailly"], "https://doi.org/10.21437/Interspeech.2016-75", 5, "interspeech", 2016]], "Yuyun Huang": [0, ["Conversational Engagement Recognition Using Auditory and Visual Cues", ["Yuyun Huang", "Emer Gilmartin", "Nick Campbell"], "https://doi.org/10.21437/Interspeech.2016-846", 5, "interspeech", 2016]], "Emer Gilmartin": [0, ["Conversational Engagement Recognition Using Auditory and Visual Cues", ["Yuyun Huang", "Emer Gilmartin", "Nick Campbell"], "https://doi.org/10.21437/Interspeech.2016-846", 5, "interspeech", 2016]], "Nick Campbell": [0, ["Conversational Engagement Recognition Using Auditory and Visual Cues", ["Yuyun Huang", "Emer Gilmartin", "Nick Campbell"], "https://doi.org/10.21437/Interspeech.2016-846", 5, "interspeech", 2016], ["Talking to a System and Talking to a Human: A Study from a Speech-to-Speech, Machine Translation Mediated Map Task", ["Hayakawa Akira", "Saturnino Luz", "Nick Campbell"], "https://doi.org/10.21437/Interspeech.2016-1623", 5, "interspeech", 2016]], "Theodora Chaspari": [0, ["An Acoustic Analysis of Child-Child and Child-Robot Interactions for Understanding Engagement during Speech-Controlled Computer Games", ["Theodora Chaspari", "Jill Fain Lehman"], "https://doi.org/10.21437/Interspeech.2016-85", 5, "interspeech", 2016]], "Jill Fain Lehman": [0, ["An Acoustic Analysis of Child-Child and Child-Robot Interactions for Understanding Engagement during Speech-Controlled Computer Games", ["Theodora Chaspari", "Jill Fain Lehman"], "https://doi.org/10.21437/Interspeech.2016-85", 5, "interspeech", 2016], ["Estimation of Children's Physical Characteristics from Their Voices", ["Jill Fain Lehman", "Rita Singh"], "https://doi.org/10.21437/Interspeech.2016-146", 5, "interspeech", 2016]], "Benjawan Kasisopa": [0, ["Auditory-Visual Lexical Tone Perception in Thai Elderly Listeners with and without Hearing Impairment", ["Benjawan Kasisopa", "Chutamanee Onsuwan", "Charturong Tantibundhit", "Nittayapa Klangpornkun", "Suparak Techacharoenrungrueang", "Sudaporn Luksaneeyanawin", "Denis Burnham"], "https://doi.org/10.21437/Interspeech.2016-908", 5, "interspeech", 2016]], "Chutamanee Onsuwan": [0, ["Auditory-Visual Lexical Tone Perception in Thai Elderly Listeners with and without Hearing Impairment", ["Benjawan Kasisopa", "Chutamanee Onsuwan", "Charturong Tantibundhit", "Nittayapa Klangpornkun", "Suparak Techacharoenrungrueang", "Sudaporn Luksaneeyanawin", "Denis Burnham"], "https://doi.org/10.21437/Interspeech.2016-908", 5, "interspeech", 2016]], "Charturong Tantibundhit": [0, ["Auditory-Visual Lexical Tone Perception in Thai Elderly Listeners with and without Hearing Impairment", ["Benjawan Kasisopa", "Chutamanee Onsuwan", "Charturong Tantibundhit", "Nittayapa Klangpornkun", "Suparak Techacharoenrungrueang", "Sudaporn Luksaneeyanawin", "Denis Burnham"], "https://doi.org/10.21437/Interspeech.2016-908", 5, "interspeech", 2016]], "Nittayapa Klangpornkun": [0, ["Auditory-Visual Lexical Tone Perception in Thai Elderly Listeners with and without Hearing Impairment", ["Benjawan Kasisopa", "Chutamanee Onsuwan", "Charturong Tantibundhit", "Nittayapa Klangpornkun", "Suparak Techacharoenrungrueang", "Sudaporn Luksaneeyanawin", "Denis Burnham"], "https://doi.org/10.21437/Interspeech.2016-908", 5, "interspeech", 2016]], "Suparak Techacharoenrungrueang": [0, ["Auditory-Visual Lexical Tone Perception in Thai Elderly Listeners with and without Hearing Impairment", ["Benjawan Kasisopa", "Chutamanee Onsuwan", "Charturong Tantibundhit", "Nittayapa Klangpornkun", "Suparak Techacharoenrungrueang", "Sudaporn Luksaneeyanawin", "Denis Burnham"], "https://doi.org/10.21437/Interspeech.2016-908", 5, "interspeech", 2016]], "Sudaporn Luksaneeyanawin": [0, ["Auditory-Visual Lexical Tone Perception in Thai Elderly Listeners with and without Hearing Impairment", ["Benjawan Kasisopa", "Chutamanee Onsuwan", "Charturong Tantibundhit", "Nittayapa Klangpornkun", "Suparak Techacharoenrungrueang", "Sudaporn Luksaneeyanawin", "Denis Burnham"], "https://doi.org/10.21437/Interspeech.2016-908", 5, "interspeech", 2016]], "Denis Burnham": [0, ["Auditory-Visual Lexical Tone Perception in Thai Elderly Listeners with and without Hearing Impairment", ["Benjawan Kasisopa", "Chutamanee Onsuwan", "Charturong Tantibundhit", "Nittayapa Klangpornkun", "Suparak Techacharoenrungrueang", "Sudaporn Luksaneeyanawin", "Denis Burnham"], "https://doi.org/10.21437/Interspeech.2016-908", 5, "interspeech", 2016]], "Hossein Khaki": [0, ["Use of Agreement/Disagreement Classification in Dyadic Interactions for Continuous Emotion Recognition", ["Hossein Khaki", "Engin Erzin"], "https://doi.org/10.21437/Interspeech.2016-407", 5, "interspeech", 2016]], "Engin Erzin": [0, ["Use of Agreement/Disagreement Classification in Dyadic Interactions for Continuous Emotion Recognition", ["Hossein Khaki", "Engin Erzin"], "https://doi.org/10.21437/Interspeech.2016-407", 5, "interspeech", 2016]], "Marc Rene Schadler": [0, ["Microscopic Multilingual Matrix Test Predictions Using an ASR-Based Speech Recognition Model", ["Marc Rene Schadler", "David Hulsmeier", "Anna Warzybok", "Sabine Hochmuth", "Birger Kollmeier"], "https://doi.org/10.21437/Interspeech.2016-1119", 5, "interspeech", 2016], ["Why do ASR Systems Despite Neural Nets Still Depend on Robust Features", ["Angel Mario Castro Martinez", "Marc Rene Schadler"], "https://doi.org/10.21437/Interspeech.2016-1552", 5, "interspeech", 2016]], "David Hulsmeier": [0, ["Microscopic Multilingual Matrix Test Predictions Using an ASR-Based Speech Recognition Model", ["Marc Rene Schadler", "David Hulsmeier", "Anna Warzybok", "Sabine Hochmuth", "Birger Kollmeier"], "https://doi.org/10.21437/Interspeech.2016-1119", 5, "interspeech", 2016]], "Anna Warzybok": [0, ["Microscopic Multilingual Matrix Test Predictions Using an ASR-Based Speech Recognition Model", ["Marc Rene Schadler", "David Hulsmeier", "Anna Warzybok", "Sabine Hochmuth", "Birger Kollmeier"], "https://doi.org/10.21437/Interspeech.2016-1119", 5, "interspeech", 2016]], "Sabine Hochmuth": [0, ["Microscopic Multilingual Matrix Test Predictions Using an ASR-Based Speech Recognition Model", ["Marc Rene Schadler", "David Hulsmeier", "Anna Warzybok", "Sabine Hochmuth", "Birger Kollmeier"], "https://doi.org/10.21437/Interspeech.2016-1119", 5, "interspeech", 2016]], "Birger Kollmeier": [0, ["Microscopic Multilingual Matrix Test Predictions Using an ASR-Based Speech Recognition Model", ["Marc Rene Schadler", "David Hulsmeier", "Anna Warzybok", "Sabine Hochmuth", "Birger Kollmeier"], "https://doi.org/10.21437/Interspeech.2016-1119", 5, "interspeech", 2016]], "Mats Exter": [0, ["DNN-Based Automatic Speech Recognition as a Model for Human Phoneme Perception", ["Mats Exter", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2016-1285", 5, "interspeech", 2016]], "Bernd T. Meyer": [0, ["DNN-Based Automatic Speech Recognition as a Model for Human Phoneme Perception", ["Mats Exter", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2016-1285", 5, "interspeech", 2016], ["Introducing Temporal Rate Coding for Speech in Cochlear Implants: A Microscopic Evaluation in Humans and Models", ["Anja Eichenauer", "Mathias Dietz", "Bernd T. Meyer", "Tim Jurgens"], "https://doi.org/10.21437/Interspeech.2016-267", 5, "interspeech", 2016], ["Neural Responses to Speech-Specific Modulations Derived from a Spectro-Temporal Filter Bank", ["Marina Frye", "Cristiano Micheli", "Inga M. Schepers", "Gerwin Schalk", "Jochem W. Rieger", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2016-1327", 5, "interspeech", 2016], ["Assessing Speech Quality in Speech-Aware Hearing Aids Based on Phoneme Posteriorgrams", ["Constantin Spille", "Hendrik Kayser", "Hynek Hermansky", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2016-1318", 5, "interspeech", 2016]], "Mate Attila Toth": [0, ["Undoing Misperceptions: A Microscopic Analysis of Consistent Confusions Through Signal Modifications", ["Mate Attila Toth", "Martin Cooke"], "https://doi.org/10.21437/Interspeech.2016-1030", 5, "interspeech", 2016], ["Misperceptions Arising from Speech-in-Babble Interactions", ["Mate Attila Toth", "Martin Cooke", "Jon Barker"], "https://doi.org/10.21437/Interspeech.2016-24", 5, "interspeech", 2016]], "Martin Cooke": [0, ["Undoing Misperceptions: A Microscopic Analysis of Consistent Confusions Through Signal Modifications", ["Mate Attila Toth", "Martin Cooke"], "https://doi.org/10.21437/Interspeech.2016-1030", 5, "interspeech", 2016], ["Misperceptions Arising from Speech-in-Babble Interactions", ["Mate Attila Toth", "Martin Cooke", "Jon Barker"], "https://doi.org/10.21437/Interspeech.2016-24", 5, "interspeech", 2016], ["Language Effects in Noise-Induced Word Misperceptions", ["Maria Luisa Garcia Lecumberri", "Jon Barker", "Ricard Marxer", "Martin Cooke"], "https://doi.org/10.21437/Interspeech.2016-330", 5, "interspeech", 2016], ["The Effects of Modified Speech Styles on Intelligibility for Non-Native Listeners", ["Martin Cooke", "Maria Luisa Garcia Lecumberri"], "https://doi.org/10.21437/Interspeech.2016-41", 5, "interspeech", 2016], ["Can Intensive Exposure to Foreign Language Sounds Affect the Perception of Native Sounds?", ["Jian Gong", "Maria Luisa Garcia Lecumberri", "Martin Cooke"], "https://doi.org/10.21437/Interspeech.2016-76", 5, "interspeech", 2016], ["Glimpse-Based Metrics for Predicting Speech Intelligibility in Additive Noise Conditions", ["Yan Tang", "Martin Cooke"], "https://doi.org/10.21437/Interspeech.2016-14", 5, "interspeech", 2016]], "Mahdie Karbasi": [0, ["Blind Non-Intrusive Speech Intelligibility Prediction Using Twin-HMMs", ["Mahdie Karbasi", "Ahmed Hussen Abdelaziz", "Hendrik Meutzner", "Dorothea Kolossa"], "https://doi.org/10.21437/Interspeech.2016-155", 5, "interspeech", 2016]], "Ahmed Hussen Abdelaziz": [0, ["Blind Non-Intrusive Speech Intelligibility Prediction Using Twin-HMMs", ["Mahdie Karbasi", "Ahmed Hussen Abdelaziz", "Hendrik Meutzner", "Dorothea Kolossa"], "https://doi.org/10.21437/Interspeech.2016-155", 5, "interspeech", 2016], ["Introducing the Turbo-Twin-HMM for Audio-Visual Speech Enhancement", ["Steffen Zeiler", "Hendrik Meutzner", "Ahmed Hussen Abdelaziz", "Dorothea Kolossa"], "https://doi.org/10.21437/Interspeech.2016-350", 5, "interspeech", 2016], ["Dynamic Stream Weighting for Turbo-Decoding-Based Audiovisual ASR", ["Sebastian Gergen", "Steffen Zeiler", "Ahmed Hussen Abdelaziz", "Robert M. Nickel", "Dorothea Kolossa"], "https://doi.org/10.21437/Interspeech.2016-166", 5, "interspeech", 2016]], "Hendrik Meutzner": [0, ["Blind Non-Intrusive Speech Intelligibility Prediction Using Twin-HMMs", ["Mahdie Karbasi", "Ahmed Hussen Abdelaziz", "Hendrik Meutzner", "Dorothea Kolossa"], "https://doi.org/10.21437/Interspeech.2016-155", 5, "interspeech", 2016], ["Introducing the Turbo-Twin-HMM for Audio-Visual Speech Enhancement", ["Steffen Zeiler", "Hendrik Meutzner", "Ahmed Hussen Abdelaziz", "Dorothea Kolossa"], "https://doi.org/10.21437/Interspeech.2016-350", 5, "interspeech", 2016]], "Dorothea Kolossa": [0, ["Blind Non-Intrusive Speech Intelligibility Prediction Using Twin-HMMs", ["Mahdie Karbasi", "Ahmed Hussen Abdelaziz", "Hendrik Meutzner", "Dorothea Kolossa"], "https://doi.org/10.21437/Interspeech.2016-155", 5, "interspeech", 2016], ["Introducing the Turbo-Twin-HMM for Audio-Visual Speech Enhancement", ["Steffen Zeiler", "Hendrik Meutzner", "Ahmed Hussen Abdelaziz", "Dorothea Kolossa"], "https://doi.org/10.21437/Interspeech.2016-350", 5, "interspeech", 2016], ["Dynamic Stream Weighting for Turbo-Decoding-Based Audiovisual ASR", ["Sebastian Gergen", "Steffen Zeiler", "Ahmed Hussen Abdelaziz", "Robert M. Nickel", "Dorothea Kolossa"], "https://doi.org/10.21437/Interspeech.2016-166", 5, "interspeech", 2016]], "Jon Barker": [0, ["Misperceptions Arising from Speech-in-Babble Interactions", ["Mate Attila Toth", "Martin Cooke", "Jon Barker"], "https://doi.org/10.21437/Interspeech.2016-24", 5, "interspeech", 2016], ["Language Effects in Noise-Induced Word Misperceptions", ["Maria Luisa Garcia Lecumberri", "Jon Barker", "Ricard Marxer", "Martin Cooke"], "https://doi.org/10.21437/Interspeech.2016-330", 5, "interspeech", 2016], ["Multichannel Spatial Clustering for Robust Far-Field Automatic Speech Recognition in Mismatched Conditions", ["Michael I. Mandel", "Jon Barker"], "https://doi.org/10.21437/Interspeech.2016-1275", 5, "interspeech", 2016], ["Use of Generalised Nonlinearity in Vector Taylor Series Noise Compensation for Robust Speech Recognition", ["Erfan Loweimi", "Jon Barker", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-1028", 5, "interspeech", 2016]], "Anja Eichenauer": [0, ["Introducing Temporal Rate Coding for Speech in Cochlear Implants: A Microscopic Evaluation in Humans and Models", ["Anja Eichenauer", "Mathias Dietz", "Bernd T. Meyer", "Tim Jurgens"], "https://doi.org/10.21437/Interspeech.2016-267", 5, "interspeech", 2016]], "Mathias Dietz": [0, ["Introducing Temporal Rate Coding for Speech in Cochlear Implants: A Microscopic Evaluation in Humans and Models", ["Anja Eichenauer", "Mathias Dietz", "Bernd T. Meyer", "Tim Jurgens"], "https://doi.org/10.21437/Interspeech.2016-267", 5, "interspeech", 2016]], "Tim Jurgens": [0, ["Introducing Temporal Rate Coding for Speech in Cochlear Implants: A Microscopic Evaluation in Humans and Models", ["Anja Eichenauer", "Mathias Dietz", "Bernd T. Meyer", "Tim Jurgens"], "https://doi.org/10.21437/Interspeech.2016-267", 5, "interspeech", 2016]], "Maria Luisa Garcia Lecumberri": [0, ["Language Effects in Noise-Induced Word Misperceptions", ["Maria Luisa Garcia Lecumberri", "Jon Barker", "Ricard Marxer", "Martin Cooke"], "https://doi.org/10.21437/Interspeech.2016-330", 5, "interspeech", 2016], ["The Effects of Modified Speech Styles on Intelligibility for Non-Native Listeners", ["Martin Cooke", "Maria Luisa Garcia Lecumberri"], "https://doi.org/10.21437/Interspeech.2016-41", 5, "interspeech", 2016], ["Can Intensive Exposure to Foreign Language Sounds Affect the Perception of Native Sounds?", ["Jian Gong", "Maria Luisa Garcia Lecumberri", "Martin Cooke"], "https://doi.org/10.21437/Interspeech.2016-76", 5, "interspeech", 2016]], "Ricard Marxer": [0, ["Language Effects in Noise-Induced Word Misperceptions", ["Maria Luisa Garcia Lecumberri", "Jon Barker", "Ricard Marxer", "Martin Cooke"], "https://doi.org/10.21437/Interspeech.2016-330", 5, "interspeech", 2016], ["CloudCAST - Remote Speech Technology for Speech Professionals", ["Phil D. Green", "Ricard Marxer", "Stuart P. Cunningham", "Heidi Christensen", "Frank Rudzicz", "Maria Yancheva", "Andre Coy", "Massimiliano Malavasi", "Lorenzo Desideri", "Fabio Tamburini"], "https://doi.org/10.21437/Interspeech.2016-148", 5, "interspeech", 2016], ["Progress and Prospects for Spoken Language Technology: Results from Four Sexennial Surveys", ["Roger K. Moore", "Ricard Marxer"], "https://doi.org/10.21437/Interspeech.2016-948", 5, "interspeech", 2016]], "Leo Varnet": [0, ["Speech Reductions Cause a De-Weighting of Secondary Acoustic Cues", ["Leo Varnet", "Fanny Meunier", "Michel Hoen"], "https://doi.org/10.21437/Interspeech.2016-343", 5, "interspeech", 2016]], "Fanny Meunier": [0, ["Speech Reductions Cause a De-Weighting of Secondary Acoustic Cues", ["Leo Varnet", "Fanny Meunier", "Michel Hoen"], "https://doi.org/10.21437/Interspeech.2016-343", 5, "interspeech", 2016], ["Categorization of Natural Spanish Whistled Vowels by Na\u00efve Spanish Listeners", ["Julien Meyer", "Laure Dentel", "Fanny Meunier"], "https://doi.org/10.21437/Interspeech.2016-379", 4, "interspeech", 2016]], "Michel Hoen": [0, ["Speech Reductions Cause a De-Weighting of Secondary Acoustic Cues", ["Leo Varnet", "Fanny Meunier", "Michel Hoen"], "https://doi.org/10.21437/Interspeech.2016-343", 5, "interspeech", 2016]], "Lionel Fontan": [0, ["Using Phonologically Weighted Levenshtein Distances for the Prediction of Microscopic Intelligibility", ["Lionel Fontan", "Isabelle Ferrane", "Jerome Farinas", "Julien Pinquier", "Xavier Aumont"], "https://doi.org/10.21437/Interspeech.2016-431", 5, "interspeech", 2016], ["Pronunciation Assessment of Japanese Learners of French with GOP Scores and Phonetic Information", ["Vincent Laborde", "Thomas Pellegrini", "Lionel Fontan", "Julie Mauclair", "Halima Sahraoui", "Jerome Farinas"], "https://doi.org/10.21437/Interspeech.2016-513", 5, "interspeech", 2016]], "Isabelle Ferrane": [0, ["Using Phonologically Weighted Levenshtein Distances for the Prediction of Microscopic Intelligibility", ["Lionel Fontan", "Isabelle Ferrane", "Jerome Farinas", "Julien Pinquier", "Xavier Aumont"], "https://doi.org/10.21437/Interspeech.2016-431", 5, "interspeech", 2016]], "Jerome Farinas": [0, ["Using Phonologically Weighted Levenshtein Distances for the Prediction of Microscopic Intelligibility", ["Lionel Fontan", "Isabelle Ferrane", "Jerome Farinas", "Julien Pinquier", "Xavier Aumont"], "https://doi.org/10.21437/Interspeech.2016-431", 5, "interspeech", 2016], ["Pronunciation Assessment of Japanese Learners of French with GOP Scores and Phonetic Information", ["Vincent Laborde", "Thomas Pellegrini", "Lionel Fontan", "Julie Mauclair", "Halima Sahraoui", "Jerome Farinas"], "https://doi.org/10.21437/Interspeech.2016-513", 5, "interspeech", 2016]], "Julien Pinquier": [0, ["Using Phonologically Weighted Levenshtein Distances for the Prediction of Microscopic Intelligibility", ["Lionel Fontan", "Isabelle Ferrane", "Jerome Farinas", "Julien Pinquier", "Xavier Aumont"], "https://doi.org/10.21437/Interspeech.2016-431", 5, "interspeech", 2016], ["CNN-Based Phone Segmentation Experiments in a Less-Represented Language", ["Celine Manenti", "Thomas Pellegrini", "Julien Pinquier"], "https://doi.org/10.21437/Interspeech.2016-796", 5, "interspeech", 2016]], "Xavier Aumont": [0, ["Using Phonologically Weighted Levenshtein Distances for the Prediction of Microscopic Intelligibility", ["Lionel Fontan", "Isabelle Ferrane", "Jerome Farinas", "Julien Pinquier", "Xavier Aumont"], "https://doi.org/10.21437/Interspeech.2016-431", 5, "interspeech", 2016]], "Mayuki Matsui": [0, ["The Impact of Manner of Articulation on the Intelligibility of Voicing Contrast in Noise: Cross-Linguistic Implications", ["Mayuki Matsui"], "https://doi.org/10.21437/Interspeech.2016-697", 5, "interspeech", 2016]], "Michael I. Mandel": [0, ["Directly Comparing the Listening Strategies of Humans and Machines", ["Michael I. Mandel"], "https://doi.org/10.21437/Interspeech.2016-932", 5, "interspeech", 2016], ["Improved MVDR Beamforming Using Single-Channel Mask Prediction Networks", ["Hakan Erdogan", "John R. Hershey", "Shinji Watanabe", "Michael I. Mandel", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2016-552", 5, "interspeech", 2016], ["Multichannel Spatial Clustering for Robust Far-Field Automatic Speech Recognition in Mismatched Conditions", ["Michael I. Mandel", "Jon Barker"], "https://doi.org/10.21437/Interspeech.2016-1275", 5, "interspeech", 2016]], "Marc-Antoine Rondeau": [0, ["LSTM-Based NeuroCRFs for Named Entity Recognition", ["Marc-Antoine Rondeau", "Yi Su"], "https://doi.org/10.21437/Interspeech.2016-288", 5, "interspeech", 2016]], "Yi Su": [0, ["LSTM-Based NeuroCRFs for Named Entity Recognition", ["Marc-Antoine Rondeau", "Yi Su"], "https://doi.org/10.21437/Interspeech.2016-288", 5, "interspeech", 2016]], "Shih-Hung Liu": [0, ["Exploring Word Mover's Distance and Semantic-Aware Embedding Techniques for Extractive Broadcast News Summarization", ["Shih-Hung Liu", "Kuan-Yu Chen", "Yu-Lun Hsieh", "Berlin Chen", "Hsin-Min Wang", "Hsu-Chun Yen", "Wen-Lian Hsu"], "https://doi.org/10.21437/Interspeech.2016-710", 5, "interspeech", 2016]], "Kuan-Yu Chen": [0, ["Exploring Word Mover's Distance and Semantic-Aware Embedding Techniques for Extractive Broadcast News Summarization", ["Shih-Hung Liu", "Kuan-Yu Chen", "Yu-Lun Hsieh", "Berlin Chen", "Hsin-Min Wang", "Hsu-Chun Yen", "Wen-Lian Hsu"], "https://doi.org/10.21437/Interspeech.2016-710", 5, "interspeech", 2016]], "Yu-Lun Hsieh": [0, ["Exploring Word Mover's Distance and Semantic-Aware Embedding Techniques for Extractive Broadcast News Summarization", ["Shih-Hung Liu", "Kuan-Yu Chen", "Yu-Lun Hsieh", "Berlin Chen", "Hsin-Min Wang", "Hsu-Chun Yen", "Wen-Lian Hsu"], "https://doi.org/10.21437/Interspeech.2016-710", 5, "interspeech", 2016]], "Berlin Chen": [0, ["Exploring Word Mover's Distance and Semantic-Aware Embedding Techniques for Extractive Broadcast News Summarization", ["Shih-Hung Liu", "Kuan-Yu Chen", "Yu-Lun Hsieh", "Berlin Chen", "Hsin-Min Wang", "Hsu-Chun Yen", "Wen-Lian Hsu"], "https://doi.org/10.21437/Interspeech.2016-710", 5, "interspeech", 2016], ["Mispronunciation Detection Leveraging Maximum Performance Criterion Training of Acoustic Models and Decision Functions", ["Yao-Chi Hsu", "Ming-Han Yang", "Hsiao-Tsung Hung", "Berlin Chen"], "https://doi.org/10.21437/Interspeech.2016-1602", 5, "interspeech", 2016]], "Hsin-Min Wang": [0.0006203135271789506, ["Exploring Word Mover's Distance and Semantic-Aware Embedding Techniques for Extractive Broadcast News Summarization", ["Shih-Hung Liu", "Kuan-Yu Chen", "Yu-Lun Hsieh", "Berlin Chen", "Hsin-Min Wang", "Hsu-Chun Yen", "Wen-Lian Hsu"], "https://doi.org/10.21437/Interspeech.2016-710", 5, "interspeech", 2016], ["Locally Linear Embedding for Exemplar-Based Spectral Conversion", ["Yi-Chiao Wu", "Hsin-Te Hwang", "Chin-Cheng Hsu", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2016-567", 5, "interspeech", 2016], ["Minimization of Regression and Ranking Losses with Shallow Neural Networks on Automatic Sincerity Evaluation", ["Hung-Shin Lee", "Yu Tsao", "Chi-Chun Lee", "Hsin-Min Wang", "Wei-Cheng Lin", "Wei-Chen Chen", "Shan-Wen Hsiao", "Shyh-Kang Jeng"], "https://doi.org/10.21437/Interspeech.2016-756", 5, "interspeech", 2016]], "Hsu-Chun Yen": [0, ["Exploring Word Mover's Distance and Semantic-Aware Embedding Techniques for Extractive Broadcast News Summarization", ["Shih-Hung Liu", "Kuan-Yu Chen", "Yu-Lun Hsieh", "Berlin Chen", "Hsin-Min Wang", "Hsu-Chun Yen", "Wen-Lian Hsu"], "https://doi.org/10.21437/Interspeech.2016-710", 5, "interspeech", 2016]], "Wen-Lian Hsu": [0, ["Exploring Word Mover's Distance and Semantic-Aware Embedding Techniques for Extractive Broadcast News Summarization", ["Shih-Hung Liu", "Kuan-Yu Chen", "Yu-Lun Hsieh", "Berlin Chen", "Hsin-Min Wang", "Hsu-Chun Yen", "Wen-Lian Hsu"], "https://doi.org/10.21437/Interspeech.2016-710", 5, "interspeech", 2016]], "Imran A. Sheikh": [0, ["Improved Neural Bag-of-Words Model to Retrieve Out-of-Vocabulary Words in Speech Recognition", ["Imran A. Sheikh", "Irina Illina", "Dominique Fohr", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2016-1219", 5, "interspeech", 2016]], "Irina Illina": [0, ["Improved Neural Bag-of-Words Model to Retrieve Out-of-Vocabulary Words in Speech Recognition", ["Imran A. Sheikh", "Irina Illina", "Dominique Fohr", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2016-1219", 5, "interspeech", 2016], ["A French Corpus for Distant-Microphone Speech Processing in Real Homes", ["Nancy Bertin", "Ewen Camberlein", "Emmanuel Vincent", "Romain Lebarbenchon", "Stephane Peillon", "Eric Lamande", "Sunit Sivasankaran", "Frederic Bimbot", "Irina Illina", "Ariane Tom", "Sylvain Fleury", "Eric Jamet"], "https://doi.org/10.21437/Interspeech.2016-1384", 5, "interspeech", 2016]], "Dominique Fohr": [0, ["Improved Neural Bag-of-Words Model to Retrieve Out-of-Vocabulary Words in Speech Recognition", ["Imran A. Sheikh", "Irina Illina", "Dominique Fohr", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2016-1219", 5, "interspeech", 2016]], "Georges Linares": [0, ["Improved Neural Bag-of-Words Model to Retrieve Out-of-Vocabulary Words in Speech Recognition", ["Imran A. Sheikh", "Irina Illina", "Dominique Fohr", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2016-1219", 5, "interspeech", 2016], ["Spoken Language Understanding in a Latent Topic-Based Subspace", ["Mohamed Morchid", "Mohamed Bouaziz", "Waad Ben Kheder", "Killian Janod", "Pierre-Michel Bousquet", "Richard Dufour", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2016-50", 5, "interspeech", 2016], ["Deep Stacked Autoencoders for Spoken Language Understanding", ["Killian Janod", "Mohamed Morchid", "Richard Dufour", "Georges Linares", "Renato De Mori"], "https://doi.org/10.21437/Interspeech.2016-63", 5, "interspeech", 2016]], "Jeremy Trione": [0, ["Beyond Utterance Extraction: Summary Recombination for Speech Summarization", ["Jeremy Trione", "Benoit Favre", "Frederic Bechet"], "https://doi.org/10.21437/Interspeech.2016-855", 5, "interspeech", 2016]], "Benoit Favre": [0, ["Beyond Utterance Extraction: Summary Recombination for Speech Summarization", ["Jeremy Trione", "Benoit Favre", "Frederic Bechet"], "https://doi.org/10.21437/Interspeech.2016-855", 5, "interspeech", 2016], ["Joint Syntactic and Semantic Analysis with a Multitask Deep Learning Framework for Spoken Language Understanding", ["Jeremie Tafforeau", "Frederic Bechet", "Thierry Artieres", "Benoit Favre"], "https://doi.org/10.21437/Interspeech.2016-851", 5, "interspeech", 2016]], "Frederic Bechet": [0, ["Beyond Utterance Extraction: Summary Recombination for Speech Summarization", ["Jeremy Trione", "Benoit Favre", "Frederic Bechet"], "https://doi.org/10.21437/Interspeech.2016-855", 5, "interspeech", 2016], ["Joint Syntactic and Semantic Analysis with a Multitask Deep Learning Framework for Spoken Language Understanding", ["Jeremie Tafforeau", "Frederic Bechet", "Thierry Artieres", "Benoit Favre"], "https://doi.org/10.21437/Interspeech.2016-851", 5, "interspeech", 2016]], "Bing Liu": [0, ["Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling", ["Bing Liu", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2016-1352", 5, "interspeech", 2016]], "Ian Lane": [0, ["Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling", ["Bing Liu", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2016-1352", 5, "interspeech", 2016], ["Speaker-Targeted Audio-Visual Models for Speech Recognition in Cocktail-Party Environments", ["Guan-Lin Chao", "William Chan", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2016-599", 5, "interspeech", 2016], ["On Online Attention-Based Speech Recognition and Joint Mandarin Character-Pinyin Training", ["William Chan", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2016-334", 5, "interspeech", 2016]], "Aaron Jaech": [0, ["Domain Adaptation of Recurrent Neural Networks for Natural Language Understanding", ["Aaron Jaech", "Larry P. Heck", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2016-1598", 5, "interspeech", 2016]], "Larry P. Heck": [0, ["Domain Adaptation of Recurrent Neural Networks for Natural Language Understanding", ["Aaron Jaech", "Larry P. Heck", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2016-1598", 5, "interspeech", 2016]], "Mari Ostendorf": [0, ["Domain Adaptation of Recurrent Neural Networks for Natural Language Understanding", ["Aaron Jaech", "Larry P. Heck", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2016-1598", 5, "interspeech", 2016], ["Disfluency Detection Using a Bidirectional LSTM", ["Vicky Zayats", "Mari Ostendorf", "Hannaneh Hajishirzi"], "https://doi.org/10.21437/Interspeech.2016-1247", 5, "interspeech", 2016]], "Faisal Ladhak": [0, ["LatticeRnn: Recurrent Neural Networks Over Lattices", ["Faisal Ladhak", "Ankur Gandhe", "Markus Dreyer", "Lambert Mathias", "Ariya Rastrow", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2016-1583", 5, "interspeech", 2016]], "Ankur Gandhe": [0, ["LatticeRnn: Recurrent Neural Networks Over Lattices", ["Faisal Ladhak", "Ankur Gandhe", "Markus Dreyer", "Lambert Mathias", "Ariya Rastrow", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2016-1583", 5, "interspeech", 2016]], "Markus Dreyer": [0, ["LatticeRnn: Recurrent Neural Networks Over Lattices", ["Faisal Ladhak", "Ankur Gandhe", "Markus Dreyer", "Lambert Mathias", "Ariya Rastrow", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2016-1583", 5, "interspeech", 2016]], "Lambert Mathias": [0, ["LatticeRnn: Recurrent Neural Networks Over Lattices", ["Faisal Ladhak", "Ankur Gandhe", "Markus Dreyer", "Lambert Mathias", "Ariya Rastrow", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2016-1583", 5, "interspeech", 2016]], "Ariya Rastrow": [0, ["LatticeRnn: Recurrent Neural Networks Over Lattices", ["Faisal Ladhak", "Ankur Gandhe", "Markus Dreyer", "Lambert Mathias", "Ariya Rastrow", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2016-1583", 5, "interspeech", 2016]], "Bjorn Hoffmeister": [0, ["LatticeRnn: Recurrent Neural Networks Over Lattices", ["Faisal Ladhak", "Ankur Gandhe", "Markus Dreyer", "Lambert Mathias", "Ariya Rastrow", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2016-1583", 5, "interspeech", 2016], ["Multi-Task Learning and Weighted Cross-Entropy for DNN-Based Keyword Spotting", ["Sankaran Panchapagesan", "Ming Sun", "Aparna Khare", "Spyros Matsoukas", "Arindam Mandal", "Bjorn Hoffmeister", "Shiv Vitaladevuni"], "https://doi.org/10.21437/Interspeech.2016-1485", 5, "interspeech", 2016], ["Anchored Speech Detection", ["Roland Maas", "Sree Hari Krishnan Parthasarathi", "Brian King", "Ruitong Huang", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2016-1346", 5, "interspeech", 2016]], "Santosh Kesiraju": [0, ["Learning Document Representations Using Subspace Multinomial Model", ["Santosh Kesiraju", "Lukas Burget", "Igor Szoke", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-1634", 5, "interspeech", 2016]], "Igor Szoke": [0, ["Learning Document Representations Using Subspace Multinomial Model", ["Santosh Kesiraju", "Lukas Burget", "Igor Szoke", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-1634", 5, "interspeech", 2016]], "Zhiwei Zhao": [0, ["Attention-Based Convolutional Neural Networks for Sentence Classification", ["Zhiwei Zhao", "Youzheng Wu"], "https://doi.org/10.21437/Interspeech.2016-354", 5, "interspeech", 2016]], "Youzheng Wu": [0.0003350695042172447, ["Attention-Based Convolutional Neural Networks for Sentence Classification", ["Zhiwei Zhao", "Youzheng Wu"], "https://doi.org/10.21437/Interspeech.2016-354", 5, "interspeech", 2016]], "Mohamed Morchid": [0, ["Spoken Language Understanding in a Latent Topic-Based Subspace", ["Mohamed Morchid", "Mohamed Bouaziz", "Waad Ben Kheder", "Killian Janod", "Pierre-Michel Bousquet", "Richard Dufour", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2016-50", 5, "interspeech", 2016], ["Deep Stacked Autoencoders for Spoken Language Understanding", ["Killian Janod", "Mohamed Morchid", "Richard Dufour", "Georges Linares", "Renato De Mori"], "https://doi.org/10.21437/Interspeech.2016-63", 5, "interspeech", 2016]], "Mohamed Bouaziz": [0, ["Spoken Language Understanding in a Latent Topic-Based Subspace", ["Mohamed Morchid", "Mohamed Bouaziz", "Waad Ben Kheder", "Killian Janod", "Pierre-Michel Bousquet", "Richard Dufour", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2016-50", 5, "interspeech", 2016]], "Waad Ben Kheder": [0, ["Spoken Language Understanding in a Latent Topic-Based Subspace", ["Mohamed Morchid", "Mohamed Bouaziz", "Waad Ben Kheder", "Killian Janod", "Pierre-Michel Bousquet", "Richard Dufour", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2016-50", 5, "interspeech", 2016], ["LIA System for the SITW Speaker Recognition Challenge", ["Waad Ben Kheder", "Moez Ajili", "Pierre-Michel Bousquet", "Driss Matrouf", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2016-1310", 5, "interspeech", 2016], ["Probabilistic Approach Using Joint Long and Short Session i-Vectors Modeling to Deal with Short Utterances for Speaker Recognition", ["Waad Ben Kheder", "Driss Matrouf", "Moez Ajili", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2016-1302", 5, "interspeech", 2016], ["Probabilistic Approach Using Joint Clean and Noisy i-Vectors Modeling for Speaker Recognition", ["Waad Ben Kheder", "Driss Matrouf", "Moez Ajili", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2016-1292", 5, "interspeech", 2016]], "Killian Janod": [0, ["Spoken Language Understanding in a Latent Topic-Based Subspace", ["Mohamed Morchid", "Mohamed Bouaziz", "Waad Ben Kheder", "Killian Janod", "Pierre-Michel Bousquet", "Richard Dufour", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2016-50", 5, "interspeech", 2016], ["Deep Stacked Autoencoders for Spoken Language Understanding", ["Killian Janod", "Mohamed Morchid", "Richard Dufour", "Georges Linares", "Renato De Mori"], "https://doi.org/10.21437/Interspeech.2016-63", 5, "interspeech", 2016]], "Pierre-Michel Bousquet": [0, ["Spoken Language Understanding in a Latent Topic-Based Subspace", ["Mohamed Morchid", "Mohamed Bouaziz", "Waad Ben Kheder", "Killian Janod", "Pierre-Michel Bousquet", "Richard Dufour", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2016-50", 5, "interspeech", 2016], ["LIA System for the SITW Speaker Recognition Challenge", ["Waad Ben Kheder", "Moez Ajili", "Pierre-Michel Bousquet", "Driss Matrouf", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2016-1310", 5, "interspeech", 2016]], "Richard Dufour": [0, ["Spoken Language Understanding in a Latent Topic-Based Subspace", ["Mohamed Morchid", "Mohamed Bouaziz", "Waad Ben Kheder", "Killian Janod", "Pierre-Michel Bousquet", "Richard Dufour", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2016-50", 5, "interspeech", 2016], ["Deep Stacked Autoencoders for Spoken Language Understanding", ["Killian Janod", "Mohamed Morchid", "Richard Dufour", "Georges Linares", "Renato De Mori"], "https://doi.org/10.21437/Interspeech.2016-63", 5, "interspeech", 2016]], "Dilek Hakkani-Tur": [0, ["Multi-Domain Joint Semantic Frame Parsing Using Bi-Directional RNN-LSTM", ["Dilek Hakkani-Tur", "Gokhan Tur", "Asli Celikyilmaz", "Yun-Nung Chen", "Jianfeng Gao", "Li Deng", "Ye-Yi Wang"], "https://doi.org/10.21437/Interspeech.2016-402", 5, "interspeech", 2016], ["End-to-End Memory Networks with Knowledge Carryover for Multi-Turn Spoken Language Understanding", ["Yun-Nung Chen", "Dilek Hakkani-Tur", "Gokhan Tur", "Jianfeng Gao", "Li Deng"], "https://doi.org/10.21437/Interspeech.2016-312", 5, "interspeech", 2016], ["A New Pre-Training Method for Training Deep Learning Models with Application to Spoken Language Understanding", ["Asli Celikyilmaz", "Ruhi Sarikaya", "Dilek Hakkani-Tur", "Xiaohu Liu", "Nikhil Ramesh", "Gokhan Tur"], "https://doi.org/10.21437/Interspeech.2016-512", 5, "interspeech", 2016]], "Gokhan Tur": [0, ["Multi-Domain Joint Semantic Frame Parsing Using Bi-Directional RNN-LSTM", ["Dilek Hakkani-Tur", "Gokhan Tur", "Asli Celikyilmaz", "Yun-Nung Chen", "Jianfeng Gao", "Li Deng", "Ye-Yi Wang"], "https://doi.org/10.21437/Interspeech.2016-402", 5, "interspeech", 2016], ["End-to-End Memory Networks with Knowledge Carryover for Multi-Turn Spoken Language Understanding", ["Yun-Nung Chen", "Dilek Hakkani-Tur", "Gokhan Tur", "Jianfeng Gao", "Li Deng"], "https://doi.org/10.21437/Interspeech.2016-312", 5, "interspeech", 2016], ["A New Pre-Training Method for Training Deep Learning Models with Application to Spoken Language Understanding", ["Asli Celikyilmaz", "Ruhi Sarikaya", "Dilek Hakkani-Tur", "Xiaohu Liu", "Nikhil Ramesh", "Gokhan Tur"], "https://doi.org/10.21437/Interspeech.2016-512", 5, "interspeech", 2016]], "Asli Celikyilmaz": [0, ["Multi-Domain Joint Semantic Frame Parsing Using Bi-Directional RNN-LSTM", ["Dilek Hakkani-Tur", "Gokhan Tur", "Asli Celikyilmaz", "Yun-Nung Chen", "Jianfeng Gao", "Li Deng", "Ye-Yi Wang"], "https://doi.org/10.21437/Interspeech.2016-402", 5, "interspeech", 2016], ["A New Pre-Training Method for Training Deep Learning Models with Application to Spoken Language Understanding", ["Asli Celikyilmaz", "Ruhi Sarikaya", "Dilek Hakkani-Tur", "Xiaohu Liu", "Nikhil Ramesh", "Gokhan Tur"], "https://doi.org/10.21437/Interspeech.2016-512", 5, "interspeech", 2016]], "Yun-Nung Chen": [0, ["Multi-Domain Joint Semantic Frame Parsing Using Bi-Directional RNN-LSTM", ["Dilek Hakkani-Tur", "Gokhan Tur", "Asli Celikyilmaz", "Yun-Nung Chen", "Jianfeng Gao", "Li Deng", "Ye-Yi Wang"], "https://doi.org/10.21437/Interspeech.2016-402", 5, "interspeech", 2016], ["End-to-End Memory Networks with Knowledge Carryover for Multi-Turn Spoken Language Understanding", ["Yun-Nung Chen", "Dilek Hakkani-Tur", "Gokhan Tur", "Jianfeng Gao", "Li Deng"], "https://doi.org/10.21437/Interspeech.2016-312", 5, "interspeech", 2016]], "Jianfeng Gao": [0, ["Multi-Domain Joint Semantic Frame Parsing Using Bi-Directional RNN-LSTM", ["Dilek Hakkani-Tur", "Gokhan Tur", "Asli Celikyilmaz", "Yun-Nung Chen", "Jianfeng Gao", "Li Deng", "Ye-Yi Wang"], "https://doi.org/10.21437/Interspeech.2016-402", 5, "interspeech", 2016], ["End-to-End Memory Networks with Knowledge Carryover for Multi-Turn Spoken Language Understanding", ["Yun-Nung Chen", "Dilek Hakkani-Tur", "Gokhan Tur", "Jianfeng Gao", "Li Deng"], "https://doi.org/10.21437/Interspeech.2016-312", 5, "interspeech", 2016]], "Li Deng": [0, ["Multi-Domain Joint Semantic Frame Parsing Using Bi-Directional RNN-LSTM", ["Dilek Hakkani-Tur", "Gokhan Tur", "Asli Celikyilmaz", "Yun-Nung Chen", "Jianfeng Gao", "Li Deng", "Ye-Yi Wang"], "https://doi.org/10.21437/Interspeech.2016-402", 5, "interspeech", 2016], ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016], ["End-to-End Memory Networks with Knowledge Carryover for Multi-Turn Spoken Language Understanding", ["Yun-Nung Chen", "Dilek Hakkani-Tur", "Gokhan Tur", "Jianfeng Gao", "Li Deng"], "https://doi.org/10.21437/Interspeech.2016-312", 5, "interspeech", 2016]], "Ye-Yi Wang": [0.004170232568867505, ["Multi-Domain Joint Semantic Frame Parsing Using Bi-Directional RNN-LSTM", ["Dilek Hakkani-Tur", "Gokhan Tur", "Asli Celikyilmaz", "Yun-Nung Chen", "Jianfeng Gao", "Li Deng", "Ye-Yi Wang"], "https://doi.org/10.21437/Interspeech.2016-402", 5, "interspeech", 2016]], "Renato De Mori": [0, ["Deep Stacked Autoencoders for Spoken Language Understanding", ["Killian Janod", "Mohamed Morchid", "Richard Dufour", "Georges Linares", "Renato De Mori"], "https://doi.org/10.21437/Interspeech.2016-63", 5, "interspeech", 2016]], "Bing Xiang": [0, ["Labeled Data Generation with Encoder-Decoder LSTM for Semantic Slot Filling", ["Gakuto Kurata", "Bing Xiang", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2016-727", 5, "interspeech", 2016]], "Bowen Zhou": [0, ["Labeled Data Generation with Encoder-Decoder LSTM for Semantic Slot Filling", ["Gakuto Kurata", "Bing Xiang", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2016-727", 5, "interspeech", 2016]], "Sabrina Stehwien": [0, ["Exploring the Correlation of Pitch Accents and Semantic Slots for Spoken Language Understanding", ["Sabrina Stehwien", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2016-511", 5, "interspeech", 2016]], "Ngoc Thang Vu": [0, ["Exploring the Correlation of Pitch Accents and Semantic Slots for Spoken Language Understanding", ["Sabrina Stehwien", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2016-511", 5, "interspeech", 2016], ["Cross-Gender and Cross-Dialect Tone Recognition for Vietnamese", ["Antje Schweitzer", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2016-405", 5, "interspeech", 2016], ["Sequential Convolutional Neural Networks for Slot Filling in Spoken Language Understanding", ["Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2016-395", 5, "interspeech", 2016]], "Yaodong Tang": [0, ["Analysis on Gated Recurrent Unit Based Question Detection Approach", ["Yaodong Tang", "Zhiyong Wu", "Helen M. Meng", "Mingxing Xu", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-964", 5, "interspeech", 2016]], "Zhiyong Wu": [4.80883099953644e-05, ["Analysis on Gated Recurrent Unit Based Question Detection Approach", ["Yaodong Tang", "Zhiyong Wu", "Helen M. Meng", "Mingxing Xu", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-964", 5, "interspeech", 2016], ["Combining CNN and BLSTM to Extract Textual and Acoustic Features for Recognizing Stances in Mandarin Ideological Debate Competition", ["Linchuan Li", "Zhiyong Wu", "Mingxing Xu", "Helen M. Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-324", 5, "interspeech", 2016], ["Phoneme Embedding and its Application to Speech Driven Talking Avatar Synthesis", ["Xu Li", "Zhiyong Wu", "Helen M. Meng", "Jia Jia", "Xiaoyan Lou", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-363", 5, "interspeech", 2016], ["Expressive Speech Driven Talking Avatar Synthesis with DBLSTM Using Limited Amount of Emotional Bimodal Data", ["Xu Li", "Zhiyong Wu", "Helen M. Meng", "Jia Jia", "Xiaoyan Lou", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-364", 5, "interspeech", 2016]], "Mingxing Xu": [0, ["Analysis on Gated Recurrent Unit Based Question Detection Approach", ["Yaodong Tang", "Zhiyong Wu", "Helen M. Meng", "Mingxing Xu", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-964", 5, "interspeech", 2016], ["Combining CNN and BLSTM to Extract Textual and Acoustic Features for Recognizing Stances in Mandarin Ideological Debate Competition", ["Linchuan Li", "Zhiyong Wu", "Mingxing Xu", "Helen M. Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-324", 5, "interspeech", 2016]], "Lianhong Cai": [0, ["Analysis on Gated Recurrent Unit Based Question Detection Approach", ["Yaodong Tang", "Zhiyong Wu", "Helen M. Meng", "Mingxing Xu", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-964", 5, "interspeech", 2016], ["Combining CNN and BLSTM to Extract Textual and Acoustic Features for Recognizing Stances in Mandarin Ideological Debate Competition", ["Linchuan Li", "Zhiyong Wu", "Mingxing Xu", "Helen M. Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-324", 5, "interspeech", 2016], ["Phoneme Embedding and its Application to Speech Driven Talking Avatar Synthesis", ["Xu Li", "Zhiyong Wu", "Helen M. Meng", "Jia Jia", "Xiaoyan Lou", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-363", 5, "interspeech", 2016], ["Expressive Speech Driven Talking Avatar Synthesis with DBLSTM Using Limited Amount of Emotional Bimodal Data", ["Xu Li", "Zhiyong Wu", "Helen M. Meng", "Jia Jia", "Xiaoyan Lou", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-364", 5, "interspeech", 2016]], "Shuji Oishi": [0, ["Combining State-Level Spotting and Posterior-Based Acoustic Match for Improved Query-by-Example Spoken Term Detection", ["Shuji Oishi", "Tatsuya Matsuba", "Mitsuaki Makino", "Atsuhiko Kai"], "https://doi.org/10.21437/Interspeech.2016-1259", 5, "interspeech", 2016]], "Tatsuya Matsuba": [0, ["Combining State-Level Spotting and Posterior-Based Acoustic Match for Improved Query-by-Example Spoken Term Detection", ["Shuji Oishi", "Tatsuya Matsuba", "Mitsuaki Makino", "Atsuhiko Kai"], "https://doi.org/10.21437/Interspeech.2016-1259", 5, "interspeech", 2016]], "Mitsuaki Makino": [0, ["Combining State-Level Spotting and Posterior-Based Acoustic Match for Improved Query-by-Example Spoken Term Detection", ["Shuji Oishi", "Tatsuya Matsuba", "Mitsuaki Makino", "Atsuhiko Kai"], "https://doi.org/10.21437/Interspeech.2016-1259", 5, "interspeech", 2016]], "Atsuhiko Kai": [0, ["Combining State-Level Spotting and Posterior-Based Acoustic Match for Improved Query-by-Example Spoken Term Detection", ["Shuji Oishi", "Tatsuya Matsuba", "Mitsuaki Makino", "Atsuhiko Kai"], "https://doi.org/10.21437/Interspeech.2016-1259", 5, "interspeech", 2016]], "Zhiqiang Lv": [0, ["A Novel Discriminative Score Calibration Method for Keyword Search", ["Zhiqiang Lv", "Meng Cai", "Wei-Qiang Zhang", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-606", 5, "interspeech", 2016]], "Meng Cai": [0, ["A Novel Discriminative Score Calibration Method for Keyword Search", ["Zhiqiang Lv", "Meng Cai", "Wei-Qiang Zhang", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-606", 5, "interspeech", 2016], ["Improving Deep Neural Networks Based Speaker Verification Using Unlabeled Data", ["Yao Tian", "Meng Cai", "Liang He", "Wei-Qiang Zhang", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-614", 5, "interspeech", 2016]], "Wei-Qiang Zhang": [0, ["A Novel Discriminative Score Calibration Method for Keyword Search", ["Zhiqiang Lv", "Meng Cai", "Wei-Qiang Zhang", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-606", 5, "interspeech", 2016], ["Improving Deep Neural Networks Based Speaker Verification Using Unlabeled Data", ["Yao Tian", "Meng Cai", "Liang He", "Wei-Qiang Zhang", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-614", 5, "interspeech", 2016]], "Jia Liu": [0, ["A Novel Discriminative Score Calibration Method for Keyword Search", ["Zhiqiang Lv", "Meng Cai", "Wei-Qiang Zhang", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-606", 5, "interspeech", 2016], ["Investigating Various Diarization Algorithms for Speaker in the Wild (SITW) Speaker Recognition Challenge", ["Yi Liu", "Yao Tian", "Liang He", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-1144", 5, "interspeech", 2016], ["Improving Deep Neural Networks Based Speaker Verification Using Unlabeled Data", ["Yao Tian", "Meng Cai", "Liang He", "Wei-Qiang Zhang", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-614", 5, "interspeech", 2016], ["THU-EE System Description for NIST LRE 2015", ["Liang He", "Yao Tian", "Yi Liu", "Jiaming Xu", "Weiwei Liu", "Cai Meng", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-791", 5, "interspeech", 2016]], "Jorge Proenca": [0, ["Segmented Dynamic Time Warping for Spoken Query-by-Example Search", ["Jorge Proenca", "Fernando Perdigao"], "https://doi.org/10.21437/Interspeech.2016-1276", 5, "interspeech", 2016]], "Fernando Perdigao": [0, ["Segmented Dynamic Time Warping for Spoken Query-by-Example Search", ["Jorge Proenca", "Fernando Perdigao"], "https://doi.org/10.21437/Interspeech.2016-1276", 5, "interspeech", 2016]], "Shi-wook Lee": [0.6669030338525772, ["Generating Complementary Acoustic Model Spaces in DNN-Based Sequence-to-Frame DTW Scheme for Out-of-Vocabulary Spoken Term Detection", ["Shi-wook Lee", "Kazuyo Tanaka", "Yoshiaki Itoh"], "https://doi.org/10.21437/Interspeech.2016-838", 5, "interspeech", 2016], ["Rescoring by Combination of Posteriorgram Score and Subword-Matching Score for Use in Query-by-Example", ["Masato Obara", "Kazunori Kojima", "Kazuyo Tanaka", "Shi-wook Lee", "Yoshiaki Itoh"], "https://doi.org/10.21437/Interspeech.2016-309", 5, "interspeech", 2016]], "Kazuyo Tanaka": [0, ["Generating Complementary Acoustic Model Spaces in DNN-Based Sequence-to-Frame DTW Scheme for Out-of-Vocabulary Spoken Term Detection", ["Shi-wook Lee", "Kazuyo Tanaka", "Yoshiaki Itoh"], "https://doi.org/10.21437/Interspeech.2016-838", 5, "interspeech", 2016], ["Rescoring by Combination of Posteriorgram Score and Subword-Matching Score for Use in Query-by-Example", ["Masato Obara", "Kazunori Kojima", "Kazuyo Tanaka", "Shi-wook Lee", "Yoshiaki Itoh"], "https://doi.org/10.21437/Interspeech.2016-309", 5, "interspeech", 2016]], "Yoshiaki Itoh": [0, ["Generating Complementary Acoustic Model Spaces in DNN-Based Sequence-to-Frame DTW Scheme for Out-of-Vocabulary Spoken Term Detection", ["Shi-wook Lee", "Kazuyo Tanaka", "Yoshiaki Itoh"], "https://doi.org/10.21437/Interspeech.2016-838", 5, "interspeech", 2016], ["Rescoring by Combination of Posteriorgram Score and Subword-Matching Score for Use in Query-by-Example", ["Masato Obara", "Kazunori Kojima", "Kazuyo Tanaka", "Shi-wook Lee", "Yoshiaki Itoh"], "https://doi.org/10.21437/Interspeech.2016-309", 5, "interspeech", 2016]], "Sankaran Panchapagesan": [0, ["Multi-Task Learning and Weighted Cross-Entropy for DNN-Based Keyword Spotting", ["Sankaran Panchapagesan", "Ming Sun", "Aparna Khare", "Spyros Matsoukas", "Arindam Mandal", "Bjorn Hoffmeister", "Shiv Vitaladevuni"], "https://doi.org/10.21437/Interspeech.2016-1485", 5, "interspeech", 2016], ["Model Compression Applied to Small-Footprint Keyword Spotting", ["George Tucker", "Minhua Wu", "Ming Sun", "Sankaran Panchapagesan", "Gengshen Fu", "Shiv Vitaladevuni"], "https://doi.org/10.21437/Interspeech.2016-1393", 5, "interspeech", 2016]], "Ming Sun": [0.00607844372279942, ["Multi-Task Learning and Weighted Cross-Entropy for DNN-Based Keyword Spotting", ["Sankaran Panchapagesan", "Ming Sun", "Aparna Khare", "Spyros Matsoukas", "Arindam Mandal", "Bjorn Hoffmeister", "Shiv Vitaladevuni"], "https://doi.org/10.21437/Interspeech.2016-1485", 5, "interspeech", 2016], ["Model Compression Applied to Small-Footprint Keyword Spotting", ["George Tucker", "Minhua Wu", "Ming Sun", "Sankaran Panchapagesan", "Gengshen Fu", "Shiv Vitaladevuni"], "https://doi.org/10.21437/Interspeech.2016-1393", 5, "interspeech", 2016]], "Aparna Khare": [0, ["Multi-Task Learning and Weighted Cross-Entropy for DNN-Based Keyword Spotting", ["Sankaran Panchapagesan", "Ming Sun", "Aparna Khare", "Spyros Matsoukas", "Arindam Mandal", "Bjorn Hoffmeister", "Shiv Vitaladevuni"], "https://doi.org/10.21437/Interspeech.2016-1485", 5, "interspeech", 2016]], "Spyros Matsoukas": [0, ["Multi-Task Learning and Weighted Cross-Entropy for DNN-Based Keyword Spotting", ["Sankaran Panchapagesan", "Ming Sun", "Aparna Khare", "Spyros Matsoukas", "Arindam Mandal", "Bjorn Hoffmeister", "Shiv Vitaladevuni"], "https://doi.org/10.21437/Interspeech.2016-1485", 5, "interspeech", 2016]], "Arindam Mandal": [0, ["Multi-Task Learning and Weighted Cross-Entropy for DNN-Based Keyword Spotting", ["Sankaran Panchapagesan", "Ming Sun", "Aparna Khare", "Spyros Matsoukas", "Arindam Mandal", "Bjorn Hoffmeister", "Shiv Vitaladevuni"], "https://doi.org/10.21437/Interspeech.2016-1485", 5, "interspeech", 2016]], "Shiv Vitaladevuni": [0, ["Multi-Task Learning and Weighted Cross-Entropy for DNN-Based Keyword Spotting", ["Sankaran Panchapagesan", "Ming Sun", "Aparna Khare", "Spyros Matsoukas", "Arindam Mandal", "Bjorn Hoffmeister", "Shiv Vitaladevuni"], "https://doi.org/10.21437/Interspeech.2016-1485", 5, "interspeech", 2016], ["Model Compression Applied to Small-Footprint Keyword Spotting", ["George Tucker", "Minhua Wu", "Ming Sun", "Sankaran Panchapagesan", "Gengshen Fu", "Shiv Vitaladevuni"], "https://doi.org/10.21437/Interspeech.2016-1393", 5, "interspeech", 2016]], "Yu-An Chung": [0.18233168497681618, ["Audio Word2Vec: Unsupervised Learning of Audio Segment Representations Using Sequence-to-Sequence Autoencoder", ["Yu-An Chung", "Chao-Chung Wu", "Chia-Hao Shen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2016-82", 5, "interspeech", 2016]], "Chao-Chung Wu": [3.38370336976368e-05, ["Audio Word2Vec: Unsupervised Learning of Audio Segment Representations Using Sequence-to-Sequence Autoencoder", ["Yu-An Chung", "Chao-Chung Wu", "Chia-Hao Shen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2016-82", 5, "interspeech", 2016]], "Chia-Hao Shen": [0, ["Audio Word2Vec: Unsupervised Learning of Audio Segment Representations Using Sequence-to-Sequence Autoencoder", ["Yu-An Chung", "Chao-Chung Wu", "Chia-Hao Shen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2016-82", 5, "interspeech", 2016]], "Hung-yi Lee": [5.7476832807878964e-05, ["Audio Word2Vec: Unsupervised Learning of Audio Segment Representations Using Sequence-to-Sequence Autoencoder", ["Yu-An Chung", "Chao-Chung Wu", "Chia-Hao Shen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2016-82", 5, "interspeech", 2016], ["Interactive Spoken Content Retrieval by Deep Reinforcement Learning", ["Yen-Chen Wu", "Tzu-Hsiang Lin", "Yang-De Chen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2016-1237", 5, "interspeech", 2016], ["Neural Attention Models for Sequence Classification: Analysis and Application to Key Term Extraction and Dialogue Act Detection", ["Sheng-syun Shen", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2016-1359", 5, "interspeech", 2016], ["Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine", ["Bo-Hsiang Tseng", "Sheng-syun Shen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2016-876", 5, "interspeech", 2016]], "Lin-Shan Lee": [3.8821162950952726e-09, ["Audio Word2Vec: Unsupervised Learning of Audio Segment Representations Using Sequence-to-Sequence Autoencoder", ["Yu-An Chung", "Chao-Chung Wu", "Chia-Hao Shen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2016-82", 5, "interspeech", 2016], ["Interactive Spoken Content Retrieval by Deep Reinforcement Learning", ["Yen-Chen Wu", "Tzu-Hsiang Lin", "Yang-De Chen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2016-1237", 5, "interspeech", 2016], ["Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine", ["Bo-Hsiang Tseng", "Sheng-syun Shen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2016-876", 5, "interspeech", 2016]], "Zhong Meng": [0, ["Non-Uniform Boosted MCE Training of Deep Neural Networks for Keyword Spotting", ["Zhong Meng", "Biing-Hwang Juang"], "https://doi.org/10.21437/Interspeech.2016-642", 5, "interspeech", 2016], ["Statistical Modeling of Speaker's Voice with Temporal Co-Location for Active Voice Authentication", ["Zhong Meng", "Biing-Hwang Juang"], "https://doi.org/10.21437/Interspeech.2016-650", 5, "interspeech", 2016]], "Biing-Hwang Juang": [0, ["Non-Uniform Boosted MCE Training of Deep Neural Networks for Keyword Spotting", ["Zhong Meng", "Biing-Hwang Juang"], "https://doi.org/10.21437/Interspeech.2016-642", 5, "interspeech", 2016], ["Statistical Modeling of Speaker's Voice with Temporal Co-Location for Active Voice Authentication", ["Zhong Meng", "Biing-Hwang Juang"], "https://doi.org/10.21437/Interspeech.2016-650", 5, "interspeech", 2016]], "Arseniy Gorin": [0, ["Language Model Data Augmentation for Keyword Spotting in Low-Resourced Training Conditions", ["Arseniy Gorin", "Rasa Lileikyte", "Guangpu Huang", "Lori Lamel", "Jean-Luc Gauvain", "Antoine Laurent"], "https://doi.org/10.21437/Interspeech.2016-1200", 5, "interspeech", 2016]], "Rasa Lileikyte": [0, ["Language Model Data Augmentation for Keyword Spotting in Low-Resourced Training Conditions", ["Arseniy Gorin", "Rasa Lileikyte", "Guangpu Huang", "Lori Lamel", "Jean-Luc Gauvain", "Antoine Laurent"], "https://doi.org/10.21437/Interspeech.2016-1200", 5, "interspeech", 2016]], "Guangpu Huang": [0, ["Language Model Data Augmentation for Keyword Spotting in Low-Resourced Training Conditions", ["Arseniy Gorin", "Rasa Lileikyte", "Guangpu Huang", "Lori Lamel", "Jean-Luc Gauvain", "Antoine Laurent"], "https://doi.org/10.21437/Interspeech.2016-1200", 5, "interspeech", 2016]], "Lori Lamel": [0, ["Language Model Data Augmentation for Keyword Spotting in Low-Resourced Training Conditions", ["Arseniy Gorin", "Rasa Lileikyte", "Guangpu Huang", "Lori Lamel", "Jean-Luc Gauvain", "Antoine Laurent"], "https://doi.org/10.21437/Interspeech.2016-1200", 5, "interspeech", 2016], ["Marginal Contrast Among Romanian Vowels: Evidence from ASR and Functional Load", ["Margaret E. L. Renwick", "Ioana Vasilescu", "Camille Dutrey", "Lori Lamel", "Bianca Vieru"], "https://doi.org/10.21437/Interspeech.2016-762", 5, "interspeech", 2016]], "Jean-Luc Gauvain": [0, ["Language Model Data Augmentation for Keyword Spotting in Low-Resourced Training Conditions", ["Arseniy Gorin", "Rasa Lileikyte", "Guangpu Huang", "Lori Lamel", "Jean-Luc Gauvain", "Antoine Laurent"], "https://doi.org/10.21437/Interspeech.2016-1200", 5, "interspeech", 2016], ["A Divide-and-Conquer Approach for Language Identification Based on Recurrent Neural Networks", ["Gregory Gelly", "Jean-Luc Gauvain", "Viet Bac Le", "Abdelkhalek Messaoudi"], "https://doi.org/10.21437/Interspeech.2016-180", 5, "interspeech", 2016]], "Antoine Laurent": [0, ["Language Model Data Augmentation for Keyword Spotting in Low-Resourced Training Conditions", ["Arseniy Gorin", "Rasa Lileikyte", "Guangpu Huang", "Lori Lamel", "Jean-Luc Gauvain", "Antoine Laurent"], "https://doi.org/10.21437/Interspeech.2016-1200", 5, "interspeech", 2016]], "Lyan Verwimp": [0, ["STON: Efficient Subtitling in Dutch Using State-of-the-Art Tools", ["Lyan Verwimp", "Brecht Desplanques", "Kris Demuynck", "Joris Pelemans", "Marieke Lycke", "Patrick Wambacq"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2006.html", 2, "interspeech", 2016], ["Analyzing the Contribution of Top-Down Lexical and Bottom-Up Acoustic Cues in the Detection of Sentence Prominence", ["Sofoklis Kakouros", "Joris Pelemans", "Lyan Verwimp", "Patrick Wambacq", "Okko Rasanen"], "https://doi.org/10.21437/Interspeech.2016-926", 5, "interspeech", 2016]], "Brecht Desplanques": [0, ["STON: Efficient Subtitling in Dutch Using State-of-the-Art Tools", ["Lyan Verwimp", "Brecht Desplanques", "Kris Demuynck", "Joris Pelemans", "Marieke Lycke", "Patrick Wambacq"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2006.html", 2, "interspeech", 2016]], "Kris Demuynck": [0, ["STON: Efficient Subtitling in Dutch Using State-of-the-Art Tools", ["Lyan Verwimp", "Brecht Desplanques", "Kris Demuynck", "Joris Pelemans", "Marieke Lycke", "Patrick Wambacq"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2006.html", 2, "interspeech", 2016]], "Joris Pelemans": [0, ["STON: Efficient Subtitling in Dutch Using State-of-the-Art Tools", ["Lyan Verwimp", "Brecht Desplanques", "Kris Demuynck", "Joris Pelemans", "Marieke Lycke", "Patrick Wambacq"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2006.html", 2, "interspeech", 2016], ["Analyzing the Contribution of Top-Down Lexical and Bottom-Up Acoustic Cues in the Detection of Sentence Prominence", ["Sofoklis Kakouros", "Joris Pelemans", "Lyan Verwimp", "Patrick Wambacq", "Okko Rasanen"], "https://doi.org/10.21437/Interspeech.2016-926", 5, "interspeech", 2016]], "Marieke Lycke": [0, ["STON: Efficient Subtitling in Dutch Using State-of-the-Art Tools", ["Lyan Verwimp", "Brecht Desplanques", "Kris Demuynck", "Joris Pelemans", "Marieke Lycke", "Patrick Wambacq"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2006.html", 2, "interspeech", 2016]], "Patrick Wambacq": [0, ["STON: Efficient Subtitling in Dutch Using State-of-the-Art Tools", ["Lyan Verwimp", "Brecht Desplanques", "Kris Demuynck", "Joris Pelemans", "Marieke Lycke", "Patrick Wambacq"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2006.html", 2, "interspeech", 2016], ["Analyzing the Contribution of Top-Down Lexical and Bottom-Up Acoustic Cues in the Detection of Sentence Prominence", ["Sofoklis Kakouros", "Joris Pelemans", "Lyan Verwimp", "Patrick Wambacq", "Okko Rasanen"], "https://doi.org/10.21437/Interspeech.2016-926", 5, "interspeech", 2016]], "Petr Stanislav": [0, ["An Automatic Training Tool for Air Traffic Control Training", ["Petr Stanislav", "Lubos Smidl", "Jan Svec"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2007.html", 2, "interspeech", 2016], ["An Engine for Online Video Search in Large Archives of the Holocaust Testimonies", ["Petr Stanislav", "Jan Svec", "Pavel Ircing"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2016.html", 2, "interspeech", 2016]], "Reima Karhila": [0, ["Digitala: An Augmented Test and Review Process Prototype for High-Stakes Spoken Foreign Language Examination", ["Reima Karhila", "Aku Rouhe", "Peter Smit", "Andre Mansikkaniemi", "Heini Kallio", "Erik Lindroos", "Raili Hilden", "Martti Vainio", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2008.html", 2, "interspeech", 2016]], "Aku Rouhe": [0, ["Digitala: An Augmented Test and Review Process Prototype for High-Stakes Spoken Foreign Language Examination", ["Reima Karhila", "Aku Rouhe", "Peter Smit", "Andre Mansikkaniemi", "Heini Kallio", "Erik Lindroos", "Raili Hilden", "Martti Vainio", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2008.html", 2, "interspeech", 2016]], "Peter Smit": [0, ["Digitala: An Augmented Test and Review Process Prototype for High-Stakes Spoken Foreign Language Examination", ["Reima Karhila", "Aku Rouhe", "Peter Smit", "Andre Mansikkaniemi", "Heini Kallio", "Erik Lindroos", "Raili Hilden", "Martti Vainio", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2008.html", 2, "interspeech", 2016]], "Andre Mansikkaniemi": [0, ["Digitala: An Augmented Test and Review Process Prototype for High-Stakes Spoken Foreign Language Examination", ["Reima Karhila", "Aku Rouhe", "Peter Smit", "Andre Mansikkaniemi", "Heini Kallio", "Erik Lindroos", "Raili Hilden", "Martti Vainio", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2008.html", 2, "interspeech", 2016]], "Heini Kallio": [0, ["Digitala: An Augmented Test and Review Process Prototype for High-Stakes Spoken Foreign Language Examination", ["Reima Karhila", "Aku Rouhe", "Peter Smit", "Andre Mansikkaniemi", "Heini Kallio", "Erik Lindroos", "Raili Hilden", "Martti Vainio", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2008.html", 2, "interspeech", 2016]], "Erik Lindroos": [0, ["Digitala: An Augmented Test and Review Process Prototype for High-Stakes Spoken Foreign Language Examination", ["Reima Karhila", "Aku Rouhe", "Peter Smit", "Andre Mansikkaniemi", "Heini Kallio", "Erik Lindroos", "Raili Hilden", "Martti Vainio", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2008.html", 2, "interspeech", 2016]], "Raili Hilden": [0, ["Digitala: An Augmented Test and Review Process Prototype for High-Stakes Spoken Foreign Language Examination", ["Reima Karhila", "Aku Rouhe", "Peter Smit", "Andre Mansikkaniemi", "Heini Kallio", "Erik Lindroos", "Raili Hilden", "Martti Vainio", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2008.html", 2, "interspeech", 2016]], "Martti Vainio": [0, ["Digitala: An Augmented Test and Review Process Prototype for High-Stakes Spoken Foreign Language Examination", ["Reima Karhila", "Aku Rouhe", "Peter Smit", "Andre Mansikkaniemi", "Heini Kallio", "Erik Lindroos", "Raili Hilden", "Martti Vainio", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2008.html", 2, "interspeech", 2016], ["Congruency Effect Between Articulation and Grasping in Native English Speakers", ["Mikko Tiainen", "Fatima M. Felisberti", "Kaisa Tiippana", "Martti Vainio", "Juraj Simko", "Jiri Lukavsky", "Lari Vainio"], "https://doi.org/10.21437/Interspeech.2016-1199", 5, "interspeech", 2016]], "Mikko Kurimo": [0, ["Digitala: An Augmented Test and Review Process Prototype for High-Stakes Spoken Foreign Language Examination", ["Reima Karhila", "Aku Rouhe", "Peter Smit", "Andre Mansikkaniemi", "Heini Kallio", "Erik Lindroos", "Raili Hilden", "Martti Vainio", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2008.html", 2, "interspeech", 2016], ["TheanoLM - An Extensible Toolkit for Neural Network Language Modeling", ["Seppo Enarvi", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2016-618", 5, "interspeech", 2016], ["Recurrent Neural Network Language Model with Incremental Updated Context Information Generated Using Bag-of-Words Representation", ["Md. Akmal Haidar", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2016-375", 5, "interspeech", 2016]], "Geraldine Damnati": [0, ["Exploring Collections of Multimedia Archives Through Innovative Interfaces in the Context of Digital Humanities", ["Geraldine Damnati", "Delphine Charlet", "Marc Denjean"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2009.html", 2, "interspeech", 2016]], "Delphine Charlet": [0, ["Exploring Collections of Multimedia Archives Through Innovative Interfaces in the Context of Digital Humanities", ["Geraldine Damnati", "Delphine Charlet", "Marc Denjean"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2009.html", 2, "interspeech", 2016], ["Iterative PLDA Adaptation for Speaker Diarization", ["Gael Le Lan", "Delphine Charlet", "Anthony Larcher", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-572", 5, "interspeech", 2016]], "Marc Denjean": [0, ["Exploring Collections of Multimedia Archives Through Innovative Interfaces in the Context of Digital Humanities", ["Geraldine Damnati", "Delphine Charlet", "Marc Denjean"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2009.html", 2, "interspeech", 2016]], "Yougen Yuan": [0, ["Learning Neural Network Representations Using Cross-Lingual Bottleneck Features with Word-Pair Information", ["Yougen Yuan", "Cheung-Chi Leung", "Lei Xie", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-317", 5, "interspeech", 2016]], "Cheung-Chi Leung": [0, ["Learning Neural Network Representations Using Cross-Lingual Bottleneck Features with Word-Pair Information", ["Yougen Yuan", "Cheung-Chi Leung", "Lei Xie", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-317", 5, "interspeech", 2016], ["Unsupervised Bottleneck Features for Low-Resource Query-by-Example Spoken Term Detection", ["Hongjie Chen", "Cheung-Chi Leung", "Lei Xie", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-313", 5, "interspeech", 2016], ["Rapid Update of Multilingual Deep Neural Network for Low-Resource Keyword Search", ["Chongjia Ni", "Lei Wang", "Cheung-Chi Leung", "Feng Rao", "Li Lu", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-53", 5, "interspeech", 2016], ["Toward High-Performance Language-Independent Query-by-Example Spoken Term Detection for MediaEval 2015: Post-Evaluation Analysis", ["Cheung-Chi Leung", "Lei Wang", "Haihua Xu", "Jingyong Hou", "Van Tung Pham", "Hang Lv", "Lei Xie", "Xiong Xiao", "Chongjia Ni", "Bin Ma", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-691", 5, "interspeech", 2016]], "Lei Xie": [0, ["Learning Neural Network Representations Using Cross-Lingual Bottleneck Features with Word-Pair Information", ["Yougen Yuan", "Cheung-Chi Leung", "Lei Xie", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-317", 5, "interspeech", 2016], ["Unsupervised Bottleneck Features for Low-Resource Query-by-Example Spoken Term Detection", ["Hongjie Chen", "Cheung-Chi Leung", "Lei Xie", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-313", 5, "interspeech", 2016], ["A DNN-HMM Approach to Story Segmentation", ["Jia Yu", "Xiong Xiao", "Lei Xie", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-873", 5, "interspeech", 2016], ["Deep Bidirectional LSTM Modeling of Timbre and Prosody for Emotional Voice Conversion", ["Huaiping Ming", "Dong-Yan Huang", "Lei Xie", "Jie Wu", "Minghui Dong", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-1053", 5, "interspeech", 2016], ["Toward High-Performance Language-Independent Query-by-Example Spoken Term Detection for MediaEval 2015: Post-Evaluation Analysis", ["Cheung-Chi Leung", "Lei Wang", "Haihua Xu", "Jingyong Hou", "Van Tung Pham", "Hang Lv", "Lei Xie", "Xiong Xiao", "Chongjia Ni", "Bin Ma", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-691", 5, "interspeech", 2016]], "Haizhou Li": [0, ["Learning Neural Network Representations Using Cross-Lingual Bottleneck Features with Word-Pair Information", ["Yougen Yuan", "Cheung-Chi Leung", "Lei Xie", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-317", 5, "interspeech", 2016], ["Unsupervised Bottleneck Features for Low-Resource Query-by-Example Spoken Term Detection", ["Hongjie Chen", "Cheung-Chi Leung", "Lei Xie", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-313", 5, "interspeech", 2016], ["Rescoring Hypothesized Detections of Out-of-Vocabulary Keywords Using Subword Samples", ["Van Tung Pham", "Haihua Xu", "Xiong Xiao", "Nancy F. Chen", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-646", 5, "interspeech", 2016], ["SERAPHIM: A Wavetable Synthesis System with 3D Lip Animation for Real-Time Speech and Singing Applications on Mobile Platforms", ["Paul Yaozhu Chan", "Minghui Dong", "Grace Xue Hui Ho", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-484", 5, "interspeech", 2016], ["Semi-Supervised and Cross-Lingual Knowledge Transfer Learnings for DNN Hybrid Acoustic Models Under Low-Resource Conditions", ["Haihua Xu", "Hang Su", "Chongjia Ni", "Xiong Xiao", "Hao Huang", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-1099", 5, "interspeech", 2016], ["A DNN-HMM Approach to Story Segmentation", ["Jia Yu", "Xiong Xiao", "Lei Xie", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-873", 5, "interspeech", 2016], ["SingaKids-Mandarin: Speech Corpus of Singaporean Children Speaking Mandarin Chinese", ["Nancy F. Chen", "Rong Tong", "Darren Wee", "Pei Xuan Lee", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-139", 5, "interspeech", 2016], ["An Investigation of Spoofing Speech Detection Under Additive Noise and Reverberant Conditions", ["Xiaohai Tian", "Zhizheng Wu", "Xiong Xiao", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-743", 5, "interspeech", 2016], ["SERAPHIM Live! - Singing Synthesis for the Performer, the Composer, and the 3D Game Developer", ["Paul Yaozhu Chan", "Minghui Dong", "Grace Xue Hui Ho", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2025.html", 2, "interspeech", 2016], ["Deep Bidirectional LSTM Modeling of Timbre and Prosody for Emotional Voice Conversion", ["Huaiping Ming", "Dong-Yan Huang", "Lei Xie", "Jie Wu", "Minghui Dong", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-1053", 5, "interspeech", 2016], ["Context Aware Mispronunciation Detection for Mandarin Pronunciation Training", ["Rong Tong", "Nancy F. Chen", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-289", 5, "interspeech", 2016], ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016], ["Out of Set Language Modelling in Hierarchical Language Identification", ["Saad Irtza", "Vidhyasaharan Sethu", "Sarith Fernando", "Eliathamby Ambikairajah", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-558", 5, "interspeech", 2016], ["Rapid Update of Multilingual Deep Neural Network for Low-Resource Keyword Search", ["Chongjia Ni", "Lei Wang", "Cheung-Chi Leung", "Feng Rao", "Li Lu", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-53", 5, "interspeech", 2016], ["Toward High-Performance Language-Independent Query-by-Example Spoken Term Detection for MediaEval 2015: Post-Evaluation Analysis", ["Cheung-Chi Leung", "Lei Wang", "Haihua Xu", "Jingyong Hou", "Van Tung Pham", "Hang Lv", "Lei Xie", "Xiong Xiao", "Chongjia Ni", "Bin Ma", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-691", 5, "interspeech", 2016]], "Yuzong Liu": [0, ["Novel Front-End Features Based on Neural Graph Embeddings for DNN-HMM and LSTM-CTC Acoustic Modeling", ["Yuzong Liu", "Katrin Kirchhoff"], "https://doi.org/10.21437/Interspeech.2016-542", 5, "interspeech", 2016]], "Katrin Kirchhoff": [0, ["Novel Front-End Features Based on Neural Graph Embeddings for DNN-HMM and LSTM-CTC Acoustic Modeling", ["Yuzong Liu", "Katrin Kirchhoff"], "https://doi.org/10.21437/Interspeech.2016-542", 5, "interspeech", 2016]], "Basil Abraham": [0, ["Articulatory Feature Extraction Using CTC to Build Articulatory Classifiers Without Forced Frame Alignments for Speech Recognition", ["Basil Abraham", "Srinivasan Umesh", "Neethu Mariam Joy"], "https://doi.org/10.21437/Interspeech.2016-925", 5, "interspeech", 2016], ["Overcoming Data Sparsity in Acoustic Modeling of Low-Resource Language by Borrowing Data and Model Parameters from High-Resource Languages", ["Basil Abraham", "Srinivasan Umesh", "Neethu Mariam Joy"], "https://doi.org/10.21437/Interspeech.2016-963", 5, "interspeech", 2016], ["DNNs for Unsupervised Extraction of Pseudo FMLLR Features Without Explicit Adaptation Data", ["Neethu Mariam Joy", "Murali Karthick Baskar", "Srinivasan Umesh", "Basil Abraham"], "https://doi.org/10.21437/Interspeech.2016-904", 5, "interspeech", 2016]], "Srinivasan Umesh": [0, ["Articulatory Feature Extraction Using CTC to Build Articulatory Classifiers Without Forced Frame Alignments for Speech Recognition", ["Basil Abraham", "Srinivasan Umesh", "Neethu Mariam Joy"], "https://doi.org/10.21437/Interspeech.2016-925", 5, "interspeech", 2016], ["Overcoming Data Sparsity in Acoustic Modeling of Low-Resource Language by Borrowing Data and Model Parameters from High-Resource Languages", ["Basil Abraham", "Srinivasan Umesh", "Neethu Mariam Joy"], "https://doi.org/10.21437/Interspeech.2016-963", 5, "interspeech", 2016], ["DNNs for Unsupervised Extraction of Pseudo FMLLR Features Without Explicit Adaptation Data", ["Neethu Mariam Joy", "Murali Karthick Baskar", "Srinivasan Umesh", "Basil Abraham"], "https://doi.org/10.21437/Interspeech.2016-904", 5, "interspeech", 2016]], "Neethu Mariam Joy": [0, ["Articulatory Feature Extraction Using CTC to Build Articulatory Classifiers Without Forced Frame Alignments for Speech Recognition", ["Basil Abraham", "Srinivasan Umesh", "Neethu Mariam Joy"], "https://doi.org/10.21437/Interspeech.2016-925", 5, "interspeech", 2016], ["Overcoming Data Sparsity in Acoustic Modeling of Low-Resource Language by Borrowing Data and Model Parameters from High-Resource Languages", ["Basil Abraham", "Srinivasan Umesh", "Neethu Mariam Joy"], "https://doi.org/10.21437/Interspeech.2016-963", 5, "interspeech", 2016], ["DNNs for Unsupervised Extraction of Pseudo FMLLR Features Without Explicit Adaptation Data", ["Neethu Mariam Joy", "Murali Karthick Baskar", "Srinivasan Umesh", "Basil Abraham"], "https://doi.org/10.21437/Interspeech.2016-904", 5, "interspeech", 2016]], "Tasha Nagamine": [0, ["On the Role of Nonlinear Transformations in Deep Neural Network Acoustic Models", ["Tasha Nagamine", "Michael L. Seltzer", "Nima Mesgarani"], "https://doi.org/10.21437/Interspeech.2016-1406", 5, "interspeech", 2016], ["Adaptation of Neural Networks Constrained by Prior Statistics of Node Co-Activations", ["Tasha Nagamine", "Zhuo Chen", "Nima Mesgarani"], "https://doi.org/10.21437/Interspeech.2016-600", 5, "interspeech", 2016]], "Michael L. Seltzer": [0, ["On the Role of Nonlinear Transformations in Deep Neural Network Acoustic Models", ["Tasha Nagamine", "Michael L. Seltzer", "Nima Mesgarani"], "https://doi.org/10.21437/Interspeech.2016-1406", 5, "interspeech", 2016]], "Nima Mesgarani": [0, ["On the Role of Nonlinear Transformations in Deep Neural Network Acoustic Models", ["Tasha Nagamine", "Michael L. Seltzer", "Nima Mesgarani"], "https://doi.org/10.21437/Interspeech.2016-1406", 5, "interspeech", 2016], ["Adaptation of Neural Networks Constrained by Prior Statistics of Node Co-Activations", ["Tasha Nagamine", "Zhuo Chen", "Nima Mesgarani"], "https://doi.org/10.21437/Interspeech.2016-600", 5, "interspeech", 2016]], "Ehsan Variani": [0, ["Complex Linear Projection (CLP): A Discriminative Approach to Joint Feature Extraction and Acoustic Modeling", ["Ehsan Variani", "Tara N. Sainath", "Izhak Shafran", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2016-1459", 5, "interspeech", 2016], ["Reducing the Computational Complexity of Multimicrophone Acoustic Models with Integrated Feature Extraction", ["Tara N. Sainath", "Arun Narayanan", "Ron J. Weiss", "Ehsan Variani", "Kevin W. Wilson", "Michiel Bacchiani", "Izhak Shafran"], "https://doi.org/10.21437/Interspeech.2016-92", 5, "interspeech", 2016]], "Izhak Shafran": [0, ["Complex Linear Projection (CLP): A Discriminative Approach to Joint Feature Extraction and Acoustic Modeling", ["Ehsan Variani", "Tara N. Sainath", "Izhak Shafran", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2016-1459", 5, "interspeech", 2016], ["Reducing the Computational Complexity of Multimicrophone Acoustic Models with Integrated Feature Extraction", ["Tara N. Sainath", "Arun Narayanan", "Ron J. Weiss", "Ehsan Variani", "Kevin W. Wilson", "Michiel Bacchiani", "Izhak Shafran"], "https://doi.org/10.21437/Interspeech.2016-92", 5, "interspeech", 2016]], "Michiel Bacchiani": [0, ["Complex Linear Projection (CLP): A Discriminative Approach to Joint Feature Extraction and Acoustic Modeling", ["Ehsan Variani", "Tara N. Sainath", "Izhak Shafran", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2016-1459", 5, "interspeech", 2016], ["Reducing the Computational Complexity of Multimicrophone Acoustic Models with Integrated Feature Extraction", ["Tara N. Sainath", "Arun Narayanan", "Ron J. Weiss", "Ehsan Variani", "Kevin W. Wilson", "Michiel Bacchiani", "Izhak Shafran"], "https://doi.org/10.21437/Interspeech.2016-92", 5, "interspeech", 2016], ["Neural Network Adaptive Beamforming for Robust Multichannel Speech Recognition", ["Bo Li", "Tara N. Sainath", "Ron J. Weiss", "Kevin W. Wilson", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2016-173", 5, "interspeech", 2016]], "Bo Li": [0, ["Modeling Time-Frequency Patterns with LSTM vs. Convolutional Architectures for LVCSR Tasks", ["Tara N. Sainath", "Bo Li"], "https://doi.org/10.21437/Interspeech.2016-84", 5, "interspeech", 2016], ["Neural Network Adaptive Beamforming for Robust Multichannel Speech Recognition", ["Bo Li", "Tara N. Sainath", "Ron J. Weiss", "Kevin W. Wilson", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2016-173", 5, "interspeech", 2016], ["Multi-Language Multi-Speaker Acoustic Modeling for LSTM-RNN Based Statistical Parametric Speech Synthesis", ["Bo Li", "Heiga Zen"], "https://doi.org/10.21437/Interspeech.2016-172", 5, "interspeech", 2016]], "Luciana Ferrer": [0, ["The Speakers in the Wild (SITW) Speaker Recognition Database", ["Mitchell McLaren", "Luciana Ferrer", "Diego Castan", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2016-1129", 5, "interspeech", 2016], ["The 2016 Speakers in the Wild Speaker Recognition Evaluation", ["Mitchell McLaren", "Luciana Ferrer", "Diego Castan", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2016-1137", 5, "interspeech", 2016], ["On the Issue of Calibration in DNN-Based Speaker Recognition Systems", ["Mitchell McLaren", "Diego Castan", "Luciana Ferrer", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2016-1134", 5, "interspeech", 2016], ["Minimizing Annotation Effort for Adaptation of Speech-Activity Detection Systems", ["Luciana Ferrer", "Martin Graciarena"], "https://doi.org/10.21437/Interspeech.2016-247", 5, "interspeech", 2016], ["The SRI System for the NIST OpenSAD 2015 Speech Activity Detection Evaluation", ["Martin Graciarena", "Luciana Ferrer", "Vikramjit Mitra"], "https://doi.org/10.21437/Interspeech.2016-550", 5, "interspeech", 2016]], "Diego Castan": [0, ["The Speakers in the Wild (SITW) Speaker Recognition Database", ["Mitchell McLaren", "Luciana Ferrer", "Diego Castan", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2016-1129", 5, "interspeech", 2016], ["The 2016 Speakers in the Wild Speaker Recognition Evaluation", ["Mitchell McLaren", "Luciana Ferrer", "Diego Castan", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2016-1137", 5, "interspeech", 2016], ["On the Issue of Calibration in DNN-Based Speaker Recognition Systems", ["Mitchell McLaren", "Diego Castan", "Luciana Ferrer", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2016-1134", 5, "interspeech", 2016]], "Ondrej Novotny": [0, ["Analysis of Speaker Recognition Systems in Realistic Scenarios of the SITW 2016 Challenge", ["Ondrej Novotny", "Pavel Matejka", "Oldrich Plchot", "Ondrej Glembek", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-981", 5, "interspeech", 2016]], "Oldrich Plchot": [0, ["Analysis of Speaker Recognition Systems in Realistic Scenarios of the SITW 2016 Challenge", ["Ondrej Novotny", "Pavel Matejka", "Oldrich Plchot", "Ondrej Glembek", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-981", 5, "interspeech", 2016], ["Exploiting Hidden-Layer Responses of Deep Neural Networks for Language Recognition", ["Ruizhi Li", "Sri Harish Reddy Mallidi", "Lukas Burget", "Oldrich Plchot", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2016-1584", 5, "interspeech", 2016]], "Ondrej Glembek": [0, ["Analysis of Speaker Recognition Systems in Realistic Scenarios of the SITW 2016 Challenge", ["Ondrej Novotny", "Pavel Matejka", "Oldrich Plchot", "Ondrej Glembek", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-981", 5, "interspeech", 2016]], "Oleg Kudashev": [0, ["A Speaker Recognition System for the SITW Challenge", ["Oleg Kudashev", "Sergey Novoselov", "Konstantin Simonchik", "Alexander Kozlov"], "https://doi.org/10.21437/Interspeech.2016-1197", 5, "interspeech", 2016]], "Sergey Novoselov": [0, ["A Speaker Recognition System for the SITW Challenge", ["Oleg Kudashev", "Sergey Novoselov", "Konstantin Simonchik", "Alexander Kozlov"], "https://doi.org/10.21437/Interspeech.2016-1197", 5, "interspeech", 2016]], "Konstantin Simonchik": [0, ["A Speaker Recognition System for the SITW Challenge", ["Oleg Kudashev", "Sergey Novoselov", "Konstantin Simonchik", "Alexander Kozlov"], "https://doi.org/10.21437/Interspeech.2016-1197", 5, "interspeech", 2016]], "Alexander Kozlov": [0, ["A Speaker Recognition System for the SITW Challenge", ["Oleg Kudashev", "Sergey Novoselov", "Konstantin Simonchik", "Alexander Kozlov"], "https://doi.org/10.21437/Interspeech.2016-1197", 5, "interspeech", 2016]], "Houman Ghaemmaghami": [0, ["Speakers In The Wild (SITW): The QUT Speaker Recognition System", ["Houman Ghaemmaghami", "Md. Hafizur Rahman", "Ivan Himawan", "David Dean", "Ahilan Kanagasundaram", "Sridha Sridharan", "Clinton Fookes"], "https://doi.org/10.21437/Interspeech.2016-945", 5, "interspeech", 2016]], "Md. Hafizur Rahman": [0, ["Speakers In The Wild (SITW): The QUT Speaker Recognition System", ["Houman Ghaemmaghami", "Md. Hafizur Rahman", "Ivan Himawan", "David Dean", "Ahilan Kanagasundaram", "Sridha Sridharan", "Clinton Fookes"], "https://doi.org/10.21437/Interspeech.2016-945", 5, "interspeech", 2016]], "Ivan Himawan": [0, ["Speakers In The Wild (SITW): The QUT Speaker Recognition System", ["Houman Ghaemmaghami", "Md. Hafizur Rahman", "Ivan Himawan", "David Dean", "Ahilan Kanagasundaram", "Sridha Sridharan", "Clinton Fookes"], "https://doi.org/10.21437/Interspeech.2016-945", 5, "interspeech", 2016], ["Short Utterance Variance Modelling and Utterance Partitioning for PLDA Speaker Verification", ["Ahilan Kanagasundaram", "David Dean", "Sridha Sridharan", "Clinton Fookes", "Ivan Himawan"], "https://doi.org/10.21437/Interspeech.2016-778", 4, "interspeech", 2016]], "David Dean": [0, ["Speakers In The Wild (SITW): The QUT Speaker Recognition System", ["Houman Ghaemmaghami", "Md. Hafizur Rahman", "Ivan Himawan", "David Dean", "Ahilan Kanagasundaram", "Sridha Sridharan", "Clinton Fookes"], "https://doi.org/10.21437/Interspeech.2016-945", 5, "interspeech", 2016], ["Short Utterance Variance Modelling and Utterance Partitioning for PLDA Speaker Verification", ["Ahilan Kanagasundaram", "David Dean", "Sridha Sridharan", "Clinton Fookes", "Ivan Himawan"], "https://doi.org/10.21437/Interspeech.2016-778", 4, "interspeech", 2016]], "Ahilan Kanagasundaram": [0, ["Speakers In The Wild (SITW): The QUT Speaker Recognition System", ["Houman Ghaemmaghami", "Md. Hafizur Rahman", "Ivan Himawan", "David Dean", "Ahilan Kanagasundaram", "Sridha Sridharan", "Clinton Fookes"], "https://doi.org/10.21437/Interspeech.2016-945", 5, "interspeech", 2016], ["Short Utterance Variance Modelling and Utterance Partitioning for PLDA Speaker Verification", ["Ahilan Kanagasundaram", "David Dean", "Sridha Sridharan", "Clinton Fookes", "Ivan Himawan"], "https://doi.org/10.21437/Interspeech.2016-778", 4, "interspeech", 2016]], "Sridha Sridharan": [0, ["Speakers In The Wild (SITW): The QUT Speaker Recognition System", ["Houman Ghaemmaghami", "Md. Hafizur Rahman", "Ivan Himawan", "David Dean", "Ahilan Kanagasundaram", "Sridha Sridharan", "Clinton Fookes"], "https://doi.org/10.21437/Interspeech.2016-945", 5, "interspeech", 2016], ["Short Utterance Variance Modelling and Utterance Partitioning for PLDA Speaker Verification", ["Ahilan Kanagasundaram", "David Dean", "Sridha Sridharan", "Clinton Fookes", "Ivan Himawan"], "https://doi.org/10.21437/Interspeech.2016-778", 4, "interspeech", 2016]], "Clinton Fookes": [0, ["Speakers In The Wild (SITW): The QUT Speaker Recognition System", ["Houman Ghaemmaghami", "Md. Hafizur Rahman", "Ivan Himawan", "David Dean", "Ahilan Kanagasundaram", "Sridha Sridharan", "Clinton Fookes"], "https://doi.org/10.21437/Interspeech.2016-945", 5, "interspeech", 2016], ["Short Utterance Variance Modelling and Utterance Partitioning for PLDA Speaker Verification", ["Ahilan Kanagasundaram", "David Dean", "Sridha Sridharan", "Clinton Fookes", "Ivan Himawan"], "https://doi.org/10.21437/Interspeech.2016-778", 4, "interspeech", 2016]], "Abbas Khosravani": [0, ["AUT System for SITW Speaker Recognition Challenge", ["Abbas Khosravani", "Mohammad Mehdi Homayounpour"], "https://doi.org/10.21437/Interspeech.2016-1378", 5, "interspeech", 2016]], "Mohammad Mehdi Homayounpour": [0, ["AUT System for SITW Speaker Recognition Challenge", ["Abbas Khosravani", "Mohammad Mehdi Homayounpour"], "https://doi.org/10.21437/Interspeech.2016-1378", 5, "interspeech", 2016]], "Moez Ajili": [0, ["LIA System for the SITW Speaker Recognition Challenge", ["Waad Ben Kheder", "Moez Ajili", "Pierre-Michel Bousquet", "Driss Matrouf", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2016-1310", 5, "interspeech", 2016], ["Probabilistic Approach Using Joint Long and Short Session i-Vectors Modeling to Deal with Short Utterances for Speaker Recognition", ["Waad Ben Kheder", "Driss Matrouf", "Moez Ajili", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2016-1302", 5, "interspeech", 2016], ["Probabilistic Approach Using Joint Clean and Noisy i-Vectors Modeling for Speaker Recognition", ["Waad Ben Kheder", "Driss Matrouf", "Moez Ajili", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2016-1292", 5, "interspeech", 2016]], "Driss Matrouf": [0, ["LIA System for the SITW Speaker Recognition Challenge", ["Waad Ben Kheder", "Moez Ajili", "Pierre-Michel Bousquet", "Driss Matrouf", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2016-1310", 5, "interspeech", 2016], ["Probabilistic Approach Using Joint Long and Short Session i-Vectors Modeling to Deal with Short Utterances for Speaker Recognition", ["Waad Ben Kheder", "Driss Matrouf", "Moez Ajili", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2016-1302", 5, "interspeech", 2016], ["Probabilistic Approach Using Joint Clean and Noisy i-Vectors Modeling for Speaker Recognition", ["Waad Ben Kheder", "Driss Matrouf", "Moez Ajili", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2016-1292", 5, "interspeech", 2016]], "Jean-Francois Bonastre": [0, ["LIA System for the SITW Speaker Recognition Challenge", ["Waad Ben Kheder", "Moez Ajili", "Pierre-Michel Bousquet", "Driss Matrouf", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2016-1310", 5, "interspeech", 2016], ["Speaker Comparison for Forensic and Investigative Applications II", ["Jean-Francois Bonastre", "Joseph P. Campbell", "Anders Eriksson", "Hirotaka Nakasone", "Reva Schwartz"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs3.html", 0, "interspeech", 2016], ["Probabilistic Approach Using Joint Long and Short Session i-Vectors Modeling to Deal with Short Utterances for Speaker Recognition", ["Waad Ben Kheder", "Driss Matrouf", "Moez Ajili", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2016-1302", 5, "interspeech", 2016], ["On the Importance of Efficient Transition Modeling for Speaker Diarization", ["Itshak Lapidot", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2016-503", 4, "interspeech", 2016], ["Probabilistic Approach Using Joint Clean and Noisy i-Vectors Modeling for Speaker Recognition", ["Waad Ben Kheder", "Driss Matrouf", "Moez Ajili", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2016-1292", 5, "interspeech", 2016]], "Yi Liu": [0, ["Investigating Various Diarization Algorithms for Speaker in the Wild (SITW) Speaker Recognition Challenge", ["Yi Liu", "Yao Tian", "Liang He", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-1144", 5, "interspeech", 2016], ["THU-EE System Description for NIST LRE 2015", ["Liang He", "Yao Tian", "Yi Liu", "Jiaming Xu", "Weiwei Liu", "Cai Meng", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-791", 5, "interspeech", 2016]], "Yao Tian": [0, ["Investigating Various Diarization Algorithms for Speaker in the Wild (SITW) Speaker Recognition Challenge", ["Yi Liu", "Yao Tian", "Liang He", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-1144", 5, "interspeech", 2016], ["Improving Deep Neural Networks Based Speaker Verification Using Unlabeled Data", ["Yao Tian", "Meng Cai", "Liang He", "Wei-Qiang Zhang", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-614", 5, "interspeech", 2016], ["THU-EE System Description for NIST LRE 2015", ["Liang He", "Yao Tian", "Yi Liu", "Jiaming Xu", "Weiwei Liu", "Cai Meng", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-791", 5, "interspeech", 2016]], "Liang He": [0, ["Investigating Various Diarization Algorithms for Speaker in the Wild (SITW) Speaker Recognition Challenge", ["Yi Liu", "Yao Tian", "Liang He", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-1144", 5, "interspeech", 2016], ["Improving Deep Neural Networks Based Speaker Verification Using Unlabeled Data", ["Yao Tian", "Meng Cai", "Liang He", "Wei-Qiang Zhang", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-614", 5, "interspeech", 2016], ["THU-EE System Description for NIST LRE 2015", ["Liang He", "Yao Tian", "Yi Liu", "Jiaming Xu", "Weiwei Liu", "Cai Meng", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-791", 5, "interspeech", 2016]], "Odette Scharenborg": [0, ["Does the Importance of Word-Initial and Word-Final Information Differ in Native versus Non-Native Spoken-Word Recognition?", ["Odette Scharenborg", "Juul Coumans", "Sofoklis Kakouros", "Roeland van Hout"], "https://doi.org/10.21437/Interspeech.2016-1095", 5, "interspeech", 2016], ["The Effect of Sentence Accent on Non-Native Speech Perception in Noise", ["Odette Scharenborg", "Elea Kolkman", "Sofoklis Kakouros", "Brechtje Post"], "https://doi.org/10.21437/Interspeech.2016-19", 5, "interspeech", 2016], ["Processing and Adaptation to Ambiguous Sounds during the Course of Perceptual Learning", ["Polina Drozdova", "Roeland van Hout", "Odette Scharenborg"], "https://doi.org/10.21437/Interspeech.2016-814", 5, "interspeech", 2016], ["The Effect of Background Noise on the Activation of Phonological and Semantic Information During Spoken-Word Recognition", ["Florian Hintz", "Odette Scharenborg"], "https://doi.org/10.21437/Interspeech.2016-882", 5, "interspeech", 2016]], "Juul Coumans": [0, ["Does the Importance of Word-Initial and Word-Final Information Differ in Native versus Non-Native Spoken-Word Recognition?", ["Odette Scharenborg", "Juul Coumans", "Sofoklis Kakouros", "Roeland van Hout"], "https://doi.org/10.21437/Interspeech.2016-1095", 5, "interspeech", 2016]], "Sofoklis Kakouros": [0, ["Does the Importance of Word-Initial and Word-Final Information Differ in Native versus Non-Native Spoken-Word Recognition?", ["Odette Scharenborg", "Juul Coumans", "Sofoklis Kakouros", "Roeland van Hout"], "https://doi.org/10.21437/Interspeech.2016-1095", 5, "interspeech", 2016], ["The Effect of Sentence Accent on Non-Native Speech Perception in Noise", ["Odette Scharenborg", "Elea Kolkman", "Sofoklis Kakouros", "Brechtje Post"], "https://doi.org/10.21437/Interspeech.2016-19", 5, "interspeech", 2016], ["Analyzing the Contribution of Top-Down Lexical and Bottom-Up Acoustic Cues in the Detection of Sentence Prominence", ["Sofoklis Kakouros", "Joris Pelemans", "Lyan Verwimp", "Patrick Wambacq", "Okko Rasanen"], "https://doi.org/10.21437/Interspeech.2016-926", 5, "interspeech", 2016]], "Roeland van Hout": [0, ["Does the Importance of Word-Initial and Word-Final Information Differ in Native versus Non-Native Spoken-Word Recognition?", ["Odette Scharenborg", "Juul Coumans", "Sofoklis Kakouros", "Roeland van Hout"], "https://doi.org/10.21437/Interspeech.2016-1095", 5, "interspeech", 2016], ["Processing and Adaptation to Ambiguous Sounds during the Course of Perceptual Learning", ["Polina Drozdova", "Roeland van Hout", "Odette Scharenborg"], "https://doi.org/10.21437/Interspeech.2016-814", 5, "interspeech", 2016]], "Elea Kolkman": [0, ["The Effect of Sentence Accent on Non-Native Speech Perception in Noise", ["Odette Scharenborg", "Elea Kolkman", "Sofoklis Kakouros", "Brechtje Post"], "https://doi.org/10.21437/Interspeech.2016-19", 5, "interspeech", 2016]], "Brechtje Post": [0, ["The Effect of Sentence Accent on Non-Native Speech Perception in Noise", ["Odette Scharenborg", "Elea Kolkman", "Sofoklis Kakouros", "Brechtje Post"], "https://doi.org/10.21437/Interspeech.2016-19", 5, "interspeech", 2016]], "Feng Shi": [0, ["The Influence of Language Experience on the Categorical Perception of Vowels: Evidence from Mandarin and Korean", ["Hao Zhang", "Fei Chen", "Nan Yan", "Lan Wang", "Feng Shi", "Manwa L. Ng"], "https://doi.org/10.21437/Interspeech.2016-887", 5, "interspeech", 2016]], "Manwa L. Ng": [0, ["The Influence of Language Experience on the Categorical Perception of Vowels: Evidence from Mandarin and Korean", ["Hao Zhang", "Fei Chen", "Nan Yan", "Lan Wang", "Feng Shi", "Manwa L. Ng"], "https://doi.org/10.21437/Interspeech.2016-887", 5, "interspeech", 2016], ["Deep Neural Networks for Voice Quality Assessment Based on the GRBAS Scale", ["Simin Xie", "Nan Yan", "Ping Yu", "Manwa L. Ng", "Lan Wang", "Zhuanzhuan Ji"], "https://doi.org/10.21437/Interspeech.2016-986", 5, "interspeech", 2016]], "Dominic W. Massaro": [0, ["Multiple Influences on Vocabulary Acquisition: Parental Input Dominates", ["Dominic W. Massaro"], "https://doi.org/10.21437/Interspeech.2016-37", 5, "interspeech", 2016]], "Jian Gong": [0.4041376858949661, ["Can Intensive Exposure to Foreign Language Sounds Affect the Perception of Native Sounds?", ["Jian Gong", "Maria Luisa Garcia Lecumberri", "Martin Cooke"], "https://doi.org/10.21437/Interspeech.2016-76", 5, "interspeech", 2016]], "Nikoletta Bassiou": [0, ["Privacy-Preserving Speech Analytics for Automatic Assessment of Student Collaboration", ["Nikoletta Bassiou", "Andreas Tsiartas", "Jennifer Smith", "Harry Bratt", "Colleen Richey", "Elizabeth Shriberg", "Cynthia DAngelo", "Nonye Alozie"], "https://doi.org/10.21437/Interspeech.2016-1569", 5, "interspeech", 2016]], "Andreas Tsiartas": [0, ["Privacy-Preserving Speech Analytics for Automatic Assessment of Student Collaboration", ["Nikoletta Bassiou", "Andreas Tsiartas", "Jennifer Smith", "Harry Bratt", "Colleen Richey", "Elizabeth Shriberg", "Cynthia DAngelo", "Nonye Alozie"], "https://doi.org/10.21437/Interspeech.2016-1569", 5, "interspeech", 2016]], "Jennifer Smith": [0, ["Privacy-Preserving Speech Analytics for Automatic Assessment of Student Collaboration", ["Nikoletta Bassiou", "Andreas Tsiartas", "Jennifer Smith", "Harry Bratt", "Colleen Richey", "Elizabeth Shriberg", "Cynthia DAngelo", "Nonye Alozie"], "https://doi.org/10.21437/Interspeech.2016-1569", 5, "interspeech", 2016]], "Colleen Richey": [0, ["Privacy-Preserving Speech Analytics for Automatic Assessment of Student Collaboration", ["Nikoletta Bassiou", "Andreas Tsiartas", "Jennifer Smith", "Harry Bratt", "Colleen Richey", "Elizabeth Shriberg", "Cynthia DAngelo", "Nonye Alozie"], "https://doi.org/10.21437/Interspeech.2016-1569", 5, "interspeech", 2016], ["The SRI Speech-Based Collaborative Learning Corpus", ["Colleen Richey", "Cynthia DAngelo", "Nonye Alozie", "Harry Bratt", "Elizabeth Shriberg"], "https://doi.org/10.21437/Interspeech.2016-1541", 5, "interspeech", 2016]], "Elizabeth Shriberg": [0, ["Privacy-Preserving Speech Analytics for Automatic Assessment of Student Collaboration", ["Nikoletta Bassiou", "Andreas Tsiartas", "Jennifer Smith", "Harry Bratt", "Colleen Richey", "Elizabeth Shriberg", "Cynthia DAngelo", "Nonye Alozie"], "https://doi.org/10.21437/Interspeech.2016-1569", 5, "interspeech", 2016], ["The SRI CLEO Speaker-State Corpus", ["Andreas Kathol", "Elizabeth Shriberg", "Massimiliano de Zambotti"], "https://doi.org/10.21437/Interspeech.2016-1141", 4, "interspeech", 2016], ["The SRI Speech-Based Collaborative Learning Corpus", ["Colleen Richey", "Cynthia DAngelo", "Nonye Alozie", "Harry Bratt", "Elizabeth Shriberg"], "https://doi.org/10.21437/Interspeech.2016-1541", 5, "interspeech", 2016]], "Cynthia DAngelo": [0, ["Privacy-Preserving Speech Analytics for Automatic Assessment of Student Collaboration", ["Nikoletta Bassiou", "Andreas Tsiartas", "Jennifer Smith", "Harry Bratt", "Colleen Richey", "Elizabeth Shriberg", "Cynthia DAngelo", "Nonye Alozie"], "https://doi.org/10.21437/Interspeech.2016-1569", 5, "interspeech", 2016], ["The SRI Speech-Based Collaborative Learning Corpus", ["Colleen Richey", "Cynthia DAngelo", "Nonye Alozie", "Harry Bratt", "Elizabeth Shriberg"], "https://doi.org/10.21437/Interspeech.2016-1541", 5, "interspeech", 2016]], "Nonye Alozie": [0, ["Privacy-Preserving Speech Analytics for Automatic Assessment of Student Collaboration", ["Nikoletta Bassiou", "Andreas Tsiartas", "Jennifer Smith", "Harry Bratt", "Colleen Richey", "Elizabeth Shriberg", "Cynthia DAngelo", "Nonye Alozie"], "https://doi.org/10.21437/Interspeech.2016-1569", 5, "interspeech", 2016], ["The SRI Speech-Based Collaborative Learning Corpus", ["Colleen Richey", "Cynthia DAngelo", "Nonye Alozie", "Harry Bratt", "Elizabeth Shriberg"], "https://doi.org/10.21437/Interspeech.2016-1541", 5, "interspeech", 2016]], "Md. Nasir": [0, ["Complexity in Prosody: A Nonlinear Dynamical Systems Approach for Dyadic Conversations; Behavior and Outcomes in Couples Therapy", ["Md. Nasir", "Brian R. Baucom", "Shrikanth S. Narayanan", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2016-1367", 5, "interspeech", 2016], ["Robust Multichannel Gender Classification from Speech in Movie Audio", ["Naveen Kumar", "Md. Nasir", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-540", 5, "interspeech", 2016]], "Brian R. Baucom": [0, ["Complexity in Prosody: A Nonlinear Dynamical Systems Approach for Dyadic Conversations; Behavior and Outcomes in Couples Therapy", ["Md. Nasir", "Brian R. Baucom", "Shrikanth S. Narayanan", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2016-1367", 5, "interspeech", 2016], ["Couples Behavior Modeling and Annotation Using Low-Resource LSTM Language Models", ["Shao-Yen Tseng", "Sandeep Nallan Chakravarthula", "Brian R. Baucom", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2016-1186", 5, "interspeech", 2016], ["Sparsely Connected and Disjointly Trained Deep Neural Networks for Low Resource Behavioral Annotation: Acoustic Classification in Couples' Therapy", ["Haoqi Li", "Brian R. Baucom", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2016-1217", 5, "interspeech", 2016]], "Shao-Yen Tseng": [0, ["Couples Behavior Modeling and Annotation Using Low-Resource LSTM Language Models", ["Shao-Yen Tseng", "Sandeep Nallan Chakravarthula", "Brian R. Baucom", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2016-1186", 5, "interspeech", 2016]], "Sandeep Nallan Chakravarthula": [0, ["Couples Behavior Modeling and Annotation Using Low-Resource LSTM Language Models", ["Shao-Yen Tseng", "Sandeep Nallan Chakravarthula", "Brian R. Baucom", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2016-1186", 5, "interspeech", 2016], ["Multimodal Fusion of Multirate Acoustic, Prosodic, and Lexical Speaker Characteristics for Native Language Identification", ["Prashanth Gurunath Shivakumar", "Sandeep Nallan Chakravarthula", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2016-1312", 5, "interspeech", 2016]], "Laura Fernandez Gallardo": [0, ["Speech Likability and Personality-Based Social Relations: A Round-Robin Analysis over Communication Channels", ["Laura Fernandez Gallardo", "Benjamin Weiss"], "https://doi.org/10.21437/Interspeech.2016-459", 5, "interspeech", 2016]], "Benjamin Weiss": [0, ["Speech Likability and Personality-Based Social Relations: A Round-Robin Analysis over Communication Channels", ["Laura Fernandez Gallardo", "Benjamin Weiss"], "https://doi.org/10.21437/Interspeech.2016-459", 5, "interspeech", 2016]], "Bo Xiao": [0, ["Behavioral Coding of Therapist Language in Addiction Counseling Using Recurrent Neural Networks", ["Bo Xiao", "Dogan Can", "James Gibson", "Zac E. Imel", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1560", 5, "interspeech", 2016], ["A Deep Learning Approach to Modeling Empathy in Addiction Counseling", ["James Gibson", "Dogan Can", "Bo Xiao", "Zac E. Imel", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-554", 5, "interspeech", 2016]], "Dogan Can": [0, ["Behavioral Coding of Therapist Language in Addiction Counseling Using Recurrent Neural Networks", ["Bo Xiao", "Dogan Can", "James Gibson", "Zac E. Imel", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1560", 5, "interspeech", 2016], ["A Deep Learning Approach to Modeling Empathy in Addiction Counseling", ["James Gibson", "Dogan Can", "Bo Xiao", "Zac E. Imel", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-554", 5, "interspeech", 2016]], "James Gibson": [0, ["Behavioral Coding of Therapist Language in Addiction Counseling Using Recurrent Neural Networks", ["Bo Xiao", "Dogan Can", "James Gibson", "Zac E. Imel", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1560", 5, "interspeech", 2016], ["A Deep Learning Approach to Modeling Empathy in Addiction Counseling", ["James Gibson", "Dogan Can", "Bo Xiao", "Zac E. Imel", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-554", 5, "interspeech", 2016]], "Zac E. Imel": [0, ["Behavioral Coding of Therapist Language in Addiction Counseling Using Recurrent Neural Networks", ["Bo Xiao", "Dogan Can", "James Gibson", "Zac E. Imel", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1560", 5, "interspeech", 2016], ["A Deep Learning Approach to Modeling Empathy in Addiction Counseling", ["James Gibson", "Dogan Can", "Bo Xiao", "Zac E. Imel", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-554", 5, "interspeech", 2016]], "Ting Dang": [0, ["Factor Analysis Based Speaker Normalisation for Continuous Emotion Prediction", ["Ting Dang", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2016-880", 5, "interspeech", 2016]], "Dhananjay Ram": [0, ["Subspace Detection of DNN Posterior Probabilities via Sparse Representation for Query by Example Spoken Term Detection", ["Dhananjay Ram", "Afsaneh Asaei", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-1278", 5, "interspeech", 2016]], "Hongjie Chen": [0, ["Unsupervised Bottleneck Features for Low-Resource Query-by-Example Spoken Term Detection", ["Hongjie Chen", "Cheung-Chi Leung", "Lei Xie", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-313", 5, "interspeech", 2016]], "Amir Hossein Harati Nejad Torbati": [0, ["A Nonparametric Bayesian Approach for Spoken Term Detection by Example Query", ["Amir Hossein Harati Nejad Torbati", "Joseph Picone"], "https://doi.org/10.21437/Interspeech.2016-315", 5, "interspeech", 2016]], "Joseph Picone": [0, ["A Nonparametric Bayesian Approach for Spoken Term Detection by Example Query", ["Amir Hossein Harati Nejad Torbati", "Joseph Picone"], "https://doi.org/10.21437/Interspeech.2016-315", 5, "interspeech", 2016]], "Van Tung Pham": [0, ["Rescoring Hypothesized Detections of Out-of-Vocabulary Keywords Using Subword Samples", ["Van Tung Pham", "Haihua Xu", "Xiong Xiao", "Nancy F. Chen", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-646", 5, "interspeech", 2016], ["Toward High-Performance Language-Independent Query-by-Example Spoken Term Detection for MediaEval 2015: Post-Evaluation Analysis", ["Cheung-Chi Leung", "Lei Wang", "Haihua Xu", "Jingyong Hou", "Van Tung Pham", "Hang Lv", "Lei Xie", "Xiong Xiao", "Chongjia Ni", "Bin Ma", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-691", 5, "interspeech", 2016]], "Haihua Xu": [0, ["Rescoring Hypothesized Detections of Out-of-Vocabulary Keywords Using Subword Samples", ["Van Tung Pham", "Haihua Xu", "Xiong Xiao", "Nancy F. Chen", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-646", 5, "interspeech", 2016], ["Semi-Supervised and Cross-Lingual Knowledge Transfer Learnings for DNN Hybrid Acoustic Models Under Low-Resource Conditions", ["Haihua Xu", "Hang Su", "Chongjia Ni", "Xiong Xiao", "Hao Huang", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-1099", 5, "interspeech", 2016], ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016], ["Toward High-Performance Language-Independent Query-by-Example Spoken Term Detection for MediaEval 2015: Post-Evaluation Analysis", ["Cheung-Chi Leung", "Lei Wang", "Haihua Xu", "Jingyong Hou", "Van Tung Pham", "Hang Lv", "Lei Xie", "Xiong Xiao", "Chongjia Ni", "Bin Ma", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-691", 5, "interspeech", 2016]], "Xiong Xiao": [0, ["Rescoring Hypothesized Detections of Out-of-Vocabulary Keywords Using Subword Samples", ["Van Tung Pham", "Haihua Xu", "Xiong Xiao", "Nancy F. Chen", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-646", 5, "interspeech", 2016], ["Semi-Supervised and Cross-Lingual Knowledge Transfer Learnings for DNN Hybrid Acoustic Models Under Low-Resource Conditions", ["Haihua Xu", "Hang Su", "Chongjia Ni", "Xiong Xiao", "Hao Huang", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-1099", 5, "interspeech", 2016], ["A DNN-HMM Approach to Story Segmentation", ["Jia Yu", "Xiong Xiao", "Lei Xie", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-873", 5, "interspeech", 2016], ["An Investigation of Spoofing Speech Detection Under Additive Noise and Reverberant Conditions", ["Xiaohai Tian", "Zhizheng Wu", "Xiong Xiao", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-743", 5, "interspeech", 2016], ["DNN-Based Amplitude and Phase Feature Enhancement for Noise Robust Speaker Identification", ["Zeyan Oo", "Yuta Kawakami", "Longbiao Wang", "Seiichi Nakagawa", "Xiong Xiao", "Masahiro Iwahashi"], "https://doi.org/10.21437/Interspeech.2016-717", 5, "interspeech", 2016], ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016], ["Toward High-Performance Language-Independent Query-by-Example Spoken Term Detection for MediaEval 2015: Post-Evaluation Analysis", ["Cheung-Chi Leung", "Lei Wang", "Haihua Xu", "Jingyong Hou", "Van Tung Pham", "Hang Lv", "Lei Xie", "Xiong Xiao", "Chongjia Ni", "Bin Ma", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-691", 5, "interspeech", 2016]], "Eng Siong Chng": [0, ["Rescoring Hypothesized Detections of Out-of-Vocabulary Keywords Using Subword Samples", ["Van Tung Pham", "Haihua Xu", "Xiong Xiao", "Nancy F. Chen", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-646", 5, "interspeech", 2016], ["Semi-Supervised and Cross-Lingual Knowledge Transfer Learnings for DNN Hybrid Acoustic Models Under Low-Resource Conditions", ["Haihua Xu", "Hang Su", "Chongjia Ni", "Xiong Xiao", "Hao Huang", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-1099", 5, "interspeech", 2016], ["A DNN-HMM Approach to Story Segmentation", ["Jia Yu", "Xiong Xiao", "Lei Xie", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-873", 5, "interspeech", 2016], ["An Investigation of Spoofing Speech Detection Under Additive Noise and Reverberant Conditions", ["Xiaohai Tian", "Zhizheng Wu", "Xiong Xiao", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-743", 5, "interspeech", 2016], ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016], ["Toward High-Performance Language-Independent Query-by-Example Spoken Term Detection for MediaEval 2015: Post-Evaluation Analysis", ["Cheung-Chi Leung", "Lei Wang", "Haihua Xu", "Jingyong Hou", "Van Tung Pham", "Hang Lv", "Lei Xie", "Xiong Xiao", "Chongjia Ni", "Bin Ma", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-691", 5, "interspeech", 2016]], "Yimeng Zhuang": [0, ["Unrestricted Vocabulary Keyword Spotting Using LSTM-CTC", ["Yimeng Zhuang", "Xuankai Chang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2016-753", 5, "interspeech", 2016]], "Xuankai Chang": [1.0287299170071845e-12, ["Unrestricted Vocabulary Keyword Spotting Using LSTM-CTC", ["Yimeng Zhuang", "Xuankai Chang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2016-753", 5, "interspeech", 2016]], "Yanmin Qian": [0, ["Unrestricted Vocabulary Keyword Spotting Using LSTM-CTC", ["Yimeng Zhuang", "Xuankai Chang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2016-753", 5, "interspeech", 2016]], "Kai Yu": [0.007579641183838248, ["Unrestricted Vocabulary Keyword Spotting Using LSTM-CTC", ["Yimeng Zhuang", "Xuankai Chang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2016-753", 5, "interspeech", 2016], ["Phone Synchronous Decoding with CTC Lattice", ["Zhehuai Chen", "Wei Deng", "Tao Xu", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2016-831", 5, "interspeech", 2016], ["Hybrid Dialogue State Tracking for Real World Human-to-Human Dialogues", ["Kai Sun", "Su Zhu", "Lu Chen", "Siqiu Yao", "Xueyang Wu", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2016-949", 5, "interspeech", 2016]], "Yen-Chen Wu": [3.734313168024528e-06, ["Interactive Spoken Content Retrieval by Deep Reinforcement Learning", ["Yen-Chen Wu", "Tzu-Hsiang Lin", "Yang-De Chen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2016-1237", 5, "interspeech", 2016]], "Tzu-Hsiang Lin": [0, ["Interactive Spoken Content Retrieval by Deep Reinforcement Learning", ["Yen-Chen Wu", "Tzu-Hsiang Lin", "Yang-De Chen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2016-1237", 5, "interspeech", 2016]], "Yang-De Chen": [0, ["Interactive Spoken Content Retrieval by Deep Reinforcement Learning", ["Yen-Chen Wu", "Tzu-Hsiang Lin", "Yang-De Chen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2016-1237", 5, "interspeech", 2016]], "Elizabeth Godoy": [0, ["Relating Estimated Cyclic Spectral Peak Frequency to Measured Epilarynx Length Using Magnetic Resonance Imaging", ["Elizabeth Godoy", "Andrew Dumas", "Jennifer Melot", "Nicolas Malyska", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2016-1362", 5, "interspeech", 2016], ["Relation of Automatically Extracted Formant Trajectories with Intelligibility Loss and Speaking Rate Decline in Amyotrophic Lateral Sclerosis", ["Rachelle L. Horwitz-Martin", "Thomas F. Quatieri", "Adam C. Lammert", "James R. Williamson", "Yana Yunusova", "Elizabeth Godoy", "Daryush D. Mehta", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2016-403", 5, "interspeech", 2016]], "Andrew Dumas": [0, ["Relating Estimated Cyclic Spectral Peak Frequency to Measured Epilarynx Length Using Magnetic Resonance Imaging", ["Elizabeth Godoy", "Andrew Dumas", "Jennifer Melot", "Nicolas Malyska", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2016-1362", 5, "interspeech", 2016]], "Jennifer Melot": [0, ["Relating Estimated Cyclic Spectral Peak Frequency to Measured Epilarynx Length Using Magnetic Resonance Imaging", ["Elizabeth Godoy", "Andrew Dumas", "Jennifer Melot", "Nicolas Malyska", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2016-1362", 5, "interspeech", 2016], ["Speaker Recognition Using Real vs Synthetic Parallel Data for DNN Channel Compensation", ["Fred Richardson", "Michael Brandstein", "Jennifer Melot", "Douglas A. Reynolds"], "https://doi.org/10.21437/Interspeech.2016-544", 5, "interspeech", 2016]], "Nicolas Malyska": [0, ["Relating Estimated Cyclic Spectral Peak Frequency to Measured Epilarynx Length Using Magnetic Resonance Imaging", ["Elizabeth Godoy", "Andrew Dumas", "Jennifer Melot", "Nicolas Malyska", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2016-1362", 5, "interspeech", 2016]], "Patrick Lumban Tobing": [0, ["Acoustic-to-Articulatory Inversion Mapping Based on Latent Trajectory Gaussian Mixture Model", ["Patrick Lumban Tobing", "Tomoki Toda", "Hirokazu Kameoka", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-1196", 5, "interspeech", 2016]], "Tomoki Toda": [0, ["Acoustic-to-Articulatory Inversion Mapping Based on Latent Trajectory Gaussian Mixture Model", ["Patrick Lumban Tobing", "Tomoki Toda", "Hirokazu Kameoka", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-1196", 5, "interspeech", 2016], ["The Voice Conversion Challenge 2016", ["Tomoki Toda", "Ling-Hui Chen", "Daisuke Saito", "Fernando Villavicencio", "Mirjam Wester", "Zhizheng Wu", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1066", 5, "interspeech", 2016], ["The NU-NAIST Voice Conversion System for the Voice Conversion Challenge 2016", ["Kazuhiro Kobayashi", "Shinnosuke Takamichi", "Satoshi Nakamura", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2016-970", 5, "interspeech", 2016], ["Model Integration for HMM- and DNN-Based Speech Synthesis Using Product-of-Experts Framework", ["Kentaro Tachibana", "Tomoki Toda", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-1006", 5, "interspeech", 2016], ["A Hybrid System for Continuous Word-Level Emphasis Modeling Based on HMM State Clustering and Adaptive Training", ["Quoc Truong Do", "Tomoki Toda", "Graham Neubig", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-930", 5, "interspeech", 2016]], "Hirokazu Kameoka": [0, ["Acoustic-to-Articulatory Inversion Mapping Based on Latent Trajectory Gaussian Mixture Model", ["Patrick Lumban Tobing", "Tomoki Toda", "Hirokazu Kameoka", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-1196", 5, "interspeech", 2016], ["Majorisation-Minimisation Based Optimisation of the Composite Autoregressive System with Application to Glottal Inverse Filtering", ["Lauri Juvela", "Hirokazu Kameoka", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-735", 5, "interspeech", 2016], ["Semi-Supervised Joint Enhancement of Spectral and Cepstral Sequences of Noisy Speech", ["Li Li", "Hirokazu Kameoka", "Takuya Higuchi", "Hiroshi Saruwatari"], "https://doi.org/10.21437/Interspeech.2016-1286", 5, "interspeech", 2016]], "Satoshi Nakamura": [0, ["Acoustic-to-Articulatory Inversion Mapping Based on Latent Trajectory Gaussian Mixture Model", ["Patrick Lumban Tobing", "Tomoki Toda", "Hirokazu Kameoka", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-1196", 5, "interspeech", 2016], ["Supervised Learning of Acoustic Models in a Zero Resource Setting to Improve DPGMM Clustering", ["Michael Heck", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-988", 5, "interspeech", 2016], ["The NU-NAIST Voice Conversion System for the Voice Conversion Challenge 2016", ["Kazuhiro Kobayashi", "Shinnosuke Takamichi", "Satoshi Nakamura", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2016-970", 5, "interspeech", 2016], ["Transferring Emphasis in Speech Translation Using Hard-Attentional Neural Network Models", ["Quoc Truong Do", "Sakriani Sakti", "Graham Neubig", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-898", 5, "interspeech", 2016], ["Unsupervised Joint Estimation of Grapheme-to-Phoneme Conversion Systems and Acoustic Model Adaptation for Non-Native Speech Recognition", ["Satoshi Tsujioka", "Sakriani Sakti", "Koichiro Yoshino", "Graham Neubig", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-919", 5, "interspeech", 2016], ["A Hybrid System for Continuous Word-Level Emphasis Modeling Based on HMM State Clustering and Adaptive Training", ["Quoc Truong Do", "Tomoki Toda", "Graham Neubig", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-930", 5, "interspeech", 2016], ["Unsupervised Phoneme Segmentation of Previously Unseen Languages", ["Marco Vetter", "Markus Muller", "Fatima Hamlaoui", "Graham Neubig", "Satoshi Nakamura", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-1440", 5, "interspeech", 2016]], "Yehoshua Dissen": [0, ["Formant Estimation and Tracking Using Deep Learning", ["Yehoshua Dissen", "Joseph Keshet"], "https://doi.org/10.21437/Interspeech.2016-490", 5, "interspeech", 2016]], "Joseph Keshet": [0, ["Formant Estimation and Tracking Using Deep Learning", ["Yehoshua Dissen", "Joseph Keshet"], "https://doi.org/10.21437/Interspeech.2016-490", 5, "interspeech", 2016], ["Automatic Measurement of Voice Onset Time and Prevoicing Using Recurrent Neural Networks", ["Yossi Adi", "Joseph Keshet", "Olga Dmitrieva", "Matthew Goldrick"], "https://doi.org/10.21437/Interspeech.2016-893", 4, "interspeech", 2016]], "Lauri Juvela": [0, ["Majorisation-Minimisation Based Optimisation of the Composite Autoregressive System with Application to Glottal Inverse Filtering", ["Lauri Juvela", "Hirokazu Kameoka", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-735", 5, "interspeech", 2016], ["Automatic Glottal Inverse Filtering with Non-Negative Matrix Factorization", ["Manu Airaksinen", "Lauri Juvela", "Tom Backstrom", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-338", 5, "interspeech", 2016], ["Using Text and Acoustic Features in Predicting Glottal Excitation Waveforms for Parametric Speech Synthesis with Recurrent Neural Networks", ["Lauri Juvela", "Xin Wang", "Shinji Takaki", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-712", 5, "interspeech", 2016], ["GlottDNN - A Full-Band Glottal Vocoder for Statistical Parametric Speech Synthesis", ["Manu Airaksinen", "Bajibabu Bollepalli", "Lauri Juvela", "Zhizheng Wu", "Simon King", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-342", 5, "interspeech", 2016]], "Manu Airaksinen": [0, ["Majorisation-Minimisation Based Optimisation of the Composite Autoregressive System with Application to Glottal Inverse Filtering", ["Lauri Juvela", "Hirokazu Kameoka", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-735", 5, "interspeech", 2016], ["Automatic Glottal Inverse Filtering with Non-Negative Matrix Factorization", ["Manu Airaksinen", "Lauri Juvela", "Tom Backstrom", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-338", 5, "interspeech", 2016], ["Using Text and Acoustic Features in Predicting Glottal Excitation Waveforms for Parametric Speech Synthesis with Recurrent Neural Networks", ["Lauri Juvela", "Xin Wang", "Shinji Takaki", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-712", 5, "interspeech", 2016], ["GlottDNN - A Full-Band Glottal Vocoder for Statistical Parametric Speech Synthesis", ["Manu Airaksinen", "Bajibabu Bollepalli", "Lauri Juvela", "Zhizheng Wu", "Simon King", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-342", 5, "interspeech", 2016]], "Paavo Alku": [0, ["Majorisation-Minimisation Based Optimisation of the Composite Autoregressive System with Application to Glottal Inverse Filtering", ["Lauri Juvela", "Hirokazu Kameoka", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-735", 5, "interspeech", 2016], ["Automatic Glottal Inverse Filtering with Non-Negative Matrix Factorization", ["Manu Airaksinen", "Lauri Juvela", "Tom Backstrom", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-338", 5, "interspeech", 2016], ["Time-Varying Quasi-Closed-Phase Weighted Linear Prediction Analysis of Speech for Accurate Formant Detection and Tracking", ["Dhananjaya N. Gowda", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-153", 5, "interspeech", 2016], ["Analysis of Face Mask Effect on Speaker Recognition", ["Rahim Saeidi", "Ilkka Huhtakallio", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-518", 5, "interspeech", 2016], ["Using Text and Acoustic Features in Predicting Glottal Excitation Waveforms for Parametric Speech Synthesis with Recurrent Neural Networks", ["Lauri Juvela", "Xin Wang", "Shinji Takaki", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-712", 5, "interspeech", 2016], ["GlottDNN - A Full-Band Glottal Vocoder for Statistical Parametric Speech Synthesis", ["Manu Airaksinen", "Bajibabu Bollepalli", "Lauri Juvela", "Zhizheng Wu", "Simon King", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-342", 5, "interspeech", 2016], ["Intelligibility Enhancement at the Receiving End of the Speech Transmission System - Effects of Far-End Noise Reduction", ["Emma Jokinen", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-144", 5, "interspeech", 2016], ["The Use of Read versus Conversational Lombard Speech in Spectral Tilt Modeling for Intelligibility Enhancement in Near-End Noise Conditions", ["Emma Jokinen", "Ulpu Remes", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-143", 5, "interspeech", 2016]], "Xiaoyun Wang": [4.158675737109263e-09, ["F0 Contour Analysis Based on Empirical Mode Decomposition for DNN Acoustic Modeling in Mandarin Speech Recognition", ["Xiaoyun Wang", "Xugang Lu", "Hisashi Kawai", "Seiichi Yamamoto"], "https://doi.org/10.21437/Interspeech.2016-653", 5, "interspeech", 2016], ["Phoneme Set Design Considering Integrated Acoustic and Linguistic Features of Second Language Speech", ["Xiaoyun Wang", "Tsuneo Kato", "Seiichi Yamamoto"], "https://doi.org/10.21437/Interspeech.2016-663", 5, "interspeech", 2016]], "Xugang Lu": [0, ["F0 Contour Analysis Based on Empirical Mode Decomposition for DNN Acoustic Modeling in Mandarin Speech Recognition", ["Xiaoyun Wang", "Xugang Lu", "Hisashi Kawai", "Seiichi Yamamoto"], "https://doi.org/10.21437/Interspeech.2016-653", 5, "interspeech", 2016], ["Investigation of Semi-Supervised Acoustic Model Training Based on the Committee of Heterogeneous Neural Networks", ["Naoyuki Kanda", "Shoji Harada", "Xugang Lu", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-72", 5, "interspeech", 2016], ["Maximum a posteriori Based Decoding for CTC Acoustic Models", ["Naoyuki Kanda", "Xugang Lu", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-71", 5, "interspeech", 2016], ["Pair-Wise Distance Metric Learning of Neural Network Model for Spoken Language Identification", ["Xugang Lu", "Peng Shen", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-722", 5, "interspeech", 2016], ["SNR-Aware Convolutional Neural Network Modeling for Speech Enhancement", ["Szu-Wei Fu", "Yu Tsao", "Xugang Lu"], "https://doi.org/10.21437/Interspeech.2016-211", 5, "interspeech", 2016]], "Hisashi Kawai": [0, ["F0 Contour Analysis Based on Empirical Mode Decomposition for DNN Acoustic Modeling in Mandarin Speech Recognition", ["Xiaoyun Wang", "Xugang Lu", "Hisashi Kawai", "Seiichi Yamamoto"], "https://doi.org/10.21437/Interspeech.2016-653", 5, "interspeech", 2016], ["Investigation of Semi-Supervised Acoustic Model Training Based on the Committee of Heterogeneous Neural Networks", ["Naoyuki Kanda", "Shoji Harada", "Xugang Lu", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-72", 5, "interspeech", 2016], ["Using Zero-Frequency Resonator to Extract Multilingual Intonation Structure", ["Jinfu Ni", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-1607", 5, "interspeech", 2016], ["Maximum a posteriori Based Decoding for CTC Acoustic Models", ["Naoyuki Kanda", "Xugang Lu", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-71", 5, "interspeech", 2016], ["Model Integration for HMM- and DNN-Based Speech Synthesis Using Product-of-Experts Framework", ["Kentaro Tachibana", "Tomoki Toda", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-1006", 5, "interspeech", 2016], ["Pair-Wise Distance Metric Learning of Neural Network Model for Spoken Language Identification", ["Xugang Lu", "Peng Shen", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-722", 5, "interspeech", 2016]], "Seiichi Yamamoto": [0, ["F0 Contour Analysis Based on Empirical Mode Decomposition for DNN Acoustic Modeling in Mandarin Speech Recognition", ["Xiaoyun Wang", "Xugang Lu", "Hisashi Kawai", "Seiichi Yamamoto"], "https://doi.org/10.21437/Interspeech.2016-653", 5, "interspeech", 2016], ["Phoneme Set Design Considering Integrated Acoustic and Linguistic Features of Second Language Speech", ["Xiaoyun Wang", "Tsuneo Kato", "Seiichi Yamamoto"], "https://doi.org/10.21437/Interspeech.2016-663", 5, "interspeech", 2016]], "Fang Hu": [0, ["Vowels and Diphthongs in Cangnan Southern Min Chinese Dialect", ["Fang Hu", "Chunyu Ge"], "https://doi.org/10.21437/Interspeech.2016-29", 5, "interspeech", 2016], ["Diphthongization of Nuclear Vowels and the Emergence of a Tetraphthong in Hetang Cantonese", ["Wenqi Hu", "Fang Hu", "Jian Jin"], "https://doi.org/10.21437/Interspeech.2016-61", 5, "interspeech", 2016], ["Vowels and Diphthongs in the Taiyuan Jin Chinese Dialect", ["Liping Xia", "Fang Hu"], "https://doi.org/10.21437/Interspeech.2016-249", 5, "interspeech", 2016]], "Chunyu Ge": [0, ["Vowels and Diphthongs in Cangnan Southern Min Chinese Dialect", ["Fang Hu", "Chunyu Ge"], "https://doi.org/10.21437/Interspeech.2016-29", 5, "interspeech", 2016]], "Wenqi Hu": [0, ["Diphthongization of Nuclear Vowels and the Emergence of a Tetraphthong in Hetang Cantonese", ["Wenqi Hu", "Fang Hu", "Jian Jin"], "https://doi.org/10.21437/Interspeech.2016-61", 5, "interspeech", 2016]], "Jian Jin": [0.4041376858949661, ["Diphthongization of Nuclear Vowels and the Emergence of a Tetraphthong in Hetang Cantonese", ["Wenqi Hu", "Fang Hu", "Jian Jin"], "https://doi.org/10.21437/Interspeech.2016-61", 5, "interspeech", 2016]], "Liping Xia": [0, ["Vowels and Diphthongs in the Taiyuan Jin Chinese Dialect", ["Liping Xia", "Fang Hu"], "https://doi.org/10.21437/Interspeech.2016-249", 5, "interspeech", 2016]], "Giuseppina Turco": [0, ["The Effects of Prosody on French V-to-V Coarticulation: A Corpus-Based Study", ["Giuseppina Turco", "Cecile Fougeron", "Nicolas Audibert"], "https://doi.org/10.21437/Interspeech.2016-1323", 4, "interspeech", 2016]], "Cecile Fougeron": [0, ["The Effects of Prosody on French V-to-V Coarticulation: A Corpus-Based Study", ["Giuseppina Turco", "Cecile Fougeron", "Nicolas Audibert"], "https://doi.org/10.21437/Interspeech.2016-1323", 4, "interspeech", 2016]], "Nicolas Audibert": [0, ["The Effects of Prosody on French V-to-V Coarticulation: A Corpus-Based Study", ["Giuseppina Turco", "Cecile Fougeron", "Nicolas Audibert"], "https://doi.org/10.21437/Interspeech.2016-1323", 4, "interspeech", 2016]], "Seung-Eun Chang": [0.9998411685228348, ["Hyperarticulated Production of Korean Glides by Age Group", ["Seung-Eun Chang", "Minsook Kim"], "https://doi.org/10.21437/Interspeech.2016-23", 4, "interspeech", 2016]], "Minsook Kim": [0.9970823377370834, ["Hyperarticulated Production of Korean Glides by Age Group", ["Seung-Eun Chang", "Minsook Kim"], "https://doi.org/10.21437/Interspeech.2016-23", 4, "interspeech", 2016]], "Ho-hsien Pan": [0, ["Coda Stop and Taiwan Min Checked Tone Sound Changes", ["Ho-hsien Pan", "Hsiao-tung Huang", "Shao-Ren Lyu"], "https://doi.org/10.21437/Interspeech.2016-597", 5, "interspeech", 2016]], "Hsiao-tung Huang": [0, ["Coda Stop and Taiwan Min Checked Tone Sound Changes", ["Ho-hsien Pan", "Hsiao-tung Huang", "Shao-Ren Lyu"], "https://doi.org/10.21437/Interspeech.2016-597", 5, "interspeech", 2016]], "Shao-Ren Lyu": [0, ["Coda Stop and Taiwan Min Checked Tone Sound Changes", ["Ho-hsien Pan", "Hsiao-tung Huang", "Shao-Ren Lyu"], "https://doi.org/10.21437/Interspeech.2016-597", 5, "interspeech", 2016]], "Sarah E. Fenwick": [0, ["The Influence of Modality and Speaking Style on the Assimilation Type and Categorization Consistency of Non-Native Speech", ["Sarah E. Fenwick", "Catherine T. Best", "Chris Davis", "Michael D. Tyler"], "https://doi.org/10.21437/Interspeech.2016-611", 5, "interspeech", 2016]], "Catherine T. Best": [0, ["The Influence of Modality and Speaking Style on the Assimilation Type and Categorization Consistency of Non-Native Speech", ["Sarah E. Fenwick", "Catherine T. Best", "Chris Davis", "Michael D. Tyler"], "https://doi.org/10.21437/Interspeech.2016-611", 5, "interspeech", 2016]], "Michael D. Tyler": [0, ["The Influence of Modality and Speaking Style on the Assimilation Type and Categorization Consistency of Non-Native Speech", ["Sarah E. Fenwick", "Catherine T. Best", "Chris Davis", "Michael D. Tyler"], "https://doi.org/10.21437/Interspeech.2016-611", 5, "interspeech", 2016]], "Margaret Zellers": [0, ["Prosodic Convergence with Spoken Stimuli in Laboratory Data", ["Margaret Zellers"], "https://doi.org/10.21437/Interspeech.2016-238", 5, "interspeech", 2016]], "Charalambos Themistocleous": [0, ["Effects of Stress on Fricatives: Evidence from Standard Modern Greek", ["Charalambos Themistocleous", "Angelandria Savva", "Andrie Aristodemou"], "https://doi.org/10.21437/Interspeech.2016-1057", 4, "interspeech", 2016]], "Angelandria Savva": [0, ["Effects of Stress on Fricatives: Evidence from Standard Modern Greek", ["Charalambos Themistocleous", "Angelandria Savva", "Andrie Aristodemou"], "https://doi.org/10.21437/Interspeech.2016-1057", 4, "interspeech", 2016]], "Andrie Aristodemou": [0, ["Effects of Stress on Fricatives: Evidence from Standard Modern Greek", ["Charalambos Themistocleous", "Angelandria Savva", "Andrie Aristodemou"], "https://doi.org/10.21437/Interspeech.2016-1057", 4, "interspeech", 2016]], "Yue Sun": [0.006344768917188048, ["Analysis of Chinese Syllable Durations in Running Speech of Japanese L2 Learners", ["Yue Sun", "Shudon Hsiao", "Yoshinori Sagisaka", "Jin-Song Zhang"], "https://doi.org/10.21437/Interspeech.2016-824", 4, "interspeech", 2016]], "Shudon Hsiao": [0, ["Analysis of Chinese Syllable Durations in Running Speech of Japanese L2 Learners", ["Yue Sun", "Shudon Hsiao", "Yoshinori Sagisaka", "Jin-Song Zhang"], "https://doi.org/10.21437/Interspeech.2016-824", 4, "interspeech", 2016]], "Yoshinori Sagisaka": [0, ["Analysis of Chinese Syllable Durations in Running Speech of Japanese L2 Learners", ["Yue Sun", "Shudon Hsiao", "Yoshinori Sagisaka", "Jin-Song Zhang"], "https://doi.org/10.21437/Interspeech.2016-824", 4, "interspeech", 2016]], "Jin-Song Zhang": [0, ["Analysis of Chinese Syllable Durations in Running Speech of Japanese L2 Learners", ["Yue Sun", "Shudon Hsiao", "Yoshinori Sagisaka", "Jin-Song Zhang"], "https://doi.org/10.21437/Interspeech.2016-824", 4, "interspeech", 2016]], "Catherine Lai": [0, ["Automatic Paragraph Segmentation with Lexical and Prosodic Features", ["Catherine Lai", "Mireia Farrus", "Johanna D. Moore"], "https://doi.org/10.21437/Interspeech.2016-992", 5, "interspeech", 2016]], "Mireia Farrus": [0, ["Automatic Paragraph Segmentation with Lexical and Prosodic Features", ["Catherine Lai", "Mireia Farrus", "Johanna D. Moore"], "https://doi.org/10.21437/Interspeech.2016-992", 5, "interspeech", 2016]], "Johanna D. Moore": [0, ["Automatic Paragraph Segmentation with Lexical and Prosodic Features", ["Catherine Lai", "Mireia Farrus", "Johanna D. Moore"], "https://doi.org/10.21437/Interspeech.2016-992", 5, "interspeech", 2016]], "Tom Backstrom": [0, ["Automatic Glottal Inverse Filtering with Non-Negative Matrix Factorization", ["Manu Airaksinen", "Lauri Juvela", "Tom Backstrom", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-338", 5, "interspeech", 2016], ["Joint Enhancement and Coding of Speech by Incorporating Wiener Filtering in a CELP Codec", ["Johannes Fischer", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2016-245", 5, "interspeech", 2016], ["Blind Recovery of Perceptual Models in Distributed Speech and Audio Coding", ["Tom Backstrom", "Florin Ghido", "Johannes Fischer"], "https://doi.org/10.21437/Interspeech.2016-27", 5, "interspeech", 2016], ["Entropy Coding of Spectral Envelopes for Speech and Audio Coding Using Distribution Quantization", ["Srikanth Korse", "Tobias Jahnel", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2016-55", 5, "interspeech", 2016]], "Soo Jin Park": [0.9360999912023544, ["Speaker Identity and Voice Quality: Modeling Human Responses and Automatic Speaker Recognition", ["Soo Jin Park", "Caroline Sigouin", "Jody Kreiman", "Patricia A. Keating", "Jinxi Guo", "Gary Yeung", "Fang-Yu Kuo", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2016-523", 5, "interspeech", 2016]], "Caroline Sigouin": [0, ["Speaker Identity and Voice Quality: Modeling Human Responses and Automatic Speaker Recognition", ["Soo Jin Park", "Caroline Sigouin", "Jody Kreiman", "Patricia A. Keating", "Jinxi Guo", "Gary Yeung", "Fang-Yu Kuo", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2016-523", 5, "interspeech", 2016]], "Jody Kreiman": [0, ["Speaker Identity and Voice Quality: Modeling Human Responses and Automatic Speaker Recognition", ["Soo Jin Park", "Caroline Sigouin", "Jody Kreiman", "Patricia A. Keating", "Jinxi Guo", "Gary Yeung", "Fang-Yu Kuo", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2016-523", 5, "interspeech", 2016]], "Patricia A. Keating": [0, ["Speaker Identity and Voice Quality: Modeling Human Responses and Automatic Speaker Recognition", ["Soo Jin Park", "Caroline Sigouin", "Jody Kreiman", "Patricia A. Keating", "Jinxi Guo", "Gary Yeung", "Fang-Yu Kuo", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2016-523", 5, "interspeech", 2016], ["Illustrating the Production of the International Phonetic Alphabet Sounds Using Fast Real-Time Magnetic Resonance Imaging", ["Asterios Toutios", "Sajan Goud Lingala", "Colin Vaz", "Jangwon Kim", "John H. Esling", "Patricia A. Keating", "Matthew Gordon", "Dani Byrd", "Louis Goldstein", "Krishna S. Nayak", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-605", 5, "interspeech", 2016]], "Jinxi Guo": [0, ["Speaker Identity and Voice Quality: Modeling Human Responses and Automatic Speaker Recognition", ["Soo Jin Park", "Caroline Sigouin", "Jody Kreiman", "Patricia A. Keating", "Jinxi Guo", "Gary Yeung", "Fang-Yu Kuo", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2016-523", 5, "interspeech", 2016], ["Speaker Verification Using Short Utterances with DNN-Based Estimation of Subglottal Acoustic Features", ["Jinxi Guo", "Gary Yeung", "Deepak Muralidharan", "Harish Arsikere", "Amber Afshan", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2016-282", 4, "interspeech", 2016]], "Gary Yeung": [0, ["Speaker Identity and Voice Quality: Modeling Human Responses and Automatic Speaker Recognition", ["Soo Jin Park", "Caroline Sigouin", "Jody Kreiman", "Patricia A. Keating", "Jinxi Guo", "Gary Yeung", "Fang-Yu Kuo", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2016-523", 5, "interspeech", 2016], ["Speaker Verification Using Short Utterances with DNN-Based Estimation of Subglottal Acoustic Features", ["Jinxi Guo", "Gary Yeung", "Deepak Muralidharan", "Harish Arsikere", "Amber Afshan", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2016-282", 4, "interspeech", 2016]], "Fang-Yu Kuo": [0, ["Speaker Identity and Voice Quality: Modeling Human Responses and Automatic Speaker Recognition", ["Soo Jin Park", "Caroline Sigouin", "Jody Kreiman", "Patricia A. Keating", "Jinxi Guo", "Gary Yeung", "Fang-Yu Kuo", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2016-523", 5, "interspeech", 2016]], "Abeer Alwan": [0, ["Speaker Identity and Voice Quality: Modeling Human Responses and Automatic Speaker Recognition", ["Soo Jin Park", "Caroline Sigouin", "Jody Kreiman", "Patricia A. Keating", "Jinxi Guo", "Gary Yeung", "Fang-Yu Kuo", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2016-523", 5, "interspeech", 2016], ["Speaker Verification Using Short Utterances with DNN-Based Estimation of Subglottal Acoustic Features", ["Jinxi Guo", "Gary Yeung", "Deepak Muralidharan", "Harish Arsikere", "Amber Afshan", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2016-282", 4, "interspeech", 2016], ["Noise-Robust Hidden Markov Models for Limited Training Data for Within-Species Bird Phrase Classification", ["Kantapon Kaewtip", "Charles E. Taylor", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2016-1360", 5, "interspeech", 2016], ["Fusion Strategies for Robust Speech Recognition and Keyword Spotting for Channel- and Noise-Degraded Speech", ["Vikramjit Mitra", "Julien van Hout", "Wen Wang", "Chris Bartels", "Horacio Franco", "Dimitra Vergyri", "Abeer Alwan", "Adam Janin", "John H. L. Hansen", "Richard M. Stern", "Abhijeet Sangwan", "Nelson Morgan"], "https://doi.org/10.21437/Interspeech.2016-279", 5, "interspeech", 2016]], "Sishir Kalita": [0, ["Analysis of Glottal Stop in Assam Sora Language", ["Sishir Kalita", "Luke Horo", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2016-877", 5, "interspeech", 2016]], "Luke Horo": [0, ["Analysis of Glottal Stop in Assam Sora Language", ["Sishir Kalita", "Luke Horo", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2016-877", 5, "interspeech", 2016]], "Priyankoo Sarmah": [0, ["Analysis of Glottal Stop in Assam Sora Language", ["Sishir Kalita", "Luke Horo", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2016-877", 5, "interspeech", 2016]], "Samarendra Dandapat": [0, ["Analysis of Glottal Stop in Assam Sora Language", ["Sishir Kalita", "Luke Horo", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2016-877", 5, "interspeech", 2016]], "Marc Garellek": [0, ["Acoustic Differences Between English /t/ Glottalization and Phrasal Creak", ["Marc Garellek", "Scott Seyfarth"], "https://doi.org/10.21437/Interspeech.2016-1472", 5, "interspeech", 2016]], "Scott Seyfarth": [0, ["Acoustic Differences Between English /t/ Glottalization and Phrasal Creak", ["Marc Garellek", "Scott Seyfarth"], "https://doi.org/10.21437/Interspeech.2016-1472", 5, "interspeech", 2016]], "Anders Eriksson": [0, ["The Acoustics of Lexical Stress in Italian as a Function of Stress Level and Speaking Style", ["Anders Eriksson", "Pier Marco Bertinetto", "Mattias Heldner", "Rosalba Nodari", "Giovanna Lenoci"], "https://doi.org/10.21437/Interspeech.2016-348", 5, "interspeech", 2016], ["Speaker Comparison for Forensic and Investigative Applications II", ["Jean-Francois Bonastre", "Joseph P. Campbell", "Anders Eriksson", "Hirotaka Nakasone", "Reva Schwartz"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs3.html", 0, "interspeech", 2016]], "Pier Marco Bertinetto": [0, ["The Acoustics of Lexical Stress in Italian as a Function of Stress Level and Speaking Style", ["Anders Eriksson", "Pier Marco Bertinetto", "Mattias Heldner", "Rosalba Nodari", "Giovanna Lenoci"], "https://doi.org/10.21437/Interspeech.2016-348", 5, "interspeech", 2016]], "Rosalba Nodari": [0, ["The Acoustics of Lexical Stress in Italian as a Function of Stress Level and Speaking Style", ["Anders Eriksson", "Pier Marco Bertinetto", "Mattias Heldner", "Rosalba Nodari", "Giovanna Lenoci"], "https://doi.org/10.21437/Interspeech.2016-348", 5, "interspeech", 2016]], "Giovanna Lenoci": [0, ["The Acoustics of Lexical Stress in Italian as a Function of Stress Level and Speaking Style", ["Anders Eriksson", "Pier Marco Bertinetto", "Mattias Heldner", "Rosalba Nodari", "Giovanna Lenoci"], "https://doi.org/10.21437/Interspeech.2016-348", 5, "interspeech", 2016]], "Antje Schweitzer": [0, ["Cross-Gender and Cross-Dialect Tone Recognition for Vietnamese", ["Antje Schweitzer", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2016-405", 5, "interspeech", 2016], ["Exemplar Dynamics in Phonetic Convergence of Speech Rate", ["Antje Schweitzer", "Michael Walsh"], "https://doi.org/10.21437/Interspeech.2016-373", 5, "interspeech", 2016]], "Karthika Vijayan": [0, ["Prosody Modification Using Allpass Residual of Speech Signals", ["Karthika Vijayan", "K. Sri Rama Murty"], "https://doi.org/10.21437/Interspeech.2016-914", 5, "interspeech", 2016]], "K. Sri Rama Murty": [0, ["Prosody Modification Using Allpass Residual of Speech Signals", ["Karthika Vijayan", "K. Sri Rama Murty"], "https://doi.org/10.21437/Interspeech.2016-914", 5, "interspeech", 2016]], "Okko Rasanen": [0, ["Analyzing the Contribution of Top-Down Lexical and Bottom-Up Acoustic Cues in the Detection of Sentence Prominence", ["Sofoklis Kakouros", "Joris Pelemans", "Lyan Verwimp", "Patrick Wambacq", "Okko Rasanen"], "https://doi.org/10.21437/Interspeech.2016-926", 5, "interspeech", 2016]], "Jeffrey Kallay": [0, ["A Longitudinal Study of Children's Intonation in Narrative Speech", ["Jeffrey Kallay", "Melissa A. Redford"], "https://doi.org/10.21437/Interspeech.2016-1396", 5, "interspeech", 2016]], "Melissa A. Redford": [0, ["A Longitudinal Study of Children's Intonation in Narrative Speech", ["Jeffrey Kallay", "Melissa A. Redford"], "https://doi.org/10.21437/Interspeech.2016-1396", 5, "interspeech", 2016]], "Reed Blaylock": [0, ["Velum Control for Oral Sounds", ["Reed Blaylock", "Louis Goldstein", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1408", 5, "interspeech", 2016]], "Gayeon Son": [0.9999302625656128, ["F0 Development in Acquiring Korean Stop Distinction", ["Gayeon Son"], "https://doi.org/10.21437/Interspeech.2016-651", 5, "interspeech", 2016]], "Clara Cohen": [0, ["Phonetic Reduction Can Lead to Lengthening, and Enhancement Can Lead to Shortening", ["Clara Cohen", "Matt Carlson"], "https://doi.org/10.21437/Interspeech.2016-1146", 5, "interspeech", 2016], ["Relationships Between Functional Load and Auditory Confusability Under Different Speech Environments", ["Shinae Kang", "Clara Cohen"], "https://doi.org/10.21437/Interspeech.2016-906", 5, "interspeech", 2016]], "Matt Carlson": [0, ["Phonetic Reduction Can Lead to Lengthening, and Enhancement Can Lead to Shortening", ["Clara Cohen", "Matt Carlson"], "https://doi.org/10.21437/Interspeech.2016-1146", 5, "interspeech", 2016]], "Takayuki Arai": [0, ["Mechanical Production of [b], [m] and [w] Using Controlled Labial and Velopharyngeal Gestures", ["Takayuki Arai"], "https://doi.org/10.21437/Interspeech.2016-189", 5, "interspeech", 2016]], "Qiang Fang": [0, ["An Improved 3D Geometric Tongue Model", ["Qiang Fang", "Yun Chen", "Haibo Wang", "Jianguo Wei", "Jianrong Wang", "Xiyu Wu", "Aijun Li"], "https://doi.org/10.21437/Interspeech.2016-901", 4, "interspeech", 2016]], "Yun Chen": [0, ["An Improved 3D Geometric Tongue Model", ["Qiang Fang", "Yun Chen", "Haibo Wang", "Jianguo Wei", "Jianrong Wang", "Xiyu Wu", "Aijun Li"], "https://doi.org/10.21437/Interspeech.2016-901", 4, "interspeech", 2016]], "Haibo Wang": [0.0030781805980950594, ["An Improved 3D Geometric Tongue Model", ["Qiang Fang", "Yun Chen", "Haibo Wang", "Jianguo Wei", "Jianrong Wang", "Xiyu Wu", "Aijun Li"], "https://doi.org/10.21437/Interspeech.2016-901", 4, "interspeech", 2016]], "Jianguo Wei": [0, ["An Improved 3D Geometric Tongue Model", ["Qiang Fang", "Yun Chen", "Haibo Wang", "Jianguo Wei", "Jianrong Wang", "Xiyu Wu", "Aijun Li"], "https://doi.org/10.21437/Interspeech.2016-901", 4, "interspeech", 2016], ["A New Model for Acoustic Wave Propagation and Scattering in the Vocal Tract", ["Jianguo Wei", "Wendan Guan", "Darcy Q. Hou", "Dingyi Pan", "Wenhuan Lu", "Jianwu Dang"], "https://doi.org/10.21437/Interspeech.2016-1513", 5, "interspeech", 2016]], "Jianrong Wang": [1.1226079266180022e-06, ["An Improved 3D Geometric Tongue Model", ["Qiang Fang", "Yun Chen", "Haibo Wang", "Jianguo Wei", "Jianrong Wang", "Xiyu Wu", "Aijun Li"], "https://doi.org/10.21437/Interspeech.2016-901", 4, "interspeech", 2016]], "Xiyu Wu": [1.7142584056273336e-05, ["An Improved 3D Geometric Tongue Model", ["Qiang Fang", "Yun Chen", "Haibo Wang", "Jianguo Wei", "Jianrong Wang", "Xiyu Wu", "Aijun Li"], "https://doi.org/10.21437/Interspeech.2016-901", 4, "interspeech", 2016]], "Aijun Li": [0, ["An Improved 3D Geometric Tongue Model", ["Qiang Fang", "Yun Chen", "Haibo Wang", "Jianguo Wei", "Jianrong Wang", "Xiyu Wu", "Aijun Li"], "https://doi.org/10.21437/Interspeech.2016-901", 4, "interspeech", 2016]], "Mikko Tiainen": [0, ["Congruency Effect Between Articulation and Grasping in Native English Speakers", ["Mikko Tiainen", "Fatima M. Felisberti", "Kaisa Tiippana", "Martti Vainio", "Juraj Simko", "Jiri Lukavsky", "Lari Vainio"], "https://doi.org/10.21437/Interspeech.2016-1199", 5, "interspeech", 2016]], "Fatima M. Felisberti": [0, ["Congruency Effect Between Articulation and Grasping in Native English Speakers", ["Mikko Tiainen", "Fatima M. Felisberti", "Kaisa Tiippana", "Martti Vainio", "Juraj Simko", "Jiri Lukavsky", "Lari Vainio"], "https://doi.org/10.21437/Interspeech.2016-1199", 5, "interspeech", 2016]], "Kaisa Tiippana": [0, ["Congruency Effect Between Articulation and Grasping in Native English Speakers", ["Mikko Tiainen", "Fatima M. Felisberti", "Kaisa Tiippana", "Martti Vainio", "Juraj Simko", "Jiri Lukavsky", "Lari Vainio"], "https://doi.org/10.21437/Interspeech.2016-1199", 5, "interspeech", 2016]], "Juraj Simko": [0, ["Congruency Effect Between Articulation and Grasping in Native English Speakers", ["Mikko Tiainen", "Fatima M. Felisberti", "Kaisa Tiippana", "Martti Vainio", "Juraj Simko", "Jiri Lukavsky", "Lari Vainio"], "https://doi.org/10.21437/Interspeech.2016-1199", 5, "interspeech", 2016]], "Jiri Lukavsky": [0, ["Congruency Effect Between Articulation and Grasping in Native English Speakers", ["Mikko Tiainen", "Fatima M. Felisberti", "Kaisa Tiippana", "Martti Vainio", "Juraj Simko", "Jiri Lukavsky", "Lari Vainio"], "https://doi.org/10.21437/Interspeech.2016-1199", 5, "interspeech", 2016]], "Lari Vainio": [0, ["Congruency Effect Between Articulation and Grasping in Native English Speakers", ["Mikko Tiainen", "Fatima M. Felisberti", "Kaisa Tiippana", "Martti Vainio", "Juraj Simko", "Jiri Lukavsky", "Lari Vainio"], "https://doi.org/10.21437/Interspeech.2016-1199", 5, "interspeech", 2016]], "Julien Meyer": [0, ["Categorization of Natural Spanish Whistled Vowels by Na\u00efve Spanish Listeners", ["Julien Meyer", "Laure Dentel", "Fanny Meunier"], "https://doi.org/10.21437/Interspeech.2016-379", 4, "interspeech", 2016]], "Laure Dentel": [0, ["Categorization of Natural Spanish Whistled Vowels by Na\u00efve Spanish Listeners", ["Julien Meyer", "Laure Dentel", "Fanny Meunier"], "https://doi.org/10.21437/Interspeech.2016-379", 4, "interspeech", 2016]], "Rob Voigt": [0, ["Between- and Within-Speaker Effects of Bilingualism on F0 Variation", ["Rob Voigt", "Dan Jurafsky", "Meghan Sumner"], "https://doi.org/10.21437/Interspeech.2016-1506", 5, "interspeech", 2016]], "Dan Jurafsky": [0, ["Between- and Within-Speaker Effects of Bilingualism on F0 Variation", ["Rob Voigt", "Dan Jurafsky", "Meghan Sumner"], "https://doi.org/10.21437/Interspeech.2016-1506", 5, "interspeech", 2016], ["Ketchup, Interdisciplinarity, and the Spread of Innovation in Speech and Language Processing", ["Dan Jurafsky"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/3004.html", 1, "interspeech", 2016]], "Meghan Sumner": [0, ["Between- and Within-Speaker Effects of Bilingualism on F0 Variation", ["Rob Voigt", "Dan Jurafsky", "Meghan Sumner"], "https://doi.org/10.21437/Interspeech.2016-1506", 5, "interspeech", 2016]], "Calbert Graham": [0, ["Vowel Characteristics in the Assessment of L2 English Pronunciation", ["Calbert Graham", "Paula Buttery", "Francis Nolan"], "https://doi.org/10.21437/Interspeech.2016-1630", 5, "interspeech", 2016]], "Paula Buttery": [0, ["Vowel Characteristics in the Assessment of L2 English Pronunciation", ["Calbert Graham", "Paula Buttery", "Francis Nolan"], "https://doi.org/10.21437/Interspeech.2016-1630", 5, "interspeech", 2016]], "Francis Nolan": [0, ["Vowel Characteristics in the Assessment of L2 English Pronunciation", ["Calbert Graham", "Paula Buttery", "Francis Nolan"], "https://doi.org/10.21437/Interspeech.2016-1630", 5, "interspeech", 2016]], "Ahmed Geneid": [0, ["Kulning (Swedish Cattle Calls): Acoustic, EGG, Stroboscopic and High-Speed Video Analyses of an Unusual Singing Style", ["Ahmed Geneid", "Anne-Maria Laukkanen", "Anita McAllister", "Robert Eklund"], "https://doi.org/10.21437/Interspeech.2016-1082", 4, "interspeech", 2016]], "Anne-Maria Laukkanen": [0, ["Kulning (Swedish Cattle Calls): Acoustic, EGG, Stroboscopic and High-Speed Video Analyses of an Unusual Singing Style", ["Ahmed Geneid", "Anne-Maria Laukkanen", "Anita McAllister", "Robert Eklund"], "https://doi.org/10.21437/Interspeech.2016-1082", 4, "interspeech", 2016]], "Anita McAllister": [0, ["Kulning (Swedish Cattle Calls): Acoustic, EGG, Stroboscopic and High-Speed Video Analyses of an Unusual Singing Style", ["Ahmed Geneid", "Anne-Maria Laukkanen", "Anita McAllister", "Robert Eklund"], "https://doi.org/10.21437/Interspeech.2016-1082", 4, "interspeech", 2016]], "Robert Eklund": [0, ["Kulning (Swedish Cattle Calls): Acoustic, EGG, Stroboscopic and High-Speed Video Analyses of an Unusual Singing Style", ["Ahmed Geneid", "Anne-Maria Laukkanen", "Anita McAllister", "Robert Eklund"], "https://doi.org/10.21437/Interspeech.2016-1082", 4, "interspeech", 2016], ["Supplementary Motor Area Activation in Disfluency Perception: An fMRI Study of Listener Neural Responses to Spontaneously Produced Unfilled and Filled Pauses", ["Robert Eklund", "Martin Ingvar"], "https://doi.org/10.21437/Interspeech.2016-973", 4, "interspeech", 2016]], "Misa Hejna": [0, ["Glottal Squeaks in VC Sequences", ["Misa Hejna", "Pertti Palo", "Scott Moisik"], "https://doi.org/10.21437/Interspeech.2016-1496", 5, "interspeech", 2016], ["Multiplicity of the Acoustic Correlates of the Fortis-Lenis Contrast: Plosives in Aberystwyth English", ["Misa Hejna"], "https://doi.org/10.21437/Interspeech.2016-1101", 5, "interspeech", 2016]], "Pertti Palo": [0, ["Glottal Squeaks in VC Sequences", ["Misa Hejna", "Pertti Palo", "Scott Moisik"], "https://doi.org/10.21437/Interspeech.2016-1496", 5, "interspeech", 2016]], "Scott Moisik": [0, ["Glottal Squeaks in VC Sequences", ["Misa Hejna", "Pertti Palo", "Scott Moisik"], "https://doi.org/10.21437/Interspeech.2016-1496", 5, "interspeech", 2016]], "Naoya Takahashi": [0, ["Automatic Pronunciation Generation by Utilizing a Semi-Supervised Deep Neural Networks", ["Naoya Takahashi", "Tofigh Naghibi", "Beat Pfister"], "https://doi.org/10.21437/Interspeech.2016-761", 5, "interspeech", 2016], ["Deep Convolutional Neural Networks and Data Augmentation for Acoustic Event Recognition", ["Naoya Takahashi", "Michael Gygli", "Beat Pfister", "Luc Van Gool"], "https://doi.org/10.21437/Interspeech.2016-805", 5, "interspeech", 2016]], "Tofigh Naghibi": [0, ["Automatic Pronunciation Generation by Utilizing a Semi-Supervised Deep Neural Networks", ["Naoya Takahashi", "Tofigh Naghibi", "Beat Pfister"], "https://doi.org/10.21437/Interspeech.2016-761", 5, "interspeech", 2016]], "Beat Pfister": [0, ["Automatic Pronunciation Generation by Utilizing a Semi-Supervised Deep Neural Networks", ["Naoya Takahashi", "Tofigh Naghibi", "Beat Pfister"], "https://doi.org/10.21437/Interspeech.2016-761", 5, "interspeech", 2016], ["The SIWIS Database: A Multilingual Speech Database with Acted Emphasis", ["Jean-Philippe Goldman", "Pierre-Edouard Honnet", "Robert A. J. Clark", "Philip N. Garner", "Maria Ivanova", "Alexandros Lazaridis", "Hui Liang", "Tiago Macedo", "Beat Pfister", "Manuel Sam Ribeiro", "Eric Wehrli", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1003", 4, "interspeech", 2016], ["Deep Convolutional Neural Networks and Data Augmentation for Acoustic Event Recognition", ["Naoya Takahashi", "Michael Gygli", "Beat Pfister", "Luc Van Gool"], "https://doi.org/10.21437/Interspeech.2016-805", 5, "interspeech", 2016]], "Xiaohu Liu": [0, ["Personalized Natural Language Understanding", ["Xiaohu Liu", "Ruhi Sarikaya", "Liang Zhao", "Yong Ni", "Yi-Cheng Pan"], "https://doi.org/10.21437/Interspeech.2016-1172", 5, "interspeech", 2016], ["A New Pre-Training Method for Training Deep Learning Models with Application to Spoken Language Understanding", ["Asli Celikyilmaz", "Ruhi Sarikaya", "Dilek Hakkani-Tur", "Xiaohu Liu", "Nikhil Ramesh", "Gokhan Tur"], "https://doi.org/10.21437/Interspeech.2016-512", 5, "interspeech", 2016]], "Ruhi Sarikaya": [0, ["Personalized Natural Language Understanding", ["Xiaohu Liu", "Ruhi Sarikaya", "Liang Zhao", "Yong Ni", "Yi-Cheng Pan"], "https://doi.org/10.21437/Interspeech.2016-1172", 5, "interspeech", 2016], ["Making Personal Digital Assistants Aware of What They Do Not Know", ["Omar Zia Khan", "Ruhi Sarikaya"], "https://doi.org/10.21437/Interspeech.2016-1534", 5, "interspeech", 2016], ["Flexible, Rapid Authoring of Goal-Orientated, Multi-Turn Dialogues Using the Task Completion Platform", ["Alex Marin", "Paul A. Crook", "Omar Zia Khan", "Vasiliy Radostev", "Khushboo Aggarwal", "Ruhi Sarikaya"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2020.html", 2, "interspeech", 2016], ["A New Pre-Training Method for Training Deep Learning Models with Application to Spoken Language Understanding", ["Asli Celikyilmaz", "Ruhi Sarikaya", "Dilek Hakkani-Tur", "Xiaohu Liu", "Nikhil Ramesh", "Gokhan Tur"], "https://doi.org/10.21437/Interspeech.2016-512", 5, "interspeech", 2016]], "Liang Zhao": [0, ["Personalized Natural Language Understanding", ["Xiaohu Liu", "Ruhi Sarikaya", "Liang Zhao", "Yong Ni", "Yi-Cheng Pan"], "https://doi.org/10.21437/Interspeech.2016-1172", 5, "interspeech", 2016]], "Yong Ni": [0, ["Personalized Natural Language Understanding", ["Xiaohu Liu", "Ruhi Sarikaya", "Liang Zhao", "Yong Ni", "Yi-Cheng Pan"], "https://doi.org/10.21437/Interspeech.2016-1172", 5, "interspeech", 2016]], "Yi-Cheng Pan": [0, ["Personalized Natural Language Understanding", ["Xiaohu Liu", "Ruhi Sarikaya", "Liang Zhao", "Yong Ni", "Yi-Cheng Pan"], "https://doi.org/10.21437/Interspeech.2016-1172", 5, "interspeech", 2016]], "Layla El Asri": [0, ["A Sequence-to-Sequence Model for User Simulation in Spoken Dialogue Systems", ["Layla El Asri", "Jing He", "Kaheer Suleman"], "https://doi.org/10.21437/Interspeech.2016-1175", 5, "interspeech", 2016]], "Jing He": [0, ["A Sequence-to-Sequence Model for User Simulation in Spoken Dialogue Systems", ["Layla El Asri", "Jing He", "Kaheer Suleman"], "https://doi.org/10.21437/Interspeech.2016-1175", 5, "interspeech", 2016]], "Kaheer Suleman": [0, ["A Sequence-to-Sequence Model for User Simulation in Spoken Dialogue Systems", ["Layla El Asri", "Jing He", "Kaheer Suleman"], "https://doi.org/10.21437/Interspeech.2016-1175", 5, "interspeech", 2016]], "Spiros Georgiladakis": [0, ["Root Cause Analysis of Miscommunication Hotspots in Spoken Dialogue Systems", ["Spiros Georgiladakis", "Georgia Athanasopoulou", "Raveesh Meena", "Jose Lopes", "Arodami Chorianopoulou", "Elisavet Palogiannidi", "Elias Iosif", "Gabriel Skantze", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2016-1273", 5, "interspeech", 2016]], "Georgia Athanasopoulou": [0, ["Root Cause Analysis of Miscommunication Hotspots in Spoken Dialogue Systems", ["Spiros Georgiladakis", "Georgia Athanasopoulou", "Raveesh Meena", "Jose Lopes", "Arodami Chorianopoulou", "Elisavet Palogiannidi", "Elias Iosif", "Gabriel Skantze", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2016-1273", 5, "interspeech", 2016]], "Raveesh Meena": [0, ["Root Cause Analysis of Miscommunication Hotspots in Spoken Dialogue Systems", ["Spiros Georgiladakis", "Georgia Athanasopoulou", "Raveesh Meena", "Jose Lopes", "Arodami Chorianopoulou", "Elisavet Palogiannidi", "Elias Iosif", "Gabriel Skantze", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2016-1273", 5, "interspeech", 2016]], "Jose Lopes": [0, ["Root Cause Analysis of Miscommunication Hotspots in Spoken Dialogue Systems", ["Spiros Georgiladakis", "Georgia Athanasopoulou", "Raveesh Meena", "Jose Lopes", "Arodami Chorianopoulou", "Elisavet Palogiannidi", "Elias Iosif", "Gabriel Skantze", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2016-1273", 5, "interspeech", 2016]], "Elisavet Palogiannidi": [0, ["Root Cause Analysis of Miscommunication Hotspots in Spoken Dialogue Systems", ["Spiros Georgiladakis", "Georgia Athanasopoulou", "Raveesh Meena", "Jose Lopes", "Arodami Chorianopoulou", "Elisavet Palogiannidi", "Elias Iosif", "Gabriel Skantze", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2016-1273", 5, "interspeech", 2016]], "Elias Iosif": [0, ["Root Cause Analysis of Miscommunication Hotspots in Spoken Dialogue Systems", ["Spiros Georgiladakis", "Georgia Athanasopoulou", "Raveesh Meena", "Jose Lopes", "Arodami Chorianopoulou", "Elisavet Palogiannidi", "Elias Iosif", "Gabriel Skantze", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2016-1273", 5, "interspeech", 2016], ["Audio-Based Distributional Representations of Meaning Using a Fusion of Feature Encodings", ["Giannis Karamanolakis", "Elias Iosif", "Athanasia Zlatintsi", "Aggelos Pikrakis", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2016-839", 5, "interspeech", 2016]], "Gabriel Skantze": [0, ["Root Cause Analysis of Miscommunication Hotspots in Spoken Dialogue Systems", ["Spiros Georgiladakis", "Georgia Athanasopoulou", "Raveesh Meena", "Jose Lopes", "Arodami Chorianopoulou", "Elisavet Palogiannidi", "Elias Iosif", "Gabriel Skantze", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2016-1273", 5, "interspeech", 2016]], "Omar Zia Khan": [0, ["Making Personal Digital Assistants Aware of What They Do Not Know", ["Omar Zia Khan", "Ruhi Sarikaya"], "https://doi.org/10.21437/Interspeech.2016-1534", 5, "interspeech", 2016], ["Flexible, Rapid Authoring of Goal-Orientated, Multi-Turn Dialogues Using the Task Completion Platform", ["Alex Marin", "Paul A. Crook", "Omar Zia Khan", "Vasiliy Radostev", "Khushboo Aggarwal", "Ruhi Sarikaya"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2020.html", 2, "interspeech", 2016]], "Rivka Levitan": [0, ["Implementing Acoustic-Prosodic Entrainment in a Conversational Avatar", ["Rivka Levitan", "Stefan Benus", "Ramiro H. Galvez", "Agustin Gravano", "Florencia Savoretti", "Marian Trnka", "Andreas Weise", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-985", 5, "interspeech", 2016], ["Automatically Classifying Self-Rated Personality Scores from Speech", ["Guozhen An", "Sarah Ita Levitan", "Rivka Levitan", "Andrew Rosenberg", "Michelle Levine", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-1328", 5, "interspeech", 2016], ["Combining Acoustic-Prosodic, Lexical, and Phonotactic Features for Automatic Deception Detection", ["Sarah Ita Levitan", "Guozhen An", "Min Ma", "Rivka Levitan", "Andrew Rosenberg", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-1519", 5, "interspeech", 2016]], "Stefan Benus": [0, ["Implementing Acoustic-Prosodic Entrainment in a Conversational Avatar", ["Rivka Levitan", "Stefan Benus", "Ramiro H. Galvez", "Agustin Gravano", "Florencia Savoretti", "Marian Trnka", "Andreas Weise", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-985", 5, "interspeech", 2016], ["Who Do You Think Will Speak Next? Perception of Turn-Taking Cues in Slovak and Argentine Spanish", ["Agustin Gravano", "Pablo Brusco", "Stefan Benus"], "https://doi.org/10.21437/Interspeech.2016-585", 5, "interspeech", 2016]], "Ramiro H. Galvez": [0, ["Implementing Acoustic-Prosodic Entrainment in a Conversational Avatar", ["Rivka Levitan", "Stefan Benus", "Ramiro H. Galvez", "Agustin Gravano", "Florencia Savoretti", "Marian Trnka", "Andreas Weise", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-985", 5, "interspeech", 2016], ["Disentrainment may be a Positive Thing: A Novel Measure of Unsigned Acoustic-Prosodic Synchrony, and its Relation to Speaker Engagement", ["Juan Manuel Perez", "Ramiro H. Galvez", "Agustin Gravano"], "https://doi.org/10.21437/Interspeech.2016-587", 5, "interspeech", 2016]], "Agustin Gravano": [0, ["Implementing Acoustic-Prosodic Entrainment in a Conversational Avatar", ["Rivka Levitan", "Stefan Benus", "Ramiro H. Galvez", "Agustin Gravano", "Florencia Savoretti", "Marian Trnka", "Andreas Weise", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-985", 5, "interspeech", 2016], ["Who Do You Think Will Speak Next? Perception of Turn-Taking Cues in Slovak and Argentine Spanish", ["Agustin Gravano", "Pablo Brusco", "Stefan Benus"], "https://doi.org/10.21437/Interspeech.2016-585", 5, "interspeech", 2016], ["Disentrainment may be a Positive Thing: A Novel Measure of Unsigned Acoustic-Prosodic Synchrony, and its Relation to Speaker Engagement", ["Juan Manuel Perez", "Ramiro H. Galvez", "Agustin Gravano"], "https://doi.org/10.21437/Interspeech.2016-587", 5, "interspeech", 2016]], "Florencia Savoretti": [0, ["Implementing Acoustic-Prosodic Entrainment in a Conversational Avatar", ["Rivka Levitan", "Stefan Benus", "Ramiro H. Galvez", "Agustin Gravano", "Florencia Savoretti", "Marian Trnka", "Andreas Weise", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-985", 5, "interspeech", 2016]], "Marian Trnka": [0, ["Implementing Acoustic-Prosodic Entrainment in a Conversational Avatar", ["Rivka Levitan", "Stefan Benus", "Ramiro H. Galvez", "Agustin Gravano", "Florencia Savoretti", "Marian Trnka", "Andreas Weise", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-985", 5, "interspeech", 2016]], "Andreas Weise": [0, ["Implementing Acoustic-Prosodic Entrainment in a Conversational Avatar", ["Rivka Levitan", "Stefan Benus", "Ramiro H. Galvez", "Agustin Gravano", "Florencia Savoretti", "Marian Trnka", "Andreas Weise", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-985", 5, "interspeech", 2016]], "Annika Silvervarg": [0, ["Perceived Usability and Cognitive Demand of Secondary Tasks in Spoken Versus Visual-Manual Automotive Interaction", ["Annika Silvervarg", "Sofia Lindvall", "Jonatan Andersson", "Ida Esberg", "Christian Jernberg", "Filip Frumerie", "Arne Jonsson"], "https://doi.org/10.21437/Interspeech.2016-99", 5, "interspeech", 2016]], "Sofia Lindvall": [0, ["Perceived Usability and Cognitive Demand of Secondary Tasks in Spoken Versus Visual-Manual Automotive Interaction", ["Annika Silvervarg", "Sofia Lindvall", "Jonatan Andersson", "Ida Esberg", "Christian Jernberg", "Filip Frumerie", "Arne Jonsson"], "https://doi.org/10.21437/Interspeech.2016-99", 5, "interspeech", 2016]], "Jonatan Andersson": [0, ["Perceived Usability and Cognitive Demand of Secondary Tasks in Spoken Versus Visual-Manual Automotive Interaction", ["Annika Silvervarg", "Sofia Lindvall", "Jonatan Andersson", "Ida Esberg", "Christian Jernberg", "Filip Frumerie", "Arne Jonsson"], "https://doi.org/10.21437/Interspeech.2016-99", 5, "interspeech", 2016]], "Ida Esberg": [0, ["Perceived Usability and Cognitive Demand of Secondary Tasks in Spoken Versus Visual-Manual Automotive Interaction", ["Annika Silvervarg", "Sofia Lindvall", "Jonatan Andersson", "Ida Esberg", "Christian Jernberg", "Filip Frumerie", "Arne Jonsson"], "https://doi.org/10.21437/Interspeech.2016-99", 5, "interspeech", 2016]], "Christian Jernberg": [0, ["Perceived Usability and Cognitive Demand of Secondary Tasks in Spoken Versus Visual-Manual Automotive Interaction", ["Annika Silvervarg", "Sofia Lindvall", "Jonatan Andersson", "Ida Esberg", "Christian Jernberg", "Filip Frumerie", "Arne Jonsson"], "https://doi.org/10.21437/Interspeech.2016-99", 5, "interspeech", 2016]], "Filip Frumerie": [0, ["Perceived Usability and Cognitive Demand of Secondary Tasks in Spoken Versus Visual-Manual Automotive Interaction", ["Annika Silvervarg", "Sofia Lindvall", "Jonatan Andersson", "Ida Esberg", "Christian Jernberg", "Filip Frumerie", "Arne Jonsson"], "https://doi.org/10.21437/Interspeech.2016-99", 5, "interspeech", 2016]], "Arne Jonsson": [0, ["Perceived Usability and Cognitive Demand of Secondary Tasks in Spoken Versus Visual-Manual Automotive Interaction", ["Annika Silvervarg", "Sofia Lindvall", "Jonatan Andersson", "Ida Esberg", "Christian Jernberg", "Filip Frumerie", "Arne Jonsson"], "https://doi.org/10.21437/Interspeech.2016-99", 5, "interspeech", 2016]], "Pascale Fung": [0, ["Zara: An Empathetic Interactive Virtual Agent", ["Pascale Fung", "Anik Dey", "Farhad Bin Siddique", "Ruixi Lin", "Yang Yang", "Yan Wan", "Ricky Ho Yin Chan"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2012.html", 2, "interspeech", 2016], ["Computational Approaches to Linguistic Code Switching", ["Mona T. Diab", "Pascale Fung", "Julia Hirschberg", "Thamar Solorio"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs16.html", 0, "interspeech", 2016]], "Anik Dey": [0, ["Zara: An Empathetic Interactive Virtual Agent", ["Pascale Fung", "Anik Dey", "Farhad Bin Siddique", "Ruixi Lin", "Yang Yang", "Yan Wan", "Ricky Ho Yin Chan"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2012.html", 2, "interspeech", 2016]], "Farhad Bin Siddique": [0, ["Zara: An Empathetic Interactive Virtual Agent", ["Pascale Fung", "Anik Dey", "Farhad Bin Siddique", "Ruixi Lin", "Yang Yang", "Yan Wan", "Ricky Ho Yin Chan"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2012.html", 2, "interspeech", 2016]], "Ruixi Lin": [0, ["Zara: An Empathetic Interactive Virtual Agent", ["Pascale Fung", "Anik Dey", "Farhad Bin Siddique", "Ruixi Lin", "Yang Yang", "Yan Wan", "Ricky Ho Yin Chan"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2012.html", 2, "interspeech", 2016]], "Yang Yang": [0.012746322434395552, ["Zara: An Empathetic Interactive Virtual Agent", ["Pascale Fung", "Anik Dey", "Farhad Bin Siddique", "Ruixi Lin", "Yang Yang", "Yan Wan", "Ricky Ho Yin Chan"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2012.html", 2, "interspeech", 2016]], "Yan Wan": [0, ["Zara: An Empathetic Interactive Virtual Agent", ["Pascale Fung", "Anik Dey", "Farhad Bin Siddique", "Ruixi Lin", "Yang Yang", "Yan Wan", "Ricky Ho Yin Chan"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2012.html", 2, "interspeech", 2016]], "Ricky Ho Yin Chan": [0, ["Zara: An Empathetic Interactive Virtual Agent", ["Pascale Fung", "Anik Dey", "Farhad Bin Siddique", "Ruixi Lin", "Yang Yang", "Yan Wan", "Ricky Ho Yin Chan"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2012.html", 2, "interspeech", 2016]], "Cristian Tejedor Garcia": [0, ["Measuring Pronunciation Improvement in Users of CAPT Tool TipTopTalk!", ["Cristian Tejedor Garcia", "David Escudero Mancebo", "Enrique Camara Arenas", "Cesar Gonzalez Ferreras", "Valentin Cardenoso-Payo"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2013.html", 2, "interspeech", 2016]], "David Escudero Mancebo": [0, ["Measuring Pronunciation Improvement in Users of CAPT Tool TipTopTalk!", ["Cristian Tejedor Garcia", "David Escudero Mancebo", "Enrique Camara Arenas", "Cesar Gonzalez Ferreras", "Valentin Cardenoso-Payo"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2013.html", 2, "interspeech", 2016], ["The Magic Stone: A Video Game to Improve Communication Skills of People with Intellectual Disabilities", ["Mario Corrales-Astorgano", "David Escudero Mancebo", "Cesar Gonzalez Ferreras", "Yurena Gutierrez-Gonzalez", "Valle Flores-Lucas", "Valentin Cardenoso-Payo", "Lourdes Aguilar-Cuevas"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2017.html", 2, "interspeech", 2016]], "Enrique Camara Arenas": [0, ["Measuring Pronunciation Improvement in Users of CAPT Tool TipTopTalk!", ["Cristian Tejedor Garcia", "David Escudero Mancebo", "Enrique Camara Arenas", "Cesar Gonzalez Ferreras", "Valentin Cardenoso-Payo"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2013.html", 2, "interspeech", 2016]], "Cesar Gonzalez Ferreras": [0, ["Measuring Pronunciation Improvement in Users of CAPT Tool TipTopTalk!", ["Cristian Tejedor Garcia", "David Escudero Mancebo", "Enrique Camara Arenas", "Cesar Gonzalez Ferreras", "Valentin Cardenoso-Payo"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2013.html", 2, "interspeech", 2016], ["The Magic Stone: A Video Game to Improve Communication Skills of People with Intellectual Disabilities", ["Mario Corrales-Astorgano", "David Escudero Mancebo", "Cesar Gonzalez Ferreras", "Yurena Gutierrez-Gonzalez", "Valle Flores-Lucas", "Valentin Cardenoso-Payo", "Lourdes Aguilar-Cuevas"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2017.html", 2, "interspeech", 2016]], "Valentin Cardenoso-Payo": [0, ["Measuring Pronunciation Improvement in Users of CAPT Tool TipTopTalk!", ["Cristian Tejedor Garcia", "David Escudero Mancebo", "Enrique Camara Arenas", "Cesar Gonzalez Ferreras", "Valentin Cardenoso-Payo"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2013.html", 2, "interspeech", 2016], ["The Magic Stone: A Video Game to Improve Communication Skills of People with Intellectual Disabilities", ["Mario Corrales-Astorgano", "David Escudero Mancebo", "Cesar Gonzalez Ferreras", "Yurena Gutierrez-Gonzalez", "Valle Flores-Lucas", "Valentin Cardenoso-Payo", "Lourdes Aguilar-Cuevas"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2017.html", 2, "interspeech", 2016]], "Hideki Kawahara": [0, ["SparkNG: Interactive MATLAB Tools for Introduction to Speech Production, Perception and Processing Fundamentals and Application of the Aliasing-Free L-F Model Component", ["Hideki Kawahara"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2014.html", 2, "interspeech", 2016], ["TUSK: A Framework for Overviewing the Performance of F0 Estimators", ["Masanori Morise", "Hideki Kawahara"], "https://doi.org/10.21437/Interspeech.2016-140", 5, "interspeech", 2016]], "Erik Marchi": [0, ["Real-Time Tracking of Speakers' Emotions, States, and Traits on Mobile Platforms", ["Erik Marchi", "Florian Eyben", "Gerhard Hagerer", "Bjorn W. Schuller"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2015.html", 2, "interspeech", 2016], ["Automatic Analysis of Typical and Atypical Encoding of Spontaneous Emotion in the Voice of Children", ["Fabien Ringeval", "Erik Marchi", "Charline Grossard", "Jean Xavier", "Mohamed Chetouani", "David Cohen", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-766", 5, "interspeech", 2016], ["Is Deception Emotional? An Emotion-Driven Predictive Approach", ["Shahin Amiriparian", "Jouni Pohjalainen", "Erik Marchi", "Sergey Pugachevskiy", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-565", 5, "interspeech", 2016], ["Enhancing Multilingual Recognition of Emotion in Speech by Language Identification", ["Hesam Sagha", "Pavel Matejka", "Maryna Gavryukova", "Filip Povolny", "Erik Marchi", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-333", 5, "interspeech", 2016], ["Facing Realism in Spontaneous Emotion Recognition from Speech: Feature Enhancement by Autoencoder with LSTM Neural Networks", ["Zixing Zhang", "Fabien Ringeval", "Jing Han", "Jun Deng", "Erik Marchi", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-998", 5, "interspeech", 2016]], "Florian Eyben": [0, ["Real-Time Tracking of Speakers' Emotions, States, and Traits on Mobile Platforms", ["Erik Marchi", "Florian Eyben", "Gerhard Hagerer", "Bjorn W. Schuller"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2015.html", 2, "interspeech", 2016]], "Gerhard Hagerer": [0, ["Real-Time Tracking of Speakers' Emotions, States, and Traits on Mobile Platforms", ["Erik Marchi", "Florian Eyben", "Gerhard Hagerer", "Bjorn W. Schuller"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2015.html", 2, "interspeech", 2016]], "Nikki Mirghafori": [0, ["Mindfulness Special Event", ["Nikki Mirghafori"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs2.html", 0, "interspeech", 2016]], "Edward Chang": [4.7297218225272886e-11, ["The Human Speech Cortex", ["Edward Chang"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/3002.html", 1, "interspeech", 2016]], "Joseph P. Campbell": [0, ["Speaker Comparison for Forensic and Investigative Applications II", ["Jean-Francois Bonastre", "Joseph P. Campbell", "Anders Eriksson", "Hirotaka Nakasone", "Reva Schwartz"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs3.html", 0, "interspeech", 2016], ["Corpora for the Evaluation of Robust Speaker Recognition Systems", ["Douglas E. Sturim", "Pedro A. Torres-Carrasquillo", "Joseph P. Campbell"], "https://doi.org/10.21437/Interspeech.2016-1609", 5, "interspeech", 2016]], "Hirotaka Nakasone": [0, ["Speaker Comparison for Forensic and Investigative Applications II", ["Jean-Francois Bonastre", "Joseph P. Campbell", "Anders Eriksson", "Hirotaka Nakasone", "Reva Schwartz"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs3.html", 0, "interspeech", 2016]], "Reva Schwartz": [0, ["Speaker Comparison for Forensic and Investigative Applications II", ["Jean-Francois Bonastre", "Joseph P. Campbell", "Anders Eriksson", "Hirotaka Nakasone", "Reva Schwartz"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs3.html", 0, "interspeech", 2016]], "Daniel Bone": [0, ["Acoustic-Prosodic and Turn-Taking Features in Interactions with Children with Neurodevelopmental Disorders", ["Daniel Bone", "Somer Bishop", "Rahul Gupta", "Sungbok Lee", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1073", 5, "interspeech", 2016], ["Objective Language Feature Analysis in Children with Neurodevelopmental Disorders During Autism Assessment", ["Manoj Kumar", "Rahul Gupta", "Daniel Bone", "Nikolaos Malandrakis", "Somer Bishop", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-563", 5, "interspeech", 2016]], "Somer Bishop": [0, ["Acoustic-Prosodic and Turn-Taking Features in Interactions with Children with Neurodevelopmental Disorders", ["Daniel Bone", "Somer Bishop", "Rahul Gupta", "Sungbok Lee", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1073", 5, "interspeech", 2016], ["Objective Language Feature Analysis in Children with Neurodevelopmental Disorders During Autism Assessment", ["Manoj Kumar", "Rahul Gupta", "Daniel Bone", "Nikolaos Malandrakis", "Somer Bishop", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-563", 5, "interspeech", 2016]], "Sungbok Lee": [0.907842606306076, ["Acoustic-Prosodic and Turn-Taking Features in Interactions with Children with Neurodevelopmental Disorders", ["Daniel Bone", "Somer Bishop", "Rahul Gupta", "Sungbok Lee", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1073", 5, "interspeech", 2016]], "Daria Hemmerling": [0, ["Automatic Detection of Parkinson's Disease Based on Modulated Vowels", ["Daria Hemmerling", "Juan Rafael Orozco-Arroyave", "Andrzej Skalski", "Janusz Gajda", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2016-1062", 5, "interspeech", 2016]], "Juan Rafael Orozco-Arroyave": [0, ["Automatic Detection of Parkinson's Disease Based on Modulated Vowels", ["Daria Hemmerling", "Juan Rafael Orozco-Arroyave", "Andrzej Skalski", "Janusz Gajda", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2016-1062", 5, "interspeech", 2016], ["Parkinson's Disease Progression Assessment from Speech Using GMM-UBM", ["Tomas Arias-Vergara", "Juan Camilo Vasquez-Correa", "Juan Rafael Orozco-Arroyave", "Jesus Francisco Vargas-Bonilla", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2016-1122", 5, "interspeech", 2016]], "Andrzej Skalski": [0, ["Automatic Detection of Parkinson's Disease Based on Modulated Vowels", ["Daria Hemmerling", "Juan Rafael Orozco-Arroyave", "Andrzej Skalski", "Janusz Gajda", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2016-1062", 5, "interspeech", 2016]], "Janusz Gajda": [0, ["Automatic Detection of Parkinson's Disease Based on Modulated Vowels", ["Daria Hemmerling", "Juan Rafael Orozco-Arroyave", "Andrzej Skalski", "Janusz Gajda", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2016-1062", 5, "interspeech", 2016]], "Elmar Noth": [0, ["Automatic Detection of Parkinson's Disease Based on Modulated Vowels", ["Daria Hemmerling", "Juan Rafael Orozco-Arroyave", "Andrzej Skalski", "Janusz Gajda", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2016-1062", 5, "interspeech", 2016], ["Combining Semantic Word Classes and Sub-Word Unit Speech Recognition for Robust OOV Detection", ["Axel Horndasch", "Anton Batliner", "Caroline Kaufhold", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2016-1250", 5, "interspeech", 2016], ["Parkinson's Disease Progression Assessment from Speech Using GMM-UBM", ["Tomas Arias-Vergara", "Juan Camilo Vasquez-Correa", "Juan Rafael Orozco-Arroyave", "Jesus Francisco Vargas-Bonilla", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2016-1122", 5, "interspeech", 2016]], "Jun Wang": [0.07243934646248817, ["Towards Automatic Detection of Amyotrophic Lateral Sclerosis from Speech Acoustic and Articulatory Samples", ["Jun Wang", "Prasanna V. Kothalkar", "Beiming Cao", "Daragh Heitzman"], "https://doi.org/10.21437/Interspeech.2016-1542", 5, "interspeech", 2016], ["Dysarthric Speech Recognition Using Kullback-Leibler Divergence-Based Hidden Markov Model", ["Myung Jong Kim", "Jun Wang", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2016-776", 5, "interspeech", 2016]], "Prasanna V. Kothalkar": [0, ["Towards Automatic Detection of Amyotrophic Lateral Sclerosis from Speech Acoustic and Articulatory Samples", ["Jun Wang", "Prasanna V. Kothalkar", "Beiming Cao", "Daragh Heitzman"], "https://doi.org/10.21437/Interspeech.2016-1542", 5, "interspeech", 2016]], "Beiming Cao": [0, ["Towards Automatic Detection of Amyotrophic Lateral Sclerosis from Speech Acoustic and Articulatory Samples", ["Jun Wang", "Prasanna V. Kothalkar", "Beiming Cao", "Daragh Heitzman"], "https://doi.org/10.21437/Interspeech.2016-1542", 5, "interspeech", 2016]], "Daragh Heitzman": [0, ["Towards Automatic Detection of Amyotrophic Lateral Sclerosis from Speech Acoustic and Articulatory Samples", ["Jun Wang", "Prasanna V. Kothalkar", "Beiming Cao", "Daragh Heitzman"], "https://doi.org/10.21437/Interspeech.2016-1542", 5, "interspeech", 2016]], "Gregory Ciccarelli": [0, ["Neurophysiological Vocal Source Modeling for Biomarkers of Disease", ["Gregory Ciccarelli", "Thomas F. Quatieri", "Satrajit S. Ghosh"], "https://doi.org/10.21437/Interspeech.2016-292", 5, "interspeech", 2016]], "Satrajit S. Ghosh": [0, ["Neurophysiological Vocal Source Modeling for Biomarkers of Disease", ["Gregory Ciccarelli", "Thomas F. Quatieri", "Satrajit S. Ghosh"], "https://doi.org/10.21437/Interspeech.2016-292", 5, "interspeech", 2016]], "Rachelle L. Horwitz-Martin": [0, ["Relation of Automatically Extracted Formant Trajectories with Intelligibility Loss and Speaking Rate Decline in Amyotrophic Lateral Sclerosis", ["Rachelle L. Horwitz-Martin", "Thomas F. Quatieri", "Adam C. Lammert", "James R. Williamson", "Yana Yunusova", "Elizabeth Godoy", "Daryush D. Mehta", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2016-403", 5, "interspeech", 2016]], "James R. Williamson": [0, ["Relation of Automatically Extracted Formant Trajectories with Intelligibility Loss and Speaking Rate Decline in Amyotrophic Lateral Sclerosis", ["Rachelle L. Horwitz-Martin", "Thomas F. Quatieri", "Adam C. Lammert", "James R. Williamson", "Yana Yunusova", "Elizabeth Godoy", "Daryush D. Mehta", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2016-403", 5, "interspeech", 2016]], "Daryush D. Mehta": [0, ["Relation of Automatically Extracted Formant Trajectories with Intelligibility Loss and Speaking Rate Decline in Amyotrophic Lateral Sclerosis", ["Rachelle L. Horwitz-Martin", "Thomas F. Quatieri", "Adam C. Lammert", "James R. Williamson", "Yana Yunusova", "Elizabeth Godoy", "Daryush D. Mehta", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2016-403", 5, "interspeech", 2016], ["Classification of Voice Modality Using Electroglottogram Waveforms", ["Michal Borsky", "Daryush D. Mehta", "Julius P. Gudjohnsen", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2016-1194", 5, "interspeech", 2016]], "Charline Grossard": [0, ["Automatic Analysis of Typical and Atypical Encoding of Spontaneous Emotion in the Voice of Children", ["Fabien Ringeval", "Erik Marchi", "Charline Grossard", "Jean Xavier", "Mohamed Chetouani", "David Cohen", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-766", 5, "interspeech", 2016]], "Jean Xavier": [0, ["Automatic Analysis of Typical and Atypical Encoding of Spontaneous Emotion in the Voice of Children", ["Fabien Ringeval", "Erik Marchi", "Charline Grossard", "Jean Xavier", "Mohamed Chetouani", "David Cohen", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-766", 5, "interspeech", 2016]], "Mohamed Chetouani": [0, ["Automatic Analysis of Typical and Atypical Encoding of Spontaneous Emotion in the Voice of Children", ["Fabien Ringeval", "Erik Marchi", "Charline Grossard", "Jean Xavier", "Mohamed Chetouani", "David Cohen", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-766", 5, "interspeech", 2016]], "David Cohen": [0, ["Automatic Analysis of Typical and Atypical Encoding of Spontaneous Emotion in the Voice of Children", ["Fabien Ringeval", "Erik Marchi", "Charline Grossard", "Jean Xavier", "Mohamed Chetouani", "David Cohen", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-766", 5, "interspeech", 2016]], "Soheil Khorram": [0, ["Recognition of Depression in Bipolar Disorder: Leveraging Cohort and Person-Specific Knowledge", ["Soheil Khorram", "John Gideon", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2016-837", 5, "interspeech", 2016]], "John Gideon": [0, ["Recognition of Depression in Bipolar Disorder: Leveraging Cohort and Person-Specific Knowledge", ["Soheil Khorram", "John Gideon", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2016-837", 5, "interspeech", 2016]], "Melvin G. McInnis": [0, ["Recognition of Depression in Bipolar Disorder: Leveraging Cohort and Person-Specific Knowledge", ["Soheil Khorram", "John Gideon", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2016-837", 5, "interspeech", 2016]], "Emily Mower Provost": [0, ["Recognition of Depression in Bipolar Disorder: Leveraging Cohort and Person-Specific Knowledge", ["Soheil Khorram", "John Gideon", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2016-837", 5, "interspeech", 2016], ["Experiences with Shared Resources for Research and Education in Speech and Language Processing", ["Rebecca Bates", "Eric Fosler-Lussier", "Florian Metze", "Martha Larson", "Gina-Anne Levow", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2016-1223", 5, "interspeech", 2016], ["Improving Automatic Recognition of Aphasic Speech with AphasiaBank", ["Duc Le", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2016-213", 5, "interspeech", 2016]], "Bahman Mirheidari": [0, ["Diagnosing People with Dementia Using Automatic Conversation Analysis", ["Bahman Mirheidari", "Daniel Blackburn", "Markus Reuber", "Traci Walker", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2016-857", 5, "interspeech", 2016]], "Daniel Blackburn": [0, ["Diagnosing People with Dementia Using Automatic Conversation Analysis", ["Bahman Mirheidari", "Daniel Blackburn", "Markus Reuber", "Traci Walker", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2016-857", 5, "interspeech", 2016]], "Markus Reuber": [0, ["Diagnosing People with Dementia Using Automatic Conversation Analysis", ["Bahman Mirheidari", "Daniel Blackburn", "Markus Reuber", "Traci Walker", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2016-857", 5, "interspeech", 2016]], "Traci Walker": [0, ["Diagnosing People with Dementia Using Automatic Conversation Analysis", ["Bahman Mirheidari", "Daniel Blackburn", "Markus Reuber", "Traci Walker", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2016-857", 5, "interspeech", 2016]], "Heidi Christensen": [0, ["Diagnosing People with Dementia Using Automatic Conversation Analysis", ["Bahman Mirheidari", "Daniel Blackburn", "Markus Reuber", "Traci Walker", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2016-857", 5, "interspeech", 2016], ["CloudCAST - Remote Speech Technology for Speech Professionals", ["Phil D. Green", "Ricard Marxer", "Stuart P. Cunningham", "Heidi Christensen", "Frank Rudzicz", "Maria Yancheva", "Andre Coy", "Massimiliano Malavasi", "Lorenzo Desideri", "Fabio Tamburini"], "https://doi.org/10.21437/Interspeech.2016-148", 5, "interspeech", 2016]], "Paul Yaozhu Chan": [0, ["SERAPHIM: A Wavetable Synthesis System with 3D Lip Animation for Real-Time Speech and Singing Applications on Mobile Platforms", ["Paul Yaozhu Chan", "Minghui Dong", "Grace Xue Hui Ho", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-484", 5, "interspeech", 2016], ["SERAPHIM Live! - Singing Synthesis for the Performer, the Composer, and the 3D Game Developer", ["Paul Yaozhu Chan", "Minghui Dong", "Grace Xue Hui Ho", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2025.html", 2, "interspeech", 2016]], "Minghui Dong": [0.0013066117535345256, ["SERAPHIM: A Wavetable Synthesis System with 3D Lip Animation for Real-Time Speech and Singing Applications on Mobile Platforms", ["Paul Yaozhu Chan", "Minghui Dong", "Grace Xue Hui Ho", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-484", 5, "interspeech", 2016], ["SERAPHIM Live! - Singing Synthesis for the Performer, the Composer, and the 3D Game Developer", ["Paul Yaozhu Chan", "Minghui Dong", "Grace Xue Hui Ho", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2025.html", 2, "interspeech", 2016], ["Deep Bidirectional LSTM Modeling of Timbre and Prosody for Emotional Voice Conversion", ["Huaiping Ming", "Dong-Yan Huang", "Lei Xie", "Jie Wu", "Minghui Dong", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-1053", 5, "interspeech", 2016]], "Grace Xue Hui Ho": [0, ["SERAPHIM: A Wavetable Synthesis System with 3D Lip Animation for Real-Time Speech and Singing Applications on Mobile Platforms", ["Paul Yaozhu Chan", "Minghui Dong", "Grace Xue Hui Ho", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-484", 5, "interspeech", 2016], ["SERAPHIM Live! - Singing Synthesis for the Performer, the Composer, and the 3D Game Developer", ["Paul Yaozhu Chan", "Minghui Dong", "Grace Xue Hui Ho", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2025.html", 2, "interspeech", 2016]], "Jordi Bonada": [0, ["Expressive Singing Synthesis Based on Unit Selection for the Singing Synthesis Challenge 2016", ["Jordi Bonada", "Marti Umbert", "Merlijn Blaauw"], "https://doi.org/10.21437/Interspeech.2016-872", 5, "interspeech", 2016], ["Applying Spectral Normalisation and Efficient Envelope Estimation and Statistical Transformation for the Voice Conversion Challenge 2016", ["Fernando Villavicencio", "Junichi Yamagishi", "Jordi Bonada", "Felipe Espic"], "https://doi.org/10.21437/Interspeech.2016-305", 5, "interspeech", 2016], ["Modeling and Transforming Speech Using Variational Autoencoders", ["Merlijn Blaauw", "Jordi Bonada"], "https://doi.org/10.21437/Interspeech.2016-1183", 5, "interspeech", 2016], ["Bird Song Synthesis Based on Hidden Markov Models", ["Jordi Bonada", "Robert Lachlan", "Merlijn Blaauw"], "https://doi.org/10.21437/Interspeech.2016-1110", 5, "interspeech", 2016]], "Marti Umbert": [0, ["Expressive Singing Synthesis Based on Unit Selection for the Singing Synthesis Challenge 2016", ["Jordi Bonada", "Marti Umbert", "Merlijn Blaauw"], "https://doi.org/10.21437/Interspeech.2016-872", 5, "interspeech", 2016]], "Merlijn Blaauw": [0, ["Expressive Singing Synthesis Based on Unit Selection for the Singing Synthesis Challenge 2016", ["Jordi Bonada", "Marti Umbert", "Merlijn Blaauw"], "https://doi.org/10.21437/Interspeech.2016-872", 5, "interspeech", 2016], ["Modeling and Transforming Speech Using Variational Autoencoders", ["Merlijn Blaauw", "Jordi Bonada"], "https://doi.org/10.21437/Interspeech.2016-1183", 5, "interspeech", 2016], ["Bird Song Synthesis Based on Hidden Markov Models", ["Jordi Bonada", "Robert Lachlan", "Merlijn Blaauw"], "https://doi.org/10.21437/Interspeech.2016-1110", 5, "interspeech", 2016]], "Olivier Perrotin": [0, ["Vocal Effort Modification for Singing Synthesis", ["Olivier Perrotin", "Christophe dAlessandro"], "https://doi.org/10.21437/Interspeech.2016-1096", 5, "interspeech", 2016]], "Christophe dAlessandro": [0, ["Vocal Effort Modification for Singing Synthesis", ["Olivier Perrotin", "Christophe dAlessandro"], "https://doi.org/10.21437/Interspeech.2016-1096", 5, "interspeech", 2016], ["Evaluation of Singing Synthesis: Methodology and Case Study with Concatenative and Performative Systems", ["Lionel Feugere", "Christophe dAlessandro", "Samuel Delalez", "Luc Ardaillon", "Axel Roebel"], "https://doi.org/10.21437/Interspeech.2016-1248", 5, "interspeech", 2016]], "Eder del Blanco": [0, ["Bertsokantari: a TTS Based Singing Synthesis System", ["Eder del Blanco", "Inma Hernaez", "Eva Navas", "Xabier Sarasola", "Daniel Erro"], "https://doi.org/10.21437/Interspeech.2016-1123", 5, "interspeech", 2016], ["ML Parameter Generation with a Reformulated MGE Training Criterion - Participation in the Voice Conversion Challenge 2016", ["Daniel Erro", "Agustin Alonso", "Luis Serrano", "David Tavarez", "Igor Odriozola", "Xabier Sarasola", "Eder del Blanco", "Jon Sanchez", "Ibon Saratxaga", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2016-219", 5, "interspeech", 2016]], "Inma Hernaez": [0, ["Bertsokantari: a TTS Based Singing Synthesis System", ["Eder del Blanco", "Inma Hernaez", "Eva Navas", "Xabier Sarasola", "Daniel Erro"], "https://doi.org/10.21437/Interspeech.2016-1123", 5, "interspeech", 2016], ["ML Parameter Generation with a Reformulated MGE Training Criterion - Participation in the Voice Conversion Challenge 2016", ["Daniel Erro", "Agustin Alonso", "Luis Serrano", "David Tavarez", "Igor Odriozola", "Xabier Sarasola", "Eder del Blanco", "Jon Sanchez", "Ibon Saratxaga", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2016-219", 5, "interspeech", 2016]], "Eva Navas": [0, ["Bertsokantari: a TTS Based Singing Synthesis System", ["Eder del Blanco", "Inma Hernaez", "Eva Navas", "Xabier Sarasola", "Daniel Erro"], "https://doi.org/10.21437/Interspeech.2016-1123", 5, "interspeech", 2016], ["ML Parameter Generation with a Reformulated MGE Training Criterion - Participation in the Voice Conversion Challenge 2016", ["Daniel Erro", "Agustin Alonso", "Luis Serrano", "David Tavarez", "Igor Odriozola", "Xabier Sarasola", "Eder del Blanco", "Jon Sanchez", "Ibon Saratxaga", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2016-219", 5, "interspeech", 2016]], "Xabier Sarasola": [0, ["Bertsokantari: a TTS Based Singing Synthesis System", ["Eder del Blanco", "Inma Hernaez", "Eva Navas", "Xabier Sarasola", "Daniel Erro"], "https://doi.org/10.21437/Interspeech.2016-1123", 5, "interspeech", 2016], ["ML Parameter Generation with a Reformulated MGE Training Criterion - Participation in the Voice Conversion Challenge 2016", ["Daniel Erro", "Agustin Alonso", "Luis Serrano", "David Tavarez", "Igor Odriozola", "Xabier Sarasola", "Eder del Blanco", "Jon Sanchez", "Ibon Saratxaga", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2016-219", 5, "interspeech", 2016]], "Daniel Erro": [0, ["Bertsokantari: a TTS Based Singing Synthesis System", ["Eder del Blanco", "Inma Hernaez", "Eva Navas", "Xabier Sarasola", "Daniel Erro"], "https://doi.org/10.21437/Interspeech.2016-1123", 5, "interspeech", 2016], ["ML Parameter Generation with a Reformulated MGE Training Criterion - Participation in the Voice Conversion Challenge 2016", ["Daniel Erro", "Agustin Alonso", "Luis Serrano", "David Tavarez", "Igor Odriozola", "Xabier Sarasola", "Eder del Blanco", "Jon Sanchez", "Ibon Saratxaga", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2016-219", 5, "interspeech", 2016]], "Lionel Feugere": [0, ["Evaluation of Singing Synthesis: Methodology and Case Study with Concatenative and Performative Systems", ["Lionel Feugere", "Christophe dAlessandro", "Samuel Delalez", "Luc Ardaillon", "Axel Roebel"], "https://doi.org/10.21437/Interspeech.2016-1248", 5, "interspeech", 2016]], "Samuel Delalez": [0, ["Evaluation of Singing Synthesis: Methodology and Case Study with Concatenative and Performative Systems", ["Lionel Feugere", "Christophe dAlessandro", "Samuel Delalez", "Luc Ardaillon", "Axel Roebel"], "https://doi.org/10.21437/Interspeech.2016-1248", 5, "interspeech", 2016]], "Luc Ardaillon": [0, ["Evaluation of Singing Synthesis: Methodology and Case Study with Concatenative and Performative Systems", ["Lionel Feugere", "Christophe dAlessandro", "Samuel Delalez", "Luc Ardaillon", "Axel Roebel"], "https://doi.org/10.21437/Interspeech.2016-1248", 5, "interspeech", 2016], ["Expressive Control of Singing Voice Synthesis Using Musical Contexts and a Parametric F0 Model", ["Luc Ardaillon", "Celine Chabot-Canet", "Axel Roebel"], "https://doi.org/10.21437/Interspeech.2016-1317", 5, "interspeech", 2016]], "Axel Roebel": [0, ["Evaluation of Singing Synthesis: Methodology and Case Study with Concatenative and Performative Systems", ["Lionel Feugere", "Christophe dAlessandro", "Samuel Delalez", "Luc Ardaillon", "Axel Roebel"], "https://doi.org/10.21437/Interspeech.2016-1248", 5, "interspeech", 2016], ["Expressive Control of Singing Voice Synthesis Using Musical Contexts and a Parametric F0 Model", ["Luc Ardaillon", "Celine Chabot-Canet", "Axel Roebel"], "https://doi.org/10.21437/Interspeech.2016-1317", 5, "interspeech", 2016]], "Celine Chabot-Canet": [0, ["Expressive Control of Singing Voice Synthesis Using Musical Contexts and a Parametric F0 Model", ["Luc Ardaillon", "Celine Chabot-Canet", "Axel Roebel"], "https://doi.org/10.21437/Interspeech.2016-1317", 5, "interspeech", 2016]], "Marius Cotescu": [0, ["Optimal Unit Stitching in a Unit Selection Singing Synthesis System", ["Marius Cotescu"], "https://doi.org/10.21437/Interspeech.2016-1390", 5, "interspeech", 2016]], "Katherine Hilton": [0, ["The Perception of Overlapping Speech: Effects of Speaker Prosody and Listener Attitudes", ["Katherine Hilton"], "https://doi.org/10.21437/Interspeech.2016-1456", 5, "interspeech", 2016]], "Pablo Brusco": [0, ["Who Do You Think Will Speak Next? Perception of Turn-Taking Cues in Slovak and Argentine Spanish", ["Agustin Gravano", "Pablo Brusco", "Stefan Benus"], "https://doi.org/10.21437/Interspeech.2016-585", 5, "interspeech", 2016]], "Juan Manuel Perez": [0, ["Disentrainment may be a Positive Thing: A Novel Measure of Unsigned Acoustic-Prosodic Synchrony, and its Relation to Speaker Engagement", ["Juan Manuel Perez", "Ramiro H. Galvez", "Agustin Gravano"], "https://doi.org/10.21437/Interspeech.2016-587", 5, "interspeech", 2016]], "Emma Rennie": [0, ["The Discourse Marker \"so\" in Turn-Taking and Turn-Releasing Behavior", ["Emma Rennie", "Rebecca Lunsford", "Peter A. Heeman"], "https://doi.org/10.21437/Interspeech.2016-547", 5, "interspeech", 2016], ["Measuring Turn-Taking Offsets in Human-Human Dialogues", ["Rebecca Lunsford", "Peter A. Heeman", "Emma Rennie"], "https://doi.org/10.21437/Interspeech.2016-1350", 5, "interspeech", 2016]], "Rebecca Lunsford": [0, ["The Discourse Marker \"so\" in Turn-Taking and Turn-Releasing Behavior", ["Emma Rennie", "Rebecca Lunsford", "Peter A. Heeman"], "https://doi.org/10.21437/Interspeech.2016-547", 5, "interspeech", 2016], ["Using Clinician Annotations to Improve Automatic Speech Recognition of Stuttered Speech", ["Peter A. Heeman", "Rebecca Lunsford", "Andy McMillin", "J. Scott Yaruss"], "https://doi.org/10.21437/Interspeech.2016-1388", 5, "interspeech", 2016], ["Measuring Turn-Taking Offsets in Human-Human Dialogues", ["Rebecca Lunsford", "Peter A. Heeman", "Emma Rennie"], "https://doi.org/10.21437/Interspeech.2016-1350", 5, "interspeech", 2016]], "Peter A. Heeman": [0, ["The Discourse Marker \"so\" in Turn-Taking and Turn-Releasing Behavior", ["Emma Rennie", "Rebecca Lunsford", "Peter A. Heeman"], "https://doi.org/10.21437/Interspeech.2016-547", 5, "interspeech", 2016], ["Using Clinician Annotations to Improve Automatic Speech Recognition of Stuttered Speech", ["Peter A. Heeman", "Rebecca Lunsford", "Andy McMillin", "J. Scott Yaruss"], "https://doi.org/10.21437/Interspeech.2016-1388", 5, "interspeech", 2016], ["Measuring Turn-Taking Offsets in Human-Human Dialogues", ["Rebecca Lunsford", "Peter A. Heeman", "Emma Rennie"], "https://doi.org/10.21437/Interspeech.2016-1350", 5, "interspeech", 2016], ["Using Past Speaker Behavior to Better Predict Turn Transitions", ["Tomer Meshorer", "Peter A. Heeman"], "https://doi.org/10.21437/Interspeech.2016-1409", 5, "interspeech", 2016]], "Ethan Sherr-Ziarko": [0, ["Acoustic Properties of Formality in Conversational Japanese", ["Ethan Sherr-Ziarko"], "https://doi.org/10.21437/Interspeech.2016-132", 5, "interspeech", 2016]], "Thomas Pellegrini": [0, ["Inferring Phonemic Classes from CNN Activation Maps Using Clustering Techniques", ["Thomas Pellegrini", "Sandrine Mouysset"], "https://doi.org/10.21437/Interspeech.2016-1299", 5, "interspeech", 2016], ["Sinusoidal Modelling for Ecoacoustics", ["Patrice Guyot", "Alice Eldridge", "Ying Chen Eyre-Walker", "Alison Johnston", "Thomas Pellegrini", "Mika Peck"], "https://doi.org/10.21437/Interspeech.2016-361", 5, "interspeech", 2016], ["Pronunciation Assessment of Japanese Learners of French with GOP Scores and Phonetic Information", ["Vincent Laborde", "Thomas Pellegrini", "Lionel Fontan", "Julie Mauclair", "Halima Sahraoui", "Jerome Farinas"], "https://doi.org/10.21437/Interspeech.2016-513", 5, "interspeech", 2016], ["CNN-Based Phone Segmentation Experiments in a Less-Represented Language", ["Celine Manenti", "Thomas Pellegrini", "Julien Pinquier"], "https://doi.org/10.21437/Interspeech.2016-796", 5, "interspeech", 2016]], "Sandrine Mouysset": [0, ["Inferring Phonemic Classes from CNN Activation Maps Using Clustering Techniques", ["Thomas Pellegrini", "Sandrine Mouysset"], "https://doi.org/10.21437/Interspeech.2016-1299", 5, "interspeech", 2016]], "Neil Zeghidour": [0, ["Joint Learning of Speaker and Phonetic Similarities with Siamese Networks", ["Neil Zeghidour", "Gabriel Synnaeve", "Nicolas Usunier", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2016-811", 5, "interspeech", 2016]], "Gabriel Synnaeve": [0, ["Joint Learning of Speaker and Phonetic Similarities with Siamese Networks", ["Neil Zeghidour", "Gabriel Synnaeve", "Nicolas Usunier", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2016-811", 5, "interspeech", 2016], ["Jointly Learning to Locate and Classify Words Using Convolutional Networks", ["Dimitri Palaz", "Gabriel Synnaeve", "Ronan Collobert"], "https://doi.org/10.21437/Interspeech.2016-968", 5, "interspeech", 2016]], "Nicolas Usunier": [0, ["Joint Learning of Speaker and Phonetic Similarities with Siamese Networks", ["Neil Zeghidour", "Gabriel Synnaeve", "Nicolas Usunier", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2016-811", 5, "interspeech", 2016]], "Emmanuel Dupoux": [0, ["Joint Learning of Speaker and Phonetic Similarities with Siamese Networks", ["Neil Zeghidour", "Gabriel Synnaeve", "Nicolas Usunier", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2016-811", 5, "interspeech", 2016]], "Dimitra Vergyri": [0, ["Unsupervised Learning of Acoustic Units Using Autoencoders and Kohonen Nets", ["Vikramjit Mitra", "Dimitra Vergyri", "Horacio Franco"], "https://doi.org/10.21437/Interspeech.2016-1374", 5, "interspeech", 2016], ["Fusion Strategies for Robust Speech Recognition and Keyword Spotting for Channel- and Noise-Degraded Speech", ["Vikramjit Mitra", "Julien van Hout", "Wen Wang", "Chris Bartels", "Horacio Franco", "Dimitra Vergyri", "Abeer Alwan", "Adam Janin", "John H. L. Hansen", "Richard M. Stern", "Abhijeet Sangwan", "Nelson Morgan"], "https://doi.org/10.21437/Interspeech.2016-279", 5, "interspeech", 2016]], "Zhenyao Zhu": [0, ["Learning Multiscale Features Directly from Waveforms", ["Zhenyao Zhu", "Jesse H. Engel", "Awni Y. Hannun"], "https://doi.org/10.21437/Interspeech.2016-256", 5, "interspeech", 2016]], "Jesse H. Engel": [0, ["Learning Multiscale Features Directly from Waveforms", ["Zhenyao Zhu", "Jesse H. Engel", "Awni Y. Hannun"], "https://doi.org/10.21437/Interspeech.2016-256", 5, "interspeech", 2016]], "Awni Y. Hannun": [0, ["Learning Multiscale Features Directly from Waveforms", ["Zhenyao Zhu", "Jesse H. Engel", "Awni Y. Hannun"], "https://doi.org/10.21437/Interspeech.2016-256", 5, "interspeech", 2016]], "Michael Heck": [0, ["Supervised Learning of Acoustic Models in a Zero Resource Setting to Improve DPGMM Clustering", ["Michael Heck", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-988", 5, "interspeech", 2016]], "Sakriani Sakti": [0, ["Supervised Learning of Acoustic Models in a Zero Resource Setting to Improve DPGMM Clustering", ["Michael Heck", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-988", 5, "interspeech", 2016], ["Transferring Emphasis in Speech Translation Using Hard-Attentional Neural Network Models", ["Quoc Truong Do", "Sakriani Sakti", "Graham Neubig", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-898", 5, "interspeech", 2016], ["Unsupervised Joint Estimation of Grapheme-to-Phoneme Conversion Systems and Acoustic Model Adaptation for Non-Native Speech Recognition", ["Satoshi Tsujioka", "Sakriani Sakti", "Koichiro Yoshino", "Graham Neubig", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-919", 5, "interspeech", 2016], ["A Hybrid System for Continuous Word-Level Emphasis Modeling Based on HMM State Clustering and Adaptive Training", ["Quoc Truong Do", "Tomoki Toda", "Graham Neubig", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-930", 5, "interspeech", 2016]], "Hang Su": [0, ["Semi-Supervised and Cross-Lingual Knowledge Transfer Learnings for DNN Hybrid Acoustic Models Under Low-Resource Conditions", ["Haihua Xu", "Hang Su", "Chongjia Ni", "Xiong Xiao", "Hao Huang", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-1099", 5, "interspeech", 2016], ["Factor Analysis Based Speaker Verification Using ASR", ["Hang Su", "Steven Wegmann"], "https://doi.org/10.21437/Interspeech.2016-1157", 5, "interspeech", 2016]], "Chongjia Ni": [0, ["Semi-Supervised and Cross-Lingual Knowledge Transfer Learnings for DNN Hybrid Acoustic Models Under Low-Resource Conditions", ["Haihua Xu", "Hang Su", "Chongjia Ni", "Xiong Xiao", "Hao Huang", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-1099", 5, "interspeech", 2016], ["Rapid Update of Multilingual Deep Neural Network for Low-Resource Keyword Search", ["Chongjia Ni", "Lei Wang", "Cheung-Chi Leung", "Feng Rao", "Li Lu", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-53", 5, "interspeech", 2016], ["Toward High-Performance Language-Independent Query-by-Example Spoken Term Detection for MediaEval 2015: Post-Evaluation Analysis", ["Cheung-Chi Leung", "Lei Wang", "Haihua Xu", "Jingyong Hou", "Van Tung Pham", "Hang Lv", "Lei Xie", "Xiong Xiao", "Chongjia Ni", "Bin Ma", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-691", 5, "interspeech", 2016]], "Hao Huang": [0, ["Semi-Supervised and Cross-Lingual Knowledge Transfer Learnings for DNN Hybrid Acoustic Models Under Low-Resource Conditions", ["Haihua Xu", "Hang Su", "Chongjia Ni", "Xiong Xiao", "Hao Huang", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-1099", 5, "interspeech", 2016]], "Ryo Masumura": [0, ["Recurrent Out-of-Vocabulary Word Detection Using Distribution of Features", ["Taichi Asami", "Ryo Masumura", "Yushi Aono", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2016-562", 5, "interspeech", 2016], ["Language Identification Based on Generative Modeling of Posteriorgram Sequences Extracted from Frame-by-Frame DNNs and LSTM-RNNs", ["Ryo Masumura", "Taichi Asami", "Hirokazu Masataki", "Yushi Aono", "Sumitaka Sakauchi"], "https://doi.org/10.21437/Interspeech.2016-719", 5, "interspeech", 2016]], "Yushi Aono": [0, ["Recurrent Out-of-Vocabulary Word Detection Using Distribution of Features", ["Taichi Asami", "Ryo Masumura", "Yushi Aono", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2016-562", 5, "interspeech", 2016], ["Language Identification Based on Generative Modeling of Posteriorgram Sequences Extracted from Frame-by-Frame DNNs and LSTM-RNNs", ["Ryo Masumura", "Taichi Asami", "Hirokazu Masataki", "Yushi Aono", "Sumitaka Sakauchi"], "https://doi.org/10.21437/Interspeech.2016-719", 5, "interspeech", 2016]], "Koichi Shinoda": [0, ["Recurrent Out-of-Vocabulary Word Detection Using Distribution of Features", ["Taichi Asami", "Ryo Masumura", "Yushi Aono", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2016-562", 5, "interspeech", 2016]], "Naoyuki Kanda": [0, ["Investigation of Semi-Supervised Acoustic Model Training Based on the Committee of Heterogeneous Neural Networks", ["Naoyuki Kanda", "Shoji Harada", "Xugang Lu", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-72", 5, "interspeech", 2016], ["Maximum a posteriori Based Decoding for CTC Acoustic Models", ["Naoyuki Kanda", "Xugang Lu", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-71", 5, "interspeech", 2016]], "Shoji Harada": [0, ["Investigation of Semi-Supervised Acoustic Model Training Based on the Committee of Heterogeneous Neural Networks", ["Naoyuki Kanda", "Shoji Harada", "Xugang Lu", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-72", 5, "interspeech", 2016]], "Sahar Ghannay": [0, ["Acoustic Word Embeddings for ASR Error Detection", ["Sahar Ghannay", "Yannick Esteve", "Nathalie Camelin", "Paul Deleglise"], "https://doi.org/10.21437/Interspeech.2016-784", 5, "interspeech", 2016]], "Yannick Esteve": [0, ["Acoustic Word Embeddings for ASR Error Detection", ["Sahar Ghannay", "Yannick Esteve", "Nathalie Camelin", "Paul Deleglise"], "https://doi.org/10.21437/Interspeech.2016-784", 5, "interspeech", 2016], ["Conditional Random Fields for the Tunisian Dialect Grapheme-to-Phoneme Conversion", ["Abir Masmoudi", "Mariem Ellouze", "Fethi Bougares", "Yannick Esteve", "Lamia Hadrich Belguith"], "https://doi.org/10.21437/Interspeech.2016-1320", 5, "interspeech", 2016], ["On the Use of Gaussian Mixture Model Framework to Improve Speaker Adaptation of Deep Neural Network Acoustic Models", ["Natalia A. Tomashenko", "Yuri Y. Khokhlov", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2016-1230", 5, "interspeech", 2016]], "Nathalie Camelin": [0, ["Acoustic Word Embeddings for ASR Error Detection", ["Sahar Ghannay", "Yannick Esteve", "Nathalie Camelin", "Paul Deleglise"], "https://doi.org/10.21437/Interspeech.2016-784", 5, "interspeech", 2016]], "Paul Deleglise": [0, ["Acoustic Word Embeddings for ASR Error Detection", ["Sahar Ghannay", "Yannick Esteve", "Nathalie Camelin", "Paul Deleglise"], "https://doi.org/10.21437/Interspeech.2016-784", 5, "interspeech", 2016]], "Axel Horndasch": [0, ["Combining Semantic Word Classes and Sub-Word Unit Speech Recognition for Robust OOV Detection", ["Axel Horndasch", "Anton Batliner", "Caroline Kaufhold", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2016-1250", 5, "interspeech", 2016]], "Anton Batliner": [0, ["Combining Semantic Word Classes and Sub-Word Unit Speech Recognition for Robust OOV Detection", ["Axel Horndasch", "Anton Batliner", "Caroline Kaufhold", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2016-1250", 5, "interspeech", 2016], ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: Deception, Sincerity & Native Language", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "https://doi.org/10.21437/Interspeech.2016-129", 5, "interspeech", 2016], ["The Deception Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs5.html", 0, "interspeech", 2016], ["The Sincerity Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs6.html", 0, "interspeech", 2016], ["The Native Language Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs11.html", 0, "interspeech", 2016], ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: A Summary of Results", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs12.html", 0, "interspeech", 2016], ["Discussion", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs13.html", 0, "interspeech", 2016]], "Caroline Kaufhold": [0, ["Combining Semantic Word Classes and Sub-Word Unit Speech Recognition for Robust OOV Detection", ["Axel Horndasch", "Anton Batliner", "Caroline Kaufhold", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2016-1250", 5, "interspeech", 2016]], "Chuandong Xie": [0, ["Web Data Selection Based on Word Embedding for Low-Resource Speech Recognition", ["Chuandong Xie", "Wu Guo", "Guoping Hu", "Junhua Liu"], "https://doi.org/10.21437/Interspeech.2016-45", 5, "interspeech", 2016]], "Wu Guo": [0, ["Web Data Selection Based on Word Embedding for Low-Resource Speech Recognition", ["Chuandong Xie", "Wu Guo", "Guoping Hu", "Junhua Liu"], "https://doi.org/10.21437/Interspeech.2016-45", 5, "interspeech", 2016]], "Guoping Hu": [0, ["Web Data Selection Based on Word Embedding for Low-Resource Speech Recognition", ["Chuandong Xie", "Wu Guo", "Guoping Hu", "Junhua Liu"], "https://doi.org/10.21437/Interspeech.2016-45", 5, "interspeech", 2016]], "Junhua Liu": [0, ["Web Data Selection Based on Word Embedding for Low-Resource Speech Recognition", ["Chuandong Xie", "Wu Guo", "Guoping Hu", "Junhua Liu"], "https://doi.org/10.21437/Interspeech.2016-45", 5, "interspeech", 2016]], "Sarah Al-Shareef": [0, ["Colloquialising Modern Standard Arabic Text for Improved Speech Recognition", ["Sarah Al-Shareef", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-788", 5, "interspeech", 2016]], "Thomas Hain": [0, ["Colloquialising Modern Standard Arabic Text for Improved Speech Recognition", ["Sarah Al-Shareef", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-788", 5, "interspeech", 2016], ["webASR 2 - Improved Cloud Based Speech Technology", ["Thomas Hain", "Jeremy Christian", "Oscar Saz", "Salil Deena", "Madina Hasan", "Raymond W. M. Ng", "Rosanna Milner", "Mortaza Doulaty", "Yulan Liu"], "https://doi.org/10.21437/Interspeech.2016-700", 5, "interspeech", 2016], ["Error Correction in Lightly Supervised Alignment of Broadcast Subtitles", ["Julia Olcoz", "Oscar Saz", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-56", 5, "interspeech", 2016], ["Automatic Genre and Show Identification of Broadcast Media", ["Mortaza Doulaty", "Oscar Saz", "Raymond W. M. Ng", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-472", 5, "interspeech", 2016], ["DNN-Based Speaker Clustering for Speaker Diarisation", ["Rosanna Milner", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-126", 5, "interspeech", 2016], ["Combining Feature and Model-Based Adaptation of RNNLMs for Multi-Genre Broadcast Speech Recognition", ["Salil Deena", "Madina Hasan", "Mortaza Doulaty", "Oscar Saz", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-480", 5, "interspeech", 2016], ["Improving Generalisation to New Speakers in Spoken Dialogue State Tracking", ["Inigo Casanueva", "Thomas Hain", "Phil D. Green"], "https://doi.org/10.21437/Interspeech.2016-404", 5, "interspeech", 2016], ["Combining Weak Tokenisers for Phonotactic Language Recognition in a Resource-Constrained Setting", ["Raymond W. M. Ng", "Bhusan Chettri", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-630", 5, "interspeech", 2016], ["Use of Generalised Nonlinearity in Vector Taylor Series Noise Compensation for Robust Speech Recognition", ["Erfan Loweimi", "Jon Barker", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-1028", 5, "interspeech", 2016], ["The Sheffield Wargame Corpus - Day Two and Day Three", ["Yulan Liu", "Charles Fox", "Madina Hasan", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-98", 5, "interspeech", 2016]], "Jianjing Kuang": [0, ["Pitch-Range Perception: The Dynamic Interaction Between Voice Quality and Fundamental Frequency", ["Jianjing Kuang", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2016-1483", 5, "interspeech", 2016]], "Benson C. L. Chiao": [0, ["Comparing the Contributions of Amplitude and Phase to Speech Intelligibility in a Vocoder-Based Speech Synthesis Model", ["Fei Chen", "Benson C. L. Chiao"], "https://doi.org/10.21437/Interspeech.2016-66", 4, "interspeech", 2016]], "Gabor Pinter": [0, ["Do GMM Phoneme Classifiers Perceive Synthetic Sibilants as Humans Do?", ["Gabor Pinter", "Hiroki Watanabe"], "https://doi.org/10.21437/Interspeech.2016-325", 5, "interspeech", 2016]], "Hiroki Watanabe": [0, ["Do GMM Phoneme Classifiers Perceive Synthetic Sibilants as Humans Do?", ["Gabor Pinter", "Hiroki Watanabe"], "https://doi.org/10.21437/Interspeech.2016-325", 5, "interspeech", 2016]], "Marina Frye": [0, ["Neural Responses to Speech-Specific Modulations Derived from a Spectro-Temporal Filter Bank", ["Marina Frye", "Cristiano Micheli", "Inga M. Schepers", "Gerwin Schalk", "Jochem W. Rieger", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2016-1327", 5, "interspeech", 2016]], "Cristiano Micheli": [0, ["Neural Responses to Speech-Specific Modulations Derived from a Spectro-Temporal Filter Bank", ["Marina Frye", "Cristiano Micheli", "Inga M. Schepers", "Gerwin Schalk", "Jochem W. Rieger", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2016-1327", 5, "interspeech", 2016]], "Inga M. Schepers": [0, ["Neural Responses to Speech-Specific Modulations Derived from a Spectro-Temporal Filter Bank", ["Marina Frye", "Cristiano Micheli", "Inga M. Schepers", "Gerwin Schalk", "Jochem W. Rieger", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2016-1327", 5, "interspeech", 2016]], "Gerwin Schalk": [0, ["Neural Responses to Speech-Specific Modulations Derived from a Spectro-Temporal Filter Bank", ["Marina Frye", "Cristiano Micheli", "Inga M. Schepers", "Gerwin Schalk", "Jochem W. Rieger", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2016-1327", 5, "interspeech", 2016]], "Jochem W. Rieger": [0, ["Neural Responses to Speech-Specific Modulations Derived from a Spectro-Temporal Filter Bank", ["Marina Frye", "Cristiano Micheli", "Inga M. Schepers", "Gerwin Schalk", "Jochem W. Rieger", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2016-1327", 5, "interspeech", 2016]], "Kimberley Mulder": [0, ["Comparing Different Methods for Analyzing ERP Signals", ["Kimberley Mulder", "Louis ten Bosch", "Lou Boves"], "https://doi.org/10.21437/Interspeech.2016-967", 5, "interspeech", 2016]], "Louis ten Bosch": [0, ["Comparing Different Methods for Analyzing ERP Signals", ["Kimberley Mulder", "Louis ten Bosch", "Lou Boves"], "https://doi.org/10.21437/Interspeech.2016-967", 5, "interspeech", 2016], ["Combining Data-Oriented and Process-Oriented Approaches to Modeling Reaction Time Data", ["Louis ten Bosch", "Lou Boves", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2016-1072", 5, "interspeech", 2016], ["Analytical Assessment of Dual-Stream Merging for Noise-Robust ASR", ["Louis ten Bosch", "Bert Cranen", "Yang Sun"], "https://doi.org/10.21437/Interspeech.2016-1050", 5, "interspeech", 2016]], "Lou Boves": [0, ["Comparing Different Methods for Analyzing ERP Signals", ["Kimberley Mulder", "Louis ten Bosch", "Lou Boves"], "https://doi.org/10.21437/Interspeech.2016-967", 5, "interspeech", 2016], ["Combining Data-Oriented and Process-Oriented Approaches to Modeling Reaction Time Data", ["Louis ten Bosch", "Lou Boves", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2016-1072", 5, "interspeech", 2016]], "Martin Ingvar": [0, ["Supplementary Motor Area Activation in Disfluency Perception: An fMRI Study of Listener Neural Responses to Spontaneously Produced Unfilled and Filled Pauses", ["Robert Eklund", "Martin Ingvar"], "https://doi.org/10.21437/Interspeech.2016-973", 4, "interspeech", 2016]], "Daniel Fogerty": [0, ["Vowel Fundamental and Formant Frequency Contributions to English and Mandarin Sentence Intelligibility", ["Daniel Fogerty", "Fei Chen"], "https://doi.org/10.21437/Interspeech.2016-28", 5, "interspeech", 2016], ["Glimpsing Predictions for Natural and Vocoded Sentence Intelligibility During Modulation Masking: Effect of the Glimpse Cutoff Criterion", ["Bobby Gibbs II", "Daniel Fogerty"], "https://doi.org/10.21437/Interspeech.2016-1587", 5, "interspeech", 2016], ["Factors Affecting the Intelligibility of Sine-Wave Speech", ["Fei Chen", "Daniel Fogerty"], "https://doi.org/10.21437/Interspeech.2016-4", 4, "interspeech", 2016]], "Che-Wei Huang": [0, ["Attention Assisted Discovery of Sub-Utterance Structure in Speech Emotion Recognition", ["Che-Wei Huang", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-448", 5, "interspeech", 2016]], "Linchuan Li": [0, ["Combining CNN and BLSTM to Extract Textual and Acoustic Features for Recognizing Stances in Mandarin Ideological Debate Competition", ["Linchuan Li", "Zhiyong Wu", "Mingxing Xu", "Helen M. Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-324", 5, "interspeech", 2016]], "Zofia Malisz": [0, ["Inter-Speech Clicks in an Interspeech Keynote", ["Jurgen Trouvain", "Zofia Malisz"], "https://doi.org/10.21437/Interspeech.2016-1064", 5, "interspeech", 2016]], "Joanna Grzybowska": [0, ["Speaker Age Classification and Regression Using i-Vectors", ["Joanna Grzybowska", "Stanislaw Kacprzak"], "https://doi.org/10.21437/Interspeech.2016-1118", 5, "interspeech", 2016]], "Stanislaw Kacprzak": [0, ["Speaker Age Classification and Regression Using i-Vectors", ["Joanna Grzybowska", "Stanislaw Kacprzak"], "https://doi.org/10.21437/Interspeech.2016-1118", 5, "interspeech", 2016]], "Haoqi Li": [0, ["Sparsely Connected and Disjointly Trained Deep Neural Networks for Low Resource Behavioral Annotation: Acoustic Classification in Couples' Therapy", ["Haoqi Li", "Brian R. Baucom", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2016-1217", 5, "interspeech", 2016]], "Guozhen An": [1.623810070780496e-11, ["Automatically Classifying Self-Rated Personality Scores from Speech", ["Guozhen An", "Sarah Ita Levitan", "Rivka Levitan", "Andrew Rosenberg", "Michelle Levine", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-1328", 5, "interspeech", 2016], ["Combining Acoustic-Prosodic, Lexical, and Phonotactic Features for Automatic Deception Detection", ["Sarah Ita Levitan", "Guozhen An", "Min Ma", "Rivka Levitan", "Andrew Rosenberg", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-1519", 5, "interspeech", 2016]], "Sarah Ita Levitan": [0, ["Automatically Classifying Self-Rated Personality Scores from Speech", ["Guozhen An", "Sarah Ita Levitan", "Rivka Levitan", "Andrew Rosenberg", "Michelle Levine", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-1328", 5, "interspeech", 2016], ["Combining Acoustic-Prosodic, Lexical, and Phonotactic Features for Automatic Deception Detection", ["Sarah Ita Levitan", "Guozhen An", "Min Ma", "Rivka Levitan", "Andrew Rosenberg", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-1519", 5, "interspeech", 2016]], "Andrew Rosenberg": [0, ["Automatically Classifying Self-Rated Personality Scores from Speech", ["Guozhen An", "Sarah Ita Levitan", "Rivka Levitan", "Andrew Rosenberg", "Michelle Levine", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-1328", 5, "interspeech", 2016], ["Combining Acoustic-Prosodic, Lexical, and Phonotactic Features for Automatic Deception Detection", ["Sarah Ita Levitan", "Guozhen An", "Min Ma", "Rivka Levitan", "Andrew Rosenberg", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-1519", 5, "interspeech", 2016]], "Michelle Levine": [0, ["Automatically Classifying Self-Rated Personality Scores from Speech", ["Guozhen An", "Sarah Ita Levitan", "Rivka Levitan", "Andrew Rosenberg", "Michelle Levine", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-1328", 5, "interspeech", 2016]], "Rita Singh": [0, ["Estimation of Children's Physical Characteristics from Their Voices", ["Jill Fain Lehman", "Rita Singh"], "https://doi.org/10.21437/Interspeech.2016-146", 5, "interspeech", 2016]], "Hayakawa Akira": [0, ["Talking to a System and Talking to a Human: A Study from a Speech-to-Speech, Machine Translation Mediated Map Task", ["Hayakawa Akira", "Saturnino Luz", "Nick Campbell"], "https://doi.org/10.21437/Interspeech.2016-1623", 5, "interspeech", 2016]], "Saturnino Luz": [0, ["Talking to a System and Talking to a Human: A Study from a Speech-to-Speech, Machine Translation Mediated Map Task", ["Hayakawa Akira", "Saturnino Luz", "Nick Campbell"], "https://doi.org/10.21437/Interspeech.2016-1623", 5, "interspeech", 2016]], "Wen-Yu Huang": [0, ["Enhancement of Automatic Oral Presentation Assessment System Using Latent N-Grams Word Representation and Part-of-Speech Information", ["Wen-Yu Huang", "Shan-Wen Hsiao", "Hung-Ching Sun", "Ming-Chuan Hsieh", "Ming-Hsueh Tsai", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2016-400", 5, "interspeech", 2016]], "Shan-Wen Hsiao": [0, ["Enhancement of Automatic Oral Presentation Assessment System Using Latent N-Grams Word Representation and Part-of-Speech Information", ["Wen-Yu Huang", "Shan-Wen Hsiao", "Hung-Ching Sun", "Ming-Chuan Hsieh", "Ming-Hsueh Tsai", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2016-400", 5, "interspeech", 2016], ["Minimization of Regression and Ranking Losses with Shallow Neural Networks on Automatic Sincerity Evaluation", ["Hung-Shin Lee", "Yu Tsao", "Chi-Chun Lee", "Hsin-Min Wang", "Wei-Cheng Lin", "Wei-Chen Chen", "Shan-Wen Hsiao", "Shyh-Kang Jeng"], "https://doi.org/10.21437/Interspeech.2016-756", 5, "interspeech", 2016]], "Hung-Ching Sun": [0.00034497265733079985, ["Enhancement of Automatic Oral Presentation Assessment System Using Latent N-Grams Word Representation and Part-of-Speech Information", ["Wen-Yu Huang", "Shan-Wen Hsiao", "Hung-Ching Sun", "Ming-Chuan Hsieh", "Ming-Hsueh Tsai", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2016-400", 5, "interspeech", 2016]], "Ming-Chuan Hsieh": [0, ["Enhancement of Automatic Oral Presentation Assessment System Using Latent N-Grams Word Representation and Part-of-Speech Information", ["Wen-Yu Huang", "Shan-Wen Hsiao", "Hung-Ching Sun", "Ming-Chuan Hsieh", "Ming-Hsueh Tsai", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2016-400", 5, "interspeech", 2016]], "Ming-Hsueh Tsai": [0, ["Enhancement of Automatic Oral Presentation Assessment System Using Latent N-Grams Word Representation and Part-of-Speech Information", ["Wen-Yu Huang", "Shan-Wen Hsiao", "Hung-Ching Sun", "Ming-Chuan Hsieh", "Ming-Hsueh Tsai", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2016-400", 5, "interspeech", 2016]], "P. Gangamohan": [0, ["Use of Vowels in Discriminating Speech-Laugh from Laughter and Neutral Speech", ["Sri Harsha Dumpala", "P. Gangamohan", "Suryakanth V. Gangashetty", "B. Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2016-1114", 5, "interspeech", 2016]], "Kan Kawabata": [0, ["A Convex Model for Linguistic Influence in Group Conversations", ["Kan Kawabata", "Visar Berisha", "Anna Scaglione", "Amy LaCross"], "https://doi.org/10.21437/Interspeech.2016-498", 5, "interspeech", 2016]], "Visar Berisha": [0, ["A Convex Model for Linguistic Influence in Group Conversations", ["Kan Kawabata", "Visar Berisha", "Anna Scaglione", "Amy LaCross"], "https://doi.org/10.21437/Interspeech.2016-498", 5, "interspeech", 2016], ["Accent Identification by Combining Deep Neural Networks and Recurrent Neural Networks Trained on Long and Short Term Features", ["Yishan Jiao", "Ming Tu", "Visar Berisha", "Julie M. Liss"], "https://doi.org/10.21437/Interspeech.2016-1148", 5, "interspeech", 2016]], "Anna Scaglione": [0, ["A Convex Model for Linguistic Influence in Group Conversations", ["Kan Kawabata", "Visar Berisha", "Anna Scaglione", "Amy LaCross"], "https://doi.org/10.21437/Interspeech.2016-498", 5, "interspeech", 2016]], "Amy LaCross": [0, ["A Convex Model for Linguistic Influence in Group Conversations", ["Kan Kawabata", "Visar Berisha", "Anna Scaglione", "Amy LaCross"], "https://doi.org/10.21437/Interspeech.2016-498", 5, "interspeech", 2016]], "Kun-Yi Huang": [0, ["Unipolar Depression vs. Bipolar Disorder: An Elicitation-Based Approach to Short-Term Detection of Mood Disorder", ["Kun-Yi Huang", "Chung-Hsien Wu", "Yu-Ting Kuo", "Fong-Lin Jang"], "https://doi.org/10.21437/Interspeech.2016-620", 5, "interspeech", 2016]], "Chung-Hsien Wu": [2.0711617594315612e-06, ["Unipolar Depression vs. Bipolar Disorder: An Elicitation-Based Approach to Short-Term Detection of Mood Disorder", ["Kun-Yi Huang", "Chung-Hsien Wu", "Yu-Ting Kuo", "Fong-Lin Jang"], "https://doi.org/10.21437/Interspeech.2016-620", 5, "interspeech", 2016], ["Generation of Emotion Control Vector Using MDS-Based Space Transformation for Expressive Speech Synthesis", ["Yan-You Chen", "Chung-Hsien Wu", "Yu-Fong Huang"], "https://doi.org/10.21437/Interspeech.2016-815", 5, "interspeech", 2016]], "Yu-Ting Kuo": [0, ["Unipolar Depression vs. Bipolar Disorder: An Elicitation-Based Approach to Short-Term Detection of Mood Disorder", ["Kun-Yi Huang", "Chung-Hsien Wu", "Yu-Ting Kuo", "Fong-Lin Jang"], "https://doi.org/10.21437/Interspeech.2016-620", 5, "interspeech", 2016]], "Fong-Lin Jang": [6.538444904435892e-05, ["Unipolar Depression vs. Bipolar Disorder: An Elicitation-Based Approach to Short-Term Detection of Mood Disorder", ["Kun-Yi Huang", "Chung-Hsien Wu", "Yu-Ting Kuo", "Fong-Lin Jang"], "https://doi.org/10.21437/Interspeech.2016-620", 5, "interspeech", 2016]], "Abir Masmoudi": [0, ["Conditional Random Fields for the Tunisian Dialect Grapheme-to-Phoneme Conversion", ["Abir Masmoudi", "Mariem Ellouze", "Fethi Bougares", "Yannick Esteve", "Lamia Hadrich Belguith"], "https://doi.org/10.21437/Interspeech.2016-1320", 5, "interspeech", 2016]], "Mariem Ellouze": [0, ["Conditional Random Fields for the Tunisian Dialect Grapheme-to-Phoneme Conversion", ["Abir Masmoudi", "Mariem Ellouze", "Fethi Bougares", "Yannick Esteve", "Lamia Hadrich Belguith"], "https://doi.org/10.21437/Interspeech.2016-1320", 5, "interspeech", 2016]], "Fethi Bougares": [0, ["Conditional Random Fields for the Tunisian Dialect Grapheme-to-Phoneme Conversion", ["Abir Masmoudi", "Mariem Ellouze", "Fethi Bougares", "Yannick Esteve", "Lamia Hadrich Belguith"], "https://doi.org/10.21437/Interspeech.2016-1320", 5, "interspeech", 2016]], "Lamia Hadrich Belguith": [0, ["Conditional Random Fields for the Tunisian Dialect Grapheme-to-Phoneme Conversion", ["Abir Masmoudi", "Mariem Ellouze", "Fethi Bougares", "Yannick Esteve", "Lamia Hadrich Belguith"], "https://doi.org/10.21437/Interspeech.2016-1320", 5, "interspeech", 2016]], "Sittipong Saychum": [0, ["Efficient Thai Grapheme-to-Phoneme Conversion Using CRF-Based Joint Sequence Modeling", ["Sittipong Saychum", "Sarawoot Kongyoung", "Anocha Rugchatjaroen", "Patcharika Chootrakool", "Sawit Kasuriya", "Chai Wutiwiwatchai"], "https://doi.org/10.21437/Interspeech.2016-621", 5, "interspeech", 2016]], "Sarawoot Kongyoung": [0, ["Efficient Thai Grapheme-to-Phoneme Conversion Using CRF-Based Joint Sequence Modeling", ["Sittipong Saychum", "Sarawoot Kongyoung", "Anocha Rugchatjaroen", "Patcharika Chootrakool", "Sawit Kasuriya", "Chai Wutiwiwatchai"], "https://doi.org/10.21437/Interspeech.2016-621", 5, "interspeech", 2016]], "Anocha Rugchatjaroen": [0, ["Efficient Thai Grapheme-to-Phoneme Conversion Using CRF-Based Joint Sequence Modeling", ["Sittipong Saychum", "Sarawoot Kongyoung", "Anocha Rugchatjaroen", "Patcharika Chootrakool", "Sawit Kasuriya", "Chai Wutiwiwatchai"], "https://doi.org/10.21437/Interspeech.2016-621", 5, "interspeech", 2016]], "Patcharika Chootrakool": [0, ["Efficient Thai Grapheme-to-Phoneme Conversion Using CRF-Based Joint Sequence Modeling", ["Sittipong Saychum", "Sarawoot Kongyoung", "Anocha Rugchatjaroen", "Patcharika Chootrakool", "Sawit Kasuriya", "Chai Wutiwiwatchai"], "https://doi.org/10.21437/Interspeech.2016-621", 5, "interspeech", 2016]], "Sawit Kasuriya": [0, ["Efficient Thai Grapheme-to-Phoneme Conversion Using CRF-Based Joint Sequence Modeling", ["Sittipong Saychum", "Sarawoot Kongyoung", "Anocha Rugchatjaroen", "Patcharika Chootrakool", "Sawit Kasuriya", "Chai Wutiwiwatchai"], "https://doi.org/10.21437/Interspeech.2016-621", 5, "interspeech", 2016]], "Chai Wutiwiwatchai": [0, ["Efficient Thai Grapheme-to-Phoneme Conversion Using CRF-Based Joint Sequence Modeling", ["Sittipong Saychum", "Sarawoot Kongyoung", "Anocha Rugchatjaroen", "Patcharika Chootrakool", "Sawit Kasuriya", "Chai Wutiwiwatchai"], "https://doi.org/10.21437/Interspeech.2016-621", 5, "interspeech", 2016]], "Aurore Jaumard-Hakoun": [0, ["An Articulatory-Based Singing Voice Synthesis Using Tongue and Lips Imaging", ["Aurore Jaumard-Hakoun", "Kele Xu", "Clemence Leboullenger", "Pierre Roussel-Ragot", "Bruce Denby"], "https://doi.org/10.21437/Interspeech.2016-385", 5, "interspeech", 2016]], "Kele Xu": [0, ["An Articulatory-Based Singing Voice Synthesis Using Tongue and Lips Imaging", ["Aurore Jaumard-Hakoun", "Kele Xu", "Clemence Leboullenger", "Pierre Roussel-Ragot", "Bruce Denby"], "https://doi.org/10.21437/Interspeech.2016-385", 5, "interspeech", 2016]], "Clemence Leboullenger": [0, ["An Articulatory-Based Singing Voice Synthesis Using Tongue and Lips Imaging", ["Aurore Jaumard-Hakoun", "Kele Xu", "Clemence Leboullenger", "Pierre Roussel-Ragot", "Bruce Denby"], "https://doi.org/10.21437/Interspeech.2016-385", 5, "interspeech", 2016]], "Pierre Roussel-Ragot": [0, ["An Articulatory-Based Singing Voice Synthesis Using Tongue and Lips Imaging", ["Aurore Jaumard-Hakoun", "Kele Xu", "Clemence Leboullenger", "Pierre Roussel-Ragot", "Bruce Denby"], "https://doi.org/10.21437/Interspeech.2016-385", 5, "interspeech", 2016]], "Bruce Denby": [0, ["An Articulatory-Based Singing Voice Synthesis Using Tongue and Lips Imaging", ["Aurore Jaumard-Hakoun", "Kele Xu", "Clemence Leboullenger", "Pierre Roussel-Ragot", "Bruce Denby"], "https://doi.org/10.21437/Interspeech.2016-385", 5, "interspeech", 2016]], "Xu Li": [0, ["Phoneme Embedding and its Application to Speech Driven Talking Avatar Synthesis", ["Xu Li", "Zhiyong Wu", "Helen M. Meng", "Jia Jia", "Xiaoyan Lou", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-363", 5, "interspeech", 2016], ["Expressive Speech Driven Talking Avatar Synthesis with DBLSTM Using Limited Amount of Emotional Bimodal Data", ["Xu Li", "Zhiyong Wu", "Helen M. Meng", "Jia Jia", "Xiaoyan Lou", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-364", 5, "interspeech", 2016], ["Adaptive Group Sparsity for Non-Negative Matrix Factorization with Application to Unsupervised Source Separation", ["Xu Li", "Ziteng Wang", "Xiaofei Wang", "Qiang Fu", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2016-321", 5, "interspeech", 2016], ["A DNN-HMM Approach to Non-Negative Matrix Factorization Based Speech Enhancement", ["Ziteng Wang", "Xu Li", "Xiaofei Wang", "Qiang Fu", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2016-147", 5, "interspeech", 2016]], "Jia Jia": [0, ["Phoneme Embedding and its Application to Speech Driven Talking Avatar Synthesis", ["Xu Li", "Zhiyong Wu", "Helen M. Meng", "Jia Jia", "Xiaoyan Lou", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-363", 5, "interspeech", 2016], ["Expressive Speech Driven Talking Avatar Synthesis with DBLSTM Using Limited Amount of Emotional Bimodal Data", ["Xu Li", "Zhiyong Wu", "Helen M. Meng", "Jia Jia", "Xiaoyan Lou", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-364", 5, "interspeech", 2016]], "Xiaoyan Lou": [0, ["Phoneme Embedding and its Application to Speech Driven Talking Avatar Synthesis", ["Xu Li", "Zhiyong Wu", "Helen M. Meng", "Jia Jia", "Xiaoyan Lou", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-363", 5, "interspeech", 2016], ["Expressive Speech Driven Talking Avatar Synthesis with DBLSTM Using Limited Amount of Emotional Bimodal Data", ["Xu Li", "Zhiyong Wu", "Helen M. Meng", "Jia Jia", "Xiaoyan Lou", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2016-364", 5, "interspeech", 2016]], "Sarah Taylor": [0, ["Audio-to-Visual Speech Conversion Using Deep Neural Networks", ["Sarah Taylor", "Akihiro Kato", "Iain A. Matthews", "Ben P. Milner"], "https://doi.org/10.21437/Interspeech.2016-483", 5, "interspeech", 2016], ["Visual Speech Synthesis Using Dynamic Visemes, Contextual Features and DNNs", ["Ausdang Thangthai", "Ben Milner", "Sarah Taylor"], "https://doi.org/10.21437/Interspeech.2016-1084", 5, "interspeech", 2016]], "Akihiro Kato": [0, ["Audio-to-Visual Speech Conversion Using Deep Neural Networks", ["Sarah Taylor", "Akihiro Kato", "Iain A. Matthews", "Ben P. Milner"], "https://doi.org/10.21437/Interspeech.2016-483", 5, "interspeech", 2016], ["HMM-Based Speech Enhancement Using Sub-Word Models and Noise Adaptation", ["Akihiro Kato", "Ben P. Milner"], "https://doi.org/10.21437/Interspeech.2016-928", 5, "interspeech", 2016]], "Iain A. Matthews": [0, ["Audio-to-Visual Speech Conversion Using Deep Neural Networks", ["Sarah Taylor", "Akihiro Kato", "Iain A. Matthews", "Ben P. Milner"], "https://doi.org/10.21437/Interspeech.2016-483", 5, "interspeech", 2016]], "Ben P. Milner": [0, ["Audio-to-Visual Speech Conversion Using Deep Neural Networks", ["Sarah Taylor", "Akihiro Kato", "Iain A. Matthews", "Ben P. Milner"], "https://doi.org/10.21437/Interspeech.2016-483", 5, "interspeech", 2016], ["HMM-Based Speech Enhancement Using Sub-Word Models and Noise Adaptation", ["Akihiro Kato", "Ben P. Milner"], "https://doi.org/10.21437/Interspeech.2016-928", 5, "interspeech", 2016]], "Toru Nakashika": [0, ["Generative Acoustic-Phonemic-Speaker Model Based on Three-Way Restricted Boltzmann Machine", ["Toru Nakashika", "Yasuhiro Minami"], "https://doi.org/10.21437/Interspeech.2016-1105", 5, "interspeech", 2016]], "Yasuhiro Minami": [0, ["Generative Acoustic-Phonemic-Speaker Model Based on Three-Way Restricted Boltzmann Machine", ["Toru Nakashika", "Yasuhiro Minami"], "https://doi.org/10.21437/Interspeech.2016-1105", 5, "interspeech", 2016]], "Krishna Somandepalli": [0, ["Articulatory Synthesis Based on Real-Time Magnetic Resonance Imaging Data", ["Asterios Toutios", "Tanner Sorensen", "Krishna Somandepalli", "Rachel Alexander", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-596", 5, "interspeech", 2016]], "Rachel Alexander": [0, ["Articulatory Synthesis Based on Real-Time Magnetic Resonance Imaging Data", ["Asterios Toutios", "Tanner Sorensen", "Krishna Somandepalli", "Rachel Alexander", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-596", 5, "interspeech", 2016]], "Xurong Xie": [0, ["Deep Neural Network Based Acoustic-to-Articulatory Inversion Using Phone Sequence Information", ["Xurong Xie", "Xunying Liu", "Lan Wang"], "https://doi.org/10.21437/Interspeech.2016-659", 5, "interspeech", 2016]], "Xunying Liu": [0, ["Deep Neural Network Based Acoustic-to-Articulatory Inversion Using Phone Sequence Information", ["Xurong Xie", "Xunying Liu", "Lan Wang"], "https://doi.org/10.21437/Interspeech.2016-659", 5, "interspeech", 2016]], "Zheng-Chen Liu": [0, ["Articulatory-to-Acoustic Conversion with Cascaded Prediction of Spectral and Excitation Features Using Neural Networks", ["Zheng-Chen Liu", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-715", 5, "interspeech", 2016]], "Christopher Liberatore": [0, ["Generating Gestural Scores from Acoustics Through a Sparse Anchor-Based Representation of Speech", ["Christopher Liberatore", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2016-1336", 5, "interspeech", 2016]], "David Guennec": [0, ["On the Suitability of Vocalic Sandwiches in a Corpus-Based TTS Engine", ["David Guennec", "Damien Lolive"], "https://doi.org/10.21437/Interspeech.2016-1222", 5, "interspeech", 2016]], "Damien Lolive": [0, ["On the Suitability of Vocalic Sandwiches in a Corpus-Based TTS Engine", ["David Guennec", "Damien Lolive"], "https://doi.org/10.21437/Interspeech.2016-1222", 5, "interspeech", 2016], ["Improving TTS with Corpus-Specific Pronunciation Adaptation", ["Marie Tahon", "Raheel Qader", "Gwenole Lecorve", "Damien Lolive"], "https://doi.org/10.21437/Interspeech.2016-864", 5, "interspeech", 2016]], "Decha Moungsri": [0, ["Unsupervised Stress Information Labeling Using Gaussian Process Latent Variable Model for Statistical Speech Synthesis", ["Decha Moungsri", "Tomoki Koriyama", "Takao Kobayashi"], "https://doi.org/10.21437/Interspeech.2016-273", 5, "interspeech", 2016]], "Tomoki Koriyama": [0, ["Unsupervised Stress Information Labeling Using Gaussian Process Latent Variable Model for Statistical Speech Synthesis", ["Decha Moungsri", "Tomoki Koriyama", "Takao Kobayashi"], "https://doi.org/10.21437/Interspeech.2016-273", 5, "interspeech", 2016]], "Takao Kobayashi": [0, ["Unsupervised Stress Information Labeling Using Gaussian Process Latent Variable Model for Statistical Speech Synthesis", ["Decha Moungsri", "Tomoki Koriyama", "Takao Kobayashi"], "https://doi.org/10.21437/Interspeech.2016-273", 5, "interspeech", 2016]], "Jinfu Ni": [0, ["Using Zero-Frequency Resonator to Extract Multilingual Intonation Structure", ["Jinfu Ni", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-1607", 5, "interspeech", 2016]], "Yoshinori Shiga": [0, ["Using Zero-Frequency Resonator to Extract Multilingual Intonation Structure", ["Jinfu Ni", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-1607", 5, "interspeech", 2016], ["Model Integration for HMM- and DNN-Based Speech Synthesis Using Product-of-Experts Framework", ["Kentaro Tachibana", "Tomoki Toda", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-1006", 5, "interspeech", 2016]], "Jia Yu": [0.05329906940460205, ["A DNN-HMM Approach to Story Segmentation", ["Jia Yu", "Xiong Xiao", "Lei Xie", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-873", 5, "interspeech", 2016]], "Jean-Philippe Goldman": [0, ["The SIWIS Database: A Multilingual Speech Database with Acted Emphasis", ["Jean-Philippe Goldman", "Pierre-Edouard Honnet", "Robert A. J. Clark", "Philip N. Garner", "Maria Ivanova", "Alexandros Lazaridis", "Hui Liang", "Tiago Macedo", "Beat Pfister", "Manuel Sam Ribeiro", "Eric Wehrli", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1003", 4, "interspeech", 2016]], "Robert A. J. Clark": [0, ["The SIWIS Database: A Multilingual Speech Database with Acted Emphasis", ["Jean-Philippe Goldman", "Pierre-Edouard Honnet", "Robert A. J. Clark", "Philip N. Garner", "Maria Ivanova", "Alexandros Lazaridis", "Hui Liang", "Tiago Macedo", "Beat Pfister", "Manuel Sam Ribeiro", "Eric Wehrli", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1003", 4, "interspeech", 2016]], "Maria Ivanova": [0, ["The SIWIS Database: A Multilingual Speech Database with Acted Emphasis", ["Jean-Philippe Goldman", "Pierre-Edouard Honnet", "Robert A. J. Clark", "Philip N. Garner", "Maria Ivanova", "Alexandros Lazaridis", "Hui Liang", "Tiago Macedo", "Beat Pfister", "Manuel Sam Ribeiro", "Eric Wehrli", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1003", 4, "interspeech", 2016]], "Alexandros Lazaridis": [0, ["The SIWIS Database: A Multilingual Speech Database with Acted Emphasis", ["Jean-Philippe Goldman", "Pierre-Edouard Honnet", "Robert A. J. Clark", "Philip N. Garner", "Maria Ivanova", "Alexandros Lazaridis", "Hui Liang", "Tiago Macedo", "Beat Pfister", "Manuel Sam Ribeiro", "Eric Wehrli", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1003", 4, "interspeech", 2016], ["Probabilistic Amplitude Demodulation Features in Speech Synthesis for Improving Prosody", ["Alexandros Lazaridis", "Milos Cernak", "Philip N. Garner"], "https://doi.org/10.21437/Interspeech.2016-258", 5, "interspeech", 2016]], "Hui Liang": [0, ["The SIWIS Database: A Multilingual Speech Database with Acted Emphasis", ["Jean-Philippe Goldman", "Pierre-Edouard Honnet", "Robert A. J. Clark", "Philip N. Garner", "Maria Ivanova", "Alexandros Lazaridis", "Hui Liang", "Tiago Macedo", "Beat Pfister", "Manuel Sam Ribeiro", "Eric Wehrli", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1003", 4, "interspeech", 2016]], "Tiago Macedo": [0, ["The SIWIS Database: A Multilingual Speech Database with Acted Emphasis", ["Jean-Philippe Goldman", "Pierre-Edouard Honnet", "Robert A. J. Clark", "Philip N. Garner", "Maria Ivanova", "Alexandros Lazaridis", "Hui Liang", "Tiago Macedo", "Beat Pfister", "Manuel Sam Ribeiro", "Eric Wehrli", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1003", 4, "interspeech", 2016]], "Manuel Sam Ribeiro": [0, ["The SIWIS Database: A Multilingual Speech Database with Acted Emphasis", ["Jean-Philippe Goldman", "Pierre-Edouard Honnet", "Robert A. J. Clark", "Philip N. Garner", "Maria Ivanova", "Alexandros Lazaridis", "Hui Liang", "Tiago Macedo", "Beat Pfister", "Manuel Sam Ribeiro", "Eric Wehrli", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1003", 4, "interspeech", 2016], ["Syllable-Level Representations of Suprasegmental Features for DNN-Based Text-to-Speech Synthesis", ["Manuel Sam Ribeiro", "Oliver Watts", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1034", 5, "interspeech", 2016]], "Eric Wehrli": [0, ["The SIWIS Database: A Multilingual Speech Database with Acted Emphasis", ["Jean-Philippe Goldman", "Pierre-Edouard Honnet", "Robert A. J. Clark", "Philip N. Garner", "Maria Ivanova", "Alexandros Lazaridis", "Hui Liang", "Tiago Macedo", "Beat Pfister", "Manuel Sam Ribeiro", "Eric Wehrli", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1003", 4, "interspeech", 2016]], "Henk van den Heuvel": [0, ["Open Source Speech and Language Resources for Frisian", ["Emre Yilmaz", "Henk van den Heuvel", "Jelske Dijkstra", "Hans Van de Velde", "Frederik Kampstra", "Jouke Algra", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2016-48", 5, "interspeech", 2016]], "Jelske Dijkstra": [0, ["Open Source Speech and Language Resources for Frisian", ["Emre Yilmaz", "Henk van den Heuvel", "Jelske Dijkstra", "Hans Van de Velde", "Frederik Kampstra", "Jouke Algra", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2016-48", 5, "interspeech", 2016]], "Hans Van de Velde": [0, ["Open Source Speech and Language Resources for Frisian", ["Emre Yilmaz", "Henk van den Heuvel", "Jelske Dijkstra", "Hans Van de Velde", "Frederik Kampstra", "Jouke Algra", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2016-48", 5, "interspeech", 2016]], "Frederik Kampstra": [0, ["Open Source Speech and Language Resources for Frisian", ["Emre Yilmaz", "Henk van den Heuvel", "Jelske Dijkstra", "Hans Van de Velde", "Frederik Kampstra", "Jouke Algra", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2016-48", 5, "interspeech", 2016]], "Jouke Algra": [0, ["Open Source Speech and Language Resources for Frisian", ["Emre Yilmaz", "Henk van den Heuvel", "Jelske Dijkstra", "Hans Van de Velde", "Frederik Kampstra", "Jouke Algra", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2016-48", 5, "interspeech", 2016]], "David A. van Leeuwen": [0, ["Open Source Speech and Language Resources for Frisian", ["Emre Yilmaz", "Henk van den Heuvel", "Jelske Dijkstra", "Hans Van de Velde", "Frederik Kampstra", "Jouke Algra", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2016-48", 5, "interspeech", 2016]], "Andreas Kathol": [0, ["The SRI CLEO Speaker-State Corpus", ["Andreas Kathol", "Elizabeth Shriberg", "Massimiliano de Zambotti"], "https://doi.org/10.21437/Interspeech.2016-1141", 4, "interspeech", 2016], ["Automatic Speech Transcription for Low-Resource Languages - The Case of Yolox\u00f3chitl Mixtec (Mexico)", ["Vikramjit Mitra", "Andreas Kathol", "Jonathan D. Amith", "Rey Castillo Garcia"], "https://doi.org/10.21437/Interspeech.2016-546", 5, "interspeech", 2016]], "Massimiliano de Zambotti": [0, ["The SRI CLEO Speaker-State Corpus", ["Andreas Kathol", "Elizabeth Shriberg", "Massimiliano de Zambotti"], "https://doi.org/10.21437/Interspeech.2016-1141", 4, "interspeech", 2016]], "Rong Tong": [0, ["SingaKids-Mandarin: Speech Corpus of Singaporean Children Speaking Mandarin Chinese", ["Nancy F. Chen", "Rong Tong", "Darren Wee", "Pei Xuan Lee", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-139", 5, "interspeech", 2016], ["Context Aware Mispronunciation Detection for Mandarin Pronunciation Training", ["Rong Tong", "Nancy F. Chen", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-289", 5, "interspeech", 2016]], "Darren Wee": [0, ["SingaKids-Mandarin: Speech Corpus of Singaporean Children Speaking Mandarin Chinese", ["Nancy F. Chen", "Rong Tong", "Darren Wee", "Pei Xuan Lee", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-139", 5, "interspeech", 2016]], "Pei Xuan Lee": [6.541672536997112e-09, ["SingaKids-Mandarin: Speech Corpus of Singaporean Children Speaking Mandarin Chinese", ["Nancy F. Chen", "Rong Tong", "Darren Wee", "Pei Xuan Lee", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-139", 5, "interspeech", 2016]], "Anil Ramakrishna": [0, ["An Expectation Maximization Approach to Joint Modeling of Multidimensional Ratings Derived from Multiple Annotators", ["Anil Ramakrishna", "Rahul Gupta", "Ruth B. Grossman", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-270", 5, "interspeech", 2016]], "Ruth B. Grossman": [0, ["An Expectation Maximization Approach to Joint Modeling of Multidimensional Ratings Derived from Multiple Annotators", ["Anil Ramakrishna", "Rahul Gupta", "Ruth B. Grossman", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-270", 5, "interspeech", 2016]], "Daniel Tihelka": [0, ["Voting Detector: A Combination of Anomaly Detectors to Reveal Annotation Errors in TTS Corpora", ["Jindrich Matousek", "Daniel Tihelka"], "https://doi.org/10.21437/Interspeech.2016-442", 5, "interspeech", 2016]], "Mario Corrales-Astorgano": [0, ["The Magic Stone: A Video Game to Improve Communication Skills of People with Intellectual Disabilities", ["Mario Corrales-Astorgano", "David Escudero Mancebo", "Cesar Gonzalez Ferreras", "Yurena Gutierrez-Gonzalez", "Valle Flores-Lucas", "Valentin Cardenoso-Payo", "Lourdes Aguilar-Cuevas"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2017.html", 2, "interspeech", 2016]], "Yurena Gutierrez-Gonzalez": [0, ["The Magic Stone: A Video Game to Improve Communication Skills of People with Intellectual Disabilities", ["Mario Corrales-Astorgano", "David Escudero Mancebo", "Cesar Gonzalez Ferreras", "Yurena Gutierrez-Gonzalez", "Valle Flores-Lucas", "Valentin Cardenoso-Payo", "Lourdes Aguilar-Cuevas"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2017.html", 2, "interspeech", 2016]], "Valle Flores-Lucas": [0, ["The Magic Stone: A Video Game to Improve Communication Skills of People with Intellectual Disabilities", ["Mario Corrales-Astorgano", "David Escudero Mancebo", "Cesar Gonzalez Ferreras", "Yurena Gutierrez-Gonzalez", "Valle Flores-Lucas", "Valentin Cardenoso-Payo", "Lourdes Aguilar-Cuevas"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2017.html", 2, "interspeech", 2016]], "Lourdes Aguilar-Cuevas": [0, ["The Magic Stone: A Video Game to Improve Communication Skills of People with Intellectual Disabilities", ["Mario Corrales-Astorgano", "David Escudero Mancebo", "Cesar Gonzalez Ferreras", "Yurena Gutierrez-Gonzalez", "Valle Flores-Lucas", "Valentin Cardenoso-Payo", "Lourdes Aguilar-Cuevas"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2017.html", 2, "interspeech", 2016]], "Finnian Kelly": [0, ["Identifying Perceptually Similar Voices with a Speaker Recognition System Using Auto-Phonetic Features", ["Finnian Kelly", "Anil Alexander", "Oscar Forth", "Samuel Kent", "Jonas Lindh", "Joel Akesson"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2018.html", 2, "interspeech", 2016], ["Text-Available Speaker Recognition System for Forensic Applications", ["Chengzhu Yu", "Chunlei Zhang", "Finnian Kelly", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2016-1520", 4, "interspeech", 2016]], "Anil Alexander": [0, ["Identifying Perceptually Similar Voices with a Speaker Recognition System Using Auto-Phonetic Features", ["Finnian Kelly", "Anil Alexander", "Oscar Forth", "Samuel Kent", "Jonas Lindh", "Joel Akesson"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2018.html", 2, "interspeech", 2016]], "Oscar Forth": [0, ["Identifying Perceptually Similar Voices with a Speaker Recognition System Using Auto-Phonetic Features", ["Finnian Kelly", "Anil Alexander", "Oscar Forth", "Samuel Kent", "Jonas Lindh", "Joel Akesson"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2018.html", 2, "interspeech", 2016]], "Samuel Kent": [0, ["Identifying Perceptually Similar Voices with a Speaker Recognition System Using Auto-Phonetic Features", ["Finnian Kelly", "Anil Alexander", "Oscar Forth", "Samuel Kent", "Jonas Lindh", "Joel Akesson"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2018.html", 2, "interspeech", 2016]], "Jonas Lindh": [0, ["Identifying Perceptually Similar Voices with a Speaker Recognition System Using Auto-Phonetic Features", ["Finnian Kelly", "Anil Alexander", "Oscar Forth", "Samuel Kent", "Jonas Lindh", "Joel Akesson"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2018.html", 2, "interspeech", 2016]], "Joel Akesson": [0, ["Identifying Perceptually Similar Voices with a Speaker Recognition System Using Auto-Phonetic Features", ["Finnian Kelly", "Anil Alexander", "Oscar Forth", "Samuel Kent", "Jonas Lindh", "Joel Akesson"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2018.html", 2, "interspeech", 2016]], "Kristy James": [0, ["A Real-Time Framework for Visual Feedback of Articulatory Data Using Statistical Shape Models", ["Kristy James", "Alexander Hewer", "Ingmar Steiner", "Stefanie Wuhrer"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2019.html", 2, "interspeech", 2016]], "Alexander Hewer": [0, ["A Real-Time Framework for Visual Feedback of Articulatory Data Using Statistical Shape Models", ["Kristy James", "Alexander Hewer", "Ingmar Steiner", "Stefanie Wuhrer"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2019.html", 2, "interspeech", 2016]], "Ingmar Steiner": [0, ["A Real-Time Framework for Visual Feedback of Articulatory Data Using Statistical Shape Models", ["Kristy James", "Alexander Hewer", "Ingmar Steiner", "Stefanie Wuhrer"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2019.html", 2, "interspeech", 2016]], "Stefanie Wuhrer": [0, ["A Real-Time Framework for Visual Feedback of Articulatory Data Using Statistical Shape Models", ["Kristy James", "Alexander Hewer", "Ingmar Steiner", "Stefanie Wuhrer"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2019.html", 2, "interspeech", 2016]], "Alex Marin": [0, ["Flexible, Rapid Authoring of Goal-Orientated, Multi-Turn Dialogues Using the Task Completion Platform", ["Alex Marin", "Paul A. Crook", "Omar Zia Khan", "Vasiliy Radostev", "Khushboo Aggarwal", "Ruhi Sarikaya"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2020.html", 2, "interspeech", 2016]], "Paul A. Crook": [0, ["Flexible, Rapid Authoring of Goal-Orientated, Multi-Turn Dialogues Using the Task Completion Platform", ["Alex Marin", "Paul A. Crook", "Omar Zia Khan", "Vasiliy Radostev", "Khushboo Aggarwal", "Ruhi Sarikaya"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2020.html", 2, "interspeech", 2016]], "Vasiliy Radostev": [0, ["Flexible, Rapid Authoring of Goal-Orientated, Multi-Turn Dialogues Using the Task Completion Platform", ["Alex Marin", "Paul A. Crook", "Omar Zia Khan", "Vasiliy Radostev", "Khushboo Aggarwal", "Ruhi Sarikaya"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2020.html", 2, "interspeech", 2016]], "Khushboo Aggarwal": [0, ["Flexible, Rapid Authoring of Goal-Orientated, Multi-Turn Dialogues Using the Task Completion Platform", ["Alex Marin", "Paul A. Crook", "Omar Zia Khan", "Vasiliy Radostev", "Khushboo Aggarwal", "Ruhi Sarikaya"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2020.html", 2, "interspeech", 2016]], "Marc Delcroix": [0, ["Context Adaptive Neural Network for Rapid Adaptation of Deep CNN Based Acoustic Models", ["Marc Delcroix", "Keisuke Kinoshita", "Atsunori Ogawa", "Takuya Yoshioka", "Dung T. Tran", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-203", 5, "interspeech", 2016], ["Data Selection by Sequence Summarizing Neural Network in Mismatch Condition Training", ["Katerina Zmolikova", "Martin Karafiat", "Karel Vesely", "Marc Delcroix", "Shinji Watanabe", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-741", 5, "interspeech", 2016], ["Robust Example Search Using Bottleneck Features for Example-Based Speech Enhancement", ["Atsunori Ogawa", "Shogo Seki", "Keisuke Kinoshita", "Marc Delcroix", "Takuya Yoshioka", "Tomohiro Nakatani", "Kazuya Takeda"], "https://doi.org/10.21437/Interspeech.2016-671", 5, "interspeech", 2016], ["Factorized Linear Input Network for Acoustic Model Adaptation in Noisy Conditions", ["Dung T. Tran", "Marc Delcroix", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-732", 5, "interspeech", 2016]], "Keisuke Kinoshita": [0, ["Context Adaptive Neural Network for Rapid Adaptation of Deep CNN Based Acoustic Models", ["Marc Delcroix", "Keisuke Kinoshita", "Atsunori Ogawa", "Takuya Yoshioka", "Dung T. Tran", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-203", 5, "interspeech", 2016], ["Speech Intelligibility Prediction Based on the Envelope Power Spectrum Model with the Dynamic Compressive Gammachirp Auditory Filterbank", ["Katsuhiko Yamamoto", "Toshio Irino", "Toshie Matsui", "Shoko Araki", "Keisuke Kinoshita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-652", 5, "interspeech", 2016], ["Robust Example Search Using Bottleneck Features for Example-Based Speech Enhancement", ["Atsunori Ogawa", "Shogo Seki", "Keisuke Kinoshita", "Marc Delcroix", "Takuya Yoshioka", "Tomohiro Nakatani", "Kazuya Takeda"], "https://doi.org/10.21437/Interspeech.2016-671", 5, "interspeech", 2016]], "Atsunori Ogawa": [0, ["Context Adaptive Neural Network for Rapid Adaptation of Deep CNN Based Acoustic Models", ["Marc Delcroix", "Keisuke Kinoshita", "Atsunori Ogawa", "Takuya Yoshioka", "Dung T. Tran", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-203", 5, "interspeech", 2016], ["Robust Example Search Using Bottleneck Features for Example-Based Speech Enhancement", ["Atsunori Ogawa", "Shogo Seki", "Keisuke Kinoshita", "Marc Delcroix", "Takuya Yoshioka", "Tomohiro Nakatani", "Kazuya Takeda"], "https://doi.org/10.21437/Interspeech.2016-671", 5, "interspeech", 2016], ["Factorized Linear Input Network for Acoustic Model Adaptation in Noisy Conditions", ["Dung T. Tran", "Marc Delcroix", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-732", 5, "interspeech", 2016]], "Takuya Yoshioka": [0, ["Context Adaptive Neural Network for Rapid Adaptation of Deep CNN Based Acoustic Models", ["Marc Delcroix", "Keisuke Kinoshita", "Atsunori Ogawa", "Takuya Yoshioka", "Dung T. Tran", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-203", 5, "interspeech", 2016], ["Robust Example Search Using Bottleneck Features for Example-Based Speech Enhancement", ["Atsunori Ogawa", "Shogo Seki", "Keisuke Kinoshita", "Marc Delcroix", "Takuya Yoshioka", "Tomohiro Nakatani", "Kazuya Takeda"], "https://doi.org/10.21437/Interspeech.2016-671", 5, "interspeech", 2016], ["Optimization of Speech Enhancement Front-End with Speech Recognition-Level Criterion", ["Takuya Higuchi", "Takuya Yoshioka", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-681", 5, "interspeech", 2016]], "Dung T. Tran": [0, ["Context Adaptive Neural Network for Rapid Adaptation of Deep CNN Based Acoustic Models", ["Marc Delcroix", "Keisuke Kinoshita", "Atsunori Ogawa", "Takuya Yoshioka", "Dung T. Tran", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-203", 5, "interspeech", 2016], ["Factorized Linear Input Network for Acoustic Model Adaptation in Noisy Conditions", ["Dung T. Tran", "Marc Delcroix", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-732", 5, "interspeech", 2016]], "Tomohiro Nakatani": [0, ["Context Adaptive Neural Network for Rapid Adaptation of Deep CNN Based Acoustic Models", ["Marc Delcroix", "Keisuke Kinoshita", "Atsunori Ogawa", "Takuya Yoshioka", "Dung T. Tran", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-203", 5, "interspeech", 2016], ["Speech Intelligibility Prediction Based on the Envelope Power Spectrum Model with the Dynamic Compressive Gammachirp Auditory Filterbank", ["Katsuhiko Yamamoto", "Toshio Irino", "Toshie Matsui", "Shoko Araki", "Keisuke Kinoshita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-652", 5, "interspeech", 2016], ["Robust Example Search Using Bottleneck Features for Example-Based Speech Enhancement", ["Atsunori Ogawa", "Shogo Seki", "Keisuke Kinoshita", "Marc Delcroix", "Takuya Yoshioka", "Tomohiro Nakatani", "Kazuya Takeda"], "https://doi.org/10.21437/Interspeech.2016-671", 5, "interspeech", 2016], ["Optimization of Speech Enhancement Front-End with Speech Recognition-Level Criterion", ["Takuya Higuchi", "Takuya Yoshioka", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-681", 5, "interspeech", 2016], ["Factorized Linear Input Network for Acoustic Model Adaptation in Noisy Conditions", ["Dung T. Tran", "Marc Delcroix", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-732", 5, "interspeech", 2016]], "Faith Wong": [0, ["Transfer Learning with Bottleneck Feature Networks for Whispered Speech Recognition", ["Boon Pang Lim", "Faith Wong", "Yuyao Li", "Jia Wei Bay"], "https://doi.org/10.21437/Interspeech.2016-250", 5, "interspeech", 2016]], "Yuyao Li": [0, ["Transfer Learning with Bottleneck Feature Networks for Whispered Speech Recognition", ["Boon Pang Lim", "Faith Wong", "Yuyao Li", "Jia Wei Bay"], "https://doi.org/10.21437/Interspeech.2016-250", 5, "interspeech", 2016]], "Jia Wei Bay": [0, ["Transfer Learning with Bottleneck Feature Networks for Whispered Speech Recognition", ["Boon Pang Lim", "Faith Wong", "Yuyao Li", "Jia Wei Bay"], "https://doi.org/10.21437/Interspeech.2016-250", 5, "interspeech", 2016]], "Masayuki Suzuki": [0, ["Domain Adaptation of CNN Based Acoustic Models Under Limited Resource Settings", ["Masayuki Suzuki", "Ryuki Tachibana", "Samuel Thomas", "Bhuvana Ramabhadran", "George Saon"], "https://doi.org/10.21437/Interspeech.2016-1161", 5, "interspeech", 2016]], "Ryuki Tachibana": [0, ["Domain Adaptation of CNN Based Acoustic Models Under Limited Resource Settings", ["Masayuki Suzuki", "Ryuki Tachibana", "Samuel Thomas", "Bhuvana Ramabhadran", "George Saon"], "https://doi.org/10.21437/Interspeech.2016-1161", 5, "interspeech", 2016]], "Samuel Thomas": [0, ["Domain Adaptation of CNN Based Acoustic Models Under Limited Resource Settings", ["Masayuki Suzuki", "Ryuki Tachibana", "Samuel Thomas", "Bhuvana Ramabhadran", "George Saon"], "https://doi.org/10.21437/Interspeech.2016-1161", 5, "interspeech", 2016], ["An Investigation on the Use of i-Vectors for Robust ASR", ["Dimitrios Dimitriadis", "Samuel Thomas", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2016-1482", 5, "interspeech", 2016], ["Multilingual Data Selection for Low Resource Speech Recognition", ["Samuel Thomas", "Kartik Audhkhasi", "Jia Cui", "Brian Kingsbury", "Bhuvana Ramabhadran"], "https://doi.org/10.21437/Interspeech.2016-598", 5, "interspeech", 2016]], "Lahiru Samarakoon": [0, ["Subspace LHUC for Fast Adaptation of Deep Neural Network Acoustic Models", ["Lahiru Samarakoon", "Khe Chai Sim"], "https://doi.org/10.21437/Interspeech.2016-1249", 5, "interspeech", 2016], ["Multi-Attribute Factorized Hidden Layer Adaptation for DNN Acoustic Models", ["Lahiru Samarakoon", "Khe Chai Sim"], "https://doi.org/10.21437/Interspeech.2016-1233", 5, "interspeech", 2016]], "Joachim Fainberg": [0, ["Improving Children's Speech Recognition Through Out-of-Domain Data Augmentation", ["Joachim Fainberg", "Peter Bell", "Mike Lincoln", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-1348", 5, "interspeech", 2016]], "Peter Bell": [0, ["Improving Children's Speech Recognition Through Out-of-Domain Data Augmentation", ["Joachim Fainberg", "Peter Bell", "Mike Lincoln", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-1348", 5, "interspeech", 2016], ["Unsupervised Adaptation of Recurrent Neural Network Language Models", ["Siva Reddy Gangireddy", "Pawel Swietojanski", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-1342", 5, "interspeech", 2016], ["Automatic Dialect Detection in Arabic Broadcast Speech", ["Ahmed M. Ali", "Najim Dehak", "Patrick Cardinal", "Sameer Khurana", "Sree Harsha Yella", "James R. Glass", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-1297", 5, "interspeech", 2016]], "Mike Lincoln": [0, ["Improving Children's Speech Recognition Through Out-of-Domain Data Augmentation", ["Joachim Fainberg", "Peter Bell", "Mike Lincoln", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-1348", 5, "interspeech", 2016]], "Florian Metze": [0, ["Virtual Machines and Containers as a Platform for Experimentation", ["Florian Metze", "Eric Riebling", "Anne S. Warlaumont", "Elika Bergelson"], "https://doi.org/10.21437/Interspeech.2016-997", 5, "interspeech", 2016], ["Experiences with Shared Resources for Research and Education in Speech and Language Processing", ["Rebecca Bates", "Eric Fosler-Lussier", "Florian Metze", "Martha Larson", "Gina-Anne Levow", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2016-1223", 5, "interspeech", 2016], ["Manipulating Word Lattices to Incorporate Human Corrections", ["Yashesh Gaur", "Florian Metze", "Jeffrey P. Bigham"], "https://doi.org/10.21437/Interspeech.2016-660", 4, "interspeech", 2016], ["Open-Domain Audio-Visual Speech Recognition: A Deep Learning Approach", ["Yajie Miao", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2016-412", 5, "interspeech", 2016]], "Eric Riebling": [0, ["Virtual Machines and Containers as a Platform for Experimentation", ["Florian Metze", "Eric Riebling", "Anne S. Warlaumont", "Elika Bergelson"], "https://doi.org/10.21437/Interspeech.2016-997", 5, "interspeech", 2016]], "Anne S. Warlaumont": [0, ["Virtual Machines and Containers as a Platform for Experimentation", ["Florian Metze", "Eric Riebling", "Anne S. Warlaumont", "Elika Bergelson"], "https://doi.org/10.21437/Interspeech.2016-997", 5, "interspeech", 2016], ["Detection of Total Syllables and Canonical Syllables in Infant Vocalizations", ["Anne S. Warlaumont", "Heather L. Ramsdell-Hudock"], "https://doi.org/10.21437/Interspeech.2016-1518", 5, "interspeech", 2016]], "Elika Bergelson": [0, ["Virtual Machines and Containers as a Platform for Experimentation", ["Florian Metze", "Eric Riebling", "Anne S. Warlaumont", "Elika Bergelson"], "https://doi.org/10.21437/Interspeech.2016-997", 5, "interspeech", 2016]], "Phil D. Green": [0, ["CloudCAST - Remote Speech Technology for Speech Professionals", ["Phil D. Green", "Ricard Marxer", "Stuart P. Cunningham", "Heidi Christensen", "Frank Rudzicz", "Maria Yancheva", "Andre Coy", "Massimiliano Malavasi", "Lorenzo Desideri", "Fabio Tamburini"], "https://doi.org/10.21437/Interspeech.2016-148", 5, "interspeech", 2016], ["Improving Generalisation to New Speakers in Spoken Dialogue State Tracking", ["Inigo Casanueva", "Thomas Hain", "Phil D. Green"], "https://doi.org/10.21437/Interspeech.2016-404", 5, "interspeech", 2016]], "Stuart P. Cunningham": [0, ["CloudCAST - Remote Speech Technology for Speech Professionals", ["Phil D. Green", "Ricard Marxer", "Stuart P. Cunningham", "Heidi Christensen", "Frank Rudzicz", "Maria Yancheva", "Andre Coy", "Massimiliano Malavasi", "Lorenzo Desideri", "Fabio Tamburini"], "https://doi.org/10.21437/Interspeech.2016-148", 5, "interspeech", 2016]], "Frank Rudzicz": [0, ["CloudCAST - Remote Speech Technology for Speech Professionals", ["Phil D. Green", "Ricard Marxer", "Stuart P. Cunningham", "Heidi Christensen", "Frank Rudzicz", "Maria Yancheva", "Andre Coy", "Massimiliano Malavasi", "Lorenzo Desideri", "Fabio Tamburini"], "https://doi.org/10.21437/Interspeech.2016-148", 5, "interspeech", 2016], ["Speech Recognition in Alzheimer's Disease and in its Assessment", ["Luke Zhou", "Kathleen C. Fraser", "Frank Rudzicz"], "https://doi.org/10.21437/Interspeech.2016-1228", 5, "interspeech", 2016]], "Maria Yancheva": [0, ["CloudCAST - Remote Speech Technology for Speech Professionals", ["Phil D. Green", "Ricard Marxer", "Stuart P. Cunningham", "Heidi Christensen", "Frank Rudzicz", "Maria Yancheva", "Andre Coy", "Massimiliano Malavasi", "Lorenzo Desideri", "Fabio Tamburini"], "https://doi.org/10.21437/Interspeech.2016-148", 5, "interspeech", 2016]], "Andre Coy": [0, ["CloudCAST - Remote Speech Technology for Speech Professionals", ["Phil D. Green", "Ricard Marxer", "Stuart P. Cunningham", "Heidi Christensen", "Frank Rudzicz", "Maria Yancheva", "Andre Coy", "Massimiliano Malavasi", "Lorenzo Desideri", "Fabio Tamburini"], "https://doi.org/10.21437/Interspeech.2016-148", 5, "interspeech", 2016]], "Massimiliano Malavasi": [0, ["CloudCAST - Remote Speech Technology for Speech Professionals", ["Phil D. Green", "Ricard Marxer", "Stuart P. Cunningham", "Heidi Christensen", "Frank Rudzicz", "Maria Yancheva", "Andre Coy", "Massimiliano Malavasi", "Lorenzo Desideri", "Fabio Tamburini"], "https://doi.org/10.21437/Interspeech.2016-148", 5, "interspeech", 2016]], "Lorenzo Desideri": [0, ["CloudCAST - Remote Speech Technology for Speech Professionals", ["Phil D. Green", "Ricard Marxer", "Stuart P. Cunningham", "Heidi Christensen", "Frank Rudzicz", "Maria Yancheva", "Andre Coy", "Massimiliano Malavasi", "Lorenzo Desideri", "Fabio Tamburini"], "https://doi.org/10.21437/Interspeech.2016-148", 5, "interspeech", 2016]], "Fabio Tamburini": [0, ["CloudCAST - Remote Speech Technology for Speech Professionals", ["Phil D. Green", "Ricard Marxer", "Stuart P. Cunningham", "Heidi Christensen", "Frank Rudzicz", "Maria Yancheva", "Andre Coy", "Massimiliano Malavasi", "Lorenzo Desideri", "Fabio Tamburini"], "https://doi.org/10.21437/Interspeech.2016-148", 5, "interspeech", 2016]], "Jeremy Christian": [0, ["webASR 2 - Improved Cloud Based Speech Technology", ["Thomas Hain", "Jeremy Christian", "Oscar Saz", "Salil Deena", "Madina Hasan", "Raymond W. M. Ng", "Rosanna Milner", "Mortaza Doulaty", "Yulan Liu"], "https://doi.org/10.21437/Interspeech.2016-700", 5, "interspeech", 2016]], "Oscar Saz": [0, ["webASR 2 - Improved Cloud Based Speech Technology", ["Thomas Hain", "Jeremy Christian", "Oscar Saz", "Salil Deena", "Madina Hasan", "Raymond W. M. Ng", "Rosanna Milner", "Mortaza Doulaty", "Yulan Liu"], "https://doi.org/10.21437/Interspeech.2016-700", 5, "interspeech", 2016], ["Error Correction in Lightly Supervised Alignment of Broadcast Subtitles", ["Julia Olcoz", "Oscar Saz", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-56", 5, "interspeech", 2016], ["Automatic Genre and Show Identification of Broadcast Media", ["Mortaza Doulaty", "Oscar Saz", "Raymond W. M. Ng", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-472", 5, "interspeech", 2016], ["Combining Feature and Model-Based Adaptation of RNNLMs for Multi-Genre Broadcast Speech Recognition", ["Salil Deena", "Madina Hasan", "Mortaza Doulaty", "Oscar Saz", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-480", 5, "interspeech", 2016]], "Salil Deena": [0, ["webASR 2 - Improved Cloud Based Speech Technology", ["Thomas Hain", "Jeremy Christian", "Oscar Saz", "Salil Deena", "Madina Hasan", "Raymond W. M. Ng", "Rosanna Milner", "Mortaza Doulaty", "Yulan Liu"], "https://doi.org/10.21437/Interspeech.2016-700", 5, "interspeech", 2016], ["Combining Feature and Model-Based Adaptation of RNNLMs for Multi-Genre Broadcast Speech Recognition", ["Salil Deena", "Madina Hasan", "Mortaza Doulaty", "Oscar Saz", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-480", 5, "interspeech", 2016]], "Madina Hasan": [0, ["webASR 2 - Improved Cloud Based Speech Technology", ["Thomas Hain", "Jeremy Christian", "Oscar Saz", "Salil Deena", "Madina Hasan", "Raymond W. M. Ng", "Rosanna Milner", "Mortaza Doulaty", "Yulan Liu"], "https://doi.org/10.21437/Interspeech.2016-700", 5, "interspeech", 2016], ["Combining Feature and Model-Based Adaptation of RNNLMs for Multi-Genre Broadcast Speech Recognition", ["Salil Deena", "Madina Hasan", "Mortaza Doulaty", "Oscar Saz", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-480", 5, "interspeech", 2016], ["The Sheffield Wargame Corpus - Day Two and Day Three", ["Yulan Liu", "Charles Fox", "Madina Hasan", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-98", 5, "interspeech", 2016]], "Raymond W. M. Ng": [0, ["webASR 2 - Improved Cloud Based Speech Technology", ["Thomas Hain", "Jeremy Christian", "Oscar Saz", "Salil Deena", "Madina Hasan", "Raymond W. M. Ng", "Rosanna Milner", "Mortaza Doulaty", "Yulan Liu"], "https://doi.org/10.21437/Interspeech.2016-700", 5, "interspeech", 2016], ["Automatic Genre and Show Identification of Broadcast Media", ["Mortaza Doulaty", "Oscar Saz", "Raymond W. M. Ng", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-472", 5, "interspeech", 2016], ["Combining Weak Tokenisers for Phonotactic Language Recognition in a Resource-Constrained Setting", ["Raymond W. M. Ng", "Bhusan Chettri", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-630", 5, "interspeech", 2016]], "Rosanna Milner": [0, ["webASR 2 - Improved Cloud Based Speech Technology", ["Thomas Hain", "Jeremy Christian", "Oscar Saz", "Salil Deena", "Madina Hasan", "Raymond W. M. Ng", "Rosanna Milner", "Mortaza Doulaty", "Yulan Liu"], "https://doi.org/10.21437/Interspeech.2016-700", 5, "interspeech", 2016], ["DNN-Based Speaker Clustering for Speaker Diarisation", ["Rosanna Milner", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-126", 5, "interspeech", 2016]], "Mortaza Doulaty": [0, ["webASR 2 - Improved Cloud Based Speech Technology", ["Thomas Hain", "Jeremy Christian", "Oscar Saz", "Salil Deena", "Madina Hasan", "Raymond W. M. Ng", "Rosanna Milner", "Mortaza Doulaty", "Yulan Liu"], "https://doi.org/10.21437/Interspeech.2016-700", 5, "interspeech", 2016], ["Automatic Genre and Show Identification of Broadcast Media", ["Mortaza Doulaty", "Oscar Saz", "Raymond W. M. Ng", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-472", 5, "interspeech", 2016], ["Combining Feature and Model-Based Adaptation of RNNLMs for Multi-Genre Broadcast Speech Recognition", ["Salil Deena", "Madina Hasan", "Mortaza Doulaty", "Oscar Saz", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-480", 5, "interspeech", 2016]], "Yulan Liu": [0, ["webASR 2 - Improved Cloud Based Speech Technology", ["Thomas Hain", "Jeremy Christian", "Oscar Saz", "Salil Deena", "Madina Hasan", "Raymond W. M. Ng", "Rosanna Milner", "Mortaza Doulaty", "Yulan Liu"], "https://doi.org/10.21437/Interspeech.2016-700", 5, "interspeech", 2016], ["The Sheffield Wargame Corpus - Day Two and Day Three", ["Yulan Liu", "Charles Fox", "Madina Hasan", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-98", 5, "interspeech", 2016]], "Andrew R. Plummer": [0, ["Sharing Speech Synthesis Software for Research and Education Within Low-Tech and Low-Resource Communities", ["Andrew R. Plummer", "Mary E. Beckman"], "https://doi.org/10.21437/Interspeech.2016-1540", 5, "interspeech", 2016]], "Mary E. Beckman": [0, ["Sharing Speech Synthesis Software for Research and Education Within Low-Tech and Low-Resource Communities", ["Andrew R. Plummer", "Mary E. Beckman"], "https://doi.org/10.21437/Interspeech.2016-1540", 5, "interspeech", 2016]], "Ronald L. Sprouse": [0, ["The Berkeley Phonetics Machine", ["Ronald L. Sprouse", "Keith Johnson"], "https://doi.org/10.21437/Interspeech.2016-524", 4, "interspeech", 2016]], "Keith Johnson": [0, ["The Berkeley Phonetics Machine", ["Ronald L. Sprouse", "Keith Johnson"], "https://doi.org/10.21437/Interspeech.2016-524", 4, "interspeech", 2016]], "Rebecca Bates": [0, ["Experiences with Shared Resources for Research and Education in Speech and Language Processing", ["Rebecca Bates", "Eric Fosler-Lussier", "Florian Metze", "Martha Larson", "Gina-Anne Levow", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2016-1223", 5, "interspeech", 2016]], "Eric Fosler-Lussier": [0, ["Experiences with Shared Resources for Research and Education in Speech and Language Processing", ["Rebecca Bates", "Eric Fosler-Lussier", "Florian Metze", "Martha Larson", "Gina-Anne Levow", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2016-1223", 5, "interspeech", 2016], ["A WFST Framework for Single-Pass Multi-Stream Decoding", ["Sirui Xu", "Eric Fosler-Lussier"], "https://doi.org/10.21437/Interspeech.2016-1307", 5, "interspeech", 2016]], "Martha Larson": [0, ["Experiences with Shared Resources for Research and Education in Speech and Language Processing", ["Rebecca Bates", "Eric Fosler-Lussier", "Florian Metze", "Martha Larson", "Gina-Anne Levow", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2016-1223", 5, "interspeech", 2016]], "Gina-Anne Levow": [0, ["Experiences with Shared Resources for Research and Education in Speech and Language Processing", ["Rebecca Bates", "Eric Fosler-Lussier", "Florian Metze", "Martha Larson", "Gina-Anne Levow", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2016-1223", 5, "interspeech", 2016]], "Ling-Hui Chen": [0, ["The Voice Conversion Challenge 2016", ["Tomoki Toda", "Ling-Hui Chen", "Daisuke Saito", "Fernando Villavicencio", "Mirjam Wester", "Zhizheng Wu", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1066", 5, "interspeech", 2016], ["The USTC System for Voice Conversion Challenge 2016: Neural Network Based Approaches for Spectrum, Aperiodicity and F0 Conversion", ["Ling-Hui Chen", "Li-Juan Liu", "Zhen-Hua Ling", "Yuan Jiang", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-456", 5, "interspeech", 2016]], "Fernando Villavicencio": [0, ["The Voice Conversion Challenge 2016", ["Tomoki Toda", "Ling-Hui Chen", "Daisuke Saito", "Fernando Villavicencio", "Mirjam Wester", "Zhizheng Wu", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1066", 5, "interspeech", 2016], ["Applying Spectral Normalisation and Efficient Envelope Estimation and Statistical Transformation for the Voice Conversion Challenge 2016", ["Fernando Villavicencio", "Junichi Yamagishi", "Jordi Bonada", "Felipe Espic"], "https://doi.org/10.21437/Interspeech.2016-305", 5, "interspeech", 2016]], "Zhizheng Wu": [1.3821066166541662e-10, ["The Voice Conversion Challenge 2016", ["Tomoki Toda", "Ling-Hui Chen", "Daisuke Saito", "Fernando Villavicencio", "Mirjam Wester", "Zhizheng Wu", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1066", 5, "interspeech", 2016], ["Analysis of the Voice Conversion Challenge 2016 Evaluation Results", ["Mirjam Wester", "Zhizheng Wu", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2016-1331", 5, "interspeech", 2016], ["An Investigation of Spoofing Speech Detection Under Additive Noise and Reverberant Conditions", ["Xiaohai Tian", "Zhizheng Wu", "Xiong Xiao", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-743", 5, "interspeech", 2016], ["Waveform Generation Based on Signal Reshaping for Statistical Parametric Speech Synthesis", ["Felipe Espic", "Cassia Valentini-Botinhao", "Zhizheng Wu", "Simon King"], "https://doi.org/10.21437/Interspeech.2016-487", 5, "interspeech", 2016], ["A Template-Based Approach for Speech Synthesis Intonation Generation Using LSTMs", ["Srikanth Ronanki", "Gustav Eje Henter", "Zhizheng Wu", "Simon King"], "https://doi.org/10.21437/Interspeech.2016-96", 5, "interspeech", 2016], ["GlottDNN - A Full-Band Glottal Vocoder for Statistical Parametric Speech Synthesis", ["Manu Airaksinen", "Bajibabu Bollepalli", "Lauri Juvela", "Zhizheng Wu", "Simon King", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-342", 5, "interspeech", 2016]], "Li-Juan Liu": [0, ["The USTC System for Voice Conversion Challenge 2016: Neural Network Based Approaches for Spectrum, Aperiodicity and F0 Conversion", ["Ling-Hui Chen", "Li-Juan Liu", "Zhen-Hua Ling", "Yuan Jiang", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-456", 5, "interspeech", 2016]], "Yuan Jiang": [0, ["The USTC System for Voice Conversion Challenge 2016: Neural Network Based Approaches for Spectrum, Aperiodicity and F0 Conversion", ["Ling-Hui Chen", "Li-Juan Liu", "Zhen-Hua Ling", "Yuan Jiang", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-456", 5, "interspeech", 2016]], "Seyed Hamidreza Mohammadi": [0, ["A Voice Conversion Mapping Function Based on a Stacked Joint-Autoencoder", ["Seyed Hamidreza Mohammadi", "Alexander Kain"], "https://doi.org/10.21437/Interspeech.2016-1437", 5, "interspeech", 2016]], "Alexander Kain": [0, ["A Voice Conversion Mapping Function Based on a Stacked Joint-Autoencoder", ["Seyed Hamidreza Mohammadi", "Alexander Kain"], "https://doi.org/10.21437/Interspeech.2016-1437", 5, "interspeech", 2016]], "Yi-Chiao Wu": [6.146249789229074e-14, ["Locally Linear Embedding for Exemplar-Based Spectral Conversion", ["Yi-Chiao Wu", "Hsin-Te Hwang", "Chin-Cheng Hsu", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2016-567", 5, "interspeech", 2016]], "Hsin-Te Hwang": [0.0003545229192241095, ["Locally Linear Embedding for Exemplar-Based Spectral Conversion", ["Yi-Chiao Wu", "Hsin-Te Hwang", "Chin-Cheng Hsu", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2016-567", 5, "interspeech", 2016]], "Chin-Cheng Hsu": [0, ["Locally Linear Embedding for Exemplar-Based Spectral Conversion", ["Yi-Chiao Wu", "Hsin-Te Hwang", "Chin-Cheng Hsu", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2016-567", 5, "interspeech", 2016]], "Yu Tsao": [0, ["Locally Linear Embedding for Exemplar-Based Spectral Conversion", ["Yi-Chiao Wu", "Hsin-Te Hwang", "Chin-Cheng Hsu", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2016-567", 5, "interspeech", 2016], ["Minimization of Regression and Ranking Losses with Shallow Neural Networks on Automatic Sincerity Evaluation", ["Hung-Shin Lee", "Yu Tsao", "Chi-Chun Lee", "Hsin-Min Wang", "Wei-Cheng Lin", "Wei-Chen Chen", "Shan-Wen Hsiao", "Shyh-Kang Jeng"], "https://doi.org/10.21437/Interspeech.2016-756", 5, "interspeech", 2016], ["Pair-Wise Distance Metric Learning of Neural Network Model for Spoken Language Identification", ["Xugang Lu", "Peng Shen", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-722", 5, "interspeech", 2016], ["SNR-Aware Convolutional Neural Network Modeling for Speech Enhancement", ["Szu-Wei Fu", "Yu Tsao", "Xugang Lu"], "https://doi.org/10.21437/Interspeech.2016-211", 5, "interspeech", 2016]], "Felipe Espic": [0, ["Applying Spectral Normalisation and Efficient Envelope Estimation and Statistical Transformation for the Voice Conversion Challenge 2016", ["Fernando Villavicencio", "Junichi Yamagishi", "Jordi Bonada", "Felipe Espic"], "https://doi.org/10.21437/Interspeech.2016-305", 5, "interspeech", 2016], ["Waveform Generation Based on Signal Reshaping for Statistical Parametric Speech Synthesis", ["Felipe Espic", "Cassia Valentini-Botinhao", "Zhizheng Wu", "Simon King"], "https://doi.org/10.21437/Interspeech.2016-487", 5, "interspeech", 2016]], "Agustin Alonso": [0, ["ML Parameter Generation with a Reformulated MGE Training Criterion - Participation in the Voice Conversion Challenge 2016", ["Daniel Erro", "Agustin Alonso", "Luis Serrano", "David Tavarez", "Igor Odriozola", "Xabier Sarasola", "Eder del Blanco", "Jon Sanchez", "Ibon Saratxaga", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2016-219", 5, "interspeech", 2016]], "Luis Serrano": [0, ["ML Parameter Generation with a Reformulated MGE Training Criterion - Participation in the Voice Conversion Challenge 2016", ["Daniel Erro", "Agustin Alonso", "Luis Serrano", "David Tavarez", "Igor Odriozola", "Xabier Sarasola", "Eder del Blanco", "Jon Sanchez", "Ibon Saratxaga", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2016-219", 5, "interspeech", 2016]], "David Tavarez": [0, ["ML Parameter Generation with a Reformulated MGE Training Criterion - Participation in the Voice Conversion Challenge 2016", ["Daniel Erro", "Agustin Alonso", "Luis Serrano", "David Tavarez", "Igor Odriozola", "Xabier Sarasola", "Eder del Blanco", "Jon Sanchez", "Ibon Saratxaga", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2016-219", 5, "interspeech", 2016]], "Igor Odriozola": [0, ["ML Parameter Generation with a Reformulated MGE Training Criterion - Participation in the Voice Conversion Challenge 2016", ["Daniel Erro", "Agustin Alonso", "Luis Serrano", "David Tavarez", "Igor Odriozola", "Xabier Sarasola", "Eder del Blanco", "Jon Sanchez", "Ibon Saratxaga", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2016-219", 5, "interspeech", 2016]], "Jon Sanchez": [0, ["ML Parameter Generation with a Reformulated MGE Training Criterion - Participation in the Voice Conversion Challenge 2016", ["Daniel Erro", "Agustin Alonso", "Luis Serrano", "David Tavarez", "Igor Odriozola", "Xabier Sarasola", "Eder del Blanco", "Jon Sanchez", "Ibon Saratxaga", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2016-219", 5, "interspeech", 2016]], "Ibon Saratxaga": [0, ["ML Parameter Generation with a Reformulated MGE Training Criterion - Participation in the Voice Conversion Challenge 2016", ["Daniel Erro", "Agustin Alonso", "Luis Serrano", "David Tavarez", "Igor Odriozola", "Xabier Sarasola", "Eder del Blanco", "Jon Sanchez", "Ibon Saratxaga", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2016-219", 5, "interspeech", 2016]], "Kazuhiro Kobayashi": [0, ["The NU-NAIST Voice Conversion System for the Voice Conversion Challenge 2016", ["Kazuhiro Kobayashi", "Shinnosuke Takamichi", "Satoshi Nakamura", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2016-970", 5, "interspeech", 2016]], "Shinnosuke Takamichi": [0, ["The NU-NAIST Voice Conversion System for the Voice Conversion Challenge 2016", ["Kazuhiro Kobayashi", "Shinnosuke Takamichi", "Satoshi Nakamura", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2016-970", 5, "interspeech", 2016]], "Maury Lander-Portnoy": [0, ["Release from Energetic Masking Caused by Repeated Patterns of Glimpsing Windows", ["Maury Lander-Portnoy"], "https://doi.org/10.21437/Interspeech.2016-1571", 5, "interspeech", 2016]], "Bobby Gibbs II": [0, ["Glimpsing Predictions for Natural and Vocoded Sentence Intelligibility During Modulation Masking: Effect of the Glimpse Cutoff Criterion", ["Bobby Gibbs II", "Daniel Fogerty"], "https://doi.org/10.21437/Interspeech.2016-1587", 5, "interspeech", 2016]], "Li Xu": [0, ["Temporal Envelopes in Sine-Wave Speech Recognition", ["Li Xu"], "https://doi.org/10.21437/Interspeech.2016-171", 5, "interspeech", 2016], ["Tone Classification in Mandarin Chinese Using Convolutional Neural Networks", ["Charles Chen", "Razvan C. Bunescu", "Li Xu", "Chang Liu"], "https://doi.org/10.21437/Interspeech.2016-528", 5, "interspeech", 2016]], "Jing Liu": [0, ["Understanding Periodically Interrupted Mandarin Speech", ["Jing Liu", "Rosanna H. N. Tong", "Fei Chen"], "https://doi.org/10.21437/Interspeech.2016-176", 5, "interspeech", 2016]], "Rosanna H. N. Tong": [0, ["Understanding Periodically Interrupted Mandarin Speech", ["Jing Liu", "Rosanna H. N. Tong", "Fei Chen"], "https://doi.org/10.21437/Interspeech.2016-176", 5, "interspeech", 2016]], "Nao Hodoshima": [0, ["Effects of Urgent Speech and Preceding Sounds on Speech Intelligibility in Noisy and Reverberant Environments", ["Nao Hodoshima"], "https://doi.org/10.21437/Interspeech.2016-1618", 4, "interspeech", 2016]], "Hong Yu": [0.00414914614520967, ["Integrated Spoofing Countermeasures and Automatic Speaker Verification: An Evaluation on ASVspoof 2015", ["Md. Sahidullah", "Hector Delgado", "Massimiliano Todisco", "Hong Yu", "Tomi Kinnunen", "Nicholas W. D. Evans", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1280", 5, "interspeech", 2016]], "Pavel Korshunov": [0, ["Cross-Database Evaluation of Audio-Based Spoofing Detection Systems", ["Pavel Korshunov", "Sebastien Marcel"], "https://doi.org/10.21437/Interspeech.2016-1326", 5, "interspeech", 2016]], "Sebastien Marcel": [0, ["Cross-Database Evaluation of Audio-Based Spoofing Detection Systems", ["Pavel Korshunov", "Sebastien Marcel"], "https://doi.org/10.21437/Interspeech.2016-1326", 5, "interspeech", 2016]], "Phu Ngoc Le": [0, ["Investigation of Sub-Band Discriminative Information Between Spoofed and Genuine Speech", ["Kaavya Sriskandaraja", "Vidhyasaharan Sethu", "Phu Ngoc Le", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2016-844", 5, "interspeech", 2016]], "Xiaohai Tian": [0, ["An Investigation of Spoofing Speech Detection Under Additive Noise and Reverberant Conditions", ["Xiaohai Tian", "Zhizheng Wu", "Xiong Xiao", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-743", 5, "interspeech", 2016]], "Rosa Gonzalez Hautamaki": [0, ["Robust Speaker Recognition with Combined Use of Acoustic and Throat Microphone Speech", ["Md. Sahidullah", "Rosa Gonzalez Hautamaki", "Dennis Alexander Lehmann Thomsen", "Tomi Kinnunen", "Zheng-Hua Tan", "Ville Hautamaki", "Robert Parts", "Martti Pitkanen"], "https://doi.org/10.21437/Interspeech.2016-1153", 5, "interspeech", 2016]], "Dennis Alexander Lehmann Thomsen": [0, ["Robust Speaker Recognition with Combined Use of Acoustic and Throat Microphone Speech", ["Md. Sahidullah", "Rosa Gonzalez Hautamaki", "Dennis Alexander Lehmann Thomsen", "Tomi Kinnunen", "Zheng-Hua Tan", "Ville Hautamaki", "Robert Parts", "Martti Pitkanen"], "https://doi.org/10.21437/Interspeech.2016-1153", 5, "interspeech", 2016], ["Speaker-Dependent Dictionary-Based Speech Enhancement for Text-Dependent Speaker Verification", ["Nicolai Baek Thomsen", "Dennis Alexander Lehmann Thomsen", "Zheng-Hua Tan", "Borge Lindberg", "Soren Holdt Jensen"], "https://doi.org/10.21437/Interspeech.2016-763", 5, "interspeech", 2016], ["HAPPY Team Entry to NIST OpenSAD Challenge: A Fusion of Short-Term Unsupervised and Segment i-Vector Based Speech Activity Detectors", ["Tomi Kinnunen", "Alexey Sholokhov", "Elie el Khoury", "Dennis Alexander Lehmann Thomsen", "Md. Sahidullah", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1281", 5, "interspeech", 2016]], "Robert Parts": [0, ["Robust Speaker Recognition with Combined Use of Acoustic and Throat Microphone Speech", ["Md. Sahidullah", "Rosa Gonzalez Hautamaki", "Dennis Alexander Lehmann Thomsen", "Tomi Kinnunen", "Zheng-Hua Tan", "Ville Hautamaki", "Robert Parts", "Martti Pitkanen"], "https://doi.org/10.21437/Interspeech.2016-1153", 5, "interspeech", 2016]], "Martti Pitkanen": [0, ["Robust Speaker Recognition with Combined Use of Acoustic and Throat Microphone Speech", ["Md. Sahidullah", "Rosa Gonzalez Hautamaki", "Dennis Alexander Lehmann Thomsen", "Tomi Kinnunen", "Zheng-Hua Tan", "Ville Hautamaki", "Robert Parts", "Martti Pitkanen"], "https://doi.org/10.21437/Interspeech.2016-1153", 5, "interspeech", 2016]], "Johannes Fischer": [0, ["Joint Enhancement and Coding of Speech by Incorporating Wiener Filtering in a CELP Codec", ["Johannes Fischer", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2016-245", 5, "interspeech", 2016], ["Blind Recovery of Perceptual Models in Distributed Speech and Audio Coding", ["Tom Backstrom", "Florin Ghido", "Johannes Fischer"], "https://doi.org/10.21437/Interspeech.2016-27", 5, "interspeech", 2016]], "Hong Liu": [0, ["Multi-Channel Linear Prediction Based on Binaural Coherence for Speech Dereverberation", ["Hong Liu", "Xiuling Wang", "Miao Sun", "Cheng Pang"], "https://doi.org/10.21437/Interspeech.2016-729", 5, "interspeech", 2016]], "Xiuling Wang": [2.520640779435368e-10, ["Multi-Channel Linear Prediction Based on Binaural Coherence for Speech Dereverberation", ["Hong Liu", "Xiuling Wang", "Miao Sun", "Cheng Pang"], "https://doi.org/10.21437/Interspeech.2016-729", 5, "interspeech", 2016]], "Miao Sun": [0.003910996369086206, ["Multi-Channel Linear Prediction Based on Binaural Coherence for Speech Dereverberation", ["Hong Liu", "Xiuling Wang", "Miao Sun", "Cheng Pang"], "https://doi.org/10.21437/Interspeech.2016-729", 5, "interspeech", 2016]], "Cheng Pang": [0, ["Multi-Channel Linear Prediction Based on Binaural Coherence for Speech Dereverberation", ["Hong Liu", "Xiuling Wang", "Miao Sun", "Cheng Pang"], "https://doi.org/10.21437/Interspeech.2016-729", 5, "interspeech", 2016]], "Martin Blass": [0, ["Single-Channel Speech Enhancement Using Double Spectrum", ["Martin Blass", "Pejman Mowlaee", "W. Bastiaan Kleijn"], "https://doi.org/10.21437/Interspeech.2016-234", 5, "interspeech", 2016]], "Pejman Mowlaee": [0, ["Single-Channel Speech Enhancement Using Double Spectrum", ["Martin Blass", "Pejman Mowlaee", "W. Bastiaan Kleijn"], "https://doi.org/10.21437/Interspeech.2016-234", 5, "interspeech", 2016], ["Phase-Aware Signal Processing for Automatic Speech Recognition", ["Johannes Fahringer", "Tobias Schrank", "Johannes Stahl", "Pejman Mowlaee", "Franz Pernkopf"], "https://doi.org/10.21437/Interspeech.2016-823", 5, "interspeech", 2016]], "W. Bastiaan Kleijn": [0, ["Single-Channel Speech Enhancement Using Double Spectrum", ["Martin Blass", "Pejman Mowlaee", "W. Bastiaan Kleijn"], "https://doi.org/10.21437/Interspeech.2016-234", 5, "interspeech", 2016]], "Lukas Drude": [0, ["On the Appropriateness of Complex-Valued Neural Networks for Speech Enhancement", ["Lukas Drude", "Bhiksha Raj", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2016-300", 5, "interspeech", 2016]], "Bhiksha Raj": [0, ["On the Appropriateness of Complex-Valued Neural Networks for Speech Enhancement", ["Lukas Drude", "Bhiksha Raj", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2016-300", 5, "interspeech", 2016]], "Reinhold Haeb-Umbach": [0, ["On the Appropriateness of Complex-Valued Neural Networks for Speech Enhancement", ["Lukas Drude", "Bhiksha Raj", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2016-300", 5, "interspeech", 2016], ["A priori SNR Estimation Using a Generalized Decision Directed Approach", ["Aleksej Chinaev", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2016-474", 5, "interspeech", 2016]], "Steffen Zeiler": [0, ["Introducing the Turbo-Twin-HMM for Audio-Visual Speech Enhancement", ["Steffen Zeiler", "Hendrik Meutzner", "Ahmed Hussen Abdelaziz", "Dorothea Kolossa"], "https://doi.org/10.21437/Interspeech.2016-350", 5, "interspeech", 2016], ["Dynamic Stream Weighting for Turbo-Decoding-Based Audiovisual ASR", ["Sebastian Gergen", "Steffen Zeiler", "Ahmed Hussen Abdelaziz", "Robert M. Nickel", "Dorothea Kolossa"], "https://doi.org/10.21437/Interspeech.2016-166", 5, "interspeech", 2016]], "Constantin Spille": [0, ["Assessing Speech Quality in Speech-Aware Hearing Aids Based on Phoneme Posteriorgrams", ["Constantin Spille", "Hendrik Kayser", "Hynek Hermansky", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2016-1318", 5, "interspeech", 2016]], "Hendrik Kayser": [0, ["Assessing Speech Quality in Speech-Aware Hearing Aids Based on Phoneme Posteriorgrams", ["Constantin Spille", "Hendrik Kayser", "Hynek Hermansky", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2016-1318", 5, "interspeech", 2016], ["Probabilistic Spatial Filter Estimation for Signal Enhancement in Multi-Channel Automatic Speech Recognition", ["Hendrik Kayser", "Niko Moritz", "Jorn Anemuller"], "https://doi.org/10.21437/Interspeech.2016-1340", 5, "interspeech", 2016]], "Hynek Hermansky": [0, ["Assessing Speech Quality in Speech-Aware Hearing Aids Based on Phoneme Posteriorgrams", ["Constantin Spille", "Hendrik Kayser", "Hynek Hermansky", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2016-1318", 5, "interspeech", 2016], ["A Framework for Practical Multistream ASR", ["Sri Harish Reddy Mallidi", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2016-619", 5, "interspeech", 2016]], "Dhananjaya N. Gowda": [0, ["Time-Varying Quasi-Closed-Phase Weighted Linear Prediction Analysis of Speech for Accurate Formant Detection and Tracking", ["Dhananjaya N. Gowda", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-153", 5, "interspeech", 2016]], "Chandra Sekhar Seelamantula": [0, ["Phase-Encoded Speech Spectrograms", ["Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2016-1600", 5, "interspeech", 2016], ["Reverberation-Robust One-Bit TDOA Based Moving Source Localization for Automatic Camera Steering", ["Sundar Harshavardhan", "Gokul Deepak Manavalan", "T. V. Sreenivas", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2016-575", 5, "interspeech", 2016], ["A Novel Risk-Estimation-Theoretic Framework for Speech Enhancement in Nonstationary and Non-Gaussian Noise Conditions", ["Jishnu Sadasivan", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2016-151", 5, "interspeech", 2016]], "Peter Birkholz": [0, ["Towards Minimally Invasive Velar State Detection in Normal and Silent Speech", ["Peter Birkholz", "Petko Bakardjiev", "Steffen Kurbis", "Rico Petrick"], "https://doi.org/10.21437/Interspeech.2016-771", 5, "interspeech", 2016], ["Silent-Speech Command Word Recognition Using Electro-Optical Stomatography", ["Simon Stone", "Peter Birkholz"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2005.html", 2, "interspeech", 2016]], "Petko Bakardjiev": [0, ["Towards Minimally Invasive Velar State Detection in Normal and Silent Speech", ["Peter Birkholz", "Petko Bakardjiev", "Steffen Kurbis", "Rico Petrick"], "https://doi.org/10.21437/Interspeech.2016-771", 5, "interspeech", 2016]], "Steffen Kurbis": [0, ["Towards Minimally Invasive Velar State Detection in Normal and Silent Speech", ["Peter Birkholz", "Petko Bakardjiev", "Steffen Kurbis", "Rico Petrick"], "https://doi.org/10.21437/Interspeech.2016-771", 5, "interspeech", 2016]], "Rico Petrick": [0, ["Towards Minimally Invasive Velar State Detection in Normal and Silent Speech", ["Peter Birkholz", "Petko Bakardjiev", "Steffen Kurbis", "Rico Petrick"], "https://doi.org/10.21437/Interspeech.2016-771", 5, "interspeech", 2016]], "Jianshu Zhang": [0, ["RNN-BLSTM Based Multi-Pitch Estimation", ["Jianshu Zhang", "Jian Tang", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-117", 5, "interspeech", 2016]], "Jian Tang": [0, ["RNN-BLSTM Based Multi-Pitch Estimation", ["Jianshu Zhang", "Jian Tang", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-117", 5, "interspeech", 2016], ["Future Context Attention for Unidirectional LSTM Based Acoustic Model", ["Jian Tang", "Shiliang Zhang", "Si Wei", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-185", 5, "interspeech", 2016]], "Masanori Morise": [0, ["TUSK: A Framework for Overviewing the Performance of F0 Estimators", ["Masanori Morise", "Hideki Kawahara"], "https://doi.org/10.21437/Interspeech.2016-140", 5, "interspeech", 2016]], "Pradeep Rengaswamy": [0, ["A Robust Non-Parametric and Filtering Based Approach for Glottal Closure Instant Detection", ["Pradeep Rengaswamy", "Gurunath Reddy M.", "K. Sreenivasa Rao", "Pallab Dasgupta"], "https://doi.org/10.21437/Interspeech.2016-369", 5, "interspeech", 2016]], "Gurunath Reddy M.": [0, ["A Robust Non-Parametric and Filtering Based Approach for Glottal Closure Instant Detection", ["Pradeep Rengaswamy", "Gurunath Reddy M.", "K. Sreenivasa Rao", "Pallab Dasgupta"], "https://doi.org/10.21437/Interspeech.2016-369", 5, "interspeech", 2016], ["Enhanced Harmonic Content and Vocal Note Based Predominant Melody Extraction from Vocal Polyphonic Music Signals", ["Gurunath Reddy M.", "K. Sreenivasa Rao"], "https://doi.org/10.21437/Interspeech.2016-856", 5, "interspeech", 2016]], "K. Sreenivasa Rao": [0, ["A Robust Non-Parametric and Filtering Based Approach for Glottal Closure Instant Detection", ["Pradeep Rengaswamy", "Gurunath Reddy M.", "K. Sreenivasa Rao", "Pallab Dasgupta"], "https://doi.org/10.21437/Interspeech.2016-369", 5, "interspeech", 2016], ["Enhanced Harmonic Content and Vocal Note Based Predominant Melody Extraction from Vocal Polyphonic Music Signals", ["Gurunath Reddy M.", "K. Sreenivasa Rao"], "https://doi.org/10.21437/Interspeech.2016-856", 5, "interspeech", 2016]], "Pallab Dasgupta": [0, ["A Robust Non-Parametric and Filtering Based Approach for Glottal Closure Instant Detection", ["Pradeep Rengaswamy", "Gurunath Reddy M.", "K. Sreenivasa Rao", "Pallab Dasgupta"], "https://doi.org/10.21437/Interspeech.2016-369", 5, "interspeech", 2016]], "Rahim Saeidi": [0, ["Analysis of Face Mask Effect on Speaker Recognition", ["Rahim Saeidi", "Ilkka Huhtakallio", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-518", 5, "interspeech", 2016]], "Ilkka Huhtakallio": [0, ["Analysis of Face Mask Effect on Speaker Recognition", ["Rahim Saeidi", "Ilkka Huhtakallio", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-518", 5, "interspeech", 2016]], "Elliot Singer": [0, ["Data Selection for Within-Class Covariance Estimation", ["Elliot Singer", "Tyler Campbell", "Douglas A. Reynolds"], "https://doi.org/10.21437/Interspeech.2016-1282", 5, "interspeech", 2016], ["Results of The 2015 NIST Language Recognition Evaluation", ["Hui Zhao", "Desire Banse", "George R. Doddington", "Craig S. Greenberg", "Jaime Hernandez-Cordero", "John M. Howard", "Lisa P. Mason", "Alvin F. Martin", "Douglas A. Reynolds", "Elliot Singer", "Audrey Tong"], "https://doi.org/10.21437/Interspeech.2016-169", 5, "interspeech", 2016]], "Tyler Campbell": [0, ["Data Selection for Within-Class Covariance Estimation", ["Elliot Singer", "Tyler Campbell", "Douglas A. Reynolds"], "https://doi.org/10.21437/Interspeech.2016-1282", 5, "interspeech", 2016]], "Douglas A. Reynolds": [0, ["Data Selection for Within-Class Covariance Estimation", ["Elliot Singer", "Tyler Campbell", "Douglas A. Reynolds"], "https://doi.org/10.21437/Interspeech.2016-1282", 5, "interspeech", 2016], ["Speaker Recognition Using Real vs Synthetic Parallel Data for DNN Channel Compensation", ["Fred Richardson", "Michael Brandstein", "Jennifer Melot", "Douglas A. Reynolds"], "https://doi.org/10.21437/Interspeech.2016-544", 5, "interspeech", 2016], ["Results of The 2015 NIST Language Recognition Evaluation", ["Hui Zhao", "Desire Banse", "George R. Doddington", "Craig S. Greenberg", "Jaime Hernandez-Cordero", "John M. Howard", "Lisa P. Mason", "Alvin F. Martin", "Douglas A. Reynolds", "Elliot Singer", "Audrey Tong"], "https://doi.org/10.21437/Interspeech.2016-169", 5, "interspeech", 2016]], "Marc Ferras": [0, ["Inter-Task System Fusion for Speaker Recognition", ["Marc Ferras", "Srikanth R. Madikeri", "Subhadeep Dey", "Petr Motlicek", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-1179", 5, "interspeech", 2016]], "Srikanth R. Madikeri": [0, ["Inter-Task System Fusion for Speaker Recognition", ["Marc Ferras", "Srikanth R. Madikeri", "Subhadeep Dey", "Petr Motlicek", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-1179", 5, "interspeech", 2016], ["Two-Pass IB Based Speaker Diarization System Using Meeting-Specific ANN Based Features", ["Nauman Dawalatabad", "Srikanth R. Madikeri", "C. Chandra Sekhar", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2016-714", 5, "interspeech", 2016]], "Subhadeep Dey": [0, ["Inter-Task System Fusion for Speaker Recognition", ["Marc Ferras", "Srikanth R. Madikeri", "Subhadeep Dey", "Petr Motlicek", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-1179", 5, "interspeech", 2016]], "Petr Motlicek": [0, ["Inter-Task System Fusion for Speaker Recognition", ["Marc Ferras", "Srikanth R. Madikeri", "Subhadeep Dey", "Petr Motlicek", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-1179", 5, "interspeech", 2016], ["Idlak Tangle: An Open Source Kaldi Based Parametric Speech Synthesiser Based on DNN", ["Blaise Potard", "Matthew P. Aylett", "David A. Baude", "Petr Motlicek"], "https://doi.org/10.21437/Interspeech.2016-1188", 5, "interspeech", 2016]], "Zhenchun Lei": [0, ["Mahalanobis Metric Scoring Learned from Weighted Pairwise Constraints in I-Vector Speaker Recognition System", ["Zhenchun Lei", "Yanhong Wan", "Jian Luo", "Yingen Yang"], "https://doi.org/10.21437/Interspeech.2016-1071", 5, "interspeech", 2016]], "Yanhong Wan": [0, ["Mahalanobis Metric Scoring Learned from Weighted Pairwise Constraints in I-Vector Speaker Recognition System", ["Zhenchun Lei", "Yanhong Wan", "Jian Luo", "Yingen Yang"], "https://doi.org/10.21437/Interspeech.2016-1071", 5, "interspeech", 2016]], "Jian Luo": [0, ["Mahalanobis Metric Scoring Learned from Weighted Pairwise Constraints in I-Vector Speaker Recognition System", ["Zhenchun Lei", "Yanhong Wan", "Jian Luo", "Yingen Yang"], "https://doi.org/10.21437/Interspeech.2016-1071", 5, "interspeech", 2016]], "Yingen Yang": [7.710366105584399e-07, ["Mahalanobis Metric Scoring Learned from Weighted Pairwise Constraints in I-Vector Speaker Recognition System", ["Zhenchun Lei", "Yanhong Wan", "Jian Luo", "Yingen Yang"], "https://doi.org/10.21437/Interspeech.2016-1071", 5, "interspeech", 2016]], "Meet H. Soni": [0, ["Novel Subband Autoencoder Features for Detection of Spoofed Speech", ["Meet H. Soni", "Tanvina B. Patel", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2016-668", 5, "interspeech", 2016], ["Novel Subband Autoencoder Features for Non-Intrusive Quality Assessment of Noise Suppressed Speech", ["Meet H. Soni", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2016-693", 5, "interspeech", 2016]], "Borge Lindberg": [0, ["Speaker-Dependent Dictionary-Based Speech Enhancement for Text-Dependent Speaker Verification", ["Nicolai Baek Thomsen", "Dennis Alexander Lehmann Thomsen", "Zheng-Hua Tan", "Borge Lindberg", "Soren Holdt Jensen"], "https://doi.org/10.21437/Interspeech.2016-763", 5, "interspeech", 2016]], "Soren Holdt Jensen": [0, ["Speaker-Dependent Dictionary-Based Speech Enhancement for Text-Dependent Speaker Verification", ["Nicolai Baek Thomsen", "Dennis Alexander Lehmann Thomsen", "Zheng-Hua Tan", "Borge Lindberg", "Soren Holdt Jensen"], "https://doi.org/10.21437/Interspeech.2016-763", 5, "interspeech", 2016]], "Chengzhu Yu": [1.4849724266241537e-05, ["Text-Available Speaker Recognition System for Forensic Applications", ["Chengzhu Yu", "Chunlei Zhang", "Finnian Kelly", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2016-1520", 4, "interspeech", 2016]], "Chunlei Zhang": [0, ["Text-Available Speaker Recognition System for Forensic Applications", ["Chengzhu Yu", "Chunlei Zhang", "Finnian Kelly", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2016-1520", 4, "interspeech", 2016]], "Abhijeet Sangwan": [0, ["Text-Available Speaker Recognition System for Forensic Applications", ["Chengzhu Yu", "Chunlei Zhang", "Finnian Kelly", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2016-1520", 4, "interspeech", 2016], ["A Speaker Diarization System for Studying Peer-Led Team Learning Groups", ["Harishchandra Dubey", "Lakshmish Kaushik", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2016-1497", 5, "interspeech", 2016], ["Fusion Strategies for Robust Speech Recognition and Keyword Spotting for Channel- and Noise-Degraded Speech", ["Vikramjit Mitra", "Julien van Hout", "Wen Wang", "Chris Bartels", "Horacio Franco", "Dimitra Vergyri", "Abeer Alwan", "Adam Janin", "John H. L. Hansen", "Richard M. Stern", "Abhijeet Sangwan", "Nelson Morgan"], "https://doi.org/10.21437/Interspeech.2016-279", 5, "interspeech", 2016]], "John H. L. Hansen": [0, ["Text-Available Speaker Recognition System for Forensic Applications", ["Chengzhu Yu", "Chunlei Zhang", "Finnian Kelly", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2016-1520", 4, "interspeech", 2016], ["Improving Boundary Estimation in Audiovisual Speech Activity Detection Using Bayesian Information Criterion", ["Fei Tao", "John H. L. Hansen", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2016-406", 5, "interspeech", 2016], ["A Speaker Diarization System for Studying Peer-Led Team Learning Groups", ["Harishchandra Dubey", "Lakshmish Kaushik", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2016-1497", 5, "interspeech", 2016], ["Robustness in Speech, Speaker, and Language Recognition: \"You've Got to Know Your Limitations\"", ["John H. L. Hansen", "Hynek Boril"], "https://doi.org/10.21437/Interspeech.2016-1395", 5, "interspeech", 2016], ["Discussion", ["Dayana Ribas", "Emmanuel Vincent", "John H. L. Hansen", "Emma Jokinen", "Mirco Ravanelli", "Hannes Gamper", "Fred Richardson"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs14.html", 0, "interspeech", 2016], ["Generalized Discriminant Analysis (GDA) for Improved i-Vector Based Speaker Recognition", ["Fahimeh Bahmaninezhad", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2016-1523", 5, "interspeech", 2016], ["Fusion Strategies for Robust Speech Recognition and Keyword Spotting for Channel- and Noise-Degraded Speech", ["Vikramjit Mitra", "Julien van Hout", "Wen Wang", "Chris Bartels", "Horacio Franco", "Dimitra Vergyri", "Abeer Alwan", "Adam Janin", "John H. L. Hansen", "Richard M. Stern", "Abhijeet Sangwan", "Nelson Morgan"], "https://doi.org/10.21437/Interspeech.2016-279", 5, "interspeech", 2016]], "Qingyang Hong": [0.00023465284175472334, ["Transfer Learning for Speaker Verification on Short Utterances", ["Qingyang Hong", "Lin Li", "Lihong Wan", "Jun Zhang", "Feng Tong"], "https://doi.org/10.21437/Interspeech.2016-432", 5, "interspeech", 2016]], "Lin Li": [0, ["Transfer Learning for Speaker Verification on Short Utterances", ["Qingyang Hong", "Lin Li", "Lihong Wan", "Jun Zhang", "Feng Tong"], "https://doi.org/10.21437/Interspeech.2016-432", 5, "interspeech", 2016]], "Lihong Wan": [0, ["Transfer Learning for Speaker Verification on Short Utterances", ["Qingyang Hong", "Lin Li", "Lihong Wan", "Jun Zhang", "Feng Tong"], "https://doi.org/10.21437/Interspeech.2016-432", 5, "interspeech", 2016]], "Jun Zhang": [0, ["Transfer Learning for Speaker Verification on Short Utterances", ["Qingyang Hong", "Lin Li", "Lihong Wan", "Jun Zhang", "Feng Tong"], "https://doi.org/10.21437/Interspeech.2016-432", 5, "interspeech", 2016]], "Feng Tong": [0, ["Transfer Learning for Speaker Verification on Short Utterances", ["Qingyang Hong", "Lin Li", "Lihong Wan", "Jun Zhang", "Feng Tong"], "https://doi.org/10.21437/Interspeech.2016-432", 5, "interspeech", 2016]], "Xiao-Lei Zhang": [0, ["Universal Background Sparse Coding and Multilayer Bootstrap Network for Speaker Clustering", ["Xiao-Lei Zhang"], "https://doi.org/10.21437/Interspeech.2016-65", 5, "interspeech", 2016]], "Gil Luyet": [0, ["Phonetic and Phonological Posterior Search Space Hashing Exploiting Class-Specific Sparsity Structures", ["Afsaneh Asaei", "Gil Luyet", "Milos Cernak", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-938", 5, "interspeech", 2016], ["Low-Rank Representation of Nearest Neighbor Posterior Probabilities to Enhance DNN Based Acoustic Modeling", ["Gil Luyet", "Pranay Dighe", "Afsaneh Asaei", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-1279", 5, "interspeech", 2016]], "George Tucker": [0, ["Model Compression Applied to Small-Footprint Keyword Spotting", ["George Tucker", "Minhua Wu", "Ming Sun", "Sankaran Panchapagesan", "Gengshen Fu", "Shiv Vitaladevuni"], "https://doi.org/10.21437/Interspeech.2016-1393", 5, "interspeech", 2016]], "Minhua Wu": [0.0001903742813738063, ["Model Compression Applied to Small-Footprint Keyword Spotting", ["George Tucker", "Minhua Wu", "Ming Sun", "Sankaran Panchapagesan", "Gengshen Fu", "Shiv Vitaladevuni"], "https://doi.org/10.21437/Interspeech.2016-1393", 5, "interspeech", 2016]], "Gengshen Fu": [0, ["Model Compression Applied to Small-Footprint Keyword Spotting", ["George Tucker", "Minhua Wu", "Ming Sun", "Sankaran Panchapagesan", "Gengshen Fu", "Shiv Vitaladevuni"], "https://doi.org/10.21437/Interspeech.2016-1393", 5, "interspeech", 2016]], "Angel Mario Castro Martinez": [0, ["Why do ASR Systems Despite Neural Nets Still Depend on Robust Features", ["Angel Mario Castro Martinez", "Marc Rene Schadler"], "https://doi.org/10.21437/Interspeech.2016-1552", 5, "interspeech", 2016]], "Qing He": [0, ["An Adaptive Multi-Band System for Low Power Voice Command Recognition", ["Qing He", "Gregory W. Wornell", "Wei Ma"], "https://doi.org/10.21437/Interspeech.2016-1562", 5, "interspeech", 2016]], "Gregory W. Wornell": [0, ["An Adaptive Multi-Band System for Low Power Voice Command Recognition", ["Qing He", "Gregory W. Wornell", "Wei Ma"], "https://doi.org/10.21437/Interspeech.2016-1562", 5, "interspeech", 2016]], "Wei Ma": [0, ["An Adaptive Multi-Band System for Low Power Voice Command Recognition", ["Qing He", "Gregory W. Wornell", "Wei Ma"], "https://doi.org/10.21437/Interspeech.2016-1562", 5, "interspeech", 2016]], "Michael Price": [0, ["Memory-Efficient Modeling and Search Techniques for Hardware ASR Decoders", ["Michael Price", "Anantha Chandrakasan", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2016-287", 5, "interspeech", 2016]], "Anantha Chandrakasan": [0, ["Memory-Efficient Modeling and Search Techniques for Hardware ASR Decoders", ["Michael Price", "Anantha Chandrakasan", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2016-287", 5, "interspeech", 2016]], "Jingzhou Yang": [8.888727969814936e-13, ["Log-Linear System Combination Using Structured Support Vector Machines", ["Jingzhou Yang", "Anton Ragni", "Mark J. F. Gales", "Kate M. Knill"], "https://doi.org/10.21437/Interspeech.2016-377", 5, "interspeech", 2016]], "Anton Ragni": [0, ["Log-Linear System Combination Using Structured Support Vector Machines", ["Jingzhou Yang", "Anton Ragni", "Mark J. F. Gales", "Kate M. Knill"], "https://doi.org/10.21437/Interspeech.2016-377", 5, "interspeech", 2016], ["Multi-Language Neural Network Language Models", ["Anton Ragni", "Edgar Dakin", "Xie Chen", "Mark J. F. Gales", "Kate M. Knill"], "https://doi.org/10.21437/Interspeech.2016-371", 5, "interspeech", 2016]], "Kate M. Knill": [0, ["Log-Linear System Combination Using Structured Support Vector Machines", ["Jingzhou Yang", "Anton Ragni", "Mark J. F. Gales", "Kate M. Knill"], "https://doi.org/10.21437/Interspeech.2016-377", 5, "interspeech", 2016], ["Multi-Language Neural Network Language Models", ["Anton Ragni", "Edgar Dakin", "Xie Chen", "Mark J. F. Gales", "Kate M. Knill"], "https://doi.org/10.21437/Interspeech.2016-371", 5, "interspeech", 2016]], "Hao Tang": [0, ["Efficient Segmental Cascades for Speech Recognition", ["Hao Tang", "Weiran Wang", "Kevin Gimpel", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2016-1298", 5, "interspeech", 2016], ["Triphone State-Tying via Deep Canonical Correlation Analysis", ["Weiran Wang", "Hao Tang", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2016-1300", 5, "interspeech", 2016]], "Weiran Wang": [0.00301669689361006, ["Efficient Segmental Cascades for Speech Recognition", ["Hao Tang", "Weiran Wang", "Kevin Gimpel", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2016-1298", 5, "interspeech", 2016], ["Triphone State-Tying via Deep Canonical Correlation Analysis", ["Weiran Wang", "Hao Tang", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2016-1300", 5, "interspeech", 2016]], "Kevin Gimpel": [0, ["Efficient Segmental Cascades for Speech Recognition", ["Hao Tang", "Weiran Wang", "Kevin Gimpel", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2016-1298", 5, "interspeech", 2016]], "Karen Livescu": [0, ["Efficient Segmental Cascades for Speech Recognition", ["Hao Tang", "Weiran Wang", "Kevin Gimpel", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2016-1298", 5, "interspeech", 2016], ["Triphone State-Tying via Deep Canonical Correlation Analysis", ["Weiran Wang", "Hao Tang", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2016-1300", 5, "interspeech", 2016]], "Sirui Xu": [0, ["A WFST Framework for Single-Pass Multi-Stream Decoding", ["Sirui Xu", "Eric Fosler-Lussier"], "https://doi.org/10.21437/Interspeech.2016-1307", 5, "interspeech", 2016]], "William Hartmann": [0, ["Comparison of Multiple System Combination Techniques for Keyword Spotting", ["William Hartmann", "Le Zhang", "Kerri Barnes", "Roger Hsiao", "Stavros Tsakalidis", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-1381", 5, "interspeech", 2016], ["Two-Stage Data Augmentation for Low-Resourced Speech Recognition", ["William Hartmann", "Tim Ng", "Roger Hsiao", "Stavros Tsakalidis", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-1386", 5, "interspeech", 2016], ["Sage: The New BBN Speech Processing Platform", ["Roger Hsiao", "Ralf Meermeier", "Tim Ng", "Zhongqiang Huang", "Maxwell Jordan", "Enoch Kan", "Tanel Alumae", "Jan Silovsky", "William Hartmann", "Francis Keith", "Omer Lang", "Man-Hung Siu", "Owen Kimball"], "https://doi.org/10.21437/Interspeech.2016-1031", 5, "interspeech", 2016]], "Le Zhang": [0, ["Comparison of Multiple System Combination Techniques for Keyword Spotting", ["William Hartmann", "Le Zhang", "Kerri Barnes", "Roger Hsiao", "Stavros Tsakalidis", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-1381", 5, "interspeech", 2016], ["Model Adaptation and Active Learning in the BBN Speech Activity Detection System for the DARPA RATS Program", ["Damianos Karakos", "Scott Novotney", "Le Zhang", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-603", 5, "interspeech", 2016]], "Kerri Barnes": [0, ["Comparison of Multiple System Combination Techniques for Keyword Spotting", ["William Hartmann", "Le Zhang", "Kerri Barnes", "Roger Hsiao", "Stavros Tsakalidis", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-1381", 5, "interspeech", 2016]], "Roger Hsiao": [0, ["Comparison of Multiple System Combination Techniques for Keyword Spotting", ["William Hartmann", "Le Zhang", "Kerri Barnes", "Roger Hsiao", "Stavros Tsakalidis", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-1381", 5, "interspeech", 2016], ["Two-Stage Data Augmentation for Low-Resourced Speech Recognition", ["William Hartmann", "Tim Ng", "Roger Hsiao", "Stavros Tsakalidis", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-1386", 5, "interspeech", 2016], ["Sage: The New BBN Speech Processing Platform", ["Roger Hsiao", "Ralf Meermeier", "Tim Ng", "Zhongqiang Huang", "Maxwell Jordan", "Enoch Kan", "Tanel Alumae", "Jan Silovsky", "William Hartmann", "Francis Keith", "Omer Lang", "Man-Hung Siu", "Owen Kimball"], "https://doi.org/10.21437/Interspeech.2016-1031", 5, "interspeech", 2016]], "Stavros Tsakalidis": [0, ["Comparison of Multiple System Combination Techniques for Keyword Spotting", ["William Hartmann", "Le Zhang", "Kerri Barnes", "Roger Hsiao", "Stavros Tsakalidis", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-1381", 5, "interspeech", 2016], ["Two-Stage Data Augmentation for Low-Resourced Speech Recognition", ["William Hartmann", "Tim Ng", "Roger Hsiao", "Stavros Tsakalidis", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-1386", 5, "interspeech", 2016], ["Improved Multilingual Training of Stacked Neural Network Acoustic Models for Low Resource Languages", ["Tanel Alumae", "Stavros Tsakalidis", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-1426", 5, "interspeech", 2016]], "Richard M. Schwartz": [0, ["Comparison of Multiple System Combination Techniques for Keyword Spotting", ["William Hartmann", "Le Zhang", "Kerri Barnes", "Roger Hsiao", "Stavros Tsakalidis", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-1381", 5, "interspeech", 2016], ["Two-Stage Data Augmentation for Low-Resourced Speech Recognition", ["William Hartmann", "Tim Ng", "Roger Hsiao", "Stavros Tsakalidis", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-1386", 5, "interspeech", 2016], ["Model Adaptation and Active Learning in the BBN Speech Activity Detection System for the DARPA RATS Program", ["Damianos Karakos", "Scott Novotney", "Le Zhang", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-603", 5, "interspeech", 2016], ["Improved Multilingual Training of Stacked Neural Network Acoustic Models for Low Resource Languages", ["Tanel Alumae", "Stavros Tsakalidis", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-1426", 5, "interspeech", 2016]], "Masato Obara": [0, ["Rescoring by Combination of Posteriorgram Score and Subword-Matching Score for Use in Query-by-Example", ["Masato Obara", "Kazunori Kojima", "Kazuyo Tanaka", "Shi-wook Lee", "Yoshiaki Itoh"], "https://doi.org/10.21437/Interspeech.2016-309", 5, "interspeech", 2016]], "Kazunori Kojima": [0, ["Rescoring by Combination of Posteriorgram Score and Subword-Matching Score for Use in Query-by-Example", ["Masato Obara", "Kazunori Kojima", "Kazuyo Tanaka", "Shi-wook Lee", "Yoshiaki Itoh"], "https://doi.org/10.21437/Interspeech.2016-309", 5, "interspeech", 2016]], "Zhehuai Chen": [0, ["Phone Synchronous Decoding with CTC Lattice", ["Zhehuai Chen", "Wei Deng", "Tao Xu", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2016-831", 5, "interspeech", 2016]], "Wei Deng": [0, ["Phone Synchronous Decoding with CTC Lattice", ["Zhehuai Chen", "Wei Deng", "Tao Xu", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2016-831", 5, "interspeech", 2016]], "Tao Xu": [0, ["Phone Synchronous Decoding with CTC Lattice", ["Zhehuai Chen", "Wei Deng", "Tao Xu", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2016-831", 5, "interspeech", 2016]], "Saurabh Sahu": [0, ["Speech Features for Depression Detection", ["Saurabh Sahu", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2016-1566", 5, "interspeech", 2016]], "Tomas Arias-Vergara": [0, ["Parkinson's Disease Progression Assessment from Speech Using GMM-UBM", ["Tomas Arias-Vergara", "Juan Camilo Vasquez-Correa", "Juan Rafael Orozco-Arroyave", "Jesus Francisco Vargas-Bonilla", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2016-1122", 5, "interspeech", 2016]], "Juan Camilo Vasquez-Correa": [0, ["Parkinson's Disease Progression Assessment from Speech Using GMM-UBM", ["Tomas Arias-Vergara", "Juan Camilo Vasquez-Correa", "Juan Rafael Orozco-Arroyave", "Jesus Francisco Vargas-Bonilla", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2016-1122", 5, "interspeech", 2016]], "Jesus Francisco Vargas-Bonilla": [0, ["Parkinson's Disease Progression Assessment from Speech Using GMM-UBM", ["Tomas Arias-Vergara", "Juan Camilo Vasquez-Correa", "Juan Rafael Orozco-Arroyave", "Jesus Francisco Vargas-Bonilla", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2016-1122", 5, "interspeech", 2016]], "Jochen Weiner": [0, ["Speech-Based Detection of Alzheimer's Disease in Conversational German", ["Jochen Weiner", "Christian Herff", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2016-100", 5, "interspeech", 2016]], "Christian Herff": [0, ["Speech-Based Detection of Alzheimer's Disease in Conversational German", ["Jochen Weiner", "Christian Herff", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2016-100", 5, "interspeech", 2016]], "Tanja Schultz": [0, ["Speech-Based Detection of Alzheimer's Disease in Conversational German", ["Jochen Weiner", "Christian Herff", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2016-100", 5, "interspeech", 2016]], "Sharifa Alghowinem": [0, ["Cross-Cultural Depression Recognition from Vocal Biomarkers", ["Sharifa Alghowinem", "Roland Goecke", "Julien Epps", "Michael Wagner", "Jeffrey F. Cohn"], "https://doi.org/10.21437/Interspeech.2016-1339", 5, "interspeech", 2016]], "Michael Wagner": [0, ["Cross-Cultural Depression Recognition from Vocal Biomarkers", ["Sharifa Alghowinem", "Roland Goecke", "Julien Epps", "Michael Wagner", "Jeffrey F. Cohn"], "https://doi.org/10.21437/Interspeech.2016-1339", 5, "interspeech", 2016]], "Jeffrey F. Cohn": [0, ["Cross-Cultural Depression Recognition from Vocal Biomarkers", ["Sharifa Alghowinem", "Roland Goecke", "Julien Epps", "Michael Wagner", "Jeffrey F. Cohn"], "https://doi.org/10.21437/Interspeech.2016-1339", 5, "interspeech", 2016]], "Luke Zhou": [0, ["Speech Recognition in Alzheimer's Disease and in its Assessment", ["Luke Zhou", "Kathleen C. Fraser", "Frank Rudzicz"], "https://doi.org/10.21437/Interspeech.2016-1228", 5, "interspeech", 2016]], "Kathleen C. Fraser": [0, ["Speech Recognition in Alzheimer's Disease and in its Assessment", ["Luke Zhou", "Kathleen C. Fraser", "Frank Rudzicz"], "https://doi.org/10.21437/Interspeech.2016-1228", 5, "interspeech", 2016]], "Florian B. Pokorny": [0, ["Does She Speak RTT? Towards an Earlier Identification of Rett Syndrome Through Intelligent Pre-Linguistic Vocalisation Analysis", ["Florian B. Pokorny", "Peter B. Marschik", "Christa Einspieler", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-520", 5, "interspeech", 2016], ["Manual versus Automated: The Challenging Routine of Infant Vocalisation Segmentation in Home Videos to Study Neuro(mal)development", ["Florian B. Pokorny", "Robert Peharz", "Wolfgang Roth", "Matthias Zohrer", "Franz Pernkopf", "Peter B. Marschik", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-1341", 5, "interspeech", 2016]], "Peter B. Marschik": [0, ["Does She Speak RTT? Towards an Earlier Identification of Rett Syndrome Through Intelligent Pre-Linguistic Vocalisation Analysis", ["Florian B. Pokorny", "Peter B. Marschik", "Christa Einspieler", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-520", 5, "interspeech", 2016], ["Manual versus Automated: The Challenging Routine of Infant Vocalisation Segmentation in Home Videos to Study Neuro(mal)development", ["Florian B. Pokorny", "Robert Peharz", "Wolfgang Roth", "Matthias Zohrer", "Franz Pernkopf", "Peter B. Marschik", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-1341", 5, "interspeech", 2016]], "Christa Einspieler": [0, ["Does She Speak RTT? Towards an Earlier Identification of Rett Syndrome Through Intelligent Pre-Linguistic Vocalisation Analysis", ["Florian B. Pokorny", "Peter B. Marschik", "Christa Einspieler", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-520", 5, "interspeech", 2016]], "Massimo Pettorino": [0, ["Speech Rhythm in Parkinson's Disease: A Study on Italian", ["Massimo Pettorino", "Maria Grazia Busa", "Elisa Pellegrino"], "https://doi.org/10.21437/Interspeech.2016-74", 4, "interspeech", 2016]], "Maria Grazia Busa": [0, ["Speech Rhythm in Parkinson's Disease: A Study on Italian", ["Massimo Pettorino", "Maria Grazia Busa", "Elisa Pellegrino"], "https://doi.org/10.21437/Interspeech.2016-74", 4, "interspeech", 2016]], "Elisa Pellegrino": [0, ["Speech Rhythm in Parkinson's Disease: A Study on Italian", ["Massimo Pettorino", "Maria Grazia Busa", "Elisa Pellegrino"], "https://doi.org/10.21437/Interspeech.2016-74", 4, "interspeech", 2016]], "Xavier Anguera": [0, ["English Language Speech Assistant", ["Xavier Anguera", "Vu Van"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2023.html", 2, "interspeech", 2016]], "Vu Van": [0, ["English Language Speech Assistant", ["Xavier Anguera", "Vu Van"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2023.html", 2, "interspeech", 2016]], "Allen Guo": [0, ["Remeeting - Deep Insights to Conversations", ["Allen Guo", "Arlo Faria", "Korbinian Riedhammer"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2024.html", 2, "interspeech", 2016]], "Arlo Faria": [0, ["Remeeting - Deep Insights to Conversations", ["Allen Guo", "Arlo Faria", "Korbinian Riedhammer"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2024.html", 2, "interspeech", 2016]], "Korbinian Riedhammer": [0, ["Remeeting - Deep Insights to Conversations", ["Allen Guo", "Arlo Faria", "Korbinian Riedhammer"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2024.html", 2, "interspeech", 2016], ["Speech Ventures", ["Nicolas Scheffer", "Korbinian Riedhammer", "Alexandre Lebrun", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs15.html", 0, "interspeech", 2016]], "Fabrice Malfrere": [0, ["My-Own-Voice: A Web Service That Allows You to Create a Text-to-Speech Voice From Your Own Voice", ["Fabrice Malfrere", "Olivier Deroo", "Emmanuelle Franques", "Jonathan Hourez", "Nicolas Mazars", "Vincent Pagel", "Geoffrey Wilfart"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2010.html", 2, "interspeech", 2016]], "Olivier Deroo": [0, ["My-Own-Voice: A Web Service That Allows You to Create a Text-to-Speech Voice From Your Own Voice", ["Fabrice Malfrere", "Olivier Deroo", "Emmanuelle Franques", "Jonathan Hourez", "Nicolas Mazars", "Vincent Pagel", "Geoffrey Wilfart"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2010.html", 2, "interspeech", 2016]], "Emmanuelle Franques": [0, ["My-Own-Voice: A Web Service That Allows You to Create a Text-to-Speech Voice From Your Own Voice", ["Fabrice Malfrere", "Olivier Deroo", "Emmanuelle Franques", "Jonathan Hourez", "Nicolas Mazars", "Vincent Pagel", "Geoffrey Wilfart"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2010.html", 2, "interspeech", 2016]], "Jonathan Hourez": [0, ["My-Own-Voice: A Web Service That Allows You to Create a Text-to-Speech Voice From Your Own Voice", ["Fabrice Malfrere", "Olivier Deroo", "Emmanuelle Franques", "Jonathan Hourez", "Nicolas Mazars", "Vincent Pagel", "Geoffrey Wilfart"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2010.html", 2, "interspeech", 2016]], "Nicolas Mazars": [0, ["My-Own-Voice: A Web Service That Allows You to Create a Text-to-Speech Voice From Your Own Voice", ["Fabrice Malfrere", "Olivier Deroo", "Emmanuelle Franques", "Jonathan Hourez", "Nicolas Mazars", "Vincent Pagel", "Geoffrey Wilfart"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2010.html", 2, "interspeech", 2016]], "Vincent Pagel": [0, ["My-Own-Voice: A Web Service That Allows You to Create a Text-to-Speech Voice From Your Own Voice", ["Fabrice Malfrere", "Olivier Deroo", "Emmanuelle Franques", "Jonathan Hourez", "Nicolas Mazars", "Vincent Pagel", "Geoffrey Wilfart"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2010.html", 2, "interspeech", 2016]], "Geoffrey Wilfart": [0, ["My-Own-Voice: A Web Service That Allows You to Create a Text-to-Speech Voice From Your Own Voice", ["Fabrice Malfrere", "Olivier Deroo", "Emmanuelle Franques", "Jonathan Hourez", "Nicolas Mazars", "Vincent Pagel", "Geoffrey Wilfart"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2010.html", 2, "interspeech", 2016]], "Anne Fernald": [0, ["Talking with Kids Really Matters: Early Language Experience Shapes Later Life Chances", ["Anne Fernald"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/3003.html", 1, "interspeech", 2016]], "Arun Narayanan": [0, ["Reducing the Computational Complexity of Multimicrophone Acoustic Models with Integrated Feature Extraction", ["Tara N. Sainath", "Arun Narayanan", "Ron J. Weiss", "Ehsan Variani", "Kevin W. Wilson", "Michiel Bacchiani", "Izhak Shafran"], "https://doi.org/10.21437/Interspeech.2016-92", 5, "interspeech", 2016]], "Ron J. Weiss": [0, ["Reducing the Computational Complexity of Multimicrophone Acoustic Models with Integrated Feature Extraction", ["Tara N. Sainath", "Arun Narayanan", "Ron J. Weiss", "Ehsan Variani", "Kevin W. Wilson", "Michiel Bacchiani", "Izhak Shafran"], "https://doi.org/10.21437/Interspeech.2016-92", 5, "interspeech", 2016], ["Neural Network Adaptive Beamforming for Robust Multichannel Speech Recognition", ["Bo Li", "Tara N. Sainath", "Ron J. Weiss", "Kevin W. Wilson", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2016-173", 5, "interspeech", 2016]], "Kevin W. Wilson": [0, ["Reducing the Computational Complexity of Multimicrophone Acoustic Models with Integrated Feature Extraction", ["Tara N. Sainath", "Arun Narayanan", "Ron J. Weiss", "Ehsan Variani", "Kevin W. Wilson", "Michiel Bacchiani", "Izhak Shafran"], "https://doi.org/10.21437/Interspeech.2016-92", 5, "interspeech", 2016], ["Neural Network Adaptive Beamforming for Robust Multichannel Speech Recognition", ["Bo Li", "Tara N. Sainath", "Ron J. Weiss", "Kevin W. Wilson", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2016-173", 5, "interspeech", 2016]], "Hakan Erdogan": [0, ["Improved MVDR Beamforming Using Single-Channel Mask Prediction Networks", ["Hakan Erdogan", "John R. Hershey", "Shinji Watanabe", "Michael I. Mandel", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2016-552", 5, "interspeech", 2016]], "Cristina Guerrero": [0, ["Channel Selection for Distant Speech Recognition Exploiting Cepstral Distance", ["Cristina Guerrero", "Georgina Tryfou", "Maurizio Omologo"], "https://doi.org/10.21437/Interspeech.2016-865", 5, "interspeech", 2016]], "Georgina Tryfou": [0, ["Channel Selection for Distant Speech Recognition Exploiting Cepstral Distance", ["Cristina Guerrero", "Georgina Tryfou", "Maurizio Omologo"], "https://doi.org/10.21437/Interspeech.2016-865", 5, "interspeech", 2016]], "Maurizio Omologo": [0, ["Channel Selection for Distant Speech Recognition Exploiting Cepstral Distance", ["Cristina Guerrero", "Georgina Tryfou", "Maurizio Omologo"], "https://doi.org/10.21437/Interspeech.2016-865", 5, "interspeech", 2016], ["Realistic Multi-Microphone Data Simulation for Distant Speech Recognition", ["Mirco Ravanelli", "Piergiorgio Svaizer", "Maurizio Omologo"], "https://doi.org/10.21437/Interspeech.2016-731", 5, "interspeech", 2016]], "Vijayaditya Peddinti": [0, ["Far-Field ASR Without Parallel Data", ["Vijayaditya Peddinti", "Vimal Manohar", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2016-1475", 5, "interspeech", 2016], ["Purely Sequence-Trained Neural Networks for ASR Based on Lattice-Free MMI", ["Daniel Povey", "Vijayaditya Peddinti", "Daniel Galvez", "Pegah Ghahremani", "Vimal Manohar", "Xingyu Na", "Yiming Wang", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2016-595", 5, "interspeech", 2016]], "Vimal Manohar": [0, ["Far-Field ASR Without Parallel Data", ["Vijayaditya Peddinti", "Vimal Manohar", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2016-1475", 5, "interspeech", 2016], ["Purely Sequence-Trained Neural Networks for ASR Based on Lattice-Free MMI", ["Daniel Povey", "Vijayaditya Peddinti", "Daniel Galvez", "Pegah Ghahremani", "Vimal Manohar", "Xingyu Na", "Yiming Wang", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2016-595", 5, "interspeech", 2016], ["Acoustic Modelling from the Signal Domain Using CNNs", ["Pegah Ghahremani", "Vimal Manohar", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2016-1495", 5, "interspeech", 2016]], "Yiming Wang": [5.499697635968914e-06, ["Far-Field ASR Without Parallel Data", ["Vijayaditya Peddinti", "Vimal Manohar", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2016-1475", 5, "interspeech", 2016], ["Purely Sequence-Trained Neural Networks for ASR Based on Lattice-Free MMI", ["Daniel Povey", "Vijayaditya Peddinti", "Daniel Galvez", "Pegah Ghahremani", "Vimal Manohar", "Xingyu Na", "Yiming Wang", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2016-595", 5, "interspeech", 2016]], "Daniel Povey": [0, ["Far-Field ASR Without Parallel Data", ["Vijayaditya Peddinti", "Vimal Manohar", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2016-1475", 5, "interspeech", 2016], ["Purely Sequence-Trained Neural Networks for ASR Based on Lattice-Free MMI", ["Daniel Povey", "Vijayaditya Peddinti", "Daniel Galvez", "Pegah Ghahremani", "Vimal Manohar", "Xingyu Na", "Yiming Wang", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2016-595", 5, "interspeech", 2016], ["Acoustic Modelling from the Signal Domain Using CNNs", ["Pegah Ghahremani", "Vimal Manohar", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2016-1495", 5, "interspeech", 2016]], "Sanjeev Khudanpur": [0, ["Far-Field ASR Without Parallel Data", ["Vijayaditya Peddinti", "Vimal Manohar", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2016-1475", 5, "interspeech", 2016], ["Purely Sequence-Trained Neural Networks for ASR Based on Lattice-Free MMI", ["Daniel Povey", "Vijayaditya Peddinti", "Daniel Galvez", "Pegah Ghahremani", "Vimal Manohar", "Xingyu Na", "Yiming Wang", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2016-595", 5, "interspeech", 2016], ["Acoustic Modelling from the Signal Domain Using CNNs", ["Pegah Ghahremani", "Vimal Manohar", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2016-1495", 5, "interspeech", 2016]], "Stefan Steidl": [0, ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: Deception, Sincerity & Native Language", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "https://doi.org/10.21437/Interspeech.2016-129", 5, "interspeech", 2016], ["The Deception Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs5.html", 0, "interspeech", 2016], ["The Sincerity Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs6.html", 0, "interspeech", 2016], ["The Native Language Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs11.html", 0, "interspeech", 2016], ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: A Summary of Results", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs12.html", 0, "interspeech", 2016], ["Discussion", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs13.html", 0, "interspeech", 2016]], "Judee K. Burgoon": [0, ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: Deception, Sincerity & Native Language", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "https://doi.org/10.21437/Interspeech.2016-129", 5, "interspeech", 2016], ["The Deception Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs5.html", 0, "interspeech", 2016], ["The Sincerity Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs6.html", 0, "interspeech", 2016], ["The Native Language Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs11.html", 0, "interspeech", 2016], ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: A Summary of Results", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs12.html", 0, "interspeech", 2016], ["Discussion", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs13.html", 0, "interspeech", 2016]], "Alice Baird": [0, ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: Deception, Sincerity & Native Language", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "https://doi.org/10.21437/Interspeech.2016-129", 5, "interspeech", 2016], ["The Deception Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs5.html", 0, "interspeech", 2016], ["The Sincerity Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs6.html", 0, "interspeech", 2016], ["The Native Language Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs11.html", 0, "interspeech", 2016], ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: A Summary of Results", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs12.html", 0, "interspeech", 2016], ["Discussion", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs13.html", 0, "interspeech", 2016]], "Aaron C. Elkins": [0, ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: Deception, Sincerity & Native Language", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "https://doi.org/10.21437/Interspeech.2016-129", 5, "interspeech", 2016], ["The Deception Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs5.html", 0, "interspeech", 2016]], "Yue Zhang": [0, ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: Deception, Sincerity & Native Language", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "https://doi.org/10.21437/Interspeech.2016-129", 5, "interspeech", 2016], ["The Deception Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs5.html", 0, "interspeech", 2016], ["The Sincerity Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs6.html", 0, "interspeech", 2016], ["Sincerity and Deception in Speech: Two Sides of the Same Coin? A Transfer- and Multi-Task Learning Perspective", ["Yue Zhang", "Felix Weninger", "Zhao Ren", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-1305", 5, "interspeech", 2016], ["The Native Language Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs11.html", 0, "interspeech", 2016], ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: A Summary of Results", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs12.html", 0, "interspeech", 2016], ["Discussion", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs13.html", 0, "interspeech", 2016]], "Eduardo Coutinho": [0, ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: Deception, Sincerity & Native Language", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "https://doi.org/10.21437/Interspeech.2016-129", 5, "interspeech", 2016], ["The Deception Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs5.html", 0, "interspeech", 2016], ["The Sincerity Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs6.html", 0, "interspeech", 2016], ["The Native Language Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs11.html", 0, "interspeech", 2016], ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: A Summary of Results", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs12.html", 0, "interspeech", 2016], ["Discussion", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs13.html", 0, "interspeech", 2016]], "Keelan Evanini": [0, ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: Deception, Sincerity & Native Language", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "https://doi.org/10.21437/Interspeech.2016-129", 5, "interspeech", 2016], ["The Deception Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron C. Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs5.html", 0, "interspeech", 2016], ["The Sincerity Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs6.html", 0, "interspeech", 2016], ["The Native Language Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs11.html", 0, "interspeech", 2016], ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: A Summary of Results", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs12.html", 0, "interspeech", 2016], ["Discussion", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs13.html", 0, "interspeech", 2016], ["Self-Adaptive DNN for Improving Spoken Language Proficiency Assessment", ["Yao Qian", "Xinhao Wang", "Keelan Evanini", "David Suendermann-Oeft"], "https://doi.org/10.21437/Interspeech.2016-291", 5, "interspeech", 2016], ["Noise and Metadata Sensitive Bottleneck Features for Improving Speaker Recognition with Non-Native Speech Input", ["Yao Qian", "Jidong Tao", "David Suendermann-Oeft", "Keelan Evanini", "Alexei V. Ivanov", "Vikram Ramanarayanan"], "https://doi.org/10.21437/Interspeech.2016-548", 5, "interspeech", 2016]], "Min Ma": [0, ["Combining Acoustic-Prosodic, Lexical, and Phonotactic Features for Automatic Deception Detection", ["Sarah Ita Levitan", "Guozhen An", "Min Ma", "Rivka Levitan", "Andrew Rosenberg", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2016-1519", 5, "interspeech", 2016]], "Shahin Amiriparian": [0, ["Is Deception Emotional? An Emotion-Driven Predictive Approach", ["Shahin Amiriparian", "Jouni Pohjalainen", "Erik Marchi", "Sergey Pugachevskiy", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-565", 5, "interspeech", 2016]], "Jouni Pohjalainen": [0, ["Is Deception Emotional? An Emotion-Driven Predictive Approach", ["Shahin Amiriparian", "Jouni Pohjalainen", "Erik Marchi", "Sergey Pugachevskiy", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-565", 5, "interspeech", 2016], ["Convolutional Neural Networks with Data Augmentation for Classifying Speakers' Native Language", ["Gil Keren", "Jun Deng", "Jouni Pohjalainen", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-261", 5, "interspeech", 2016]], "Sergey Pugachevskiy": [0, ["Is Deception Emotional? An Emotion-Driven Predictive Approach", ["Shahin Amiriparian", "Jouni Pohjalainen", "Erik Marchi", "Sergey Pugachevskiy", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-565", 5, "interspeech", 2016]], "Claude Montacie": [0, ["Prosodic Cues and Answer Type Detection for the Deception Sub-Challenge", ["Claude Montacie", "Marie-Jose Caraty"], "https://doi.org/10.21437/Interspeech.2016-33", 5, "interspeech", 2016]], "Marie-Jose Caraty": [0, ["Prosodic Cues and Answer Type Detection for the Deception Sub-Challenge", ["Claude Montacie", "Marie-Jose Caraty"], "https://doi.org/10.21437/Interspeech.2016-33", 5, "interspeech", 2016]], "Aaron Elkins": [0, ["The Sincerity Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs6.html", 0, "interspeech", 2016], ["The Native Language Sub-Challenge: The Data", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs11.html", 0, "interspeech", 2016], ["The INTERSPEECH 2016 Computational Paralinguistics Challenge: A Summary of Results", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs12.html", 0, "interspeech", 2016], ["Discussion", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Julia Hirschberg", "Judee K. Burgoon", "Alice Baird", "Aaron Elkins", "Yue Zhang", "Eduardo Coutinho", "Keelan Evanini"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs13.html", 0, "interspeech", 2016]], "Brandon M. Booth": [0, ["Automatic Estimation of Perceived Sincerity from Spoken Language", ["Brandon M. Booth", "Rahul Gupta", "Pavlos Papadopoulos", "Ruchir Travadi", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1537", 5, "interspeech", 2016]], "Pavlos Papadopoulos": [0, ["Automatic Estimation of Perceived Sincerity from Spoken Language", ["Brandon M. Booth", "Rahul Gupta", "Pavlos Papadopoulos", "Ruchir Travadi", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1537", 5, "interspeech", 2016], ["Noise Aware and Combined Noise Models for Speech Denoising in Unknown Noise Conditions", ["Pavlos Papadopoulos", "Colin Vaz", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-501", 4, "interspeech", 2016]], "Ruchir Travadi": [0, ["Automatic Estimation of Perceived Sincerity from Spoken Language", ["Brandon M. Booth", "Rahul Gupta", "Pavlos Papadopoulos", "Ruchir Travadi", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-1537", 5, "interspeech", 2016], ["Non-Iterative Parameter Estimation for Total Variability Model Using Randomized Singular Value Decomposition", ["Ruchir Travadi", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-293", 5, "interspeech", 2016]], "Gyorgy Szaszak": [0, ["Estimating the Sincerity of Apologies in Speech by DNN Rank Learning and Prosodic Analysis", ["Gabor Gosztolya", "Tamas Grosz", "Gyorgy Szaszak", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2016-956", 5, "interspeech", 2016]], "Hung-Shin Lee": [5.500744350683817e-06, ["Minimization of Regression and Ranking Losses with Shallow Neural Networks on Automatic Sincerity Evaluation", ["Hung-Shin Lee", "Yu Tsao", "Chi-Chun Lee", "Hsin-Min Wang", "Wei-Cheng Lin", "Wei-Chen Chen", "Shan-Wen Hsiao", "Shyh-Kang Jeng"], "https://doi.org/10.21437/Interspeech.2016-756", 5, "interspeech", 2016]], "Wei-Cheng Lin": [0, ["Minimization of Regression and Ranking Losses with Shallow Neural Networks on Automatic Sincerity Evaluation", ["Hung-Shin Lee", "Yu Tsao", "Chi-Chun Lee", "Hsin-Min Wang", "Wei-Cheng Lin", "Wei-Chen Chen", "Shan-Wen Hsiao", "Shyh-Kang Jeng"], "https://doi.org/10.21437/Interspeech.2016-756", 5, "interspeech", 2016]], "Shyh-Kang Jeng": [0, ["Minimization of Regression and Ranking Losses with Shallow Neural Networks on Automatic Sincerity Evaluation", ["Hung-Shin Lee", "Yu Tsao", "Chi-Chun Lee", "Hsin-Min Wang", "Wei-Cheng Lin", "Wei-Chen Chen", "Shan-Wen Hsiao", "Shyh-Kang Jeng"], "https://doi.org/10.21437/Interspeech.2016-756", 5, "interspeech", 2016]], "Robert Herms": [0, ["Prediction of Deception and Sincerity from Speech Using Automatic Phone Recognition-Based Features", ["Robert Herms"], "https://doi.org/10.21437/Interspeech.2016-971", 5, "interspeech", 2016]], "Felix Weninger": [0, ["Sincerity and Deception in Speech: Two Sides of the Same Coin? A Transfer- and Multi-Task Learning Perspective", ["Yue Zhang", "Felix Weninger", "Zhao Ren", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-1305", 5, "interspeech", 2016]], "Zhao Ren": [0, ["Sincerity and Deception in Speech: Two Sides of the Same Coin? A Transfer- and Multi-Task Learning Perspective", ["Yue Zhang", "Felix Weninger", "Zhao Ren", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-1305", 5, "interspeech", 2016]], "Heysem Kaya": [0, ["Fusing Acoustic Feature Representations for Computational Paralinguistics Tasks", ["Heysem Kaya", "Alexey A. Karpov"], "https://doi.org/10.21437/Interspeech.2016-995", 5, "interspeech", 2016]], "Alexey A. Karpov": [0, ["Fusing Acoustic Feature Representations for Computational Paralinguistics Tasks", ["Heysem Kaya", "Alexey A. Karpov"], "https://doi.org/10.21437/Interspeech.2016-995", 5, "interspeech", 2016]], "Naomi Harte": [0, ["Introduction", ["Naomi Harte", "Peter Jancovic", "Karl-L. Schuchmann"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs7.html", 0, "interspeech", 2016], ["Poster Overview Presentations", ["Naomi Harte", "Peter Jancovic", "Karl-L. Schuchmann"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs8.html", 0, "interspeech", 2016], ["Discussion", ["Naomi Harte", "Peter Jancovic", "Karl-L. Schuchmann"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs9.html", 0, "interspeech", 2016], ["Closing Remarks", ["Naomi Harte", "Peter Jancovic", "Karl-L. Schuchmann"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs10.html", 0, "interspeech", 2016], ["YIN-Bird: Improved Pitch Tracking for Bird Vocalisations", ["Colm OReilly", "Nicola M. Marples", "David J. Kelly", "Naomi Harte"], "https://doi.org/10.21437/Interspeech.2016-90", 5, "interspeech", 2016]], "Peter Jancovic": [0, ["Introduction", ["Naomi Harte", "Peter Jancovic", "Karl-L. Schuchmann"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs7.html", 0, "interspeech", 2016], ["Poster Overview Presentations", ["Naomi Harte", "Peter Jancovic", "Karl-L. Schuchmann"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs8.html", 0, "interspeech", 2016], ["Discussion", ["Naomi Harte", "Peter Jancovic", "Karl-L. Schuchmann"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs9.html", 0, "interspeech", 2016], ["Closing Remarks", ["Naomi Harte", "Peter Jancovic", "Karl-L. Schuchmann"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs10.html", 0, "interspeech", 2016], ["Recognition of Multiple Bird Species Based on Penalised Maximum Likelihood and HMM-Based Modelling of Individual Vocalisation Elements", ["Peter Jancovic", "Munevver Kokuer"], "https://doi.org/10.21437/Interspeech.2016-669", 5, "interspeech", 2016], ["Interpretation of Low Dimensional Neural Network Bottleneck Features in Terms of Human Perception and Production", ["Philip Weber", "Linxue Bai", "Martin J. Russell", "Peter Jancovic", "Stephen M. Houghton"], "https://doi.org/10.21437/Interspeech.2016-124", 5, "interspeech", 2016]], "Karl-L. Schuchmann": [0, ["Introduction", ["Naomi Harte", "Peter Jancovic", "Karl-L. Schuchmann"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs7.html", 0, "interspeech", 2016], ["Poster Overview Presentations", ["Naomi Harte", "Peter Jancovic", "Karl-L. Schuchmann"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs8.html", 0, "interspeech", 2016], ["Discussion", ["Naomi Harte", "Peter Jancovic", "Karl-L. Schuchmann"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs9.html", 0, "interspeech", 2016], ["Closing Remarks", ["Naomi Harte", "Peter Jancovic", "Karl-L. Schuchmann"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs10.html", 0, "interspeech", 2016]], "Merwan Barlier": [0, ["A Stochastic Model for Computer-Aided Human-Human Dialogue", ["Merwan Barlier", "Romain Laroche", "Olivier Pietquin"], "https://doi.org/10.21437/Interspeech.2016-479", 5, "interspeech", 2016]], "Romain Laroche": [0, ["A Stochastic Model for Computer-Aided Human-Human Dialogue", ["Merwan Barlier", "Romain Laroche", "Olivier Pietquin"], "https://doi.org/10.21437/Interspeech.2016-479", 5, "interspeech", 2016]], "Olivier Pietquin": [0, ["A Stochastic Model for Computer-Aided Human-Human Dialogue", ["Merwan Barlier", "Romain Laroche", "Olivier Pietquin"], "https://doi.org/10.21437/Interspeech.2016-479", 5, "interspeech", 2016]], "Gael Lejeune": [0, ["Highlighting Psychological Features for Predicting Child Interjections During Story Telling", ["Gael Lejeune", "Francois Rioult", "Bruno Cremilleux"], "https://doi.org/10.21437/Interspeech.2016-527", 4, "interspeech", 2016]], "Francois Rioult": [0, ["Highlighting Psychological Features for Predicting Child Interjections During Story Telling", ["Gael Lejeune", "Francois Rioult", "Bruno Cremilleux"], "https://doi.org/10.21437/Interspeech.2016-527", 4, "interspeech", 2016]], "Bruno Cremilleux": [0, ["Highlighting Psychological Features for Predicting Child Interjections During Story Telling", ["Gael Lejeune", "Francois Rioult", "Bruno Cremilleux"], "https://doi.org/10.21437/Interspeech.2016-527", 4, "interspeech", 2016]], "Kai Sun": [0.007579641183838248, ["Hybrid Dialogue State Tracking for Real World Human-to-Human Dialogues", ["Kai Sun", "Su Zhu", "Lu Chen", "Siqiu Yao", "Xueyang Wu", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2016-949", 5, "interspeech", 2016]], "Su Zhu": [0, ["Hybrid Dialogue State Tracking for Real World Human-to-Human Dialogues", ["Kai Sun", "Su Zhu", "Lu Chen", "Siqiu Yao", "Xueyang Wu", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2016-949", 5, "interspeech", 2016]], "Lu Chen": [0, ["Hybrid Dialogue State Tracking for Real World Human-to-Human Dialogues", ["Kai Sun", "Su Zhu", "Lu Chen", "Siqiu Yao", "Xueyang Wu", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2016-949", 5, "interspeech", 2016]], "Siqiu Yao": [0, ["Hybrid Dialogue State Tracking for Real World Human-to-Human Dialogues", ["Kai Sun", "Su Zhu", "Lu Chen", "Siqiu Yao", "Xueyang Wu", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2016-949", 5, "interspeech", 2016]], "Xueyang Wu": [3.381595615792321e-05, ["Hybrid Dialogue State Tracking for Real World Human-to-Human Dialogues", ["Kai Sun", "Su Zhu", "Lu Chen", "Siqiu Yao", "Xueyang Wu", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2016-949", 5, "interspeech", 2016]], "Gaurav Fotedar": [0, ["Automatic Recognition of Social Roles Using Long Term Role Transitions in Small Group Interactions", ["Gaurav Fotedar", "Aditya Gaonkar P.", "Saikat Chatterjee", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2016-202", 5, "interspeech", 2016]], "Aditya Gaonkar P.": [0, ["Automatic Recognition of Social Roles Using Long Term Role Transitions in Small Group Interactions", ["Gaurav Fotedar", "Aditya Gaonkar P.", "Saikat Chatterjee", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2016-202", 5, "interspeech", 2016]], "Saikat Chatterjee": [0, ["Automatic Recognition of Social Roles Using Long Term Role Transitions in Small Group Interactions", ["Gaurav Fotedar", "Aditya Gaonkar P.", "Saikat Chatterjee", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2016-202", 5, "interspeech", 2016]], "Prasanta Kumar Ghosh": [0, ["Automatic Recognition of Social Roles Using Long Term Role Transitions in Small Group Interactions", ["Gaurav Fotedar", "Aditya Gaonkar P.", "Saikat Chatterjee", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2016-202", 5, "interspeech", 2016], ["A Class-Specific Speech Enhancement for Phoneme Recognition: A Dictionary Learning Approach", ["Nazreen P. M.", "A. G. Ramakrishnan", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2016-236", 5, "interspeech", 2016]], "Paul Van Eecke": [0, ["On the Influence of Gender on Interruptions in Multiparty Dialogue", ["Paul Van Eecke", "Raquel Fernandez"], "https://doi.org/10.21437/Interspeech.2016-951", 5, "interspeech", 2016]], "Raquel Fernandez": [0, ["On the Influence of Gender on Interruptions in Multiparty Dialogue", ["Paul Van Eecke", "Raquel Fernandez"], "https://doi.org/10.21437/Interspeech.2016-951", 5, "interspeech", 2016]], "Ian Beaver": [0, ["Detection of User Escalation in Human-Computer Interactions", ["Ian Beaver", "Cynthia Freeman"], "https://doi.org/10.21437/Interspeech.2016-535", 5, "interspeech", 2016]], "Cynthia Freeman": [0, ["Detection of User Escalation in Human-Computer Interactions", ["Ian Beaver", "Cynthia Freeman"], "https://doi.org/10.21437/Interspeech.2016-535", 5, "interspeech", 2016]], "Marie-Lou Barnaud": [0, ["Assessing Idiosyncrasies in a Bayesian Model of Speech Communication", ["Marie-Lou Barnaud", "Julien Diard", "Pierre Bessiere", "Jean-Luc Schwartz"], "https://doi.org/10.21437/Interspeech.2016-396", 5, "interspeech", 2016]], "Julien Diard": [0, ["Assessing Idiosyncrasies in a Bayesian Model of Speech Communication", ["Marie-Lou Barnaud", "Julien Diard", "Pierre Bessiere", "Jean-Luc Schwartz"], "https://doi.org/10.21437/Interspeech.2016-396", 5, "interspeech", 2016], ["Bayesian Modeling in Speech Motor Control: A Principled Structure for the Integration of Various Constraints", ["Jean-Francois Patri", "Pascal Perrier", "Julien Diard"], "https://doi.org/10.21437/Interspeech.2016-441", 5, "interspeech", 2016]], "Pierre Bessiere": [0, ["Assessing Idiosyncrasies in a Bayesian Model of Speech Communication", ["Marie-Lou Barnaud", "Julien Diard", "Pierre Bessiere", "Jean-Luc Schwartz"], "https://doi.org/10.21437/Interspeech.2016-396", 5, "interspeech", 2016]], "Maria K. Wolters": [0, ["Prosodic and Linguistic Analysis of Semantic Fluency Data: A Window into Speech Production and Cognition", ["Maria K. Wolters", "Najoung Kim", "Jung-Ho Kim", "Sarah E. MacPherson", "Jong C. Park"], "https://doi.org/10.21437/Interspeech.2016-420", 5, "interspeech", 2016]], "Najoung Kim": [0.5, ["Prosodic and Linguistic Analysis of Semantic Fluency Data: A Window into Speech Production and Cognition", ["Maria K. Wolters", "Najoung Kim", "Jung-Ho Kim", "Sarah E. MacPherson", "Jong C. Park"], "https://doi.org/10.21437/Interspeech.2016-420", 5, "interspeech", 2016]], "Jung-Ho Kim": [0.9047393798828125, ["Prosodic and Linguistic Analysis of Semantic Fluency Data: A Window into Speech Production and Cognition", ["Maria K. Wolters", "Najoung Kim", "Jung-Ho Kim", "Sarah E. MacPherson", "Jong C. Park"], "https://doi.org/10.21437/Interspeech.2016-420", 5, "interspeech", 2016]], "Sarah E. MacPherson": [0, ["Prosodic and Linguistic Analysis of Semantic Fluency Data: A Window into Speech Production and Cognition", ["Maria K. Wolters", "Najoung Kim", "Jung-Ho Kim", "Sarah E. MacPherson", "Jong C. Park"], "https://doi.org/10.21437/Interspeech.2016-420", 5, "interspeech", 2016]], "Jong C. Park": [0.33369308710098267, ["Prosodic and Linguistic Analysis of Semantic Fluency Data: A Window into Speech Production and Cognition", ["Maria K. Wolters", "Najoung Kim", "Jung-Ho Kim", "Sarah E. MacPherson", "Jong C. Park"], "https://doi.org/10.21437/Interspeech.2016-420", 5, "interspeech", 2016]], "William F. Katz": [0, ["Sensorimotor Response to Visual Imagery of Tongue Displacement", ["William F. Katz", "Divya Prabhakaran"], "https://doi.org/10.21437/Interspeech.2016-1594", 5, "interspeech", 2016]], "Divya Prabhakaran": [0, ["Sensorimotor Response to Visual Imagery of Tongue Displacement", ["William F. Katz", "Divya Prabhakaran"], "https://doi.org/10.21437/Interspeech.2016-1594", 5, "interspeech", 2016]], "Tiphaine Caudrelier": [0, ["Does Auditory-Motor Learning of Speech Transfer from the CV Syllable to the CVCV Word?", ["Tiphaine Caudrelier", "Pascal Perrier", "Jean-Luc Schwartz", "Amelie Rochet-Capellan"], "https://doi.org/10.21437/Interspeech.2016-262", 5, "interspeech", 2016]], "Pascal Perrier": [0, ["Does Auditory-Motor Learning of Speech Transfer from the CV Syllable to the CVCV Word?", ["Tiphaine Caudrelier", "Pascal Perrier", "Jean-Luc Schwartz", "Amelie Rochet-Capellan"], "https://doi.org/10.21437/Interspeech.2016-262", 5, "interspeech", 2016], ["Uncontrolled Manifolds in Vowel Production: Assessment with a Biomechanical Model of the Tongue", ["Andrew Szabados", "Pascal Perrier"], "https://doi.org/10.21437/Interspeech.2016-1579", 5, "interspeech", 2016], ["Bayesian Modeling in Speech Motor Control: A Principled Structure for the Integration of Various Constraints", ["Jean-Francois Patri", "Pascal Perrier", "Julien Diard"], "https://doi.org/10.21437/Interspeech.2016-441", 5, "interspeech", 2016]], "Michael Walsh": [0, ["Exemplar Dynamics in Phonetic Convergence of Speech Rate", ["Antje Schweitzer", "Michael Walsh"], "https://doi.org/10.21437/Interspeech.2016-373", 5, "interspeech", 2016]], "Outi Tuomainen": [0, ["Articulation Rate in Adverse Listening Conditions in Younger and Older Adults", ["Outi Tuomainen", "Valerie Hazan"], "https://doi.org/10.21437/Interspeech.2016-843", 5, "interspeech", 2016]], "Valerie Hazan": [0, ["Articulation Rate in Adverse Listening Conditions in Younger and Older Adults", ["Outi Tuomainen", "Valerie Hazan"], "https://doi.org/10.21437/Interspeech.2016-843", 5, "interspeech", 2016]], "Julia Olcoz": [0, ["Error Correction in Lightly Supervised Alignment of Broadcast Subtitles", ["Julia Olcoz", "Oscar Saz", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-56", 5, "interspeech", 2016]], "Guan-Lin Chao": [0, ["Speaker-Targeted Audio-Visual Models for Speech Recognition in Cocktail-Party Environments", ["Guan-Lin Chao", "William Chan", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2016-599", 5, "interspeech", 2016]], "William Chan": [0, ["Speaker-Targeted Audio-Visual Models for Speech Recognition in Cocktail-Party Environments", ["Guan-Lin Chao", "William Chan", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2016-599", 5, "interspeech", 2016], ["On Online Attention-Based Speech Recognition and Joint Mandarin Character-Pinyin Training", ["William Chan", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2016-334", 5, "interspeech", 2016]], "Amit Aides": [0, ["Text-Dependent Audiovisual Synchrony Detection for Spoofing Detection in Mobile Person Recognition", ["Amit Aides", "Hagai Aronowitz"], "https://doi.org/10.21437/Interspeech.2016-196", 5, "interspeech", 2016]], "Hagai Aronowitz": [0, ["Text-Dependent Audiovisual Synchrony Detection for Spoofing Detection in Mobile Person Recognition", ["Amit Aides", "Hagai Aronowitz"], "https://doi.org/10.21437/Interspeech.2016-196", 5, "interspeech", 2016]], "Sebastian Gergen": [0, ["Dynamic Stream Weighting for Turbo-Decoding-Based Audiovisual ASR", ["Sebastian Gergen", "Steffen Zeiler", "Ahmed Hussen Abdelaziz", "Robert M. Nickel", "Dorothea Kolossa"], "https://doi.org/10.21437/Interspeech.2016-166", 5, "interspeech", 2016]], "Robert M. Nickel": [0, ["Dynamic Stream Weighting for Turbo-Decoding-Based Audiovisual ASR", ["Sebastian Gergen", "Steffen Zeiler", "Ahmed Hussen Abdelaziz", "Robert M. Nickel", "Dorothea Kolossa"], "https://doi.org/10.21437/Interspeech.2016-166", 5, "interspeech", 2016]], "Anna M. Kruspe": [0, ["Retrieval of Textual Song Lyrics from Sung Inputs", ["Anna M. Kruspe"], "https://doi.org/10.21437/Interspeech.2016-1272", 5, "interspeech", 2016], ["Phonotactic Language Identification for Singing", ["Anna M. Kruspe"], "https://doi.org/10.21437/Interspeech.2016-131", 5, "interspeech", 2016]], "Charles Chen": [0, ["Tone Classification in Mandarin Chinese Using Convolutional Neural Networks", ["Charles Chen", "Razvan C. Bunescu", "Li Xu", "Chang Liu"], "https://doi.org/10.21437/Interspeech.2016-528", 5, "interspeech", 2016]], "Razvan C. Bunescu": [0, ["Tone Classification in Mandarin Chinese Using Convolutional Neural Networks", ["Charles Chen", "Razvan C. Bunescu", "Li Xu", "Chang Liu"], "https://doi.org/10.21437/Interspeech.2016-528", 5, "interspeech", 2016]], "Chang Liu": [0, ["Tone Classification in Mandarin Chinese Using Convolutional Neural Networks", ["Charles Chen", "Razvan C. Bunescu", "Li Xu", "Chang Liu"], "https://doi.org/10.21437/Interspeech.2016-528", 5, "interspeech", 2016]], "Vishala Pannala": [0, ["Robust Estimation of Fundamental Frequency Using Single Frequency Filtering Approach", ["Vishala Pannala", "G. Aneeja", "Sudarsana Reddy Kadiri", "B. Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2016-1401", 5, "interspeech", 2016]], "G. Aneeja": [0, ["Robust Estimation of Fundamental Frequency Using Single Frequency Filtering Approach", ["Vishala Pannala", "G. Aneeja", "Sudarsana Reddy Kadiri", "B. Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2016-1401", 5, "interspeech", 2016]], "Sudarsana Reddy Kadiri": [0, ["Robust Estimation of Fundamental Frequency Using Single Frequency Filtering Approach", ["Vishala Pannala", "G. Aneeja", "Sudarsana Reddy Kadiri", "B. Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2016-1401", 5, "interspeech", 2016]], "Ryunosuke Daido": [0, ["A Fast and Accurate Fundamental Frequency Estimator Using Recursive Moving Average Filters", ["Ryunosuke Daido", "Yuji Hisaminato"], "https://doi.org/10.21437/Interspeech.2016-394", 5, "interspeech", 2016]], "Yuji Hisaminato": [0, ["A Fast and Accurate Fundamental Frequency Estimator Using Recursive Moving Average Filters", ["Ryunosuke Daido", "Yuji Hisaminato"], "https://doi.org/10.21437/Interspeech.2016-394", 5, "interspeech", 2016]], "Prateek Verma": [0, ["Frequency Estimation from Waveforms Using Multi-Layered Neural Networks", ["Prateek Verma", "Ronald W. Schafer"], "https://doi.org/10.21437/Interspeech.2016-679", 5, "interspeech", 2016]], "Ronald W. Schafer": [0, ["Frequency Estimation from Waveforms Using Multi-Layered Neural Networks", ["Prateek Verma", "Ronald W. Schafer"], "https://doi.org/10.21437/Interspeech.2016-679", 5, "interspeech", 2016]], "Douglas E. Sturim": [0, ["Speaker Linking and Applications Using Non-Parametric Hashing Methods", ["Douglas E. Sturim", "William M. Campbell"], "https://doi.org/10.21437/Interspeech.2016-468", 5, "interspeech", 2016], ["Corpora for the Evaluation of Robust Speaker Recognition Systems", ["Douglas E. Sturim", "Pedro A. Torres-Carrasquillo", "Joseph P. Campbell"], "https://doi.org/10.21437/Interspeech.2016-1609", 5, "interspeech", 2016], ["Language Recognition via Sparse Coding", ["Youngjune Gwon", "William M. Campbell", "Douglas E. Sturim", "H. T. Kung"], "https://doi.org/10.21437/Interspeech.2016-881", 5, "interspeech", 2016]], "William M. Campbell": [0, ["Speaker Linking and Applications Using Non-Parametric Hashing Methods", ["Douglas E. Sturim", "William M. Campbell"], "https://doi.org/10.21437/Interspeech.2016-468", 5, "interspeech", 2016], ["Language Recognition via Sparse Coding", ["Youngjune Gwon", "William M. Campbell", "Douglas E. Sturim", "H. T. Kung"], "https://doi.org/10.21437/Interspeech.2016-881", 5, "interspeech", 2016]], "Gael Le Lan": [0, ["Iterative PLDA Adaptation for Speaker Diarization", ["Gael Le Lan", "Delphine Charlet", "Anthony Larcher", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-572", 5, "interspeech", 2016]], "Anthony Larcher": [0, ["Iterative PLDA Adaptation for Speaker Diarization", ["Gael Le Lan", "Delphine Charlet", "Anthony Larcher", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-572", 5, "interspeech", 2016], ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016]], "Sylvain Meignier": [0, ["Iterative PLDA Adaptation for Speaker Diarization", ["Gael Le Lan", "Delphine Charlet", "Anthony Larcher", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-572", 5, "interspeech", 2016], ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016]], "Harishchandra Dubey": [0, ["A Speaker Diarization System for Studying Peer-Led Team Learning Groups", ["Harishchandra Dubey", "Lakshmish Kaushik", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2016-1497", 5, "interspeech", 2016]], "Lakshmish Kaushik": [0, ["A Speaker Diarization System for Studying Peer-Led Team Learning Groups", ["Harishchandra Dubey", "Lakshmish Kaushik", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2016-1497", 5, "interspeech", 2016]], "Itshak Lapidot": [0, ["On the Importance of Efficient Transition Modeling for Speaker Diarization", ["Itshak Lapidot", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2016-503", 4, "interspeech", 2016]], "Gregory Sell": [0, ["Priors for Speaker Counting and Diarization with AHC", ["Gregory Sell", "Alan McCree", "Daniel Garcia-Romero"], "https://doi.org/10.21437/Interspeech.2016-1380", 5, "interspeech", 2016]], "Alan McCree": [0, ["Priors for Speaker Counting and Diarization with AHC", ["Gregory Sell", "Alan McCree", "Daniel Garcia-Romero"], "https://doi.org/10.21437/Interspeech.2016-1380", 5, "interspeech", 2016], ["Stacked Long-Term TDNN for Spoken Language Recognition", ["Daniel Garcia-Romero", "Alan McCree"], "https://doi.org/10.21437/Interspeech.2016-1334", 5, "interspeech", 2016]], "Daniel Garcia-Romero": [0, ["Priors for Speaker Counting and Diarization with AHC", ["Gregory Sell", "Alan McCree", "Daniel Garcia-Romero"], "https://doi.org/10.21437/Interspeech.2016-1380", 5, "interspeech", 2016], ["Stacked Long-Term TDNN for Spoken Language Recognition", ["Daniel Garcia-Romero", "Alan McCree"], "https://doi.org/10.21437/Interspeech.2016-1334", 5, "interspeech", 2016]], "Nauman Dawalatabad": [0, ["Two-Pass IB Based Speaker Diarization System Using Meeting-Specific ANN Based Features", ["Nauman Dawalatabad", "Srikanth R. Madikeri", "C. Chandra Sekhar", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2016-714", 5, "interspeech", 2016]], "C. Chandra Sekhar": [0, ["Two-Pass IB Based Speaker Diarization System Using Meeting-Specific ANN Based Features", ["Nauman Dawalatabad", "Srikanth R. Madikeri", "C. Chandra Sekhar", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2016-714", 5, "interspeech", 2016]], "Zeyan Oo": [0, ["DNN-Based Amplitude and Phase Feature Enhancement for Noise Robust Speaker Identification", ["Zeyan Oo", "Yuta Kawakami", "Longbiao Wang", "Seiichi Nakagawa", "Xiong Xiao", "Masahiro Iwahashi"], "https://doi.org/10.21437/Interspeech.2016-717", 5, "interspeech", 2016]], "Yuta Kawakami": [0, ["DNN-Based Amplitude and Phase Feature Enhancement for Noise Robust Speaker Identification", ["Zeyan Oo", "Yuta Kawakami", "Longbiao Wang", "Seiichi Nakagawa", "Xiong Xiao", "Masahiro Iwahashi"], "https://doi.org/10.21437/Interspeech.2016-717", 5, "interspeech", 2016]], "Longbiao Wang": [1.2193843162932157e-15, ["DNN-Based Amplitude and Phase Feature Enhancement for Noise Robust Speaker Identification", ["Zeyan Oo", "Yuta Kawakami", "Longbiao Wang", "Seiichi Nakagawa", "Xiong Xiao", "Masahiro Iwahashi"], "https://doi.org/10.21437/Interspeech.2016-717", 5, "interspeech", 2016]], "Seiichi Nakagawa": [0, ["DNN-Based Amplitude and Phase Feature Enhancement for Noise Robust Speaker Identification", ["Zeyan Oo", "Yuta Kawakami", "Longbiao Wang", "Seiichi Nakagawa", "Xiong Xiao", "Masahiro Iwahashi"], "https://doi.org/10.21437/Interspeech.2016-717", 5, "interspeech", 2016]], "Masahiro Iwahashi": [0, ["DNN-Based Amplitude and Phase Feature Enhancement for Noise Robust Speaker Identification", ["Zeyan Oo", "Yuta Kawakami", "Longbiao Wang", "Seiichi Nakagawa", "Xiong Xiao", "Masahiro Iwahashi"], "https://doi.org/10.21437/Interspeech.2016-717", 5, "interspeech", 2016]], "Ulrich Scherhag": [0, ["Unit-Selection Attack Detection Based on Unfiltered Frequency-Domain Features", ["Ulrich Scherhag", "Andreas Nautsch", "Christian Rathgeb", "Christoph Busch"], "https://doi.org/10.21437/Interspeech.2016-969", 5, "interspeech", 2016]], "Andreas Nautsch": [0, ["Unit-Selection Attack Detection Based on Unfiltered Frequency-Domain Features", ["Ulrich Scherhag", "Andreas Nautsch", "Christian Rathgeb", "Christoph Busch"], "https://doi.org/10.21437/Interspeech.2016-969", 5, "interspeech", 2016]], "Christian Rathgeb": [0, ["Unit-Selection Attack Detection Based on Unfiltered Frequency-Domain Features", ["Ulrich Scherhag", "Andreas Nautsch", "Christian Rathgeb", "Christoph Busch"], "https://doi.org/10.21437/Interspeech.2016-969", 5, "interspeech", 2016]], "Christoph Busch": [0, ["Unit-Selection Attack Detection Based on Unfiltered Frequency-Domain Features", ["Ulrich Scherhag", "Andreas Nautsch", "Christian Rathgeb", "Christoph Busch"], "https://doi.org/10.21437/Interspeech.2016-969", 5, "interspeech", 2016]], "Mairym Llorens Monteserin": [0, ["Investigating the Impact of Dialect Prestige on Lexical Decision", ["Mairym Llorens Monteserin", "Jason Zevin"], "https://doi.org/10.21437/Interspeech.2016-1549", 5, "interspeech", 2016], ["Perceptual Lateralization of Coda Rhotic Production in Puerto Rican Spanish", ["Mairym Llorens Monteserin", "Shrikanth S. Narayanan", "Louis Goldstein"], "https://doi.org/10.21437/Interspeech.2016-1498", 5, "interspeech", 2016]], "Jason Zevin": [0, ["Investigating the Impact of Dialect Prestige on Lexical Decision", ["Mairym Llorens Monteserin", "Jason Zevin"], "https://doi.org/10.21437/Interspeech.2016-1549", 5, "interspeech", 2016]], "Deepak Muralidharan": [0, ["Speaker Verification Using Short Utterances with DNN-Based Estimation of Subglottal Acoustic Features", ["Jinxi Guo", "Gary Yeung", "Deepak Muralidharan", "Harish Arsikere", "Amber Afshan", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2016-282", 4, "interspeech", 2016]], "Harish Arsikere": [0, ["Speaker Verification Using Short Utterances with DNN-Based Estimation of Subglottal Acoustic Features", ["Jinxi Guo", "Gary Yeung", "Deepak Muralidharan", "Harish Arsikere", "Amber Afshan", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2016-282", 4, "interspeech", 2016]], "Amber Afshan": [0, ["Speaker Verification Using Short Utterances with DNN-Based Estimation of Subglottal Acoustic Features", ["Jinxi Guo", "Gary Yeung", "Deepak Muralidharan", "Harish Arsikere", "Amber Afshan", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2016-282", 4, "interspeech", 2016]], "Steven Wegmann": [0, ["Factor Analysis Based Speaker Verification Using ASR", ["Hang Su", "Steven Wegmann"], "https://doi.org/10.21437/Interspeech.2016-1157", 5, "interspeech", 2016], ["How Neural Network Depth Compensates for HMM Conditional Independence Assumptions in DNN-HMM Acoustic Models", ["Suman V. Ravuri", "Steven Wegmann"], "https://doi.org/10.21437/Interspeech.2016-283", 5, "interspeech", 2016]], "Jeroen Zegers": [0, ["Joint Sound Source Separation and Speaker Recognition", ["Jeroen Zegers", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2016-773", 5, "interspeech", 2016]], "Hugo Van hamme": [0, ["Joint Sound Source Separation and Speaker Recognition", ["Jeroen Zegers", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2016-773", 5, "interspeech", 2016]], "Naveen Kumar": [0, ["Robust Multichannel Gender Classification from Speech in Movie Audio", ["Naveen Kumar", "Md. Nasir", "Panayiotis G. Georgiou", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-540", 5, "interspeech", 2016]], "Xavi Gonzalvo": [0, ["Recent Advances in Google Real-Time HMM-Driven Unit Selection Synthesizer", ["Xavi Gonzalvo", "Siamak Tazari", "Chun-an Chan", "Markus Becker", "Alexander Gutkin", "Hanna Silen"], "https://doi.org/10.21437/Interspeech.2016-264", 5, "interspeech", 2016]], "Siamak Tazari": [0, ["Recent Advances in Google Real-Time HMM-Driven Unit Selection Synthesizer", ["Xavi Gonzalvo", "Siamak Tazari", "Chun-an Chan", "Markus Becker", "Alexander Gutkin", "Hanna Silen"], "https://doi.org/10.21437/Interspeech.2016-264", 5, "interspeech", 2016]], "Chun-an Chan": [0, ["Recent Advances in Google Real-Time HMM-Driven Unit Selection Synthesizer", ["Xavi Gonzalvo", "Siamak Tazari", "Chun-an Chan", "Markus Becker", "Alexander Gutkin", "Hanna Silen"], "https://doi.org/10.21437/Interspeech.2016-264", 5, "interspeech", 2016]], "Markus Becker": [0, ["Recent Advances in Google Real-Time HMM-Driven Unit Selection Synthesizer", ["Xavi Gonzalvo", "Siamak Tazari", "Chun-an Chan", "Markus Becker", "Alexander Gutkin", "Hanna Silen"], "https://doi.org/10.21437/Interspeech.2016-264", 5, "interspeech", 2016]], "Alexander Gutkin": [0, ["Recent Advances in Google Real-Time HMM-Driven Unit Selection Synthesizer", ["Xavi Gonzalvo", "Siamak Tazari", "Chun-an Chan", "Markus Becker", "Alexander Gutkin", "Hanna Silen"], "https://doi.org/10.21437/Interspeech.2016-264", 5, "interspeech", 2016]], "Hanna Silen": [0, ["Recent Advances in Google Real-Time HMM-Driven Unit Selection Synthesizer", ["Xavi Gonzalvo", "Siamak Tazari", "Chun-an Chan", "Markus Becker", "Alexander Gutkin", "Hanna Silen"], "https://doi.org/10.21437/Interspeech.2016-264", 5, "interspeech", 2016]], "Wenfu Wang": [1.7313902844762197e-07, ["First Step Towards End-to-End Parametric TTS Synthesis: Generating Spectral Parameters with Neural Attention", ["Wenfu Wang", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2016-134", 5, "interspeech", 2016], ["End-to-End Language Identification Using Attention-Based Recurrent Neural Networks", ["Wang Geng", "Wenfu Wang", "Yuanyuan Zhao", "Xinyuan Cai", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2016-686", 5, "interspeech", 2016], ["Gating Recurrent Enhanced Memory Neural Networks on Language Identification", ["Wang Geng", "Yuanyuan Zhao", "Wenfu Wang", "Xinyuan Cai", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2016-684", 5, "interspeech", 2016]], "Shuang Xu": [0, ["First Step Towards End-to-End Parametric TTS Synthesis: Generating Spectral Parameters with Neural Attention", ["Wenfu Wang", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2016-134", 5, "interspeech", 2016], ["Multidimensional Residual Learning Based on Recurrent Neural Networks for Acoustic Modeling", ["Yuanyuan Zhao", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2016-677", 5, "interspeech", 2016]], "Bo Xu": [0, ["First Step Towards End-to-End Parametric TTS Synthesis: Generating Spectral Parameters with Neural Attention", ["Wenfu Wang", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2016-134", 5, "interspeech", 2016], ["End-to-End Language Identification Using Attention-Based Recurrent Neural Networks", ["Wang Geng", "Wenfu Wang", "Yuanyuan Zhao", "Xinyuan Cai", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2016-686", 5, "interspeech", 2016], ["Gating Recurrent Enhanced Memory Neural Networks on Language Identification", ["Wang Geng", "Yuanyuan Zhao", "Wenfu Wang", "Xinyuan Cai", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2016-684", 5, "interspeech", 2016], ["Multidimensional Residual Learning Based on Recurrent Neural Networks for Acoustic Modeling", ["Yuanyuan Zhao", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2016-677", 5, "interspeech", 2016]], "Zhengqi Wen": [0, ["The Parameterized Phoneme Identity Feature as a Continuous Real-Valued Vector for Neural Network Based Speech Synthesis", ["Zhengqi Wen", "Ya Li", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2016-222", 5, "interspeech", 2016], ["Improving Prosodic Boundaries Prediction for Mandarin Speech Synthesis by Using Enhanced Embedding Feature and Model Fusion Approach", ["Yibin Zheng", "Ya Li", "Zhengqi Wen", "Xingguang Ding", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2016-1060", 5, "interspeech", 2016]], "Eunwoo Song": [0.9905647486448288, ["Improved Time-Frequency Trajectory Excitation Vocoder for DNN-Based Speech Synthesis", ["Eunwoo Song", "Frank K. Soong", "Hong-Goo Kang"], "https://doi.org/10.21437/Interspeech.2016-230", 5, "interspeech", 2016]], "Hong-Goo Kang": [1, ["Improved Time-Frequency Trajectory Excitation Vocoder for DNN-Based Speech Synthesis", ["Eunwoo Song", "Frank K. Soong", "Hong-Goo Kang"], "https://doi.org/10.21437/Interspeech.2016-230", 5, "interspeech", 2016]], "Yamato Ohtani": [0, ["Voice Quality Control Using Perceptual Expressions for Statistical Parametric Speech Synthesis Based on Cluster Adaptive Training", ["Yamato Ohtani", "Koichiro Mori", "Masahiro Morita"], "https://doi.org/10.21437/Interspeech.2016-290", 5, "interspeech", 2016]], "Koichiro Mori": [0, ["Voice Quality Control Using Perceptual Expressions for Statistical Parametric Speech Synthesis Based on Cluster Adaptive Training", ["Yamato Ohtani", "Koichiro Mori", "Masahiro Morita"], "https://doi.org/10.21437/Interspeech.2016-290", 5, "interspeech", 2016]], "Masahiro Morita": [0, ["Voice Quality Control Using Perceptual Expressions for Statistical Parametric Speech Synthesis Based on Cluster Adaptive Training", ["Yamato Ohtani", "Koichiro Mori", "Masahiro Morita"], "https://doi.org/10.21437/Interspeech.2016-290", 5, "interspeech", 2016]], "Simon King": [0, ["Waveform Generation Based on Signal Reshaping for Statistical Parametric Speech Synthesis", ["Felipe Espic", "Cassia Valentini-Botinhao", "Zhizheng Wu", "Simon King"], "https://doi.org/10.21437/Interspeech.2016-487", 5, "interspeech", 2016], ["The Use of Locally Normalized Cepstral Coefficients (LNCC) to Improve Speaker Recognition Accuracy in Highly Reverberant Rooms", ["Victor Poblete", "Juan Pablo Escudero", "Josue Fredes", "Jose Novoa", "Richard M. Stern", "Simon King", "Nestor Becerra Yoma"], "https://doi.org/10.21437/Interspeech.2016-1277", 5, "interspeech", 2016], ["A Template-Based Approach for Speech Synthesis Intonation Generation Using LSTMs", ["Srikanth Ronanki", "Gustav Eje Henter", "Zhizheng Wu", "Simon King"], "https://doi.org/10.21437/Interspeech.2016-96", 5, "interspeech", 2016], ["GlottDNN - A Full-Band Glottal Vocoder for Statistical Parametric Speech Synthesis", ["Manu Airaksinen", "Bajibabu Bollepalli", "Lauri Juvela", "Zhizheng Wu", "Simon King", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-342", 5, "interspeech", 2016]], "Yi Zhao": [0, ["Speaker Representations for Speaker Adaptation in Multiple Speakers' BLSTM-RNN-Based Speech Synthesis", ["Yi Zhao", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2016-506", 5, "interspeech", 2016]], "Heiga Zen": [0, ["Fast, Compact, and High Quality LSTM-RNN Based Statistical Parametric Speech Synthesizers for Mobile Devices", ["Heiga Zen", "Yannis Agiomyrgiannakis", "Niels Egberts", "Fergus Henderson", "Przemyslaw Szczepaniak"], "https://doi.org/10.21437/Interspeech.2016-522", 5, "interspeech", 2016], ["Multi-Language Multi-Speaker Acoustic Modeling for LSTM-RNN Based Statistical Parametric Speech Synthesis", ["Bo Li", "Heiga Zen"], "https://doi.org/10.21437/Interspeech.2016-172", 5, "interspeech", 2016]], "Yannis Agiomyrgiannakis": [0, ["Fast, Compact, and High Quality LSTM-RNN Based Statistical Parametric Speech Synthesizers for Mobile Devices", ["Heiga Zen", "Yannis Agiomyrgiannakis", "Niels Egberts", "Fergus Henderson", "Przemyslaw Szczepaniak"], "https://doi.org/10.21437/Interspeech.2016-522", 5, "interspeech", 2016]], "Niels Egberts": [0, ["Fast, Compact, and High Quality LSTM-RNN Based Statistical Parametric Speech Synthesizers for Mobile Devices", ["Heiga Zen", "Yannis Agiomyrgiannakis", "Niels Egberts", "Fergus Henderson", "Przemyslaw Szczepaniak"], "https://doi.org/10.21437/Interspeech.2016-522", 5, "interspeech", 2016]], "Fergus Henderson": [0, ["Fast, Compact, and High Quality LSTM-RNN Based Statistical Parametric Speech Synthesizers for Mobile Devices", ["Heiga Zen", "Yannis Agiomyrgiannakis", "Niels Egberts", "Fergus Henderson", "Przemyslaw Szczepaniak"], "https://doi.org/10.21437/Interspeech.2016-522", 5, "interspeech", 2016]], "Przemyslaw Szczepaniak": [0, ["Fast, Compact, and High Quality LSTM-RNN Based Statistical Parametric Speech Synthesizers for Mobile Devices", ["Heiga Zen", "Yannis Agiomyrgiannakis", "Niels Egberts", "Fergus Henderson", "Przemyslaw Szczepaniak"], "https://doi.org/10.21437/Interspeech.2016-522", 5, "interspeech", 2016]], "Nobukatsu Hojo": [0, ["An Investigation of DNN-Based Speech Synthesis Using Speaker Codes", ["Nobukatsu Hojo", "Yusuke Ijima", "Hideyuki Mizuno"], "https://doi.org/10.21437/Interspeech.2016-589", 5, "interspeech", 2016]], "Kentaro Tachibana": [0, ["Model Integration for HMM- and DNN-Based Speech Synthesis Using Product-of-Experts Framework", ["Kentaro Tachibana", "Tomoki Toda", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-1006", 5, "interspeech", 2016]], "Blaise Potard": [0, ["Idlak Tangle: An Open Source Kaldi Based Parametric Speech Synthesiser Based on DNN", ["Blaise Potard", "Matthew P. Aylett", "David A. Baude", "Petr Motlicek"], "https://doi.org/10.21437/Interspeech.2016-1188", 5, "interspeech", 2016]], "Matthew P. Aylett": [0, ["Idlak Tangle: An Open Source Kaldi Based Parametric Speech Synthesiser Based on DNN", ["Blaise Potard", "Matthew P. Aylett", "David A. Baude", "Petr Motlicek"], "https://doi.org/10.21437/Interspeech.2016-1188", 5, "interspeech", 2016]], "David A. Baude": [0, ["Idlak Tangle: An Open Source Kaldi Based Parametric Speech Synthesiser Based on DNN", ["Blaise Potard", "Matthew P. Aylett", "David A. Baude", "Petr Motlicek"], "https://doi.org/10.21437/Interspeech.2016-1188", 5, "interspeech", 2016]], "Chen-Yu Chiang": [0, ["On Smoothing and Enhancing Dynamics of Pitch Contours Represented by Discrete Orthogonal Polynomials for Prosody Generation", ["Chen-Yu Chiang"], "https://doi.org/10.21437/Interspeech.2016-409", 5, "interspeech", 2016]], "Anandaswarup Vadapalli": [0, ["An Investigation of Recurrent Neural Network Architectures Using Word Embeddings for Phrase Break Prediction", ["Anandaswarup Vadapalli", "Suryakanth V. Gangashetty"], "https://doi.org/10.21437/Interspeech.2016-885", 5, "interspeech", 2016]], "Hao Liu": [0, ["Model-Based Parametric Prosody Synthesis with Deep Neural Network", ["Hao Liu", "Heng Lu", "Xu Shao", "Yi Xu"], "https://doi.org/10.21437/Interspeech.2016-1325", 5, "interspeech", 2016]], "Heng Lu": [0, ["Model-Based Parametric Prosody Synthesis with Deep Neural Network", ["Hao Liu", "Heng Lu", "Xu Shao", "Yi Xu"], "https://doi.org/10.21437/Interspeech.2016-1325", 5, "interspeech", 2016]], "Xu Shao": [0, ["Model-Based Parametric Prosody Synthesis with Deep Neural Network", ["Hao Liu", "Heng Lu", "Xu Shao", "Yi Xu"], "https://doi.org/10.21437/Interspeech.2016-1325", 5, "interspeech", 2016]], "Yi Xu": [0, ["Model-Based Parametric Prosody Synthesis with Deep Neural Network", ["Hao Liu", "Heng Lu", "Xu Shao", "Yi Xu"], "https://doi.org/10.21437/Interspeech.2016-1325", 5, "interspeech", 2016]], "Thomas Drugman": [0, ["Active and Semi-Supervised Learning in ASR: Benefits on the Acoustic and Language Models", ["Thomas Drugman", "Janne Pylkkonen", "Reinhard Kneser"], "https://doi.org/10.21437/Interspeech.2016-1382", 5, "interspeech", 2016], ["Optimizing Speech Recognition Evaluation Using Stratified Sampling", ["Janne Pylkkonen", "Thomas Drugman", "Max Bisani"], "https://doi.org/10.21437/Interspeech.2016-1364", 5, "interspeech", 2016]], "Janne Pylkkonen": [0, ["Active and Semi-Supervised Learning in ASR: Benefits on the Acoustic and Language Models", ["Thomas Drugman", "Janne Pylkkonen", "Reinhard Kneser"], "https://doi.org/10.21437/Interspeech.2016-1382", 5, "interspeech", 2016], ["Optimizing Speech Recognition Evaluation Using Stratified Sampling", ["Janne Pylkkonen", "Thomas Drugman", "Max Bisani"], "https://doi.org/10.21437/Interspeech.2016-1364", 5, "interspeech", 2016]], "Reinhard Kneser": [0, ["Active and Semi-Supervised Learning in ASR: Benefits on the Acoustic and Language Models", ["Thomas Drugman", "Janne Pylkkonen", "Reinhard Kneser"], "https://doi.org/10.21437/Interspeech.2016-1382", 5, "interspeech", 2016]], "Vitaly Kuznetsov": [0, ["Learning N-Gram Language Models from Uncertain Data", ["Vitaly Kuznetsov", "Hank Liao", "Mehryar Mohri", "Michael Riley", "Brian Roark"], "https://doi.org/10.21437/Interspeech.2016-1093", 5, "interspeech", 2016]], "Hank Liao": [0, ["Learning N-Gram Language Models from Uncertain Data", ["Vitaly Kuznetsov", "Hank Liao", "Mehryar Mohri", "Michael Riley", "Brian Roark"], "https://doi.org/10.21437/Interspeech.2016-1093", 5, "interspeech", 2016]], "Mehryar Mohri": [0, ["Learning N-Gram Language Models from Uncertain Data", ["Vitaly Kuznetsov", "Hank Liao", "Mehryar Mohri", "Michael Riley", "Brian Roark"], "https://doi.org/10.21437/Interspeech.2016-1093", 5, "interspeech", 2016]], "Michael Riley": [0, ["Learning N-Gram Language Models from Uncertain Data", ["Vitaly Kuznetsov", "Hank Liao", "Mehryar Mohri", "Michael Riley", "Brian Roark"], "https://doi.org/10.21437/Interspeech.2016-1093", 5, "interspeech", 2016], ["Contextual Prediction Models for Speech Recognition", ["Yoni Halpern", "Keith B. Hall", "Vlad Schogol", "Michael Riley", "Brian Roark", "Gleb Skobeltsyn", "Martin Bauml"], "https://doi.org/10.21437/Interspeech.2016-1358", 5, "interspeech", 2016]], "Brian Roark": [0, ["Learning N-Gram Language Models from Uncertain Data", ["Vitaly Kuznetsov", "Hank Liao", "Mehryar Mohri", "Michael Riley", "Brian Roark"], "https://doi.org/10.21437/Interspeech.2016-1093", 5, "interspeech", 2016], ["Contextual Prediction Models for Speech Recognition", ["Yoni Halpern", "Keith B. Hall", "Vlad Schogol", "Michael Riley", "Brian Roark", "Gleb Skobeltsyn", "Martin Bauml"], "https://doi.org/10.21437/Interspeech.2016-1358", 5, "interspeech", 2016]], "Barlas Oguz": [0, ["Entropy Based Pruning for Non-Negative Matrix Based Language Models with Contextual Features", ["Barlas Oguz", "Issac Alphonso", "Shuangyu Chang"], "https://doi.org/10.21437/Interspeech.2016-130", 5, "interspeech", 2016]], "Issac Alphonso": [0, ["Entropy Based Pruning for Non-Negative Matrix Based Language Models with Contextual Features", ["Barlas Oguz", "Issac Alphonso", "Shuangyu Chang"], "https://doi.org/10.21437/Interspeech.2016-130", 5, "interspeech", 2016]], "Shuangyu Chang": [3.845395468715651e-07, ["Entropy Based Pruning for Non-Negative Matrix Based Language Models with Contextual Features", ["Barlas Oguz", "Issac Alphonso", "Shuangyu Chang"], "https://doi.org/10.21437/Interspeech.2016-130", 5, "interspeech", 2016], ["Word-Phrase-Entity Recurrent Neural Networks for Language Modeling", ["Michael Levit", "Sarangarajan Parthasarathy", "Shuangyu Chang"], "https://doi.org/10.21437/Interspeech.2016-44", 5, "interspeech", 2016]], "Siva Reddy Gangireddy": [0, ["Unsupervised Adaptation of Recurrent Neural Network Language Models", ["Siva Reddy Gangireddy", "Pawel Swietojanski", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-1342", 5, "interspeech", 2016]], "Pawel Swietojanski": [0, ["Unsupervised Adaptation of Recurrent Neural Network Language Models", ["Siva Reddy Gangireddy", "Pawel Swietojanski", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-1342", 5, "interspeech", 2016]], "Yoni Halpern": [0, ["Contextual Prediction Models for Speech Recognition", ["Yoni Halpern", "Keith B. Hall", "Vlad Schogol", "Michael Riley", "Brian Roark", "Gleb Skobeltsyn", "Martin Bauml"], "https://doi.org/10.21437/Interspeech.2016-1358", 5, "interspeech", 2016]], "Keith B. Hall": [0, ["Contextual Prediction Models for Speech Recognition", ["Yoni Halpern", "Keith B. Hall", "Vlad Schogol", "Michael Riley", "Brian Roark", "Gleb Skobeltsyn", "Martin Bauml"], "https://doi.org/10.21437/Interspeech.2016-1358", 5, "interspeech", 2016]], "Vlad Schogol": [0, ["Contextual Prediction Models for Speech Recognition", ["Yoni Halpern", "Keith B. Hall", "Vlad Schogol", "Michael Riley", "Brian Roark", "Gleb Skobeltsyn", "Martin Bauml"], "https://doi.org/10.21437/Interspeech.2016-1358", 5, "interspeech", 2016]], "Gleb Skobeltsyn": [0, ["Contextual Prediction Models for Speech Recognition", ["Yoni Halpern", "Keith B. Hall", "Vlad Schogol", "Michael Riley", "Brian Roark", "Gleb Skobeltsyn", "Martin Bauml"], "https://doi.org/10.21437/Interspeech.2016-1358", 5, "interspeech", 2016]], "Martin Bauml": [0, ["Contextual Prediction Models for Speech Recognition", ["Yoni Halpern", "Keith B. Hall", "Vlad Schogol", "Michael Riley", "Brian Roark", "Gleb Skobeltsyn", "Martin Bauml"], "https://doi.org/10.21437/Interspeech.2016-1358", 5, "interspeech", 2016]], "Michael C. Brady": [0, ["A Low Cost Desktop Robot and Tele-Presence Device for Interactive Speech Research", ["Michael C. Brady"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2022.html", 2, "interspeech", 2016]], "Simon Stone": [0, ["Silent-Speech Command Word Recognition Using Electro-Optical Stomatography", ["Simon Stone", "Peter Birkholz"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2005.html", 2, "interspeech", 2016]], "Pavel Ircing": [0, ["An Engine for Online Video Search in Large Archives of the Holocaust Testimonies", ["Petr Stanislav", "Jan Svec", "Pavel Ircing"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/2016.html", 2, "interspeech", 2016]], "Piero Cosi": [0, ["MIVOQ-PTTS - A Revolutionary New Way of Thinking TTS", ["Piero Cosi", "Giulio Paci", "Giacomo Sommavilla", "Fabio Tesser"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/cosi.html", 2, "interspeech", 2016]], "Giulio Paci": [0, ["MIVOQ-PTTS - A Revolutionary New Way of Thinking TTS", ["Piero Cosi", "Giulio Paci", "Giacomo Sommavilla", "Fabio Tesser"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/cosi.html", 2, "interspeech", 2016]], "Giacomo Sommavilla": [0, ["MIVOQ-PTTS - A Revolutionary New Way of Thinking TTS", ["Piero Cosi", "Giulio Paci", "Giacomo Sommavilla", "Fabio Tesser"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/cosi.html", 2, "interspeech", 2016]], "Fabio Tesser": [0, ["MIVOQ-PTTS - A Revolutionary New Way of Thinking TTS", ["Piero Cosi", "Giulio Paci", "Giacomo Sommavilla", "Fabio Tesser"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/cosi.html", 2, "interspeech", 2016]], "Katerina Zmolikova": [0, ["Data Selection by Sequence Summarizing Neural Network in Mismatch Condition Training", ["Katerina Zmolikova", "Martin Karafiat", "Karel Vesely", "Marc Delcroix", "Shinji Watanabe", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-741", 5, "interspeech", 2016]], "Martin Karafiat": [0, ["Data Selection by Sequence Summarizing Neural Network in Mismatch Condition Training", ["Katerina Zmolikova", "Martin Karafiat", "Karel Vesely", "Marc Delcroix", "Shinji Watanabe", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-741", 5, "interspeech", 2016]], "Karel Vesely": [0, ["Data Selection by Sequence Summarizing Neural Network in Mismatch Condition Training", ["Katerina Zmolikova", "Martin Karafiat", "Karel Vesely", "Marc Delcroix", "Shinji Watanabe", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-741", 5, "interspeech", 2016]], "Souvik Kundu": [0, ["Incorporating a Generative Front-End Layer to Deep Neural Network for Noise Robust Automatic Speech Recognition", ["Souvik Kundu", "Khe Chai Sim", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2016-760", 5, "interspeech", 2016]], "Konstantin Markov": [0, ["Robust Speech Recognition Using Generalized Distillation Framework", ["Konstantin Markov", "Tomoko Matsui"], "https://doi.org/10.21437/Interspeech.2016-852", 5, "interspeech", 2016]], "Tomoko Matsui": [0, ["Robust Speech Recognition Using Generalized Distillation Framework", ["Konstantin Markov", "Tomoko Matsui"], "https://doi.org/10.21437/Interspeech.2016-852", 5, "interspeech", 2016]], "Yusuke Shinohara": [0, ["Adversarial Multi-Task Learning of Deep Neural Networks for Robust Speech Recognition", ["Yusuke Shinohara"], "https://doi.org/10.21437/Interspeech.2016-879", 4, "interspeech", 2016]], "Victor Poblete": [0, ["The Use of Locally Normalized Cepstral Coefficients (LNCC) to Improve Speaker Recognition Accuracy in Highly Reverberant Rooms", ["Victor Poblete", "Juan Pablo Escudero", "Josue Fredes", "Jose Novoa", "Richard M. Stern", "Simon King", "Nestor Becerra Yoma"], "https://doi.org/10.21437/Interspeech.2016-1277", 5, "interspeech", 2016]], "Juan Pablo Escudero": [0, ["The Use of Locally Normalized Cepstral Coefficients (LNCC) to Improve Speaker Recognition Accuracy in Highly Reverberant Rooms", ["Victor Poblete", "Juan Pablo Escudero", "Josue Fredes", "Jose Novoa", "Richard M. Stern", "Simon King", "Nestor Becerra Yoma"], "https://doi.org/10.21437/Interspeech.2016-1277", 5, "interspeech", 2016]], "Josue Fredes": [0, ["The Use of Locally Normalized Cepstral Coefficients (LNCC) to Improve Speaker Recognition Accuracy in Highly Reverberant Rooms", ["Victor Poblete", "Juan Pablo Escudero", "Josue Fredes", "Jose Novoa", "Richard M. Stern", "Simon King", "Nestor Becerra Yoma"], "https://doi.org/10.21437/Interspeech.2016-1277", 5, "interspeech", 2016]], "Jose Novoa": [0, ["The Use of Locally Normalized Cepstral Coefficients (LNCC) to Improve Speaker Recognition Accuracy in Highly Reverberant Rooms", ["Victor Poblete", "Juan Pablo Escudero", "Josue Fredes", "Jose Novoa", "Richard M. Stern", "Simon King", "Nestor Becerra Yoma"], "https://doi.org/10.21437/Interspeech.2016-1277", 5, "interspeech", 2016]], "Richard M. Stern": [0, ["The Use of Locally Normalized Cepstral Coefficients (LNCC) to Improve Speaker Recognition Accuracy in Highly Reverberant Rooms", ["Victor Poblete", "Juan Pablo Escudero", "Josue Fredes", "Jose Novoa", "Richard M. Stern", "Simon King", "Nestor Becerra Yoma"], "https://doi.org/10.21437/Interspeech.2016-1277", 5, "interspeech", 2016], ["Fusion Strategies for Robust Speech Recognition and Keyword Spotting for Channel- and Noise-Degraded Speech", ["Vikramjit Mitra", "Julien van Hout", "Wen Wang", "Chris Bartels", "Horacio Franco", "Dimitra Vergyri", "Abeer Alwan", "Adam Janin", "John H. L. Hansen", "Richard M. Stern", "Abhijeet Sangwan", "Nelson Morgan"], "https://doi.org/10.21437/Interspeech.2016-279", 5, "interspeech", 2016]], "Nestor Becerra Yoma": [0, ["The Use of Locally Normalized Cepstral Coefficients (LNCC) to Improve Speaker Recognition Accuracy in Highly Reverberant Rooms", ["Victor Poblete", "Juan Pablo Escudero", "Josue Fredes", "Jose Novoa", "Richard M. Stern", "Simon King", "Nestor Becerra Yoma"], "https://doi.org/10.21437/Interspeech.2016-1277", 5, "interspeech", 2016]], "Tim Ng": [0, ["Two-Stage Data Augmentation for Low-Resourced Speech Recognition", ["William Hartmann", "Tim Ng", "Roger Hsiao", "Stavros Tsakalidis", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-1386", 5, "interspeech", 2016], ["Sage: The New BBN Speech Processing Platform", ["Roger Hsiao", "Ralf Meermeier", "Tim Ng", "Zhongqiang Huang", "Maxwell Jordan", "Enoch Kan", "Tanel Alumae", "Jan Silovsky", "William Hartmann", "Francis Keith", "Omer Lang", "Man-Hung Siu", "Owen Kimball"], "https://doi.org/10.21437/Interspeech.2016-1031", 5, "interspeech", 2016]], "Avni Rajpal": [0, ["Native Language Identification Using Spectral and Source-Based Features", ["Avni Rajpal", "Tanvina B. Patel", "Hardik B. Sailor", "Maulik C. Madhavi", "Hemant A. Patil", "Hiroya Fujisaki"], "https://doi.org/10.21437/Interspeech.2016-1100", 5, "interspeech", 2016]], "Hardik B. Sailor": [0, ["Native Language Identification Using Spectral and Source-Based Features", ["Avni Rajpal", "Tanvina B. Patel", "Hardik B. Sailor", "Maulik C. Madhavi", "Hemant A. Patil", "Hiroya Fujisaki"], "https://doi.org/10.21437/Interspeech.2016-1100", 5, "interspeech", 2016], ["Unsupervised Deep Auditory Model Using Stack of Convolutional RBMs for Speech Recognition", ["Hardik B. Sailor", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2016-812", 5, "interspeech", 2016]], "Maulik C. Madhavi": [0, ["Native Language Identification Using Spectral and Source-Based Features", ["Avni Rajpal", "Tanvina B. Patel", "Hardik B. Sailor", "Maulik C. Madhavi", "Hemant A. Patil", "Hiroya Fujisaki"], "https://doi.org/10.21437/Interspeech.2016-1100", 5, "interspeech", 2016]], "Hiroya Fujisaki": [0, ["Native Language Identification Using Spectral and Source-Based Features", ["Avni Rajpal", "Tanvina B. Patel", "Hardik B. Sailor", "Maulik C. Madhavi", "Hemant A. Patil", "Hiroya Fujisaki"], "https://doi.org/10.21437/Interspeech.2016-1100", 5, "interspeech", 2016]], "Yishan Jiao": [0, ["Accent Identification by Combining Deep Neural Networks and Recurrent Neural Networks Trained on Long and Short Term Features", ["Yishan Jiao", "Ming Tu", "Visar Berisha", "Julie M. Liss"], "https://doi.org/10.21437/Interspeech.2016-1148", 5, "interspeech", 2016]], "Ming Tu": [0, ["Accent Identification by Combining Deep Neural Networks and Recurrent Neural Networks Trained on Long and Short Term Features", ["Yishan Jiao", "Ming Tu", "Visar Berisha", "Julie M. Liss"], "https://doi.org/10.21437/Interspeech.2016-1148", 5, "interspeech", 2016]], "Julie M. Liss": [0, ["Accent Identification by Combining Deep Neural Networks and Recurrent Neural Networks Trained on Long and Short Term Features", ["Yishan Jiao", "Ming Tu", "Visar Berisha", "Julie M. Liss"], "https://doi.org/10.21437/Interspeech.2016-1148", 5, "interspeech", 2016]], "Gil Keren": [0, ["Convolutional Neural Networks with Data Augmentation for Classifying Speakers' Native Language", ["Gil Keren", "Jun Deng", "Jouni Pohjalainen", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-261", 5, "interspeech", 2016]], "Jun Deng": [0, ["Convolutional Neural Networks with Data Augmentation for Classifying Speakers' Native Language", ["Gil Keren", "Jun Deng", "Jouni Pohjalainen", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-261", 5, "interspeech", 2016], ["Facing Realism in Spontaneous Emotion Recognition from Speech: Feature Enhancement by Autoencoder with LSTM Neural Networks", ["Zixing Zhang", "Fabien Ringeval", "Jing Han", "Jun Deng", "Erik Marchi", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-998", 5, "interspeech", 2016]], "Mohammed Senoussaoui": [0, ["Native Language Detection Using the I-Vector Framework", ["Mohammed Senoussaoui", "Patrick Cardinal", "Najim Dehak", "Alessandro L. Koerich"], "https://doi.org/10.21437/Interspeech.2016-1473", 5, "interspeech", 2016]], "Patrick Cardinal": [0, ["Native Language Detection Using the I-Vector Framework", ["Mohammed Senoussaoui", "Patrick Cardinal", "Najim Dehak", "Alessandro L. Koerich"], "https://doi.org/10.21437/Interspeech.2016-1473", 5, "interspeech", 2016], ["Automatic Dialect Detection in Arabic Broadcast Speech", ["Ahmed M. Ali", "Najim Dehak", "Patrick Cardinal", "Sameer Khurana", "Sree Harsha Yella", "James R. Glass", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-1297", 5, "interspeech", 2016]], "Najim Dehak": [0, ["Native Language Detection Using the I-Vector Framework", ["Mohammed Senoussaoui", "Patrick Cardinal", "Najim Dehak", "Alessandro L. Koerich"], "https://doi.org/10.21437/Interspeech.2016-1473", 5, "interspeech", 2016], ["Automatic Dialect Detection in Arabic Broadcast Speech", ["Ahmed M. Ali", "Najim Dehak", "Patrick Cardinal", "Sameer Khurana", "Sree Harsha Yella", "James R. Glass", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-1297", 5, "interspeech", 2016], ["Exploiting Hidden-Layer Responses of Deep Neural Networks for Language Recognition", ["Ruizhi Li", "Sri Harish Reddy Mallidi", "Lukas Burget", "Oldrich Plchot", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2016-1584", 5, "interspeech", 2016]], "Alessandro L. Koerich": [0, ["Native Language Detection Using the I-Vector Framework", ["Mohammed Senoussaoui", "Patrick Cardinal", "Najim Dehak", "Alessandro L. Koerich"], "https://doi.org/10.21437/Interspeech.2016-1473", 5, "interspeech", 2016]], "Mark Huckvale": [0, ["Within-Speaker Features for Native Language Recognition in the Interspeech 2016 Computational Paralinguistics Challenge", ["Mark Huckvale"], "https://doi.org/10.21437/Interspeech.2016-1466", 5, "interspeech", 2016]], "Prashanth Gurunath Shivakumar": [0, ["Multimodal Fusion of Multirate Acoustic, Prosodic, and Lexical Speaker Characteristics for Native Language Identification", ["Prashanth Gurunath Shivakumar", "Sandeep Nallan Chakravarthula", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2016-1312", 5, "interspeech", 2016], ["Perception Optimized Deep Denoising AutoEncoders for Speech Enhancement", ["Prashanth Gurunath Shivakumar", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2016-1284", 5, "interspeech", 2016]], "Alberto Abad": [0, ["Exploiting Phone Log-Likelihood Ratio Features for the Detection of the Native Language of Non-Native English Speakers", ["Alberto Abad", "Eugenio Ribeiro", "Fabio Kepler", "Ramon Fernandez Astudillo", "Isabel Trancoso"], "https://doi.org/10.21437/Interspeech.2016-1491", 5, "interspeech", 2016]], "Eugenio Ribeiro": [0, ["Exploiting Phone Log-Likelihood Ratio Features for the Detection of the Native Language of Non-Native English Speakers", ["Alberto Abad", "Eugenio Ribeiro", "Fabio Kepler", "Ramon Fernandez Astudillo", "Isabel Trancoso"], "https://doi.org/10.21437/Interspeech.2016-1491", 5, "interspeech", 2016]], "Fabio Kepler": [0, ["Exploiting Phone Log-Likelihood Ratio Features for the Detection of the Native Language of Non-Native English Speakers", ["Alberto Abad", "Eugenio Ribeiro", "Fabio Kepler", "Ramon Fernandez Astudillo", "Isabel Trancoso"], "https://doi.org/10.21437/Interspeech.2016-1491", 5, "interspeech", 2016]], "Ramon Fernandez Astudillo": [0, ["Exploiting Phone Log-Likelihood Ratio Features for the Detection of the Native Language of Non-Native English Speakers", ["Alberto Abad", "Eugenio Ribeiro", "Fabio Kepler", "Ramon Fernandez Astudillo", "Isabel Trancoso"], "https://doi.org/10.21437/Interspeech.2016-1491", 5, "interspeech", 2016]], "Isabel Trancoso": [0, ["Exploiting Phone Log-Likelihood Ratio Features for the Detection of the Native Language of Non-Native English Speakers", ["Alberto Abad", "Eugenio Ribeiro", "Fabio Kepler", "Ramon Fernandez Astudillo", "Isabel Trancoso"], "https://doi.org/10.21437/Interspeech.2016-1491", 5, "interspeech", 2016]], "Robert Busa-Fekete": [0, ["Determining Native Language and Deception Using Phonetic Features and Classifier Combination", ["Gabor Gosztolya", "Tamas Grosz", "Robert Busa-Fekete", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2016-962", 5, "interspeech", 2016]], "Marija Tabain": [0, ["A Preliminary Ultrasound Study of Nasal and Lateral Coronals in Arrernte", ["Marija Tabain", "Richard Beare"], "https://doi.org/10.21437/Interspeech.2016-568", 5, "interspeech", 2016]], "Richard Beare": [0, ["A Preliminary Ultrasound Study of Nasal and Lateral Coronals in Arrernte", ["Marija Tabain", "Richard Beare"], "https://doi.org/10.21437/Interspeech.2016-568", 5, "interspeech", 2016]], "Jangwon Kim": [0.9735527485609055, ["Illustrating the Production of the International Phonetic Alphabet Sounds Using Fast Real-Time Magnetic Resonance Imaging", ["Asterios Toutios", "Sajan Goud Lingala", "Colin Vaz", "Jangwon Kim", "John H. Esling", "Patricia A. Keating", "Matthew Gordon", "Dani Byrd", "Louis Goldstein", "Krishna S. Nayak", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-605", 5, "interspeech", 2016]], "John H. Esling": [0, ["Illustrating the Production of the International Phonetic Alphabet Sounds Using Fast Real-Time Magnetic Resonance Imaging", ["Asterios Toutios", "Sajan Goud Lingala", "Colin Vaz", "Jangwon Kim", "John H. Esling", "Patricia A. Keating", "Matthew Gordon", "Dani Byrd", "Louis Goldstein", "Krishna S. Nayak", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-605", 5, "interspeech", 2016]], "Matthew Gordon": [0, ["Illustrating the Production of the International Phonetic Alphabet Sounds Using Fast Real-Time Magnetic Resonance Imaging", ["Asterios Toutios", "Sajan Goud Lingala", "Colin Vaz", "Jangwon Kim", "John H. Esling", "Patricia A. Keating", "Matthew Gordon", "Dani Byrd", "Louis Goldstein", "Krishna S. Nayak", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-605", 5, "interspeech", 2016]], "Dani Byrd": [0, ["Illustrating the Production of the International Phonetic Alphabet Sounds Using Fast Real-Time Magnetic Resonance Imaging", ["Asterios Toutios", "Sajan Goud Lingala", "Colin Vaz", "Jangwon Kim", "John H. Esling", "Patricia A. Keating", "Matthew Gordon", "Dani Byrd", "Louis Goldstein", "Krishna S. Nayak", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-605", 5, "interspeech", 2016]], "Margaret E. L. Renwick": [0, ["Marginal Contrast Among Romanian Vowels: Evidence from ASR and Functional Load", ["Margaret E. L. Renwick", "Ioana Vasilescu", "Camille Dutrey", "Lori Lamel", "Bianca Vieru"], "https://doi.org/10.21437/Interspeech.2016-762", 5, "interspeech", 2016]], "Ioana Vasilescu": [0, ["Marginal Contrast Among Romanian Vowels: Evidence from ASR and Functional Load", ["Margaret E. L. Renwick", "Ioana Vasilescu", "Camille Dutrey", "Lori Lamel", "Bianca Vieru"], "https://doi.org/10.21437/Interspeech.2016-762", 5, "interspeech", 2016]], "Camille Dutrey": [0, ["Marginal Contrast Among Romanian Vowels: Evidence from ASR and Functional Load", ["Margaret E. L. Renwick", "Ioana Vasilescu", "Camille Dutrey", "Lori Lamel", "Bianca Vieru"], "https://doi.org/10.21437/Interspeech.2016-762", 5, "interspeech", 2016]], "Bianca Vieru": [0, ["Marginal Contrast Among Romanian Vowels: Evidence from ASR and Functional Load", ["Margaret E. L. Renwick", "Ioana Vasilescu", "Camille Dutrey", "Lori Lamel", "Bianca Vieru"], "https://doi.org/10.21437/Interspeech.2016-762", 5, "interspeech", 2016]], "Shuanglin Fan": [0, ["Effects of Subglottal-Coupling and Interdental-Space on Formant Trajectories During Front-to-Back Vowel Transitions in Chinese", ["Shuanglin Fan", "Kiyoshi Honda", "Jianwu Dang", "Hui Feng"], "https://doi.org/10.21437/Interspeech.2016-1054", 5, "interspeech", 2016]], "Kiyoshi Honda": [0, ["Effects of Subglottal-Coupling and Interdental-Space on Formant Trajectories During Front-to-Back Vowel Transitions in Chinese", ["Shuanglin Fan", "Kiyoshi Honda", "Jianwu Dang", "Hui Feng"], "https://doi.org/10.21437/Interspeech.2016-1054", 5, "interspeech", 2016]], "Jianwu Dang": [0, ["Effects of Subglottal-Coupling and Interdental-Space on Formant Trajectories During Front-to-Back Vowel Transitions in Chinese", ["Shuanglin Fan", "Kiyoshi Honda", "Jianwu Dang", "Hui Feng"], "https://doi.org/10.21437/Interspeech.2016-1054", 5, "interspeech", 2016], ["A New Model for Acoustic Wave Propagation and Scattering in the Vocal Tract", ["Jianguo Wei", "Wendan Guan", "Darcy Q. Hou", "Dingyi Pan", "Wenhuan Lu", "Jianwu Dang"], "https://doi.org/10.21437/Interspeech.2016-1513", 5, "interspeech", 2016]], "Hui Feng": [0, ["Effects of Subglottal-Coupling and Interdental-Space on Formant Trajectories During Front-to-Back Vowel Transitions in Chinese", ["Shuanglin Fan", "Kiyoshi Honda", "Jianwu Dang", "Hui Feng"], "https://doi.org/10.21437/Interspeech.2016-1054", 5, "interspeech", 2016]], "Hao Yi": [0.05930126644670963, ["Interaction Between Lexical Tone and Intonation: An EMA Study", ["Hao Yi", "Sam Tilsen"], "https://doi.org/10.21437/Interspeech.2016-662", 5, "interspeech", 2016]], "Sam Tilsen": [0, ["Interaction Between Lexical Tone and Intonation: An EMA Study", ["Hao Yi", "Sam Tilsen"], "https://doi.org/10.21437/Interspeech.2016-662", 5, "interspeech", 2016]], "Huaiping Ming": [0, ["Deep Bidirectional LSTM Modeling of Timbre and Prosody for Emotional Voice Conversion", ["Huaiping Ming", "Dong-Yan Huang", "Lei Xie", "Jie Wu", "Minghui Dong", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-1053", 5, "interspeech", 2016]], "Dong-Yan Huang": [0, ["Deep Bidirectional LSTM Modeling of Timbre and Prosody for Emotional Voice Conversion", ["Huaiping Ming", "Dong-Yan Huang", "Lei Xie", "Jie Wu", "Minghui Dong", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-1053", 5, "interspeech", 2016]], "Jie Wu": [0.031336840242147446, ["Deep Bidirectional LSTM Modeling of Timbre and Prosody for Emotional Voice Conversion", ["Huaiping Ming", "Dong-Yan Huang", "Lei Xie", "Jie Wu", "Minghui Dong", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-1053", 5, "interspeech", 2016]], "Ausdang Thangthai": [0, ["Visual Speech Synthesis Using Dynamic Visemes, Contextual Features and DNNs", ["Ausdang Thangthai", "Ben Milner", "Sarah Taylor"], "https://doi.org/10.21437/Interspeech.2016-1084", 5, "interspeech", 2016]], "Ben Milner": [0, ["Visual Speech Synthesis Using Dynamic Visemes, Contextual Features and DNNs", ["Ausdang Thangthai", "Ben Milner", "Sarah Taylor"], "https://doi.org/10.21437/Interspeech.2016-1084", 5, "interspeech", 2016]], "Srikanth Ronanki": [0, ["A Template-Based Approach for Speech Synthesis Intonation Generation Using LSTMs", ["Srikanth Ronanki", "Gustav Eje Henter", "Zhizheng Wu", "Simon King"], "https://doi.org/10.21437/Interspeech.2016-96", 5, "interspeech", 2016]], "Bajibabu Bollepalli": [0, ["GlottDNN - A Full-Band Glottal Vocoder for Statistical Parametric Speech Synthesis", ["Manu Airaksinen", "Bajibabu Bollepalli", "Lauri Juvela", "Zhizheng Wu", "Simon King", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-342", 5, "interspeech", 2016]], "Masanari Nishimura": [0, ["Singing Voice Synthesis Based on Deep Neural Networks", ["Masanari Nishimura", "Kei Hashimoto", "Keiichiro Oura", "Yoshihiko Nankaku", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-1027", 5, "interspeech", 2016]], "Florin Ghido": [0, ["Blind Recovery of Perceptual Models in Distributed Speech and Audio Coding", ["Tom Backstrom", "Florin Ghido", "Johannes Fischer"], "https://doi.org/10.21437/Interspeech.2016-27", 5, "interspeech", 2016]], "Friedemann Koster": [0, ["Analyzing the Relation Between Overall Quality and the Quality of Individual Phases in a Telephone Conversation", ["Friedemann Koster", "Sebastian Moller"], "https://doi.org/10.21437/Interspeech.2016-255", 5, "interspeech", 2016]], "Sebastian Moller": [0, ["Analyzing the Relation Between Overall Quality and the Quality of Individual Phases in a Telephone Conversation", ["Friedemann Koster", "Sebastian Moller"], "https://doi.org/10.21437/Interspeech.2016-255", 5, "interspeech", 2016]], "Emma Jokinen": [0, ["Intelligibility Enhancement at the Receiving End of the Speech Transmission System - Effects of Far-End Noise Reduction", ["Emma Jokinen", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-144", 5, "interspeech", 2016], ["The Use of Read versus Conversational Lombard Speech in Spectral Tilt Modeling for Intelligibility Enhancement in Near-End Noise Conditions", ["Emma Jokinen", "Ulpu Remes", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-143", 5, "interspeech", 2016], ["Discussion", ["Dayana Ribas", "Emmanuel Vincent", "John H. L. Hansen", "Emma Jokinen", "Mirco Ravanelli", "Hannes Gamper", "Fred Richardson"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs14.html", 0, "interspeech", 2016]], "Marjoke Bakker": [0, ["Intelligibility of Disordered Speech: Global and Detailed Scores", ["Mario Ganzeboom", "Marjoke Bakker", "Catia Cucchiarini", "Helmer Strik"], "https://doi.org/10.21437/Interspeech.2016-1448", 5, "interspeech", 2016]], "Maria Koutsogiannaki": [0, ["Modulation Enhancement of Temporal Envelopes for Increasing Speech Intelligibility in Noise", ["Maria Koutsogiannaki", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2016-500", 5, "interspeech", 2016]], "Jan Niehues": [0, ["Dynamic Transcription for Low-Latency Speech Translation", ["Jan Niehues", "Thai Son Nguyen", "Eunah Cho", "Thanh-Le Ha", "Kevin Kilgour", "Markus Muller", "Matthias Sperber", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-154", 5, "interspeech", 2016]], "Thai Son Nguyen": [0, ["Dynamic Transcription for Low-Latency Speech Translation", ["Jan Niehues", "Thai Son Nguyen", "Eunah Cho", "Thanh-Le Ha", "Kevin Kilgour", "Markus Muller", "Matthias Sperber", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-154", 5, "interspeech", 2016]], "Eunah Cho": [0.5, ["Dynamic Transcription for Low-Latency Speech Translation", ["Jan Niehues", "Thai Son Nguyen", "Eunah Cho", "Thanh-Le Ha", "Kevin Kilgour", "Markus Muller", "Matthias Sperber", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-154", 5, "interspeech", 2016]], "Thanh-Le Ha": [1.1013308665042132e-06, ["Dynamic Transcription for Low-Latency Speech Translation", ["Jan Niehues", "Thai Son Nguyen", "Eunah Cho", "Thanh-Le Ha", "Kevin Kilgour", "Markus Muller", "Matthias Sperber", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-154", 5, "interspeech", 2016]], "Kevin Kilgour": [0, ["Dynamic Transcription for Low-Latency Speech Translation", ["Jan Niehues", "Thai Son Nguyen", "Eunah Cho", "Thanh-Le Ha", "Kevin Kilgour", "Markus Muller", "Matthias Sperber", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-154", 5, "interspeech", 2016]], "Markus Muller": [0, ["Dynamic Transcription for Low-Latency Speech Translation", ["Jan Niehues", "Thai Son Nguyen", "Eunah Cho", "Thanh-Le Ha", "Kevin Kilgour", "Markus Muller", "Matthias Sperber", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-154", 5, "interspeech", 2016], ["Unsupervised Phoneme Segmentation of Previously Unseen Languages", ["Marco Vetter", "Markus Muller", "Fatima Hamlaoui", "Graham Neubig", "Satoshi Nakamura", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-1440", 5, "interspeech", 2016], ["Language Adaptive DNNs for Improved Low Resource Speech Recognition", ["Markus Muller", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-1143", 5, "interspeech", 2016]], "Matthias Sperber": [0, ["Dynamic Transcription for Low-Latency Speech Translation", ["Jan Niehues", "Thai Son Nguyen", "Eunah Cho", "Thanh-Le Ha", "Kevin Kilgour", "Markus Muller", "Matthias Sperber", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-154", 5, "interspeech", 2016]], "Sebastian Stuker": [0, ["Dynamic Transcription for Low-Latency Speech Translation", ["Jan Niehues", "Thai Son Nguyen", "Eunah Cho", "Thanh-Le Ha", "Kevin Kilgour", "Markus Muller", "Matthias Sperber", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-154", 5, "interspeech", 2016], ["Unsupervised Phoneme Segmentation of Previously Unseen Languages", ["Marco Vetter", "Markus Muller", "Fatima Hamlaoui", "Graham Neubig", "Satoshi Nakamura", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-1440", 5, "interspeech", 2016], ["Language Adaptive DNNs for Improved Low Resource Speech Recognition", ["Markus Muller", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-1143", 5, "interspeech", 2016]], "Alex Waibel": [0, ["Dynamic Transcription for Low-Latency Speech Translation", ["Jan Niehues", "Thai Son Nguyen", "Eunah Cho", "Thanh-Le Ha", "Kevin Kilgour", "Markus Muller", "Matthias Sperber", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-154", 5, "interspeech", 2016], ["Unsupervised Phoneme Segmentation of Previously Unseen Languages", ["Marco Vetter", "Markus Muller", "Fatima Hamlaoui", "Graham Neubig", "Satoshi Nakamura", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-1440", 5, "interspeech", 2016], ["Language Adaptive DNNs for Improved Low Resource Speech Recognition", ["Markus Muller", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-1143", 5, "interspeech", 2016]], "Oliver Adams": [0, ["Learning a Translation Model from Word Lattices", ["Oliver Adams", "Graham Neubig", "Trevor Cohn", "Steven Bird"], "https://doi.org/10.21437/Interspeech.2016-862", 5, "interspeech", 2016]], "Graham Neubig": [0, ["Learning a Translation Model from Word Lattices", ["Oliver Adams", "Graham Neubig", "Trevor Cohn", "Steven Bird"], "https://doi.org/10.21437/Interspeech.2016-862", 5, "interspeech", 2016], ["Transferring Emphasis in Speech Translation Using Hard-Attentional Neural Network Models", ["Quoc Truong Do", "Sakriani Sakti", "Graham Neubig", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-898", 5, "interspeech", 2016], ["Unsupervised Joint Estimation of Grapheme-to-Phoneme Conversion Systems and Acoustic Model Adaptation for Non-Native Speech Recognition", ["Satoshi Tsujioka", "Sakriani Sakti", "Koichiro Yoshino", "Graham Neubig", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-919", 5, "interspeech", 2016], ["A Hybrid System for Continuous Word-Level Emphasis Modeling Based on HMM State Clustering and Adaptive Training", ["Quoc Truong Do", "Tomoki Toda", "Graham Neubig", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-930", 5, "interspeech", 2016], ["Unsupervised Phoneme Segmentation of Previously Unseen Languages", ["Marco Vetter", "Markus Muller", "Fatima Hamlaoui", "Graham Neubig", "Satoshi Nakamura", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-1440", 5, "interspeech", 2016]], "Trevor Cohn": [0, ["Learning a Translation Model from Word Lattices", ["Oliver Adams", "Graham Neubig", "Trevor Cohn", "Steven Bird"], "https://doi.org/10.21437/Interspeech.2016-862", 5, "interspeech", 2016]], "Steven Bird": [0, ["Learning a Translation Model from Word Lattices", ["Oliver Adams", "Graham Neubig", "Trevor Cohn", "Steven Bird"], "https://doi.org/10.21437/Interspeech.2016-862", 5, "interspeech", 2016]], "Vicky Zayats": [0, ["Disfluency Detection Using a Bidirectional LSTM", ["Vicky Zayats", "Mari Ostendorf", "Hannaneh Hajishirzi"], "https://doi.org/10.21437/Interspeech.2016-1247", 5, "interspeech", 2016]], "Hannaneh Hajishirzi": [0, ["Disfluency Detection Using a Bidirectional LSTM", ["Vicky Zayats", "Mari Ostendorf", "Hannaneh Hajishirzi"], "https://doi.org/10.21437/Interspeech.2016-1247", 5, "interspeech", 2016]], "Xiaoyin Che": [0, ["Sentence Boundary Detection Based on Parallel Lexical and Acoustic Models", ["Xiaoyin Che", "Sheng Luo", "Haojin Yang", "Christoph Meinel"], "https://doi.org/10.21437/Interspeech.2016-257", 5, "interspeech", 2016]], "Sheng Luo": [0, ["Sentence Boundary Detection Based on Parallel Lexical and Acoustic Models", ["Xiaoyin Che", "Sheng Luo", "Haojin Yang", "Christoph Meinel"], "https://doi.org/10.21437/Interspeech.2016-257", 5, "interspeech", 2016]], "Haojin Yang": [0.039444051682949066, ["Sentence Boundary Detection Based on Parallel Lexical and Acoustic Models", ["Xiaoyin Che", "Sheng Luo", "Haojin Yang", "Christoph Meinel"], "https://doi.org/10.21437/Interspeech.2016-257", 5, "interspeech", 2016]], "Christoph Meinel": [0, ["Sentence Boundary Detection Based on Parallel Lexical and Acoustic Models", ["Xiaoyin Che", "Sheng Luo", "Haojin Yang", "Christoph Meinel"], "https://doi.org/10.21437/Interspeech.2016-257", 5, "interspeech", 2016]], "Quoc Truong Do": [3.3253068470995815e-14, ["Transferring Emphasis in Speech Translation Using Hard-Attentional Neural Network Models", ["Quoc Truong Do", "Sakriani Sakti", "Graham Neubig", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-898", 5, "interspeech", 2016], ["A Hybrid System for Continuous Word-Level Emphasis Modeling Based on HMM State Clustering and Adaptive Training", ["Quoc Truong Do", "Tomoki Toda", "Graham Neubig", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-930", 5, "interspeech", 2016]], "Ngoc-Tien Le": [0, ["Better Evaluation of ASR in Speech Translation Context Using Word Embeddings", ["Ngoc-Tien Le", "Christophe Servan", "Benjamin Lecouteux", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2016-464", 5, "interspeech", 2016]], "Christophe Servan": [0, ["Better Evaluation of ASR in Speech Translation Context Using Word Embeddings", ["Ngoc-Tien Le", "Christophe Servan", "Benjamin Lecouteux", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2016-464", 5, "interspeech", 2016]], "Benjamin Lecouteux": [0, ["Better Evaluation of ASR in Speech Translation Context Using Word Embeddings", ["Ngoc-Tien Le", "Christophe Servan", "Benjamin Lecouteux", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2016-464", 5, "interspeech", 2016]], "Srikanth Korse": [0, ["Entropy Coding of Spectral Envelopes for Speech and Audio Coding Using Distribution Quantization", ["Srikanth Korse", "Tobias Jahnel", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2016-55", 5, "interspeech", 2016]], "Tobias Jahnel": [0, ["Entropy Coding of Spectral Envelopes for Speech and Audio Coding Using Distribution Quantization", ["Srikanth Korse", "Tobias Jahnel", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2016-55", 5, "interspeech", 2016]], "Stephane Villette": [0, ["An Objective Evaluation Methodology for Blind Bandwidth Extension", ["Stephane Villette", "Sen Li", "Pravin Ramadas", "Daniel J. Sinder"], "https://doi.org/10.21437/Interspeech.2016-1595", 5, "interspeech", 2016]], "Sen Li": [0, ["An Objective Evaluation Methodology for Blind Bandwidth Extension", ["Stephane Villette", "Sen Li", "Pravin Ramadas", "Daniel J. Sinder"], "https://doi.org/10.21437/Interspeech.2016-1595", 5, "interspeech", 2016]], "Pravin Ramadas": [0, ["An Objective Evaluation Methodology for Blind Bandwidth Extension", ["Stephane Villette", "Sen Li", "Pravin Ramadas", "Daniel J. Sinder"], "https://doi.org/10.21437/Interspeech.2016-1595", 5, "interspeech", 2016]], "Daniel J. Sinder": [0, ["An Objective Evaluation Methodology for Blind Bandwidth Extension", ["Stephane Villette", "Sen Li", "Pravin Ramadas", "Daniel J. Sinder"], "https://doi.org/10.21437/Interspeech.2016-1595", 5, "interspeech", 2016]], "Anssi Ramo": [0, ["EVS Channel Aware Mode Robustness to Frame Erasures", ["Anssi Ramo", "Antti Kurittu", "Henri Toukomaa"], "https://doi.org/10.21437/Interspeech.2016-917", 5, "interspeech", 2016]], "Antti Kurittu": [0, ["EVS Channel Aware Mode Robustness to Frame Erasures", ["Anssi Ramo", "Antti Kurittu", "Henri Toukomaa"], "https://doi.org/10.21437/Interspeech.2016-917", 5, "interspeech", 2016]], "Henri Toukomaa": [0, ["EVS Channel Aware Mode Robustness to Frame Erasures", ["Anssi Ramo", "Antti Kurittu", "Henri Toukomaa"], "https://doi.org/10.21437/Interspeech.2016-917", 5, "interspeech", 2016]], "Shadi Pirhosseinloo": [0, ["An Interaural Magnification Algorithm for Enhancement of Naturally-Occurring Level Differences", ["Shadi Pirhosseinloo", "Kostas Kokkinakis"], "https://doi.org/10.21437/Interspeech.2016-1049", 4, "interspeech", 2016]], "Kostas Kokkinakis": [0, ["An Interaural Magnification Algorithm for Enhancement of Naturally-Occurring Level Differences", ["Shadi Pirhosseinloo", "Kostas Kokkinakis"], "https://doi.org/10.21437/Interspeech.2016-1049", 4, "interspeech", 2016]], "Niko Moritz": [0, ["Probabilistic Spatial Filter Estimation for Signal Enhancement in Multi-Channel Automatic Speech Recognition", ["Hendrik Kayser", "Niko Moritz", "Jorn Anemuller"], "https://doi.org/10.21437/Interspeech.2016-1340", 5, "interspeech", 2016]], "Jorn Anemuller": [0, ["Probabilistic Spatial Filter Estimation for Signal Enhancement in Multi-Channel Automatic Speech Recognition", ["Hendrik Kayser", "Niko Moritz", "Jorn Anemuller"], "https://doi.org/10.21437/Interspeech.2016-1340", 5, "interspeech", 2016]], "Youna Ji": [0.6857354044914246, ["Improved a priori SAP Estimator in Complex Noisy Environment for Dual Channel Microphone System", ["Youna Ji", "Young-Cheol Park"], "https://doi.org/10.21437/Interspeech.2016-894", 5, "interspeech", 2016]], "Young-Cheol Park": [0.9999881982803345, ["Improved a priori SAP Estimator in Complex Noisy Environment for Dual Channel Microphone System", ["Youna Ji", "Young-Cheol Park"], "https://doi.org/10.21437/Interspeech.2016-894", 5, "interspeech", 2016]], "Kah-Meng Cheong": [1.947809687408153e-05, ["A Spectral Modulation Sensitivity Weighted Pre-Emphasis Filter for Active Noise Control System", ["Kah-Meng Cheong", "Yuh-Yuan Wang", "Tai-Shih Chi"], "https://doi.org/10.21437/Interspeech.2016-757", 5, "interspeech", 2016]], "Yuh-Yuan Wang": [0.018843684811145067, ["A Spectral Modulation Sensitivity Weighted Pre-Emphasis Filter for Active Noise Control System", ["Kah-Meng Cheong", "Yuh-Yuan Wang", "Tai-Shih Chi"], "https://doi.org/10.21437/Interspeech.2016-757", 5, "interspeech", 2016]], "Ganji Sreeram": [0, ["Semi-Coupled Dictionary Based Automatic Bandwidth Extension Approach for Enhancing Children's ASR", ["Ganji Sreeram", "Rohit Sinha"], "https://doi.org/10.21437/Interspeech.2016-798", 5, "interspeech", 2016]], "Rohit Sinha": [0, ["Semi-Coupled Dictionary Based Automatic Bandwidth Extension Approach for Enhancing Children's ASR", ["Ganji Sreeram", "Rohit Sinha"], "https://doi.org/10.21437/Interspeech.2016-798", 5, "interspeech", 2016], ["Pitch-Adaptive Front-End Features for Robust Children's ASR", ["Syed Shahnawazuddin", "Abhishek Dey", "Rohit Sinha"], "https://doi.org/10.21437/Interspeech.2016-1020", 5, "interspeech", 2016]], "Robert Lachlan": [0, ["Bird Song Synthesis Based on Hidden Markov Models", ["Jordi Bonada", "Robert Lachlan", "Merlijn Blaauw"], "https://doi.org/10.21437/Interspeech.2016-1110", 5, "interspeech", 2016]], "Kantapon Kaewtip": [0, ["Noise-Robust Hidden Markov Models for Limited Training Data for Within-Species Bird Phrase Classification", ["Kantapon Kaewtip", "Charles E. Taylor", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2016-1360", 5, "interspeech", 2016]], "Charles E. Taylor": [0, ["Noise-Robust Hidden Markov Models for Limited Training Data for Within-Species Bird Phrase Classification", ["Kantapon Kaewtip", "Charles E. Taylor", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2016-1360", 5, "interspeech", 2016]], "Alan Wisler": [0, ["A Framework for Automated Marmoset Vocalization Detection and Classification", ["Alan Wisler", "Laura J. Brattain", "Rogier Landman", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2016-1410", 5, "interspeech", 2016]], "Laura J. Brattain": [0, ["A Framework for Automated Marmoset Vocalization Detection and Classification", ["Alan Wisler", "Laura J. Brattain", "Rogier Landman", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2016-1410", 5, "interspeech", 2016]], "Rogier Landman": [0, ["A Framework for Automated Marmoset Vocalization Detection and Classification", ["Alan Wisler", "Laura J. Brattain", "Rogier Landman", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2016-1410", 5, "interspeech", 2016]], "Ikkyu Aihara": [0, ["Call Alternation Between Specific Pairs of Male Frogs Revealed by a Sound-Imaging Method in Their Natural Habitat", ["Ikkyu Aihara", "Takeshi Mizumoto", "Hiromitsu Awano", "Hiroshi G. Okuno"], "https://doi.org/10.21437/Interspeech.2016-336", 5, "interspeech", 2016]], "Takeshi Mizumoto": [0, ["Call Alternation Between Specific Pairs of Male Frogs Revealed by a Sound-Imaging Method in Their Natural Habitat", ["Ikkyu Aihara", "Takeshi Mizumoto", "Hiromitsu Awano", "Hiroshi G. Okuno"], "https://doi.org/10.21437/Interspeech.2016-336", 5, "interspeech", 2016]], "Hiromitsu Awano": [0, ["Call Alternation Between Specific Pairs of Male Frogs Revealed by a Sound-Imaging Method in Their Natural Habitat", ["Ikkyu Aihara", "Takeshi Mizumoto", "Hiromitsu Awano", "Hiroshi G. Okuno"], "https://doi.org/10.21437/Interspeech.2016-336", 5, "interspeech", 2016]], "Hiroshi G. Okuno": [0, ["Call Alternation Between Specific Pairs of Male Frogs Revealed by a Sound-Imaging Method in Their Natural Habitat", ["Ikkyu Aihara", "Takeshi Mizumoto", "Hiromitsu Awano", "Hiroshi G. Okuno"], "https://doi.org/10.21437/Interspeech.2016-336", 5, "interspeech", 2016], ["Localizing Bird Songs Using an Open Source Robot Audition System with a Microphone Array", ["Reiji Suzuki", "Shiho Matsubayashi", "Kazuhiro Nakadai", "Hiroshi G. Okuno"], "https://doi.org/10.21437/Interspeech.2016-782", 5, "interspeech", 2016]], "Patrice Guyot": [0, ["Sinusoidal Modelling for Ecoacoustics", ["Patrice Guyot", "Alice Eldridge", "Ying Chen Eyre-Walker", "Alison Johnston", "Thomas Pellegrini", "Mika Peck"], "https://doi.org/10.21437/Interspeech.2016-361", 5, "interspeech", 2016]], "Alice Eldridge": [0, ["Sinusoidal Modelling for Ecoacoustics", ["Patrice Guyot", "Alice Eldridge", "Ying Chen Eyre-Walker", "Alison Johnston", "Thomas Pellegrini", "Mika Peck"], "https://doi.org/10.21437/Interspeech.2016-361", 5, "interspeech", 2016]], "Ying Chen Eyre-Walker": [0, ["Sinusoidal Modelling for Ecoacoustics", ["Patrice Guyot", "Alice Eldridge", "Ying Chen Eyre-Walker", "Alison Johnston", "Thomas Pellegrini", "Mika Peck"], "https://doi.org/10.21437/Interspeech.2016-361", 5, "interspeech", 2016]], "Alison Johnston": [0, ["Sinusoidal Modelling for Ecoacoustics", ["Patrice Guyot", "Alice Eldridge", "Ying Chen Eyre-Walker", "Alison Johnston", "Thomas Pellegrini", "Mika Peck"], "https://doi.org/10.21437/Interspeech.2016-361", 5, "interspeech", 2016]], "Mika Peck": [0, ["Sinusoidal Modelling for Ecoacoustics", ["Patrice Guyot", "Alice Eldridge", "Ying Chen Eyre-Walker", "Alison Johnston", "Thomas Pellegrini", "Mika Peck"], "https://doi.org/10.21437/Interspeech.2016-361", 5, "interspeech", 2016]], "Dan Stowell": [0, ["Individual Identity in Songbirds: Signal Representations and Metric Learning for Locating the Information in Complex Corvid Calls", ["Dan Stowell", "Veronica Morfi", "Lisa F. Gill"], "https://doi.org/10.21437/Interspeech.2016-465", 5, "interspeech", 2016]], "Veronica Morfi": [0, ["Individual Identity in Songbirds: Signal Representations and Metric Learning for Locating the Information in Complex Corvid Calls", ["Dan Stowell", "Veronica Morfi", "Lisa F. Gill"], "https://doi.org/10.21437/Interspeech.2016-465", 5, "interspeech", 2016]], "Lisa F. Gill": [0, ["Individual Identity in Songbirds: Signal Representations and Metric Learning for Locating the Information in Complex Corvid Calls", ["Dan Stowell", "Veronica Morfi", "Lisa F. Gill"], "https://doi.org/10.21437/Interspeech.2016-465", 5, "interspeech", 2016]], "Munevver Kokuer": [0, ["Recognition of Multiple Bird Species Based on Penalised Maximum Likelihood and HMM-Based Modelling of Individual Vocalisation Elements", ["Peter Jancovic", "Munevver Kokuer"], "https://doi.org/10.21437/Interspeech.2016-669", 5, "interspeech", 2016]], "Ciira Wa Maina": [0, ["Cost Effective Acoustic Monitoring of Bird Species", ["Ciira Wa Maina"], "https://doi.org/10.21437/Interspeech.2016-746", 4, "interspeech", 2016]], "Daniel Kohlsdorf": [0, ["Feature Learning and Automatic Segmentation for Dolphin Communication Analysis", ["Daniel Kohlsdorf", "Denise Herzing", "Thad Starner"], "https://doi.org/10.21437/Interspeech.2016-748", 5, "interspeech", 2016]], "Denise Herzing": [0, ["Feature Learning and Automatic Segmentation for Dolphin Communication Analysis", ["Daniel Kohlsdorf", "Denise Herzing", "Thad Starner"], "https://doi.org/10.21437/Interspeech.2016-748", 5, "interspeech", 2016]], "Thad Starner": [0, ["Feature Learning and Automatic Segmentation for Dolphin Communication Analysis", ["Daniel Kohlsdorf", "Denise Herzing", "Thad Starner"], "https://doi.org/10.21437/Interspeech.2016-748", 5, "interspeech", 2016]], "Reiji Suzuki": [0, ["Localizing Bird Songs Using an Open Source Robot Audition System with a Microphone Array", ["Reiji Suzuki", "Shiho Matsubayashi", "Kazuhiro Nakadai", "Hiroshi G. Okuno"], "https://doi.org/10.21437/Interspeech.2016-782", 5, "interspeech", 2016]], "Shiho Matsubayashi": [0, ["Localizing Bird Songs Using an Open Source Robot Audition System with a Microphone Array", ["Reiji Suzuki", "Shiho Matsubayashi", "Kazuhiro Nakadai", "Hiroshi G. Okuno"], "https://doi.org/10.21437/Interspeech.2016-782", 5, "interspeech", 2016]], "Kazuhiro Nakadai": [0, ["Localizing Bird Songs Using an Open Source Robot Audition System with a Microphone Array", ["Reiji Suzuki", "Shiho Matsubayashi", "Kazuhiro Nakadai", "Hiroshi G. Okuno"], "https://doi.org/10.21437/Interspeech.2016-782", 5, "interspeech", 2016]], "Frank Kurth": [0, ["Robust Detection of Multiple Bioacoustic Events with Repetitive Structures", ["Frank Kurth"], "https://doi.org/10.21437/Interspeech.2016-83", 5, "interspeech", 2016]], "Roger K. Moore": [0, ["A Real-Time Parametric General-Purpose Mammalian Vocal Synthesiser", ["Roger K. Moore"], "https://doi.org/10.21437/Interspeech.2016-841", 5, "interspeech", 2016], ["Progress and Prospects for Spoken Language Technology: What Ordinary People Think", ["Roger K. Moore", "Hui Li", "Shih-Hao Liao"], "https://doi.org/10.21437/Interspeech.2016-874", 5, "interspeech", 2016], ["Progress and Prospects for Spoken Language Technology: Results from Four Sexennial Surveys", ["Roger K. Moore", "Ricard Marxer"], "https://doi.org/10.21437/Interspeech.2016-948", 5, "interspeech", 2016]], "Colm OReilly": [0, ["YIN-Bird: Improved Pitch Tracking for Bird Vocalisations", ["Colm OReilly", "Nicola M. Marples", "David J. Kelly", "Naomi Harte"], "https://doi.org/10.21437/Interspeech.2016-90", 5, "interspeech", 2016]], "Nicola M. Marples": [0, ["YIN-Bird: Improved Pitch Tracking for Bird Vocalisations", ["Colm OReilly", "Nicola M. Marples", "David J. Kelly", "Naomi Harte"], "https://doi.org/10.21437/Interspeech.2016-90", 5, "interspeech", 2016]], "David J. Kelly": [0, ["YIN-Bird: Improved Pitch Tracking for Bird Vocalisations", ["Colm OReilly", "Nicola M. Marples", "David J. Kelly", "Naomi Harte"], "https://doi.org/10.21437/Interspeech.2016-90", 5, "interspeech", 2016]], "Yao-Chi Hsu": [0, ["Mispronunciation Detection Leveraging Maximum Performance Criterion Training of Acoustic Models and Decision Functions", ["Yao-Chi Hsu", "Ming-Han Yang", "Hsiao-Tsung Hung", "Berlin Chen"], "https://doi.org/10.21437/Interspeech.2016-1602", 5, "interspeech", 2016]], "Ming-Han Yang": [0.0139719326980412, ["Mispronunciation Detection Leveraging Maximum Performance Criterion Training of Acoustic Models and Decision Functions", ["Yao-Chi Hsu", "Ming-Han Yang", "Hsiao-Tsung Hung", "Berlin Chen"], "https://doi.org/10.21437/Interspeech.2016-1602", 5, "interspeech", 2016]], "Hsiao-Tsung Hung": [0, ["Mispronunciation Detection Leveraging Maximum Performance Criterion Training of Acoustic Models and Decision Functions", ["Yao-Chi Hsu", "Ming-Han Yang", "Hsiao-Tsung Hung", "Berlin Chen"], "https://doi.org/10.21437/Interspeech.2016-1602", 5, "interspeech", 2016]], "Andy McMillin": [0, ["Using Clinician Annotations to Improve Automatic Speech Recognition of Stuttered Speech", ["Peter A. Heeman", "Rebecca Lunsford", "Andy McMillin", "J. Scott Yaruss"], "https://doi.org/10.21437/Interspeech.2016-1388", 5, "interspeech", 2016]], "J. Scott Yaruss": [0, ["Using Clinician Annotations to Improve Automatic Speech Recognition of Stuttered Speech", ["Peter A. Heeman", "Rebecca Lunsford", "Andy McMillin", "J. Scott Yaruss"], "https://doi.org/10.21437/Interspeech.2016-1388", 5, "interspeech", 2016]], "Simin Xie": [0, ["Deep Neural Networks for Voice Quality Assessment Based on the GRBAS Scale", ["Simin Xie", "Nan Yan", "Ping Yu", "Manwa L. Ng", "Lan Wang", "Zhuanzhuan Ji"], "https://doi.org/10.21437/Interspeech.2016-986", 5, "interspeech", 2016]], "Ping Yu": [4.002336663688766e-05, ["Deep Neural Networks for Voice Quality Assessment Based on the GRBAS Scale", ["Simin Xie", "Nan Yan", "Ping Yu", "Manwa L. Ng", "Lan Wang", "Zhuanzhuan Ji"], "https://doi.org/10.21437/Interspeech.2016-986", 5, "interspeech", 2016]], "Lauren Ward": [0, ["Automated Screening of Speech Development Issues in Children by Identifying Phonological Error Patterns", ["Lauren Ward", "Alessandro Stefani", "Daniel Smith", "Andreas Duenser", "Jill Freyne", "Barbara Dodd", "Angela Morgan"], "https://doi.org/10.21437/Interspeech.2016-850", 5, "interspeech", 2016]], "Alessandro Stefani": [0, ["Automated Screening of Speech Development Issues in Children by Identifying Phonological Error Patterns", ["Lauren Ward", "Alessandro Stefani", "Daniel Smith", "Andreas Duenser", "Jill Freyne", "Barbara Dodd", "Angela Morgan"], "https://doi.org/10.21437/Interspeech.2016-850", 5, "interspeech", 2016]], "Daniel Smith": [0, ["Automated Screening of Speech Development Issues in Children by Identifying Phonological Error Patterns", ["Lauren Ward", "Alessandro Stefani", "Daniel Smith", "Andreas Duenser", "Jill Freyne", "Barbara Dodd", "Angela Morgan"], "https://doi.org/10.21437/Interspeech.2016-850", 5, "interspeech", 2016]], "Andreas Duenser": [0, ["Automated Screening of Speech Development Issues in Children by Identifying Phonological Error Patterns", ["Lauren Ward", "Alessandro Stefani", "Daniel Smith", "Andreas Duenser", "Jill Freyne", "Barbara Dodd", "Angela Morgan"], "https://doi.org/10.21437/Interspeech.2016-850", 5, "interspeech", 2016]], "Jill Freyne": [0, ["Automated Screening of Speech Development Issues in Children by Identifying Phonological Error Patterns", ["Lauren Ward", "Alessandro Stefani", "Daniel Smith", "Andreas Duenser", "Jill Freyne", "Barbara Dodd", "Angela Morgan"], "https://doi.org/10.21437/Interspeech.2016-850", 5, "interspeech", 2016]], "Barbara Dodd": [0, ["Automated Screening of Speech Development Issues in Children by Identifying Phonological Error Patterns", ["Lauren Ward", "Alessandro Stefani", "Daniel Smith", "Andreas Duenser", "Jill Freyne", "Barbara Dodd", "Angela Morgan"], "https://doi.org/10.21437/Interspeech.2016-850", 5, "interspeech", 2016]], "Angela Morgan": [0, ["Automated Screening of Speech Development Issues in Children by Identifying Phonological Error Patterns", ["Lauren Ward", "Alessandro Stefani", "Daniel Smith", "Andreas Duenser", "Jill Freyne", "Barbara Dodd", "Angela Morgan"], "https://doi.org/10.21437/Interspeech.2016-850", 5, "interspeech", 2016]], "Ju Lin": [0, ["Automatic Pronunciation Evaluation of Non-Native Mandarin Tone by Using Multi-Level Confidence Measures", ["Ju Lin", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2016-1162", 5, "interspeech", 2016]], "Yanlu Xie": [0, ["Automatic Pronunciation Evaluation of Non-Native Mandarin Tone by Using Multi-Level Confidence Measures", ["Ju Lin", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2016-1162", 5, "interspeech", 2016]], "Jinsong Zhang": [0, ["Automatic Pronunciation Evaluation of Non-Native Mandarin Tone by Using Multi-Level Confidence Measures", ["Ju Lin", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2016-1162", 5, "interspeech", 2016]], "Myung Jong Kim": [0.9044822454452515, ["Dysarthric Speech Recognition Using Kullback-Leibler Divergence-Based Hidden Markov Model", ["Myung Jong Kim", "Jun Wang", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2016-776", 5, "interspeech", 2016]], "Hoirin Kim": [0.12472091987729073, ["Dysarthric Speech Recognition Using Kullback-Leibler Divergence-Based Hidden Markov Model", ["Myung Jong Kim", "Jun Wang", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2016-776", 5, "interspeech", 2016], ["Speaker Normalization Through Feature Shifting of Linearly Transformed i-Vector", ["Jahyun Goo", "Younggwan Kim", "Hyungjun Lim", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2016-819", 5, "interspeech", 2016]], "Heather L. Ramsdell-Hudock": [0, ["Detection of Total Syllables and Canonical Syllables in Infant Vocalizations", ["Anne S. Warlaumont", "Heather L. Ramsdell-Hudock"], "https://doi.org/10.21437/Interspeech.2016-1518", 5, "interspeech", 2016]], "Duc Le": [0, ["Improving Automatic Recognition of Aphasic Speech with AphasiaBank", ["Duc Le", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2016-213", 5, "interspeech", 2016]], "Vincent Laborde": [0, ["Pronunciation Assessment of Japanese Learners of French with GOP Scores and Phonetic Information", ["Vincent Laborde", "Thomas Pellegrini", "Lionel Fontan", "Julie Mauclair", "Halima Sahraoui", "Jerome Farinas"], "https://doi.org/10.21437/Interspeech.2016-513", 5, "interspeech", 2016]], "Julie Mauclair": [0, ["Pronunciation Assessment of Japanese Learners of French with GOP Scores and Phonetic Information", ["Vincent Laborde", "Thomas Pellegrini", "Lionel Fontan", "Julie Mauclair", "Halima Sahraoui", "Jerome Farinas"], "https://doi.org/10.21437/Interspeech.2016-513", 5, "interspeech", 2016]], "Halima Sahraoui": [0, ["Pronunciation Assessment of Japanese Learners of French with GOP Scores and Phonetic Information", ["Vincent Laborde", "Thomas Pellegrini", "Lionel Fontan", "Julie Mauclair", "Halima Sahraoui", "Jerome Farinas"], "https://doi.org/10.21437/Interspeech.2016-513", 5, "interspeech", 2016]], "Sean Robertson": [0, ["Pronunciation Error Detection for New Language Learners", ["Sean Robertson", "Cosmin Munteanu", "Gerald Penn"], "https://doi.org/10.21437/Interspeech.2016-539", 5, "interspeech", 2016]], "Cosmin Munteanu": [0, ["Pronunciation Error Detection for New Language Learners", ["Sean Robertson", "Cosmin Munteanu", "Gerald Penn"], "https://doi.org/10.21437/Interspeech.2016-539", 5, "interspeech", 2016]], "Gerald Penn": [0, ["Pronunciation Error Detection for New Language Learners", ["Sean Robertson", "Cosmin Munteanu", "Gerald Penn"], "https://doi.org/10.21437/Interspeech.2016-539", 5, "interspeech", 2016]], "Hongwei Ding": [0, ["L2 English Rhythm in Read Speech by Chinese Students", ["Hongwei Ding", "Xinping Xu"], "https://doi.org/10.21437/Interspeech.2016-427", 5, "interspeech", 2016]], "Xinping Xu": [0, ["L2 English Rhythm in Read Speech by Chinese Students", ["Hongwei Ding", "Xinping Xu"], "https://doi.org/10.21437/Interspeech.2016-427", 5, "interspeech", 2016]], "Miao Li": [0, ["Improving the Probabilistic Framework for Representing Dialogue Systems with User Response Model", ["Miao Li", "Zhipeng Chen", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2016-810", 5, "interspeech", 2016], ["Target-Based State and Tracking Algorithm for Spoken Dialogue System", ["Miao Li", "Zhiyang He", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2016-800", 5, "interspeech", 2016]], "Yiping Song": [7.76787434375592e-08, ["Dialogue Session Segmentation by Embedding-Enhanced TextTiling", ["Yiping Song", "Lili Mou", "Rui Yan", "Li Yi", "Zinan Zhu", "Xiaohua Hu", "Ming Zhang"], "https://doi.org/10.21437/Interspeech.2016-1234", 5, "interspeech", 2016]], "Lili Mou": [0, ["Dialogue Session Segmentation by Embedding-Enhanced TextTiling", ["Yiping Song", "Lili Mou", "Rui Yan", "Li Yi", "Zinan Zhu", "Xiaohua Hu", "Ming Zhang"], "https://doi.org/10.21437/Interspeech.2016-1234", 5, "interspeech", 2016]], "Rui Yan": [0, ["Dialogue Session Segmentation by Embedding-Enhanced TextTiling", ["Yiping Song", "Lili Mou", "Rui Yan", "Li Yi", "Zinan Zhu", "Xiaohua Hu", "Ming Zhang"], "https://doi.org/10.21437/Interspeech.2016-1234", 5, "interspeech", 2016]], "Li Yi": [0.0002926277811639011, ["Dialogue Session Segmentation by Embedding-Enhanced TextTiling", ["Yiping Song", "Lili Mou", "Rui Yan", "Li Yi", "Zinan Zhu", "Xiaohua Hu", "Ming Zhang"], "https://doi.org/10.21437/Interspeech.2016-1234", 5, "interspeech", 2016]], "Zinan Zhu": [0, ["Dialogue Session Segmentation by Embedding-Enhanced TextTiling", ["Yiping Song", "Lili Mou", "Rui Yan", "Li Yi", "Zinan Zhu", "Xiaohua Hu", "Ming Zhang"], "https://doi.org/10.21437/Interspeech.2016-1234", 5, "interspeech", 2016]], "Xiaohua Hu": [0, ["Dialogue Session Segmentation by Embedding-Enhanced TextTiling", ["Yiping Song", "Lili Mou", "Rui Yan", "Li Yi", "Zinan Zhu", "Xiaohua Hu", "Ming Zhang"], "https://doi.org/10.21437/Interspeech.2016-1234", 5, "interspeech", 2016]], "Ming Zhang": [0, ["Dialogue Session Segmentation by Embedding-Enhanced TextTiling", ["Yiping Song", "Lili Mou", "Rui Yan", "Li Yi", "Zinan Zhu", "Xiaohua Hu", "Ming Zhang"], "https://doi.org/10.21437/Interspeech.2016-1234", 5, "interspeech", 2016]], "Zhiyang He": [0, ["Target-Based State and Tracking Algorithm for Spoken Dialogue System", ["Miao Li", "Zhiyang He", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2016-800", 5, "interspeech", 2016]], "Sheng-syun Shen": [0, ["Neural Attention Models for Sequence Classification: Analysis and Application to Key Term Extraction and Dialogue Act Detection", ["Sheng-syun Shen", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2016-1359", 5, "interspeech", 2016], ["Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine", ["Bo-Hsiang Tseng", "Sheng-syun Shen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2016-876", 5, "interspeech", 2016]], "Manoj Kumar": [0, ["Objective Language Feature Analysis in Children with Neurodevelopmental Disorders During Autism Assessment", ["Manoj Kumar", "Rahul Gupta", "Daniel Bone", "Nikolaos Malandrakis", "Somer Bishop", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-563", 5, "interspeech", 2016]], "Nikolaos Malandrakis": [0, ["Objective Language Feature Analysis in Children with Neurodevelopmental Disorders During Autism Assessment", ["Manoj Kumar", "Rahul Gupta", "Daniel Bone", "Nikolaos Malandrakis", "Somer Bishop", "Shrikanth S. Narayanan"], "https://doi.org/10.21437/Interspeech.2016-563", 5, "interspeech", 2016]], "Inigo Casanueva": [0, ["Improving Generalisation to New Speakers in Spoken Dialogue State Tracking", ["Inigo Casanueva", "Thomas Hain", "Phil D. Green"], "https://doi.org/10.21437/Interspeech.2016-404", 5, "interspeech", 2016]], "Bo-Hsiang Tseng": [0, ["Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine", ["Bo-Hsiang Tseng", "Sheng-syun Shen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2016-876", 5, "interspeech", 2016]], "Suman V. Ravuri": [0, ["How Neural Network Depth Compensates for HMM Conditional Independence Assumptions in DNN-HMM Acoustic Models", ["Suman V. Ravuri", "Steven Wegmann"], "https://doi.org/10.21437/Interspeech.2016-283", 5, "interspeech", 2016]], "Dimitri Palaz": [0, ["Jointly Learning to Locate and Classify Words Using Convolutional Networks", ["Dimitri Palaz", "Gabriel Synnaeve", "Ronan Collobert"], "https://doi.org/10.21437/Interspeech.2016-968", 5, "interspeech", 2016]], "Ronan Collobert": [0, ["Jointly Learning to Locate and Classify Words Using Convolutional Networks", ["Dimitri Palaz", "Gabriel Synnaeve", "Ronan Collobert"], "https://doi.org/10.21437/Interspeech.2016-968", 5, "interspeech", 2016]], "Raziel Alvarez": [0, ["On the Efficient Representation and Execution of Deep Acoustic Models", ["Raziel Alvarez", "Rohit Prabhavalkar", "Anton Bakhtin"], "https://doi.org/10.21437/Interspeech.2016-128", 5, "interspeech", 2016]], "Rohit Prabhavalkar": [0, ["On the Efficient Representation and Execution of Deep Acoustic Models", ["Raziel Alvarez", "Rohit Prabhavalkar", "Anton Bakhtin"], "https://doi.org/10.21437/Interspeech.2016-128", 5, "interspeech", 2016]], "Anton Bakhtin": [0, ["On the Efficient Representation and Execution of Deep Acoustic Models", ["Raziel Alvarez", "Rohit Prabhavalkar", "Anton Bakhtin"], "https://doi.org/10.21437/Interspeech.2016-128", 5, "interspeech", 2016]], "Daniel Galvez": [0, ["Purely Sequence-Trained Neural Networks for ASR Based on Lattice-Free MMI", ["Daniel Povey", "Vijayaditya Peddinti", "Daniel Galvez", "Pegah Ghahremani", "Vimal Manohar", "Xingyu Na", "Yiming Wang", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2016-595", 5, "interspeech", 2016]], "Pegah Ghahremani": [0, ["Purely Sequence-Trained Neural Networks for ASR Based on Lattice-Free MMI", ["Daniel Povey", "Vijayaditya Peddinti", "Daniel Galvez", "Pegah Ghahremani", "Vimal Manohar", "Xingyu Na", "Yiming Wang", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2016-595", 5, "interspeech", 2016], ["Acoustic Modelling from the Signal Domain Using CNNs", ["Pegah Ghahremani", "Vimal Manohar", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2016-1495", 5, "interspeech", 2016]], "Xingyu Na": [0.0001845632868935354, ["Purely Sequence-Trained Neural Networks for ASR Based on Lattice-Free MMI", ["Daniel Povey", "Vijayaditya Peddinti", "Daniel Galvez", "Pegah Ghahremani", "Vimal Manohar", "Xingyu Na", "Yiming Wang", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2016-595", 5, "interspeech", 2016]], "Martin Ratajczak": [0, ["Virtual Adversarial Training Applied to Neural Higher-Order Factors for Phone Classification", ["Martin Ratajczak", "Sebastian Tschiatschek", "Franz Pernkopf"], "https://doi.org/10.21437/Interspeech.2016-832", 5, "interspeech", 2016]], "Sebastian Tschiatschek": [0, ["Virtual Adversarial Training Applied to Neural Higher-Order Factors for Phone Classification", ["Martin Ratajczak", "Sebastian Tschiatschek", "Franz Pernkopf"], "https://doi.org/10.21437/Interspeech.2016-832", 5, "interspeech", 2016]], "Franz Pernkopf": [0, ["Virtual Adversarial Training Applied to Neural Higher-Order Factors for Phone Classification", ["Martin Ratajczak", "Sebastian Tschiatschek", "Franz Pernkopf"], "https://doi.org/10.21437/Interspeech.2016-832", 5, "interspeech", 2016], ["Manual versus Automated: The Challenging Routine of Infant Vocalisation Segmentation in Home Videos to Study Neuro(mal)development", ["Florian B. Pokorny", "Robert Peharz", "Wolfgang Roth", "Matthias Zohrer", "Franz Pernkopf", "Peter B. Marschik", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-1341", 5, "interspeech", 2016], ["Phase-Aware Signal Processing for Automatic Speech Recognition", ["Johannes Fahringer", "Tobias Schrank", "Johannes Stahl", "Pejman Mowlaee", "Franz Pernkopf"], "https://doi.org/10.21437/Interspeech.2016-823", 5, "interspeech", 2016]], "Jeremy H. M. Wong": [0, ["Sequence Student-Teacher Training of Deep Neural Networks", ["Jeremy H. M. Wong", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2016-911", 5, "interspeech", 2016]], "Hynek Boril": [0, ["Robustness in Speech, Speaker, and Language Recognition: \"You've Got to Know Your Limitations\"", ["John H. L. Hansen", "Hynek Boril"], "https://doi.org/10.21437/Interspeech.2016-1395", 5, "interspeech", 2016]], "Ulpu Remes": [0, ["The Use of Read versus Conversational Lombard Speech in Spectral Tilt Modeling for Intelligibility Enhancement in Near-End Noise Conditions", ["Emma Jokinen", "Ulpu Remes", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2016-143", 5, "interspeech", 2016]], "Pedro A. Torres-Carrasquillo": [0, ["Corpora for the Evaluation of Robust Speaker Recognition Systems", ["Douglas E. Sturim", "Pedro A. Torres-Carrasquillo", "Joseph P. Campbell"], "https://doi.org/10.21437/Interspeech.2016-1609", 5, "interspeech", 2016]], "Nancy Bertin": [0, ["A French Corpus for Distant-Microphone Speech Processing in Real Homes", ["Nancy Bertin", "Ewen Camberlein", "Emmanuel Vincent", "Romain Lebarbenchon", "Stephane Peillon", "Eric Lamande", "Sunit Sivasankaran", "Frederic Bimbot", "Irina Illina", "Ariane Tom", "Sylvain Fleury", "Eric Jamet"], "https://doi.org/10.21437/Interspeech.2016-1384", 5, "interspeech", 2016]], "Ewen Camberlein": [0, ["A French Corpus for Distant-Microphone Speech Processing in Real Homes", ["Nancy Bertin", "Ewen Camberlein", "Emmanuel Vincent", "Romain Lebarbenchon", "Stephane Peillon", "Eric Lamande", "Sunit Sivasankaran", "Frederic Bimbot", "Irina Illina", "Ariane Tom", "Sylvain Fleury", "Eric Jamet"], "https://doi.org/10.21437/Interspeech.2016-1384", 5, "interspeech", 2016]], "Emmanuel Vincent": [0, ["A French Corpus for Distant-Microphone Speech Processing in Real Homes", ["Nancy Bertin", "Ewen Camberlein", "Emmanuel Vincent", "Romain Lebarbenchon", "Stephane Peillon", "Eric Lamande", "Sunit Sivasankaran", "Frederic Bimbot", "Irina Illina", "Ariane Tom", "Sylvain Fleury", "Eric Jamet"], "https://doi.org/10.21437/Interspeech.2016-1384", 5, "interspeech", 2016], ["Discussion", ["Dayana Ribas", "Emmanuel Vincent", "John H. L. Hansen", "Emma Jokinen", "Mirco Ravanelli", "Hannes Gamper", "Fred Richardson"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs14.html", 0, "interspeech", 2016]], "Romain Lebarbenchon": [0, ["A French Corpus for Distant-Microphone Speech Processing in Real Homes", ["Nancy Bertin", "Ewen Camberlein", "Emmanuel Vincent", "Romain Lebarbenchon", "Stephane Peillon", "Eric Lamande", "Sunit Sivasankaran", "Frederic Bimbot", "Irina Illina", "Ariane Tom", "Sylvain Fleury", "Eric Jamet"], "https://doi.org/10.21437/Interspeech.2016-1384", 5, "interspeech", 2016]], "Stephane Peillon": [0, ["A French Corpus for Distant-Microphone Speech Processing in Real Homes", ["Nancy Bertin", "Ewen Camberlein", "Emmanuel Vincent", "Romain Lebarbenchon", "Stephane Peillon", "Eric Lamande", "Sunit Sivasankaran", "Frederic Bimbot", "Irina Illina", "Ariane Tom", "Sylvain Fleury", "Eric Jamet"], "https://doi.org/10.21437/Interspeech.2016-1384", 5, "interspeech", 2016]], "Eric Lamande": [0, ["A French Corpus for Distant-Microphone Speech Processing in Real Homes", ["Nancy Bertin", "Ewen Camberlein", "Emmanuel Vincent", "Romain Lebarbenchon", "Stephane Peillon", "Eric Lamande", "Sunit Sivasankaran", "Frederic Bimbot", "Irina Illina", "Ariane Tom", "Sylvain Fleury", "Eric Jamet"], "https://doi.org/10.21437/Interspeech.2016-1384", 5, "interspeech", 2016]], "Sunit Sivasankaran": [0, ["A French Corpus for Distant-Microphone Speech Processing in Real Homes", ["Nancy Bertin", "Ewen Camberlein", "Emmanuel Vincent", "Romain Lebarbenchon", "Stephane Peillon", "Eric Lamande", "Sunit Sivasankaran", "Frederic Bimbot", "Irina Illina", "Ariane Tom", "Sylvain Fleury", "Eric Jamet"], "https://doi.org/10.21437/Interspeech.2016-1384", 5, "interspeech", 2016]], "Frederic Bimbot": [0, ["A French Corpus for Distant-Microphone Speech Processing in Real Homes", ["Nancy Bertin", "Ewen Camberlein", "Emmanuel Vincent", "Romain Lebarbenchon", "Stephane Peillon", "Eric Lamande", "Sunit Sivasankaran", "Frederic Bimbot", "Irina Illina", "Ariane Tom", "Sylvain Fleury", "Eric Jamet"], "https://doi.org/10.21437/Interspeech.2016-1384", 5, "interspeech", 2016]], "Ariane Tom": [0, ["A French Corpus for Distant-Microphone Speech Processing in Real Homes", ["Nancy Bertin", "Ewen Camberlein", "Emmanuel Vincent", "Romain Lebarbenchon", "Stephane Peillon", "Eric Lamande", "Sunit Sivasankaran", "Frederic Bimbot", "Irina Illina", "Ariane Tom", "Sylvain Fleury", "Eric Jamet"], "https://doi.org/10.21437/Interspeech.2016-1384", 5, "interspeech", 2016]], "Sylvain Fleury": [0, ["A French Corpus for Distant-Microphone Speech Processing in Real Homes", ["Nancy Bertin", "Ewen Camberlein", "Emmanuel Vincent", "Romain Lebarbenchon", "Stephane Peillon", "Eric Lamande", "Sunit Sivasankaran", "Frederic Bimbot", "Irina Illina", "Ariane Tom", "Sylvain Fleury", "Eric Jamet"], "https://doi.org/10.21437/Interspeech.2016-1384", 5, "interspeech", 2016]], "Eric Jamet": [0, ["A French Corpus for Distant-Microphone Speech Processing in Real Homes", ["Nancy Bertin", "Ewen Camberlein", "Emmanuel Vincent", "Romain Lebarbenchon", "Stephane Peillon", "Eric Lamande", "Sunit Sivasankaran", "Frederic Bimbot", "Irina Illina", "Ariane Tom", "Sylvain Fleury", "Eric Jamet"], "https://doi.org/10.21437/Interspeech.2016-1384", 5, "interspeech", 2016]], "Mirco Ravanelli": [0, ["Realistic Multi-Microphone Data Simulation for Distant Speech Recognition", ["Mirco Ravanelli", "Piergiorgio Svaizer", "Maurizio Omologo"], "https://doi.org/10.21437/Interspeech.2016-731", 5, "interspeech", 2016], ["Discussion", ["Dayana Ribas", "Emmanuel Vincent", "John H. L. Hansen", "Emma Jokinen", "Mirco Ravanelli", "Hannes Gamper", "Fred Richardson"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs14.html", 0, "interspeech", 2016]], "Piergiorgio Svaizer": [0, ["Realistic Multi-Microphone Data Simulation for Distant Speech Recognition", ["Mirco Ravanelli", "Piergiorgio Svaizer", "Maurizio Omologo"], "https://doi.org/10.21437/Interspeech.2016-731", 5, "interspeech", 2016]], "Hannes Gamper": [0, ["Synthesis of Device-Independent Noise Corpora for Realistic ASR Evaluation", ["Hannes Gamper", "Mark R. P. Thomas", "Lyle Corbin", "Ivan Tashev"], "https://doi.org/10.21437/Interspeech.2016-978", 5, "interspeech", 2016], ["Discussion", ["Dayana Ribas", "Emmanuel Vincent", "John H. L. Hansen", "Emma Jokinen", "Mirco Ravanelli", "Hannes Gamper", "Fred Richardson"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs14.html", 0, "interspeech", 2016]], "Mark R. P. Thomas": [0, ["Synthesis of Device-Independent Noise Corpora for Realistic ASR Evaluation", ["Hannes Gamper", "Mark R. P. Thomas", "Lyle Corbin", "Ivan Tashev"], "https://doi.org/10.21437/Interspeech.2016-978", 5, "interspeech", 2016]], "Lyle Corbin": [0, ["Synthesis of Device-Independent Noise Corpora for Realistic ASR Evaluation", ["Hannes Gamper", "Mark R. P. Thomas", "Lyle Corbin", "Ivan Tashev"], "https://doi.org/10.21437/Interspeech.2016-978", 5, "interspeech", 2016]], "Ivan Tashev": [0, ["Synthesis of Device-Independent Noise Corpora for Realistic ASR Evaluation", ["Hannes Gamper", "Mark R. P. Thomas", "Lyle Corbin", "Ivan Tashev"], "https://doi.org/10.21437/Interspeech.2016-978", 5, "interspeech", 2016], ["Causal Speech Enhancement Combining Data-Driven Learning and Suppression Rule Estimation", ["Seyedmahdad Mirsamadi", "Ivan Tashev"], "https://doi.org/10.21437/Interspeech.2016-437", 5, "interspeech", 2016]], "Fred Richardson": [0, ["Speaker Recognition Using Real vs Synthetic Parallel Data for DNN Channel Compensation", ["Fred Richardson", "Michael Brandstein", "Jennifer Melot", "Douglas A. Reynolds"], "https://doi.org/10.21437/Interspeech.2016-544", 5, "interspeech", 2016], ["Discussion", ["Dayana Ribas", "Emmanuel Vincent", "John H. L. Hansen", "Emma Jokinen", "Mirco Ravanelli", "Hannes Gamper", "Fred Richardson"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs14.html", 0, "interspeech", 2016]], "Michael Brandstein": [0, ["Speaker Recognition Using Real vs Synthetic Parallel Data for DNN Channel Compensation", ["Fred Richardson", "Michael Brandstein", "Jennifer Melot", "Douglas A. Reynolds"], "https://doi.org/10.21437/Interspeech.2016-544", 5, "interspeech", 2016]], "Dayana Ribas": [0, ["Discussion", ["Dayana Ribas", "Emmanuel Vincent", "John H. L. Hansen", "Emma Jokinen", "Mirco Ravanelli", "Hannes Gamper", "Fred Richardson"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs14.html", 0, "interspeech", 2016]], "Mirjam Ernestus": [0, ["Combining Data-Oriented and Process-Oriented Approaches to Modeling Reaction Time Data", ["Louis ten Bosch", "Lou Boves", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2016-1072", 5, "interspeech", 2016]], "Michael McAuliffe": [0, ["Do Listeners Learn Better from Natural Speech?", ["Michael McAuliffe", "Molly Babel", "Charlotte Vaughn"], "https://doi.org/10.21437/Interspeech.2016-610", 5, "interspeech", 2016]], "Molly Babel": [0, ["Do Listeners Learn Better from Natural Speech?", ["Michael McAuliffe", "Molly Babel", "Charlotte Vaughn"], "https://doi.org/10.21437/Interspeech.2016-610", 5, "interspeech", 2016]], "Charlotte Vaughn": [0, ["Do Listeners Learn Better from Natural Speech?", ["Michael McAuliffe", "Molly Babel", "Charlotte Vaughn"], "https://doi.org/10.21437/Interspeech.2016-610", 5, "interspeech", 2016]], "Polina Drozdova": [0, ["Processing and Adaptation to Ambiguous Sounds during the Course of Perceptual Learning", ["Polina Drozdova", "Roeland van Hout", "Odette Scharenborg"], "https://doi.org/10.21437/Interspeech.2016-814", 5, "interspeech", 2016]], "Florian Hintz": [0, ["The Effect of Background Noise on the Activation of Phonological and Semantic Information During Spoken-Word Recognition", ["Florian Hintz", "Odette Scharenborg"], "https://doi.org/10.21437/Interspeech.2016-882", 5, "interspeech", 2016]], "Shinae Kang": [0.0028240971732884645, ["Relationships Between Functional Load and Auditory Confusability Under Different Speech Environments", ["Shinae Kang", "Clara Cohen"], "https://doi.org/10.21437/Interspeech.2016-906", 5, "interspeech", 2016]], "Jasmeen Kanwal": [0, ["The Role of Pitch in Punjabi Word Identification", ["Jasmeen Kanwal", "Amanda Ritchart"], "https://doi.org/10.21437/Interspeech.2016-1445", 5, "interspeech", 2016]], "Amanda Ritchart": [0, ["The Role of Pitch in Punjabi Word Identification", ["Jasmeen Kanwal", "Amanda Ritchart"], "https://doi.org/10.21437/Interspeech.2016-1445", 5, "interspeech", 2016]], "Marie Tahon": [0, ["Improving TTS with Corpus-Specific Pronunciation Adaptation", ["Marie Tahon", "Raheel Qader", "Gwenole Lecorve", "Damien Lolive"], "https://doi.org/10.21437/Interspeech.2016-864", 5, "interspeech", 2016]], "Raheel Qader": [0, ["Improving TTS with Corpus-Specific Pronunciation Adaptation", ["Marie Tahon", "Raheel Qader", "Gwenole Lecorve", "Damien Lolive"], "https://doi.org/10.21437/Interspeech.2016-864", 5, "interspeech", 2016]], "Gwenole Lecorve": [0, ["Improving TTS with Corpus-Specific Pronunciation Adaptation", ["Marie Tahon", "Raheel Qader", "Gwenole Lecorve", "Damien Lolive"], "https://doi.org/10.21437/Interspeech.2016-864", 5, "interspeech", 2016]], "Amr El-Desoky Mousa": [0, ["Deep Bidirectional Long Short-Term Memory Recurrent Neural Networks for Grapheme-to-Phoneme Conversion Utilizing Complex Many-to-Many Alignments", ["Amr El-Desoky Mousa", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-1229", 5, "interspeech", 2016]], "Daan van Esch": [0, ["Predicting Pronunciations with Syllabification and Stress with Recurrent Neural Networks", ["Daan van Esch", "Mason Chua", "Kanishka Rao"], "https://doi.org/10.21437/Interspeech.2016-1419", 5, "interspeech", 2016]], "Mason Chua": [0, ["Predicting Pronunciations with Syllabification and Stress with Recurrent Neural Networks", ["Daan van Esch", "Mason Chua", "Kanishka Rao"], "https://doi.org/10.21437/Interspeech.2016-1419", 5, "interspeech", 2016]], "Kanishka Rao": [0, ["Predicting Pronunciations with Syllabification and Stress with Recurrent Neural Networks", ["Daan van Esch", "Mason Chua", "Kanishka Rao"], "https://doi.org/10.21437/Interspeech.2016-1419", 5, "interspeech", 2016]], "Mael Pouget": [0, ["Adaptive Latency for Part-of-Speech Tagging in Incremental Text-to-Speech Synthesis", ["Mael Pouget", "Olha Nahorna", "Thomas Hueber", "Gerard Bailly"], "https://doi.org/10.21437/Interspeech.2016-165", 5, "interspeech", 2016]], "Olha Nahorna": [0, ["Adaptive Latency for Part-of-Speech Tagging in Incremental Text-to-Speech Synthesis", ["Mael Pouget", "Olha Nahorna", "Thomas Hueber", "Gerard Bailly"], "https://doi.org/10.21437/Interspeech.2016-165", 5, "interspeech", 2016]], "Thomas Hueber": [0, ["Adaptive Latency for Part-of-Speech Tagging in Incremental Text-to-Speech Synthesis", ["Mael Pouget", "Olha Nahorna", "Thomas Hueber", "Gerard Bailly"], "https://doi.org/10.21437/Interspeech.2016-165", 5, "interspeech", 2016]], "Rasmus Dall": [0, ["Redefining the Linguistic Context Feature Set for HMM and DNN TTS Through Position and Parsing", ["Rasmus Dall", "Kei Hashimoto", "Keiichiro Oura", "Yoshihiko Nankaku", "Keiichi Tokuda"], "https://doi.org/10.21437/Interspeech.2016-399", 5, "interspeech", 2016]], "Kwang Myung Jeon": [0.9969868063926697, ["Local Sparsity Based Online Dictionary Learning for Environment-Adaptive Speech Enhancement with Nonnegative Matrix Factorization", ["Kwang Myung Jeon", "Hong Kook Kim"], "https://doi.org/10.21437/Interspeech.2016-586", 5, "interspeech", 2016]], "Hong Kook Kim": [0.9972290098667145, ["Local Sparsity Based Online Dictionary Learning for Environment-Adaptive Speech Enhancement with Nonnegative Matrix Factorization", ["Kwang Myung Jeon", "Hong Kook Kim"], "https://doi.org/10.21437/Interspeech.2016-586", 5, "interspeech", 2016]], "Seyedmahdad Mirsamadi": [0, ["Causal Speech Enhancement Combining Data-Driven Learning and Suppression Rule Estimation", ["Seyedmahdad Mirsamadi", "Ivan Tashev"], "https://doi.org/10.21437/Interspeech.2016-437", 5, "interspeech", 2016]], "Alessio Brutti": [0, ["A Phase-Based Time-Frequency Masking for Multi-Channel Speech Enhancement in Domestic Environments", ["Alessio Brutti", "Antigoni Tsiami", "Athanasios Katsamanis", "Petros Maragos"], "https://doi.org/10.21437/Interspeech.2016-150", 5, "interspeech", 2016]], "Antigoni Tsiami": [0, ["A Phase-Based Time-Frequency Masking for Multi-Channel Speech Enhancement in Domestic Environments", ["Alessio Brutti", "Antigoni Tsiami", "Athanasios Katsamanis", "Petros Maragos"], "https://doi.org/10.21437/Interspeech.2016-150", 5, "interspeech", 2016]], "Athanasios Katsamanis": [0, ["A Phase-Based Time-Frequency Masking for Multi-Channel Speech Enhancement in Domestic Environments", ["Alessio Brutti", "Antigoni Tsiami", "Athanasios Katsamanis", "Petros Maragos"], "https://doi.org/10.21437/Interspeech.2016-150", 5, "interspeech", 2016]], "Petros Maragos": [0, ["A Phase-Based Time-Frequency Masking for Multi-Channel Speech Enhancement in Domestic Environments", ["Alessio Brutti", "Antigoni Tsiami", "Athanasios Katsamanis", "Petros Maragos"], "https://doi.org/10.21437/Interspeech.2016-150", 5, "interspeech", 2016]], "Katsuhiko Yamamoto": [0, ["Speech Intelligibility Prediction Based on the Envelope Power Spectrum Model with the Dynamic Compressive Gammachirp Auditory Filterbank", ["Katsuhiko Yamamoto", "Toshio Irino", "Toshie Matsui", "Shoko Araki", "Keisuke Kinoshita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-652", 5, "interspeech", 2016]], "Toshio Irino": [0, ["Speech Intelligibility Prediction Based on the Envelope Power Spectrum Model with the Dynamic Compressive Gammachirp Auditory Filterbank", ["Katsuhiko Yamamoto", "Toshio Irino", "Toshie Matsui", "Shoko Araki", "Keisuke Kinoshita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-652", 5, "interspeech", 2016]], "Toshie Matsui": [0, ["Speech Intelligibility Prediction Based on the Envelope Power Spectrum Model with the Dynamic Compressive Gammachirp Auditory Filterbank", ["Katsuhiko Yamamoto", "Toshio Irino", "Toshie Matsui", "Shoko Araki", "Keisuke Kinoshita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-652", 5, "interspeech", 2016]], "Shoko Araki": [0, ["Speech Intelligibility Prediction Based on the Envelope Power Spectrum Model with the Dynamic Compressive Gammachirp Auditory Filterbank", ["Katsuhiko Yamamoto", "Toshio Irino", "Toshie Matsui", "Shoko Araki", "Keisuke Kinoshita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-652", 5, "interspeech", 2016]], "Tatsuya Kawahara": [0, ["Prediction and Generation of Backchannel Form for Attentive Listening Systems", ["Tatsuya Kawahara", "Takashi Yamaguchi", "Koji Inoue", "Katsuya Takanashi", "Nigel G. Ward"], "https://doi.org/10.21437/Interspeech.2016-118", 5, "interspeech", 2016], ["Joint Optimization of Denoising Autoencoder and DNN Acoustic Model Based on Multi-Target Learning for Noisy Speech Recognition", ["Masato Mimura", "Shinsuke Sakai", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2016-388", 5, "interspeech", 2016]], "Takashi Yamaguchi": [0, ["Prediction and Generation of Backchannel Form for Attentive Listening Systems", ["Tatsuya Kawahara", "Takashi Yamaguchi", "Koji Inoue", "Katsuya Takanashi", "Nigel G. Ward"], "https://doi.org/10.21437/Interspeech.2016-118", 5, "interspeech", 2016]], "Koji Inoue": [0, ["Prediction and Generation of Backchannel Form for Attentive Listening Systems", ["Tatsuya Kawahara", "Takashi Yamaguchi", "Koji Inoue", "Katsuya Takanashi", "Nigel G. Ward"], "https://doi.org/10.21437/Interspeech.2016-118", 5, "interspeech", 2016]], "Katsuya Takanashi": [0, ["Prediction and Generation of Backchannel Form for Attentive Listening Systems", ["Tatsuya Kawahara", "Takashi Yamaguchi", "Koji Inoue", "Katsuya Takanashi", "Nigel G. Ward"], "https://doi.org/10.21437/Interspeech.2016-118", 5, "interspeech", 2016]], "Nigel G. Ward": [0, ["Prediction and Generation of Backchannel Form for Attentive Listening Systems", ["Tatsuya Kawahara", "Takashi Yamaguchi", "Koji Inoue", "Katsuya Takanashi", "Nigel G. Ward"], "https://doi.org/10.21437/Interspeech.2016-118", 5, "interspeech", 2016]], "Tomer Meshorer": [0, ["Using Past Speaker Behavior to Better Predict Turn Transitions", ["Tomer Meshorer", "Peter A. Heeman"], "https://doi.org/10.21437/Interspeech.2016-1409", 5, "interspeech", 2016]], "Frederic Elisei": [0, ["Quantitative Analysis of Backchannels Uttered by an Interviewer During Neuropsychological Tests", ["Gerard Bailly", "Frederic Elisei", "Alexandra Juphard", "Olivier Moreaud"], "https://doi.org/10.21437/Interspeech.2016-22", 5, "interspeech", 2016]], "Alexandra Juphard": [0, ["Quantitative Analysis of Backchannels Uttered by an Interviewer During Neuropsychological Tests", ["Gerard Bailly", "Frederic Elisei", "Alexandra Juphard", "Olivier Moreaud"], "https://doi.org/10.21437/Interspeech.2016-22", 5, "interspeech", 2016]], "Olivier Moreaud": [0, ["Quantitative Analysis of Backchannels Uttered by an Interviewer During Neuropsychological Tests", ["Gerard Bailly", "Frederic Elisei", "Alexandra Juphard", "Olivier Moreaud"], "https://doi.org/10.21437/Interspeech.2016-22", 5, "interspeech", 2016]], "Shammur Absar Chowdhury": [0, ["Predicting User Satisfaction from Turn-Taking in Spoken Conversations", ["Shammur Absar Chowdhury", "Evgeny A. Stepanov", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2016-859", 5, "interspeech", 2016]], "Evgeny A. Stepanov": [0, ["Predicting User Satisfaction from Turn-Taking in Spoken Conversations", ["Shammur Absar Chowdhury", "Evgeny A. Stepanov", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2016-859", 5, "interspeech", 2016]], "Giuseppe Riccardi": [0, ["Predicting User Satisfaction from Turn-Taking in Spoken Conversations", ["Shammur Absar Chowdhury", "Evgeny A. Stepanov", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2016-859", 5, "interspeech", 2016]], "Catharine Oertel": [0, ["Towards Building an Attentive Artificial Listener: On the Perception of Attentiveness in Feedback Utterances", ["Catharine Oertel", "Joakim Gustafson", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2016-1274", 5, "interspeech", 2016]], "Joakim Gustafson": [0, ["Towards Building an Attentive Artificial Listener: On the Perception of Attentiveness in Feedback Utterances", ["Catharine Oertel", "Joakim Gustafson", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2016-1274", 5, "interspeech", 2016]], "Alan W. Black": [0, ["Towards Building an Attentive Artificial Listener: On the Perception of Attentiveness in Feedback Utterances", ["Catharine Oertel", "Joakim Gustafson", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2016-1274", 5, "interspeech", 2016], ["Deriving Phonetic Transcriptions and Discovering Word Segmentations for Speech-to-Speech Translation in Low-Resource Settings", ["Andrew Wilkinson", "Tiancheng Zhao", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2016-1319", 5, "interspeech", 2016]], "Youngjune Gwon": [0.9998761713504791, ["Language Recognition via Sparse Coding", ["Youngjune Gwon", "William M. Campbell", "Douglas E. Sturim", "H. T. Kung"], "https://doi.org/10.21437/Interspeech.2016-881", 5, "interspeech", 2016]], "H. T. Kung": [0.5, ["Language Recognition via Sparse Coding", ["Youngjune Gwon", "William M. Campbell", "Douglas E. Sturim", "H. T. Kung"], "https://doi.org/10.21437/Interspeech.2016-881", 5, "interspeech", 2016]], "Sarith Fernando": [0, ["A Feature Normalisation Technique for PLLR Based Language Identification Systems", ["Sarith Fernando", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2016-560", 5, "interspeech", 2016], ["Out of Set Language Modelling in Hierarchical Language Identification", ["Saad Irtza", "Vidhyasaharan Sethu", "Sarith Fernando", "Eliathamby Ambikairajah", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-558", 5, "interspeech", 2016]], "Mounika K. V.": [0, ["An Investigation of Deep Neural Network Architectures for Language Recognition in Indian Languages", ["Mounika K. V.", "Sivanand Achanta", "Lakshmi H. R.", "Suryakanth V. Gangashetty", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2016-910", 4, "interspeech", 2016]], "Sivanand Achanta": [0, ["An Investigation of Deep Neural Network Architectures for Language Recognition in Indian Languages", ["Mounika K. V.", "Sivanand Achanta", "Lakshmi H. R.", "Suryakanth V. Gangashetty", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2016-910", 4, "interspeech", 2016]], "Lakshmi H. R.": [0, ["An Investigation of Deep Neural Network Architectures for Language Recognition in Indian Languages", ["Mounika K. V.", "Sivanand Achanta", "Lakshmi H. R.", "Suryakanth V. Gangashetty", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2016-910", 4, "interspeech", 2016]], "Anil Kumar Vuppala": [0, ["An Investigation of Deep Neural Network Architectures for Language Recognition in Indian Languages", ["Mounika K. V.", "Sivanand Achanta", "Lakshmi H. R.", "Suryakanth V. Gangashetty", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2016-910", 4, "interspeech", 2016]], "Ahmed M. Ali": [0, ["Automatic Dialect Detection in Arabic Broadcast Speech", ["Ahmed M. Ali", "Najim Dehak", "Patrick Cardinal", "Sameer Khurana", "Sree Harsha Yella", "James R. Glass", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-1297", 5, "interspeech", 2016]], "Sameer Khurana": [0, ["Automatic Dialect Detection in Arabic Broadcast Speech", ["Ahmed M. Ali", "Najim Dehak", "Patrick Cardinal", "Sameer Khurana", "Sree Harsha Yella", "James R. Glass", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-1297", 5, "interspeech", 2016]], "Sree Harsha Yella": [0, ["Automatic Dialect Detection in Arabic Broadcast Speech", ["Ahmed M. Ali", "Najim Dehak", "Patrick Cardinal", "Sameer Khurana", "Sree Harsha Yella", "James R. Glass", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2016-1297", 5, "interspeech", 2016]], "Bhusan Chettri": [0, ["Combining Weak Tokenisers for Phonotactic Language Recognition in a Resource-Constrained Setting", ["Raymond W. M. Ng", "Bhusan Chettri", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-630", 5, "interspeech", 2016]], "Wang Geng": [0, ["End-to-End Language Identification Using Attention-Based Recurrent Neural Networks", ["Wang Geng", "Wenfu Wang", "Yuanyuan Zhao", "Xinyuan Cai", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2016-686", 5, "interspeech", 2016], ["Gating Recurrent Enhanced Memory Neural Networks on Language Identification", ["Wang Geng", "Yuanyuan Zhao", "Wenfu Wang", "Xinyuan Cai", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2016-684", 5, "interspeech", 2016]], "Yuanyuan Zhao": [0, ["End-to-End Language Identification Using Attention-Based Recurrent Neural Networks", ["Wang Geng", "Wenfu Wang", "Yuanyuan Zhao", "Xinyuan Cai", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2016-686", 5, "interspeech", 2016], ["Gating Recurrent Enhanced Memory Neural Networks on Language Identification", ["Wang Geng", "Yuanyuan Zhao", "Wenfu Wang", "Xinyuan Cai", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2016-684", 5, "interspeech", 2016], ["Multidimensional Residual Learning Based on Recurrent Neural Networks for Acoustic Modeling", ["Yuanyuan Zhao", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2016-677", 5, "interspeech", 2016]], "Xinyuan Cai": [0, ["End-to-End Language Identification Using Attention-Based Recurrent Neural Networks", ["Wang Geng", "Wenfu Wang", "Yuanyuan Zhao", "Xinyuan Cai", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2016-686", 5, "interspeech", 2016], ["Gating Recurrent Enhanced Memory Neural Networks on Language Identification", ["Wang Geng", "Yuanyuan Zhao", "Wenfu Wang", "Xinyuan Cai", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2016-684", 5, "interspeech", 2016]], "Hesam Sagha": [0, ["Enhancing Multilingual Recognition of Emotion in Speech by Language Identification", ["Hesam Sagha", "Pavel Matejka", "Maryna Gavryukova", "Filip Povolny", "Erik Marchi", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-333", 5, "interspeech", 2016]], "Maryna Gavryukova": [0, ["Enhancing Multilingual Recognition of Emotion in Speech by Language Identification", ["Hesam Sagha", "Pavel Matejka", "Maryna Gavryukova", "Filip Povolny", "Erik Marchi", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-333", 5, "interspeech", 2016]], "Filip Povolny": [0, ["Enhancing Multilingual Recognition of Emotion in Speech by Language Identification", ["Hesam Sagha", "Pavel Matejka", "Maryna Gavryukova", "Filip Povolny", "Erik Marchi", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-333", 5, "interspeech", 2016]], "Seongkyu Mun": [0.9999765753746033, ["Deep Neural Network Bottleneck Features for Acoustic Event Recognition", ["Seongkyu Mun", "Suwon Shon", "Wooil Kim", "Hanseok Ko"], "https://doi.org/10.21437/Interspeech.2016-1112", 4, "interspeech", 2016]], "Suwon Shon": [0, ["Deep Neural Network Bottleneck Features for Acoustic Event Recognition", ["Seongkyu Mun", "Suwon Shon", "Wooil Kim", "Hanseok Ko"], "https://doi.org/10.21437/Interspeech.2016-1112", 4, "interspeech", 2016]], "Wooil Kim": [0.990258663892746, ["Deep Neural Network Bottleneck Features for Acoustic Event Recognition", ["Seongkyu Mun", "Suwon Shon", "Wooil Kim", "Hanseok Ko"], "https://doi.org/10.21437/Interspeech.2016-1112", 4, "interspeech", 2016]], "Hanseok Ko": [0.8706581592559814, ["Deep Neural Network Bottleneck Features for Acoustic Event Recognition", ["Seongkyu Mun", "Suwon Shon", "Wooil Kim", "Hanseok Ko"], "https://doi.org/10.21437/Interspeech.2016-1112", 4, "interspeech", 2016]], "Antonio Origlia": [0, ["Combining Energy and Cross-Entropy Analysis for Nuclear Segments Detection", ["Antonio Origlia", "Francesco Cutugno"], "https://doi.org/10.21437/Interspeech.2016-1345", 5, "interspeech", 2016]], "Francesco Cutugno": [0, ["Combining Energy and Cross-Entropy Analysis for Nuclear Segments Detection", ["Antonio Origlia", "Francesco Cutugno"], "https://doi.org/10.21437/Interspeech.2016-1345", 5, "interspeech", 2016]], "Roland Maas": [0, ["Anchored Speech Detection", ["Roland Maas", "Sree Hari Krishnan Parthasarathi", "Brian King", "Ruitong Huang", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2016-1346", 5, "interspeech", 2016]], "Sree Hari Krishnan Parthasarathi": [0, ["Anchored Speech Detection", ["Roland Maas", "Sree Hari Krishnan Parthasarathi", "Brian King", "Ruitong Huang", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2016-1346", 5, "interspeech", 2016]], "Brian King": [0, ["Anchored Speech Detection", ["Roland Maas", "Sree Hari Krishnan Parthasarathi", "Brian King", "Ruitong Huang", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2016-1346", 5, "interspeech", 2016]], "Ruitong Huang": [0, ["Anchored Speech Detection", ["Roland Maas", "Sree Hari Krishnan Parthasarathi", "Brian King", "Ruitong Huang", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2016-1346", 5, "interspeech", 2016]], "Mahesh Kumar Nandwana": [0, ["Towards Smart-Cars That Can Listen: Abnormal Acoustic Event Detection on the Road", ["Mahesh Kumar Nandwana", "Taufiq Hasan"], "https://doi.org/10.21437/Interspeech.2016-1366", 4, "interspeech", 2016]], "Taufiq Hasan": [0, ["Towards Smart-Cars That Can Listen: Abnormal Acoustic Event Detection on the Road", ["Mahesh Kumar Nandwana", "Taufiq Hasan"], "https://doi.org/10.21437/Interspeech.2016-1366", 4, "interspeech", 2016]], "K. V. Vijay Girish": [0, ["Hierarchical Classification of Speaker and Background Noise and Estimation of SNR Using Sparse Representation", ["K. V. Vijay Girish", "A. G. Ramakrishnan", "T. V. Ananthapadmanabha"], "https://doi.org/10.21437/Interspeech.2016-175", 5, "interspeech", 2016]], "A. G. Ramakrishnan": [0, ["Hierarchical Classification of Speaker and Background Noise and Estimation of SNR Using Sparse Representation", ["K. V. Vijay Girish", "A. G. Ramakrishnan", "T. V. Ananthapadmanabha"], "https://doi.org/10.21437/Interspeech.2016-175", 5, "interspeech", 2016], ["A Class-Specific Speech Enhancement for Phoneme Recognition: A Dictionary Learning Approach", ["Nazreen P. M.", "A. G. Ramakrishnan", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2016-236", 5, "interspeech", 2016]], "T. V. Ananthapadmanabha": [0, ["Hierarchical Classification of Speaker and Background Noise and Estimation of SNR Using Sparse Representation", ["K. V. Vijay Girish", "A. G. Ramakrishnan", "T. V. Ananthapadmanabha"], "https://doi.org/10.21437/Interspeech.2016-175", 5, "interspeech", 2016]], "Haomin Zhang": [0, ["Robust Sound Event Detection in Continuous Audio Environments", ["Haomin Zhang", "Ian Vince McLoughlin", "Yan Song"], "https://doi.org/10.21437/Interspeech.2016-392", 5, "interspeech", 2016]], "Ian Vince McLoughlin": [0, ["Robust Sound Event Detection in Continuous Audio Environments", ["Haomin Zhang", "Ian Vince McLoughlin", "Yan Song"], "https://doi.org/10.21437/Interspeech.2016-392", 5, "interspeech", 2016]], "Yan Song": [0.002282193163409829, ["Robust Sound Event Detection in Continuous Audio Environments", ["Haomin Zhang", "Ian Vince McLoughlin", "Yan Song"], "https://doi.org/10.21437/Interspeech.2016-392", 5, "interspeech", 2016]], "Michael Gygli": [0, ["Deep Convolutional Neural Networks and Data Augmentation for Acoustic Event Recognition", ["Naoya Takahashi", "Michael Gygli", "Beat Pfister", "Luc Van Gool"], "https://doi.org/10.21437/Interspeech.2016-805", 5, "interspeech", 2016]], "Luc Van Gool": [0, ["Deep Convolutional Neural Networks and Data Augmentation for Acoustic Event Recognition", ["Naoya Takahashi", "Michael Gygli", "Beat Pfister", "Luc Van Gool"], "https://doi.org/10.21437/Interspeech.2016-805", 5, "interspeech", 2016]], "Stefan Meier": [0, ["Artificial Neural Network-Based Feature Combination for Spatial Voice Activity Detection", ["Stefan Meier", "Walter Kellermann"], "https://doi.org/10.21437/Interspeech.2016-1184", 5, "interspeech", 2016]], "Walter Kellermann": [0, ["Artificial Neural Network-Based Feature Combination for Spatial Voice Activity Detection", ["Stefan Meier", "Walter Kellermann"], "https://doi.org/10.21437/Interspeech.2016-1184", 5, "interspeech", 2016]], "Alexey Sholokhov": [0, ["HAPPY Team Entry to NIST OpenSAD Challenge: A Fusion of Short-Term Unsupervised and Segment i-Vector Based Speech Activity Detectors", ["Tomi Kinnunen", "Alexey Sholokhov", "Elie el Khoury", "Dennis Alexander Lehmann Thomsen", "Md. Sahidullah", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1281", 5, "interspeech", 2016]], "Elie el Khoury": [0, ["HAPPY Team Entry to NIST OpenSAD Challenge: A Fusion of Short-Term Unsupervised and Segment i-Vector Based Speech Activity Detectors", ["Tomi Kinnunen", "Alexey Sholokhov", "Elie el Khoury", "Dennis Alexander Lehmann Thomsen", "Md. Sahidullah", "Zheng-Hua Tan"], "https://doi.org/10.21437/Interspeech.2016-1281", 5, "interspeech", 2016]], "Robert Peharz": [0, ["Manual versus Automated: The Challenging Routine of Infant Vocalisation Segmentation in Home Videos to Study Neuro(mal)development", ["Florian B. Pokorny", "Robert Peharz", "Wolfgang Roth", "Matthias Zohrer", "Franz Pernkopf", "Peter B. Marschik", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-1341", 5, "interspeech", 2016]], "Wolfgang Roth": [0, ["Manual versus Automated: The Challenging Routine of Infant Vocalisation Segmentation in Home Videos to Study Neuro(mal)development", ["Florian B. Pokorny", "Robert Peharz", "Wolfgang Roth", "Matthias Zohrer", "Franz Pernkopf", "Peter B. Marschik", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-1341", 5, "interspeech", 2016]], "Matthias Zohrer": [0, ["Manual versus Automated: The Challenging Routine of Infant Vocalisation Segmentation in Home Videos to Study Neuro(mal)development", ["Florian B. Pokorny", "Robert Peharz", "Wolfgang Roth", "Matthias Zohrer", "Franz Pernkopf", "Peter B. Marschik", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-1341", 5, "interspeech", 2016]], "Hui Li": [0, ["Progress and Prospects for Spoken Language Technology: What Ordinary People Think", ["Roger K. Moore", "Hui Li", "Shih-Hao Liao"], "https://doi.org/10.21437/Interspeech.2016-874", 5, "interspeech", 2016]], "Shih-Hao Liao": [0, ["Progress and Prospects for Spoken Language Technology: What Ordinary People Think", ["Roger K. Moore", "Hui Li", "Shih-Hao Liao"], "https://doi.org/10.21437/Interspeech.2016-874", 5, "interspeech", 2016]], "Purushotam G. Radadia": [0, ["On Employing a Highly Mismatched Crowd for Speech Transcription", ["Purushotam G. Radadia", "Rahul Kumar", "Kanika Kalra", "Shirish Subhash Karande", "Sachin Lodha"], "https://doi.org/10.21437/Interspeech.2016-673", 5, "interspeech", 2016]], "Rahul Kumar": [0, ["On Employing a Highly Mismatched Crowd for Speech Transcription", ["Purushotam G. Radadia", "Rahul Kumar", "Kanika Kalra", "Shirish Subhash Karande", "Sachin Lodha"], "https://doi.org/10.21437/Interspeech.2016-673", 5, "interspeech", 2016]], "Kanika Kalra": [0, ["On Employing a Highly Mismatched Crowd for Speech Transcription", ["Purushotam G. Radadia", "Rahul Kumar", "Kanika Kalra", "Shirish Subhash Karande", "Sachin Lodha"], "https://doi.org/10.21437/Interspeech.2016-673", 5, "interspeech", 2016]], "Shirish Subhash Karande": [0, ["On Employing a Highly Mismatched Crowd for Speech Transcription", ["Purushotam G. Radadia", "Rahul Kumar", "Kanika Kalra", "Shirish Subhash Karande", "Sachin Lodha"], "https://doi.org/10.21437/Interspeech.2016-673", 5, "interspeech", 2016]], "Sachin Lodha": [0, ["On Employing a Highly Mismatched Crowd for Speech Transcription", ["Purushotam G. Radadia", "Rahul Kumar", "Kanika Kalra", "Shirish Subhash Karande", "Sachin Lodha"], "https://doi.org/10.21437/Interspeech.2016-673", 5, "interspeech", 2016]], "Ralf Meermeier": [0, ["Sage: The New BBN Speech Processing Platform", ["Roger Hsiao", "Ralf Meermeier", "Tim Ng", "Zhongqiang Huang", "Maxwell Jordan", "Enoch Kan", "Tanel Alumae", "Jan Silovsky", "William Hartmann", "Francis Keith", "Omer Lang", "Man-Hung Siu", "Owen Kimball"], "https://doi.org/10.21437/Interspeech.2016-1031", 5, "interspeech", 2016]], "Zhongqiang Huang": [0, ["Sage: The New BBN Speech Processing Platform", ["Roger Hsiao", "Ralf Meermeier", "Tim Ng", "Zhongqiang Huang", "Maxwell Jordan", "Enoch Kan", "Tanel Alumae", "Jan Silovsky", "William Hartmann", "Francis Keith", "Omer Lang", "Man-Hung Siu", "Owen Kimball"], "https://doi.org/10.21437/Interspeech.2016-1031", 5, "interspeech", 2016]], "Maxwell Jordan": [0, ["Sage: The New BBN Speech Processing Platform", ["Roger Hsiao", "Ralf Meermeier", "Tim Ng", "Zhongqiang Huang", "Maxwell Jordan", "Enoch Kan", "Tanel Alumae", "Jan Silovsky", "William Hartmann", "Francis Keith", "Omer Lang", "Man-Hung Siu", "Owen Kimball"], "https://doi.org/10.21437/Interspeech.2016-1031", 5, "interspeech", 2016]], "Enoch Kan": [0, ["Sage: The New BBN Speech Processing Platform", ["Roger Hsiao", "Ralf Meermeier", "Tim Ng", "Zhongqiang Huang", "Maxwell Jordan", "Enoch Kan", "Tanel Alumae", "Jan Silovsky", "William Hartmann", "Francis Keith", "Omer Lang", "Man-Hung Siu", "Owen Kimball"], "https://doi.org/10.21437/Interspeech.2016-1031", 5, "interspeech", 2016]], "Tanel Alumae": [0, ["Sage: The New BBN Speech Processing Platform", ["Roger Hsiao", "Ralf Meermeier", "Tim Ng", "Zhongqiang Huang", "Maxwell Jordan", "Enoch Kan", "Tanel Alumae", "Jan Silovsky", "William Hartmann", "Francis Keith", "Omer Lang", "Man-Hung Siu", "Owen Kimball"], "https://doi.org/10.21437/Interspeech.2016-1031", 5, "interspeech", 2016], ["Bidirectional Recurrent Neural Network with Attention Mechanism for Punctuation Restoration", ["Ottokar Tilk", "Tanel Alumae"], "https://doi.org/10.21437/Interspeech.2016-1517", 5, "interspeech", 2016], ["Improved Multilingual Training of Stacked Neural Network Acoustic Models for Low Resource Languages", ["Tanel Alumae", "Stavros Tsakalidis", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-1426", 5, "interspeech", 2016]], "Jan Silovsky": [0, ["Sage: The New BBN Speech Processing Platform", ["Roger Hsiao", "Ralf Meermeier", "Tim Ng", "Zhongqiang Huang", "Maxwell Jordan", "Enoch Kan", "Tanel Alumae", "Jan Silovsky", "William Hartmann", "Francis Keith", "Omer Lang", "Man-Hung Siu", "Owen Kimball"], "https://doi.org/10.21437/Interspeech.2016-1031", 5, "interspeech", 2016]], "Francis Keith": [0, ["Sage: The New BBN Speech Processing Platform", ["Roger Hsiao", "Ralf Meermeier", "Tim Ng", "Zhongqiang Huang", "Maxwell Jordan", "Enoch Kan", "Tanel Alumae", "Jan Silovsky", "William Hartmann", "Francis Keith", "Omer Lang", "Man-Hung Siu", "Owen Kimball"], "https://doi.org/10.21437/Interspeech.2016-1031", 5, "interspeech", 2016]], "Omer Lang": [0, ["Sage: The New BBN Speech Processing Platform", ["Roger Hsiao", "Ralf Meermeier", "Tim Ng", "Zhongqiang Huang", "Maxwell Jordan", "Enoch Kan", "Tanel Alumae", "Jan Silovsky", "William Hartmann", "Francis Keith", "Omer Lang", "Man-Hung Siu", "Owen Kimball"], "https://doi.org/10.21437/Interspeech.2016-1031", 5, "interspeech", 2016]], "Man-Hung Siu": [0, ["Sage: The New BBN Speech Processing Platform", ["Roger Hsiao", "Ralf Meermeier", "Tim Ng", "Zhongqiang Huang", "Maxwell Jordan", "Enoch Kan", "Tanel Alumae", "Jan Silovsky", "William Hartmann", "Francis Keith", "Omer Lang", "Man-Hung Siu", "Owen Kimball"], "https://doi.org/10.21437/Interspeech.2016-1031", 5, "interspeech", 2016]], "Owen Kimball": [0, ["Sage: The New BBN Speech Processing Platform", ["Roger Hsiao", "Ralf Meermeier", "Tim Ng", "Zhongqiang Huang", "Maxwell Jordan", "Enoch Kan", "Tanel Alumae", "Jan Silovsky", "William Hartmann", "Francis Keith", "Omer Lang", "Man-Hung Siu", "Owen Kimball"], "https://doi.org/10.21437/Interspeech.2016-1031", 5, "interspeech", 2016]], "Kang Hyun Lee": [0.9981042593717575, ["DNN-Based Feature Enhancement Using Joint Training Framework for Robust Multichannel Speech Recognition", ["Kang Hyun Lee", "Tae Gyoon Kang", "Woo Hyun Kang", "Nam Soo Kim"], "https://doi.org/10.21437/Interspeech.2016-105", 5, "interspeech", 2016]], "Tae Gyoon Kang": [0.9992877393960953, ["DNN-Based Feature Enhancement Using Joint Training Framework for Robust Multichannel Speech Recognition", ["Kang Hyun Lee", "Tae Gyoon Kang", "Woo Hyun Kang", "Nam Soo Kim"], "https://doi.org/10.21437/Interspeech.2016-105", 5, "interspeech", 2016]], "Woo Hyun Kang": [0.9989664554595947, ["DNN-Based Feature Enhancement Using Joint Training Framework for Robust Multichannel Speech Recognition", ["Kang Hyun Lee", "Tae Gyoon Kang", "Woo Hyun Kang", "Nam Soo Kim"], "https://doi.org/10.21437/Interspeech.2016-105", 5, "interspeech", 2016]], "Nam Soo Kim": [1, ["DNN-Based Feature Enhancement Using Joint Training Framework for Robust Multichannel Speech Recognition", ["Kang Hyun Lee", "Tae Gyoon Kang", "Woo Hyun Kang", "Nam Soo Kim"], "https://doi.org/10.21437/Interspeech.2016-105", 5, "interspeech", 2016]], "Michael Wand": [0, ["Deep Neural Network Frontend for Continuous EMG-Based Speech Recognition", ["Michael Wand", "Jurgen Schmidhuber"], "https://doi.org/10.21437/Interspeech.2016-340", 5, "interspeech", 2016]], "Jurgen Schmidhuber": [0, ["Deep Neural Network Frontend for Continuous EMG-Based Speech Recognition", ["Michael Wand", "Jurgen Schmidhuber"], "https://doi.org/10.21437/Interspeech.2016-340", 5, "interspeech", 2016]], "Edgar Dakin": [0, ["Multi-Language Neural Network Language Models", ["Anton Ragni", "Edgar Dakin", "Xie Chen", "Mark J. F. Gales", "Kate M. Knill"], "https://doi.org/10.21437/Interspeech.2016-371", 5, "interspeech", 2016]], "Xie Chen": [0, ["Multi-Language Neural Network Language Models", ["Anton Ragni", "Edgar Dakin", "Xie Chen", "Mark J. F. Gales", "Kate M. Knill"], "https://doi.org/10.21437/Interspeech.2016-371", 5, "interspeech", 2016]], "Ottokar Tilk": [0, ["Bidirectional Recurrent Neural Network with Attention Mechanism for Punctuation Restoration", ["Ottokar Tilk", "Tanel Alumae"], "https://doi.org/10.21437/Interspeech.2016-1517", 5, "interspeech", 2016]], "Seppo Enarvi": [0, ["TheanoLM - An Extensible Toolkit for Neural Network Language Modeling", ["Seppo Enarvi", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2016-618", 5, "interspeech", 2016]], "Pierre Lanchantin": [0, ["Selection of Multi-Genre Broadcast Data for the Training of Automatic Speech Recognition Systems", ["Pierre Lanchantin", "Mark J. F. Gales", "Penny Karanasou", "X. Liu", "Y. Qian", "L. Wang", "Philip C. Woodland", "C. Zhang"], "https://doi.org/10.21437/Interspeech.2016-462", 5, "interspeech", 2016]], "X. Liu": [0, ["Selection of Multi-Genre Broadcast Data for the Training of Automatic Speech Recognition Systems", ["Pierre Lanchantin", "Mark J. F. Gales", "Penny Karanasou", "X. Liu", "Y. Qian", "L. Wang", "Philip C. Woodland", "C. Zhang"], "https://doi.org/10.21437/Interspeech.2016-462", 5, "interspeech", 2016]], "Y. Qian": [0, ["Selection of Multi-Genre Broadcast Data for the Training of Automatic Speech Recognition Systems", ["Pierre Lanchantin", "Mark J. F. Gales", "Penny Karanasou", "X. Liu", "Y. Qian", "L. Wang", "Philip C. Woodland", "C. Zhang"], "https://doi.org/10.21437/Interspeech.2016-462", 5, "interspeech", 2016]], "L. Wang": [0.5, ["Selection of Multi-Genre Broadcast Data for the Training of Automatic Speech Recognition Systems", ["Pierre Lanchantin", "Mark J. F. Gales", "Penny Karanasou", "X. Liu", "Y. Qian", "L. Wang", "Philip C. Woodland", "C. Zhang"], "https://doi.org/10.21437/Interspeech.2016-462", 5, "interspeech", 2016]], "Philip C. Woodland": [0, ["Selection of Multi-Genre Broadcast Data for the Training of Automatic Speech Recognition Systems", ["Pierre Lanchantin", "Mark J. F. Gales", "Penny Karanasou", "X. Liu", "Y. Qian", "L. Wang", "Philip C. Woodland", "C. Zhang"], "https://doi.org/10.21437/Interspeech.2016-462", 5, "interspeech", 2016]], "C. Zhang": [0, ["Selection of Multi-Genre Broadcast Data for the Training of Automatic Speech Recognition Systems", ["Pierre Lanchantin", "Mark J. F. Gales", "Penny Karanasou", "X. Liu", "Y. Qian", "L. Wang", "Philip C. Woodland", "C. Zhang"], "https://doi.org/10.21437/Interspeech.2016-462", 5, "interspeech", 2016]], "Yashesh Gaur": [0, ["Manipulating Word Lattices to Incorporate Human Corrections", ["Yashesh Gaur", "Florian Metze", "Jeffrey P. Bigham"], "https://doi.org/10.21437/Interspeech.2016-660", 4, "interspeech", 2016]], "Jeffrey P. Bigham": [0, ["Manipulating Word Lattices to Incorporate Human Corrections", ["Yashesh Gaur", "Florian Metze", "Jeffrey P. Bigham"], "https://doi.org/10.21437/Interspeech.2016-660", 4, "interspeech", 2016]], "Philipp Fischer": [0, ["Context-Aware Restaurant Recommendation for Natural Language Queries: A Formative User Study in the Automotive Domain", ["Philipp Fischer", "Cornelius Styp von Rekowski", "Andreas Nurnberger"], "https://doi.org/10.21437/Interspeech.2016-1503", 5, "interspeech", 2016]], "Cornelius Styp von Rekowski": [0, ["Context-Aware Restaurant Recommendation for Natural Language Queries: A Formative User Study in the Automotive Domain", ["Philipp Fischer", "Cornelius Styp von Rekowski", "Andreas Nurnberger"], "https://doi.org/10.21437/Interspeech.2016-1503", 5, "interspeech", 2016]], "Andreas Nurnberger": [0, ["Context-Aware Restaurant Recommendation for Natural Language Queries: A Formative User Study in the Automotive Domain", ["Philipp Fischer", "Cornelius Styp von Rekowski", "Andreas Nurnberger"], "https://doi.org/10.21437/Interspeech.2016-1503", 5, "interspeech", 2016]], "Stephanie Pancoast": [0, ["Teaming Up: Making the Most of Diverse Representations for a Novel Personalized Speech Retrieval Application", ["Stephanie Pancoast", "Murat Akbacak"], "https://doi.org/10.21437/Interspeech.2016-1589", 5, "interspeech", 2016]], "Murat Akbacak": [0, ["Teaming Up: Making the Most of Diverse Representations for a Novel Personalized Speech Retrieval Application", ["Stephanie Pancoast", "Murat Akbacak"], "https://doi.org/10.21437/Interspeech.2016-1589", 5, "interspeech", 2016]], "Jonathan D. Amith": [0, ["Automatic Speech Transcription for Low-Resource Languages - The Case of Yolox\u00f3chitl Mixtec (Mexico)", ["Vikramjit Mitra", "Andreas Kathol", "Jonathan D. Amith", "Rey Castillo Garcia"], "https://doi.org/10.21437/Interspeech.2016-546", 5, "interspeech", 2016]], "Rey Castillo Garcia": [0, ["Automatic Speech Transcription for Low-Resource Languages - The Case of Yolox\u00f3chitl Mixtec (Mexico)", ["Vikramjit Mitra", "Andreas Kathol", "Jonathan D. Amith", "Rey Castillo Garcia"], "https://doi.org/10.21437/Interspeech.2016-546", 5, "interspeech", 2016]], "Reza Asadi": [0, ["Real-Time Presentation Tracking Using Semantic Keyword Spotting", ["Reza Asadi", "Harriet J. Fell", "Timothy W. Bickmore", "Ha Trinh"], "https://doi.org/10.21437/Interspeech.2016-617", 5, "interspeech", 2016]], "Harriet J. Fell": [0, ["Real-Time Presentation Tracking Using Semantic Keyword Spotting", ["Reza Asadi", "Harriet J. Fell", "Timothy W. Bickmore", "Ha Trinh"], "https://doi.org/10.21437/Interspeech.2016-617", 5, "interspeech", 2016]], "Timothy W. Bickmore": [0, ["Real-Time Presentation Tracking Using Semantic Keyword Spotting", ["Reza Asadi", "Harriet J. Fell", "Timothy W. Bickmore", "Ha Trinh"], "https://doi.org/10.21437/Interspeech.2016-617", 5, "interspeech", 2016]], "Ha Trinh": [0, ["Real-Time Presentation Tracking Using Semantic Keyword Spotting", ["Reza Asadi", "Harriet J. Fell", "Timothy W. Bickmore", "Ha Trinh"], "https://doi.org/10.21437/Interspeech.2016-617", 5, "interspeech", 2016]], "Andrew Wilkinson": [0, ["Deriving Phonetic Transcriptions and Discovering Word Segmentations for Speech-to-Speech Translation in Low-Resource Settings", ["Andrew Wilkinson", "Tiancheng Zhao", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2016-1319", 5, "interspeech", 2016]], "Tiancheng Zhao": [0, ["Deriving Phonetic Transcriptions and Discovering Word Segmentations for Speech-to-Speech Translation in Low-Resource Settings", ["Andrew Wilkinson", "Tiancheng Zhao", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2016-1319", 5, "interspeech", 2016]], "Satoshi Tsujioka": [0, ["Unsupervised Joint Estimation of Grapheme-to-Phoneme Conversion Systems and Acoustic Model Adaptation for Non-Native Speech Recognition", ["Satoshi Tsujioka", "Sakriani Sakti", "Koichiro Yoshino", "Graham Neubig", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-919", 5, "interspeech", 2016]], "Koichiro Yoshino": [0, ["Unsupervised Joint Estimation of Grapheme-to-Phoneme Conversion Systems and Acoustic Model Adaptation for Non-Native Speech Recognition", ["Satoshi Tsujioka", "Sakriani Sakti", "Koichiro Yoshino", "Graham Neubig", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2016-919", 5, "interspeech", 2016]], "Antoine Bruguier": [0, ["Learning Personalized Pronunciations for Contact Name Recognition", ["Antoine Bruguier", "Fuchun Peng", "Francoise Beaufays"], "https://doi.org/10.21437/Interspeech.2016-537", 5, "interspeech", 2016], ["NN-Grams: Unifying Neural Network and n-Gram Language Models for Speech Recognition", ["Babak Damavandi", "Shankar Kumar", "Noam Shazeer", "Antoine Bruguier"], "https://doi.org/10.21437/Interspeech.2016-1295", 5, "interspeech", 2016]], "Fuchun Peng": [0, ["Learning Personalized Pronunciations for Contact Name Recognition", ["Antoine Bruguier", "Fuchun Peng", "Francoise Beaufays"], "https://doi.org/10.21437/Interspeech.2016-537", 5, "interspeech", 2016]], "Francoise Beaufays": [0, ["Learning Personalized Pronunciations for Contact Name Recognition", ["Antoine Bruguier", "Fuchun Peng", "Francoise Beaufays"], "https://doi.org/10.21437/Interspeech.2016-537", 5, "interspeech", 2016]], "Zhenhao Ge": [0, ["Generation and Pruning of Pronunciation Variants to Improve ASR Accuracy", ["Zhenhao Ge", "Aravind Ganapathiraju", "Ananth N. Iyer", "Scott A. Randal", "Felix I. Wyss"], "https://doi.org/10.21437/Interspeech.2016-1375", 5, "interspeech", 2016]], "Aravind Ganapathiraju": [0, ["Generation and Pruning of Pronunciation Variants to Improve ASR Accuracy", ["Zhenhao Ge", "Aravind Ganapathiraju", "Ananth N. Iyer", "Scott A. Randal", "Felix I. Wyss"], "https://doi.org/10.21437/Interspeech.2016-1375", 5, "interspeech", 2016]], "Ananth N. Iyer": [0, ["Generation and Pruning of Pronunciation Variants to Improve ASR Accuracy", ["Zhenhao Ge", "Aravind Ganapathiraju", "Ananth N. Iyer", "Scott A. Randal", "Felix I. Wyss"], "https://doi.org/10.21437/Interspeech.2016-1375", 5, "interspeech", 2016]], "Scott A. Randal": [0, ["Generation and Pruning of Pronunciation Variants to Improve ASR Accuracy", ["Zhenhao Ge", "Aravind Ganapathiraju", "Ananth N. Iyer", "Scott A. Randal", "Felix I. Wyss"], "https://doi.org/10.21437/Interspeech.2016-1375", 5, "interspeech", 2016]], "Felix I. Wyss": [0, ["Generation and Pruning of Pronunciation Variants to Improve ASR Accuracy", ["Zhenhao Ge", "Aravind Ganapathiraju", "Ananth N. Iyer", "Scott A. Randal", "Felix I. Wyss"], "https://doi.org/10.21437/Interspeech.2016-1375", 5, "interspeech", 2016]], "Max Bisani": [0, ["Optimizing Speech Recognition Evaluation Using Stratified Sampling", ["Janne Pylkkonen", "Thomas Drugman", "Max Bisani"], "https://doi.org/10.21437/Interspeech.2016-1364", 5, "interspeech", 2016]], "Nicolas Scheffer": [0, ["Speech Ventures", ["Nicolas Scheffer", "Korbinian Riedhammer", "Alexandre Lebrun", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs15.html", 0, "interspeech", 2016]], "Alexandre Lebrun": [0, ["Speech Ventures", ["Nicolas Scheffer", "Korbinian Riedhammer", "Alexandre Lebrun", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs15.html", 0, "interspeech", 2016]], "David Suendermann-Oeft": [0, ["Speech Ventures", ["Nicolas Scheffer", "Korbinian Riedhammer", "Alexandre Lebrun", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs15.html", 0, "interspeech", 2016], ["Self-Adaptive DNN for Improving Spoken Language Proficiency Assessment", ["Yao Qian", "Xinhao Wang", "Keelan Evanini", "David Suendermann-Oeft"], "https://doi.org/10.21437/Interspeech.2016-291", 5, "interspeech", 2016], ["Noise and Metadata Sensitive Bottleneck Features for Improving Speaker Recognition with Non-Native Speech Input", ["Yao Qian", "Jidong Tao", "David Suendermann-Oeft", "Keelan Evanini", "Alexei V. Ivanov", "Vikram Ramanarayanan"], "https://doi.org/10.21437/Interspeech.2016-548", 5, "interspeech", 2016]], "Jidong Tao": [0, ["DNN Online with iVectors Acoustic Modeling and Doc2Vec Distributed Representations for Improving Automated Speech Scoring", ["Jidong Tao", "Lei Chen", "Chong Min Lee"], "https://doi.org/10.21437/Interspeech.2016-1457", 5, "interspeech", 2016], ["Noise and Metadata Sensitive Bottleneck Features for Improving Speaker Recognition with Non-Native Speech Input", ["Yao Qian", "Jidong Tao", "David Suendermann-Oeft", "Keelan Evanini", "Alexei V. Ivanov", "Vikram Ramanarayanan"], "https://doi.org/10.21437/Interspeech.2016-548", 5, "interspeech", 2016]], "Yao Qian": [0, ["Self-Adaptive DNN for Improving Spoken Language Proficiency Assessment", ["Yao Qian", "Xinhao Wang", "Keelan Evanini", "David Suendermann-Oeft"], "https://doi.org/10.21437/Interspeech.2016-291", 5, "interspeech", 2016], ["Noise and Metadata Sensitive Bottleneck Features for Improving Speaker Recognition with Non-Native Speech Input", ["Yao Qian", "Jidong Tao", "David Suendermann-Oeft", "Keelan Evanini", "Alexei V. Ivanov", "Vikram Ramanarayanan"], "https://doi.org/10.21437/Interspeech.2016-548", 5, "interspeech", 2016]], "Xinhao Wang": [5.575418953185363e-07, ["Self-Adaptive DNN for Improving Spoken Language Proficiency Assessment", ["Yao Qian", "Xinhao Wang", "Keelan Evanini", "David Suendermann-Oeft"], "https://doi.org/10.21437/Interspeech.2016-291", 5, "interspeech", 2016]], "Wei Li": [0, ["Detecting Mispronunciations of L2 Learners and Providing Corrective Feedback Using Knowledge-Guided and Data-Driven Decision Trees", ["Wei Li", "Kehuang Li", "Sabato Marco Siniscalchi", "Nancy F. Chen", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2016-517", 5, "interspeech", 2016]], "Kehuang Li": [0, ["Detecting Mispronunciations of L2 Learners and Providing Corrective Feedback Using Knowledge-Guided and Data-Driven Decision Trees", ["Wei Li", "Kehuang Li", "Sabato Marco Siniscalchi", "Nancy F. Chen", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2016-517", 5, "interspeech", 2016], ["An Iterative Phase Recovery Framework with Phase Mask for Spectral Mapping with an Application to Speech Enhancement", ["Kehuang Li", "Bo Wu", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2016-494", 5, "interspeech", 2016]], "Sabato Marco Siniscalchi": [0, ["Detecting Mispronunciations of L2 Learners and Providing Corrective Feedback Using Knowledge-Guided and Data-Driven Decision Trees", ["Wei Li", "Kehuang Li", "Sabato Marco Siniscalchi", "Nancy F. Chen", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2016-517", 5, "interspeech", 2016]], "Chin-Hui Lee": [0.5, ["Detecting Mispronunciations of L2 Learners and Providing Corrective Feedback Using Knowledge-Guided and Data-Driven Decision Trees", ["Wei Li", "Kehuang Li", "Sabato Marco Siniscalchi", "Nancy F. Chen", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2016-517", 5, "interspeech", 2016], ["SNR-Based Progressive Learning of Deep Neural Network for Speech Enhancement", ["Tian Gao", "Jun Du", "Li-Rong Dai", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2016-224", 5, "interspeech", 2016], ["An Iterative Phase Recovery Framework with Phase Mask for Spectral Mapping with an Application to Speech Enhancement", ["Kehuang Li", "Bo Wu", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2016-494", 5, "interspeech", 2016]], "Tsuneo Kato": [0, ["Phoneme Set Design Considering Integrated Acoustic and Linguistic Features of Second Language Speech", ["Xiaoyun Wang", "Tsuneo Kato", "Seiichi Yamamoto"], "https://doi.org/10.21437/Interspeech.2016-663", 5, "interspeech", 2016]], "Ramya Rasipuram": [0, ["HMM-Based Non-Native Accent Assessment Using Posterior Features", ["Ramya Rasipuram", "Milos Cernak", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2016-750", 5, "interspeech", 2016]], "Mathew Magimai-Doss": [0, ["HMM-Based Non-Native Accent Assessment Using Posterior Features", ["Ramya Rasipuram", "Milos Cernak", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2016-750", 5, "interspeech", 2016], ["Improving Under-Resourced Language ASR Through Latent Subword Unit Space Discovery", ["Marzieh Razavi", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2016-1010", 5, "interspeech", 2016]], "Shuju Shi": [0, ["Automatic Assessment and Error Detection of Shadowing Speech: Case of English Spoken by Japanese Learners", ["Shuju Shi", "Yosuke Kashiwagi", "Shohei Toyama", "Junwei Yue", "Yutaka Yamauchi", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2016-915", 5, "interspeech", 2016]], "Yosuke Kashiwagi": [0, ["Automatic Assessment and Error Detection of Shadowing Speech: Case of English Spoken by Japanese Learners", ["Shuju Shi", "Yosuke Kashiwagi", "Shohei Toyama", "Junwei Yue", "Yutaka Yamauchi", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2016-915", 5, "interspeech", 2016]], "Shohei Toyama": [0, ["Automatic Assessment and Error Detection of Shadowing Speech: Case of English Spoken by Japanese Learners", ["Shuju Shi", "Yosuke Kashiwagi", "Shohei Toyama", "Junwei Yue", "Yutaka Yamauchi", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2016-915", 5, "interspeech", 2016]], "Junwei Yue": [0, ["Automatic Assessment and Error Detection of Shadowing Speech: Case of English Spoken by Japanese Learners", ["Shuju Shi", "Yosuke Kashiwagi", "Shohei Toyama", "Junwei Yue", "Yutaka Yamauchi", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2016-915", 5, "interspeech", 2016]], "Yutaka Yamauchi": [0, ["Automatic Assessment and Error Detection of Shadowing Speech: Case of English Spoken by Japanese Learners", ["Shuju Shi", "Yosuke Kashiwagi", "Shohei Toyama", "Junwei Yue", "Yutaka Yamauchi", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2016-915", 5, "interspeech", 2016]], "Yossi Adi": [0, ["Automatic Measurement of Voice Onset Time and Prevoicing Using Recurrent Neural Networks", ["Yossi Adi", "Joseph Keshet", "Olga Dmitrieva", "Matthew Goldrick"], "https://doi.org/10.21437/Interspeech.2016-893", 4, "interspeech", 2016]], "Olga Dmitrieva": [0, ["Automatic Measurement of Voice Onset Time and Prevoicing Using Recurrent Neural Networks", ["Yossi Adi", "Joseph Keshet", "Olga Dmitrieva", "Matthew Goldrick"], "https://doi.org/10.21437/Interspeech.2016-893", 4, "interspeech", 2016]], "Matthew Goldrick": [0, ["Automatic Measurement of Voice Onset Time and Prevoicing Using Recurrent Neural Networks", ["Yossi Adi", "Joseph Keshet", "Olga Dmitrieva", "Matthew Goldrick"], "https://doi.org/10.21437/Interspeech.2016-893", 4, "interspeech", 2016]], "Sucheta Ghosh": [0, ["L1-L2 Interference: The Case of Final Devoicing of French Voiced Fricatives in Final Position by German Learners", ["Sucheta Ghosh", "Camille Fauth", "Aghilas Sini", "Yves Laprie"], "https://doi.org/10.21437/Interspeech.2016-954", 5, "interspeech", 2016]], "Camille Fauth": [0, ["L1-L2 Interference: The Case of Final Devoicing of French Voiced Fricatives in Final Position by German Learners", ["Sucheta Ghosh", "Camille Fauth", "Aghilas Sini", "Yves Laprie"], "https://doi.org/10.21437/Interspeech.2016-954", 5, "interspeech", 2016]], "Aghilas Sini": [0, ["L1-L2 Interference: The Case of Final Devoicing of French Voiced Fricatives in Final Position by German Learners", ["Sucheta Ghosh", "Camille Fauth", "Aghilas Sini", "Yves Laprie"], "https://doi.org/10.21437/Interspeech.2016-954", 5, "interspeech", 2016]], "Yves Laprie": [0, ["L1-L2 Interference: The Case of Final Devoicing of French Voiced Fricatives in Final Position by German Learners", ["Sucheta Ghosh", "Camille Fauth", "Aghilas Sini", "Yves Laprie"], "https://doi.org/10.21437/Interspeech.2016-954", 5, "interspeech", 2016]], "Irena Yanushevskaya": [0, ["Perceptual Salience of Voice Source Parameters in Signaling Focal Prominence", ["Irena Yanushevskaya", "Andy Murphy", "Christer Gobl", "Ailbhe Ni Chasaide"], "https://doi.org/10.21437/Interspeech.2016-1160", 5, "interspeech", 2016]], "Andy Murphy": [0, ["Perceptual Salience of Voice Source Parameters in Signaling Focal Prominence", ["Irena Yanushevskaya", "Andy Murphy", "Christer Gobl", "Ailbhe Ni Chasaide"], "https://doi.org/10.21437/Interspeech.2016-1160", 5, "interspeech", 2016]], "Christer Gobl": [0, ["Perceptual Salience of Voice Source Parameters in Signaling Focal Prominence", ["Irena Yanushevskaya", "Andy Murphy", "Christer Gobl", "Ailbhe Ni Chasaide"], "https://doi.org/10.21437/Interspeech.2016-1160", 5, "interspeech", 2016]], "Ailbhe Ni Chasaide": [0, ["Perceptual Salience of Voice Source Parameters in Signaling Focal Prominence", ["Irena Yanushevskaya", "Andy Murphy", "Christer Gobl", "Ailbhe Ni Chasaide"], "https://doi.org/10.21437/Interspeech.2016-1160", 5, "interspeech", 2016]], "Michal Borsky": [0, ["Classification of Voice Modality Using Electroglottogram Waveforms", ["Michal Borsky", "Daryush D. Mehta", "Julius P. Gudjohnsen", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2016-1194", 5, "interspeech", 2016]], "Julius P. Gudjohnsen": [0, ["Classification of Voice Modality Using Electroglottogram Waveforms", ["Michal Borsky", "Daryush D. Mehta", "Julius P. Gudjohnsen", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2016-1194", 5, "interspeech", 2016]], "Jon Gudnason": [0, ["Classification of Voice Modality Using Electroglottogram Waveforms", ["Michal Borsky", "Daryush D. Mehta", "Julius P. Gudjohnsen", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2016-1194", 5, "interspeech", 2016]], "Kikuo Maekawa": [0, ["Voice-Quality Difference Between the Vowels in Filled Pauses and Ordinary Lexical Items", ["Kikuo Maekawa", "Hiroki Mori"], "https://doi.org/10.21437/Interspeech.2016-1309", 5, "interspeech", 2016]], "Hiroki Mori": [0, ["Voice-Quality Difference Between the Vowels in Filled Pauses and Ordinary Lexical Items", ["Kikuo Maekawa", "Hiroki Mori"], "https://doi.org/10.21437/Interspeech.2016-1309", 5, "interspeech", 2016]], "Yan-You Chen": [0, ["Generation of Emotion Control Vector Using MDS-Based Space Transformation for Expressive Speech Synthesis", ["Yan-You Chen", "Chung-Hsien Wu", "Yu-Fong Huang"], "https://doi.org/10.21437/Interspeech.2016-815", 5, "interspeech", 2016]], "Yu-Fong Huang": [0, ["Generation of Emotion Control Vector Using MDS-Based Space Transformation for Expressive Speech Synthesis", ["Yan-You Chen", "Chung-Hsien Wu", "Yu-Fong Huang"], "https://doi.org/10.21437/Interspeech.2016-815", 5, "interspeech", 2016]], "Igor Jauk": [0, ["Direct Expressive Voice Training Based on Semantic Selection", ["Igor Jauk", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2016-979", 5, "interspeech", 2016]], "Ranniery Maia": [0, ["Pause Prediction from Text for Speech Synthesis with User-Definable Pause Insertion Likelihood Threshold", ["Norbert Braunschweiler", "Ranniery Maia"], "https://doi.org/10.21437/Interspeech.2016-752", 5, "interspeech", 2016]], "Yibin Zheng": [0, ["Improving Prosodic Boundaries Prediction for Mandarin Speech Synthesis by Using Enhanced Embedding Feature and Model Fusion Approach", ["Yibin Zheng", "Ya Li", "Zhengqi Wen", "Xingguang Ding", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2016-1060", 5, "interspeech", 2016]], "Xingguang Ding": [0, ["Improving Prosodic Boundaries Prediction for Mandarin Speech Synthesis by Using Enhanced Embedding Feature and Model Fusion Approach", ["Yibin Zheng", "Ya Li", "Zhengqi Wen", "Xingguang Ding", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2016-1060", 5, "interspeech", 2016]], "Hui Zhao": [0, ["Results of The 2015 NIST Language Recognition Evaluation", ["Hui Zhao", "Desire Banse", "George R. Doddington", "Craig S. Greenberg", "Jaime Hernandez-Cordero", "John M. Howard", "Lisa P. Mason", "Alvin F. Martin", "Douglas A. Reynolds", "Elliot Singer", "Audrey Tong"], "https://doi.org/10.21437/Interspeech.2016-169", 5, "interspeech", 2016]], "Desire Banse": [0, ["Results of The 2015 NIST Language Recognition Evaluation", ["Hui Zhao", "Desire Banse", "George R. Doddington", "Craig S. Greenberg", "Jaime Hernandez-Cordero", "John M. Howard", "Lisa P. Mason", "Alvin F. Martin", "Douglas A. Reynolds", "Elliot Singer", "Audrey Tong"], "https://doi.org/10.21437/Interspeech.2016-169", 5, "interspeech", 2016]], "George R. Doddington": [0, ["Results of The 2015 NIST Language Recognition Evaluation", ["Hui Zhao", "Desire Banse", "George R. Doddington", "Craig S. Greenberg", "Jaime Hernandez-Cordero", "John M. Howard", "Lisa P. Mason", "Alvin F. Martin", "Douglas A. Reynolds", "Elliot Singer", "Audrey Tong"], "https://doi.org/10.21437/Interspeech.2016-169", 5, "interspeech", 2016]], "Craig S. Greenberg": [0, ["Results of The 2015 NIST Language Recognition Evaluation", ["Hui Zhao", "Desire Banse", "George R. Doddington", "Craig S. Greenberg", "Jaime Hernandez-Cordero", "John M. Howard", "Lisa P. Mason", "Alvin F. Martin", "Douglas A. Reynolds", "Elliot Singer", "Audrey Tong"], "https://doi.org/10.21437/Interspeech.2016-169", 5, "interspeech", 2016]], "Jaime Hernandez-Cordero": [0, ["Results of The 2015 NIST Language Recognition Evaluation", ["Hui Zhao", "Desire Banse", "George R. Doddington", "Craig S. Greenberg", "Jaime Hernandez-Cordero", "John M. Howard", "Lisa P. Mason", "Alvin F. Martin", "Douglas A. Reynolds", "Elliot Singer", "Audrey Tong"], "https://doi.org/10.21437/Interspeech.2016-169", 5, "interspeech", 2016]], "John M. Howard": [0, ["Results of The 2015 NIST Language Recognition Evaluation", ["Hui Zhao", "Desire Banse", "George R. Doddington", "Craig S. Greenberg", "Jaime Hernandez-Cordero", "John M. Howard", "Lisa P. Mason", "Alvin F. Martin", "Douglas A. Reynolds", "Elliot Singer", "Audrey Tong"], "https://doi.org/10.21437/Interspeech.2016-169", 5, "interspeech", 2016]], "Lisa P. Mason": [0, ["Results of The 2015 NIST Language Recognition Evaluation", ["Hui Zhao", "Desire Banse", "George R. Doddington", "Craig S. Greenberg", "Jaime Hernandez-Cordero", "John M. Howard", "Lisa P. Mason", "Alvin F. Martin", "Douglas A. Reynolds", "Elliot Singer", "Audrey Tong"], "https://doi.org/10.21437/Interspeech.2016-169", 5, "interspeech", 2016]], "Alvin F. Martin": [0, ["Results of The 2015 NIST Language Recognition Evaluation", ["Hui Zhao", "Desire Banse", "George R. Doddington", "Craig S. Greenberg", "Jaime Hernandez-Cordero", "John M. Howard", "Lisa P. Mason", "Alvin F. Martin", "Douglas A. Reynolds", "Elliot Singer", "Audrey Tong"], "https://doi.org/10.21437/Interspeech.2016-169", 5, "interspeech", 2016]], "Audrey Tong": [0, ["Results of The 2015 NIST Language Recognition Evaluation", ["Hui Zhao", "Desire Banse", "George R. Doddington", "Craig S. Greenberg", "Jaime Hernandez-Cordero", "John M. Howard", "Lisa P. Mason", "Alvin F. Martin", "Douglas A. Reynolds", "Elliot Singer", "Audrey Tong"], "https://doi.org/10.21437/Interspeech.2016-169", 5, "interspeech", 2016]], "Wei Rao": [0, ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016]], "Aleksandr Sizov": [0, ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016]], "Jianshu Chen": [0, ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016]], "Amir Hossein Poorjam": [0, ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016]], "Trung Ngo Trong": [0, ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016], ["Variation in Spoken North Sami Language", ["Kristiina Jokinen", "Trung Ngo Trong", "Ville Hautamaki"], "https://doi.org/10.21437/Interspeech.2016-1438", 5, "interspeech", 2016]], "Chenglin Xu": [0, ["The 2015 NIST Language Recognition Evaluation: The Shared View of I2R, Fantastic4 and SingaMS", ["Kong-Aik Lee", "Haizhou Li", "Li Deng", "Ville Hautamaki", "Wei Rao", "Xiong Xiao", "Anthony Larcher", "Hanwu Sun", "Trung Hieu Nguyen", "Guangsen Wang", "Aleksandr Sizov", "Jianshu Chen", "Ivan Kukanov", "Amir Hossein Poorjam", "Trung Ngo Trong", "Chenglin Xu", "Haihua Xu", "Bin Ma", "Eng Siong Chng", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2016-624", 5, "interspeech", 2016]], "Peng Shen": [0, ["Pair-Wise Distance Metric Learning of Neural Network Model for Spoken Language Identification", ["Xugang Lu", "Peng Shen", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2016-722", 5, "interspeech", 2016]], "Gregory Gelly": [0, ["A Divide-and-Conquer Approach for Language Identification Based on Recurrent Neural Networks", ["Gregory Gelly", "Jean-Luc Gauvain", "Viet Bac Le", "Abdelkhalek Messaoudi"], "https://doi.org/10.21437/Interspeech.2016-180", 5, "interspeech", 2016]], "Viet Bac Le": [0, ["A Divide-and-Conquer Approach for Language Identification Based on Recurrent Neural Networks", ["Gregory Gelly", "Jean-Luc Gauvain", "Viet Bac Le", "Abdelkhalek Messaoudi"], "https://doi.org/10.21437/Interspeech.2016-180", 5, "interspeech", 2016]], "Abdelkhalek Messaoudi": [0, ["A Divide-and-Conquer Approach for Language Identification Based on Recurrent Neural Networks", ["Gregory Gelly", "Jean-Luc Gauvain", "Viet Bac Le", "Abdelkhalek Messaoudi"], "https://doi.org/10.21437/Interspeech.2016-180", 5, "interspeech", 2016]], "Chiori Hori": [0, ["Context-Sensitive and Role-Dependent Spoken Language Understanding Using Bidirectional and Attention LSTMs", ["Chiori Hori", "Takaaki Hori", "Shinji Watanabe", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2016-1171", 5, "interspeech", 2016]], "Takaaki Hori": [0, ["Context-Sensitive and Role-Dependent Spoken Language Understanding Using Bidirectional and Attention LSTMs", ["Chiori Hori", "Takaaki Hori", "Shinji Watanabe", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2016-1171", 5, "interspeech", 2016]], "Vedran Vukotic": [0, ["A Step Beyond Local Observations with a Dialog Aware Bidirectional GRU Network for Spoken Language Understanding", ["Vedran Vukotic", "Christian Raymond", "Guillaume Gravier"], "https://doi.org/10.21437/Interspeech.2016-1301", 4, "interspeech", 2016]], "Christian Raymond": [0, ["A Step Beyond Local Observations with a Dialog Aware Bidirectional GRU Network for Spoken Language Understanding", ["Vedran Vukotic", "Christian Raymond", "Guillaume Gravier"], "https://doi.org/10.21437/Interspeech.2016-1301", 4, "interspeech", 2016]], "Guillaume Gravier": [0, ["A Step Beyond Local Observations with a Dialog Aware Bidirectional GRU Network for Spoken Language Understanding", ["Vedran Vukotic", "Christian Raymond", "Guillaume Gravier"], "https://doi.org/10.21437/Interspeech.2016-1301", 4, "interspeech", 2016]], "Nikhil Ramesh": [0, ["A New Pre-Training Method for Training Deep Learning Models with Application to Spoken Language Understanding", ["Asli Celikyilmaz", "Ruhi Sarikaya", "Dilek Hakkani-Tur", "Xiaohu Liu", "Nikhil Ramesh", "Gokhan Tur"], "https://doi.org/10.21437/Interspeech.2016-512", 5, "interspeech", 2016]], "Jeremie Tafforeau": [0, ["Joint Syntactic and Semantic Analysis with a Multitask Deep Learning Framework for Spoken Language Understanding", ["Jeremie Tafforeau", "Frederic Bechet", "Thierry Artieres", "Benoit Favre"], "https://doi.org/10.21437/Interspeech.2016-851", 5, "interspeech", 2016]], "Thierry Artieres": [0, ["Joint Syntactic and Semantic Analysis with a Multitask Deep Learning Framework for Spoken Language Understanding", ["Jeremie Tafforeau", "Frederic Bechet", "Thierry Artieres", "Benoit Favre"], "https://doi.org/10.21437/Interspeech.2016-851", 5, "interspeech", 2016]], "Ruizhi Li": [0, ["Exploiting Hidden-Layer Responses of Deep Neural Networks for Language Recognition", ["Ruizhi Li", "Sri Harish Reddy Mallidi", "Lukas Burget", "Oldrich Plchot", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2016-1584", 5, "interspeech", 2016]], "Sri Harish Reddy Mallidi": [0, ["Exploiting Hidden-Layer Responses of Deep Neural Networks for Language Recognition", ["Ruizhi Li", "Sri Harish Reddy Mallidi", "Lukas Burget", "Oldrich Plchot", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2016-1584", 5, "interspeech", 2016], ["A Framework for Practical Multistream ASR", ["Sri Harish Reddy Mallidi", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2016-619", 5, "interspeech", 2016]], "Hirokazu Masataki": [0, ["Language Identification Based on Generative Modeling of Posteriorgram Sequences Extracted from Frame-by-Frame DNNs and LSTM-RNNs", ["Ryo Masumura", "Taichi Asami", "Hirokazu Masataki", "Yushi Aono", "Sumitaka Sakauchi"], "https://doi.org/10.21437/Interspeech.2016-719", 5, "interspeech", 2016]], "Sumitaka Sakauchi": [0, ["Language Identification Based on Generative Modeling of Posteriorgram Sequences Extracted from Frame-by-Frame DNNs and LSTM-RNNs", ["Ryo Masumura", "Taichi Asami", "Hirokazu Masataki", "Yushi Aono", "Sumitaka Sakauchi"], "https://doi.org/10.21437/Interspeech.2016-719", 5, "interspeech", 2016]], "Jan Pesan": [0, ["Sequence Summarizing Neural Networks for Spoken Language Recognition", ["Jan Pesan", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2016-764", 4, "interspeech", 2016]], "Michelle R. Kapolowicz": [0, ["The Role of Spectral Resolution in Foreign-Accented Speech Perception", ["Michelle R. Kapolowicz", "Vahid Montazeri", "Peter F. Assmann"], "https://doi.org/10.21437/Interspeech.2016-1585", 5, "interspeech", 2016]], "Vahid Montazeri": [0, ["The Role of Spectral Resolution in Foreign-Accented Speech Perception", ["Michelle R. Kapolowicz", "Vahid Montazeri", "Peter F. Assmann"], "https://doi.org/10.21437/Interspeech.2016-1585", 5, "interspeech", 2016], ["Effects of Cochlear Hearing Loss on the Benefits of Ideal Binary Masking", ["Vahid Montazeri", "Shaikat Hossain", "Peter F. Assmann"], "https://doi.org/10.21437/Interspeech.2016-1555", 5, "interspeech", 2016]], "Peter F. Assmann": [0, ["The Role of Spectral Resolution in Foreign-Accented Speech Perception", ["Michelle R. Kapolowicz", "Vahid Montazeri", "Peter F. Assmann"], "https://doi.org/10.21437/Interspeech.2016-1585", 5, "interspeech", 2016], ["Effects of Cochlear Hearing Loss on the Benefits of Ideal Binary Masking", ["Vahid Montazeri", "Shaikat Hossain", "Peter F. Assmann"], "https://doi.org/10.21437/Interspeech.2016-1555", 5, "interspeech", 2016]], "Jiaming Xu": [0, ["THU-EE System Description for NIST LRE 2015", ["Liang He", "Yao Tian", "Yi Liu", "Jiaming Xu", "Weiwei Liu", "Cai Meng", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-791", 5, "interspeech", 2016]], "Weiwei Liu": [0, ["THU-EE System Description for NIST LRE 2015", ["Liang He", "Yao Tian", "Yi Liu", "Jiaming Xu", "Weiwei Liu", "Cai Meng", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-791", 5, "interspeech", 2016]], "Cai Meng": [0, ["THU-EE System Description for NIST LRE 2015", ["Liang He", "Yao Tian", "Yi Liu", "Jiaming Xu", "Weiwei Liu", "Cai Meng", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2016-791", 5, "interspeech", 2016]], "Kristiina Jokinen": [0, ["Variation in Spoken North Sami Language", ["Kristiina Jokinen", "Trung Ngo Trong", "Ville Hautamaki"], "https://doi.org/10.21437/Interspeech.2016-1438", 5, "interspeech", 2016]], "Weibin Zhang": [0, ["Improved Music Genre Classification with Convolutional Neural Networks", ["Weibin Zhang", "Wenkang Lei", "Xiangmin Xu", "Xiaofeng Xing"], "https://doi.org/10.21437/Interspeech.2016-1236", 5, "interspeech", 2016]], "Wenkang Lei": [0, ["Improved Music Genre Classification with Convolutional Neural Networks", ["Weibin Zhang", "Wenkang Lei", "Xiangmin Xu", "Xiaofeng Xing"], "https://doi.org/10.21437/Interspeech.2016-1236", 5, "interspeech", 2016]], "Xiangmin Xu": [0, ["Improved Music Genre Classification with Convolutional Neural Networks", ["Weibin Zhang", "Wenkang Lei", "Xiangmin Xu", "Xiaofeng Xing"], "https://doi.org/10.21437/Interspeech.2016-1236", 5, "interspeech", 2016]], "Xiaofeng Xing": [0, ["Improved Music Genre Classification with Convolutional Neural Networks", ["Weibin Zhang", "Wenkang Lei", "Xiangmin Xu", "Xiaofeng Xing"], "https://doi.org/10.21437/Interspeech.2016-1236", 5, "interspeech", 2016]], "Jitong Chen": [0, ["Long Short-Term Memory for Speaker Generalization in Supervised Speech Separation", ["Jitong Chen", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2016-551", 5, "interspeech", 2016]], "Thomas Bentsen": [0, ["Comparing the Influence of Spectro-Temporal Integration in Computational Speech Segregation", ["Thomas Bentsen", "Tobias May", "Abigail A. Kressner", "Torsten Dau"], "https://doi.org/10.21437/Interspeech.2016-1025", 5, "interspeech", 2016]], "Tobias May": [0, ["Comparing the Influence of Spectro-Temporal Integration in Computational Speech Segregation", ["Thomas Bentsen", "Tobias May", "Abigail A. Kressner", "Torsten Dau"], "https://doi.org/10.21437/Interspeech.2016-1025", 5, "interspeech", 2016]], "Abigail A. Kressner": [0, ["Comparing the Influence of Spectro-Temporal Integration in Computational Speech Segregation", ["Thomas Bentsen", "Tobias May", "Abigail A. Kressner", "Torsten Dau"], "https://doi.org/10.21437/Interspeech.2016-1025", 5, "interspeech", 2016]], "Torsten Dau": [0, ["Comparing the Influence of Spectro-Temporal Integration in Computational Speech Segregation", ["Thomas Bentsen", "Tobias May", "Abigail A. Kressner", "Torsten Dau"], "https://doi.org/10.21437/Interspeech.2016-1025", 5, "interspeech", 2016]], "Sean U. N. Wood": [0, ["Blind Speech Separation with GCC-NMF", ["Sean U. N. Wood", "Jean Rouat"], "https://doi.org/10.21437/Interspeech.2016-1449", 5, "interspeech", 2016]], "Jean Rouat": [0, ["Blind Speech Separation with GCC-NMF", ["Sean U. N. Wood", "Jean Rouat"], "https://doi.org/10.21437/Interspeech.2016-1449", 5, "interspeech", 2016]], "Shaikat Hossain": [0, ["Effects of Cochlear Hearing Loss on the Benefits of Ideal Binary Masking", ["Vahid Montazeri", "Shaikat Hossain", "Peter F. Assmann"], "https://doi.org/10.21437/Interspeech.2016-1555", 5, "interspeech", 2016]], "Emad M. Grais": [0, ["Combining Mask Estimates for Single Channel Audio Source Separation Using Deep Neural Networks", ["Emad M. Grais", "Gerard Roma", "Andrew J. R. Simpson", "Mark D. Plumbley"], "https://doi.org/10.21437/Interspeech.2016-216", 5, "interspeech", 2016]], "Gerard Roma": [0, ["Combining Mask Estimates for Single Channel Audio Source Separation Using Deep Neural Networks", ["Emad M. Grais", "Gerard Roma", "Andrew J. R. Simpson", "Mark D. Plumbley"], "https://doi.org/10.21437/Interspeech.2016-216", 5, "interspeech", 2016]], "Andrew J. R. Simpson": [0, ["Combining Mask Estimates for Single Channel Audio Source Separation Using Deep Neural Networks", ["Emad M. Grais", "Gerard Roma", "Andrew J. R. Simpson", "Mark D. Plumbley"], "https://doi.org/10.21437/Interspeech.2016-216", 5, "interspeech", 2016]], "Mark D. Plumbley": [0, ["Combining Mask Estimates for Single Channel Audio Source Separation Using Deep Neural Networks", ["Emad M. Grais", "Gerard Roma", "Andrew J. R. Simpson", "Mark D. Plumbley"], "https://doi.org/10.21437/Interspeech.2016-216", 5, "interspeech", 2016]], "Cosimo Riday": [0, ["Monaural Source Separation Using a Random Forest Classifier", ["Cosimo Riday", "Saurabh Bhargava", "Richard H. R. Hahnloser", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2016-252", 5, "interspeech", 2016]], "Saurabh Bhargava": [0, ["Monaural Source Separation Using a Random Forest Classifier", ["Cosimo Riday", "Saurabh Bhargava", "Richard H. R. Hahnloser", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2016-252", 5, "interspeech", 2016]], "Richard H. R. Hahnloser": [0, ["Monaural Source Separation Using a Random Forest Classifier", ["Cosimo Riday", "Saurabh Bhargava", "Richard H. R. Hahnloser", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2016-252", 5, "interspeech", 2016]], "Shih-Chii Liu": [0, ["Monaural Source Separation Using a Random Forest Classifier", ["Cosimo Riday", "Saurabh Bhargava", "Richard H. R. Hahnloser", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2016-252", 5, "interspeech", 2016]], "Ziteng Wang": [7.95463854785794e-08, ["Adaptive Group Sparsity for Non-Negative Matrix Factorization with Application to Unsupervised Source Separation", ["Xu Li", "Ziteng Wang", "Xiaofei Wang", "Qiang Fu", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2016-321", 5, "interspeech", 2016], ["A DNN-HMM Approach to Non-Negative Matrix Factorization Based Speech Enhancement", ["Ziteng Wang", "Xu Li", "Xiaofei Wang", "Qiang Fu", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2016-147", 5, "interspeech", 2016]], "Xiaofei Wang": [3.716913874361944e-15, ["Adaptive Group Sparsity for Non-Negative Matrix Factorization with Application to Unsupervised Source Separation", ["Xu Li", "Ziteng Wang", "Xiaofei Wang", "Qiang Fu", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2016-321", 5, "interspeech", 2016], ["A Robust Dual-Microphone Speech Source Localization Algorithm for Reverberant Environments", ["Yanmeng Guo", "Xiaofei Wang", "Chao Wu", "Qiang Fu", "Ning Ma", "Guy J. Brown"], "https://doi.org/10.21437/Interspeech.2016-1063", 5, "interspeech", 2016], ["A DNN-HMM Approach to Non-Negative Matrix Factorization Based Speech Enhancement", ["Ziteng Wang", "Xu Li", "Xiaofei Wang", "Qiang Fu", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2016-147", 5, "interspeech", 2016]], "Qiang Fu": [0, ["Adaptive Group Sparsity for Non-Negative Matrix Factorization with Application to Unsupervised Source Separation", ["Xu Li", "Ziteng Wang", "Xiaofei Wang", "Qiang Fu", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2016-321", 5, "interspeech", 2016], ["A Robust Dual-Microphone Speech Source Localization Algorithm for Reverberant Environments", ["Yanmeng Guo", "Xiaofei Wang", "Chao Wu", "Qiang Fu", "Ning Ma", "Guy J. Brown"], "https://doi.org/10.21437/Interspeech.2016-1063", 5, "interspeech", 2016], ["A DNN-HMM Approach to Non-Negative Matrix Factorization Based Speech Enhancement", ["Ziteng Wang", "Xu Li", "Xiaofei Wang", "Qiang Fu", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2016-147", 5, "interspeech", 2016]], "Yonghong Yan": [0, ["Adaptive Group Sparsity for Non-Negative Matrix Factorization with Application to Unsupervised Source Separation", ["Xu Li", "Ziteng Wang", "Xiaofei Wang", "Qiang Fu", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2016-321", 5, "interspeech", 2016], ["A DNN-HMM Approach to Non-Negative Matrix Factorization Based Speech Enhancement", ["Ziteng Wang", "Xu Li", "Xiaofei Wang", "Qiang Fu", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2016-147", 5, "interspeech", 2016]], "Yanmeng Guo": [0, ["A Robust Dual-Microphone Speech Source Localization Algorithm for Reverberant Environments", ["Yanmeng Guo", "Xiaofei Wang", "Chao Wu", "Qiang Fu", "Ning Ma", "Guy J. Brown"], "https://doi.org/10.21437/Interspeech.2016-1063", 5, "interspeech", 2016]], "Chao Wu": [0.37833376228809357, ["A Robust Dual-Microphone Speech Source Localization Algorithm for Reverberant Environments", ["Yanmeng Guo", "Xiaofei Wang", "Chao Wu", "Qiang Fu", "Ning Ma", "Guy J. Brown"], "https://doi.org/10.21437/Interspeech.2016-1063", 5, "interspeech", 2016]], "Ning Ma": [0, ["A Robust Dual-Microphone Speech Source Localization Algorithm for Reverberant Environments", ["Yanmeng Guo", "Xiaofei Wang", "Chao Wu", "Qiang Fu", "Ning Ma", "Guy J. Brown"], "https://doi.org/10.21437/Interspeech.2016-1063", 5, "interspeech", 2016], ["Speech Localisation in a Multitalker Mixture by Humans and Machines", ["Ning Ma", "Guy J. Brown"], "https://doi.org/10.21437/Interspeech.2016-1149", 5, "interspeech", 2016]], "Guy J. Brown": [0, ["A Robust Dual-Microphone Speech Source Localization Algorithm for Reverberant Environments", ["Yanmeng Guo", "Xiaofei Wang", "Chao Wu", "Qiang Fu", "Ning Ma", "Guy J. Brown"], "https://doi.org/10.21437/Interspeech.2016-1063", 5, "interspeech", 2016], ["Speech Localisation in a Multitalker Mixture by Humans and Machines", ["Ning Ma", "Guy J. Brown"], "https://doi.org/10.21437/Interspeech.2016-1149", 5, "interspeech", 2016]], "Sundar Harshavardhan": [0, ["Reverberation-Robust One-Bit TDOA Based Moving Source Localization for Automatic Camera Steering", ["Sundar Harshavardhan", "Gokul Deepak Manavalan", "T. V. Sreenivas", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2016-575", 5, "interspeech", 2016]], "Gokul Deepak Manavalan": [0, ["Reverberation-Robust One-Bit TDOA Based Moving Source Localization for Automatic Camera Steering", ["Sundar Harshavardhan", "Gokul Deepak Manavalan", "T. V. Sreenivas", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2016-575", 5, "interspeech", 2016]], "T. V. Sreenivas": [0, ["Reverberation-Robust One-Bit TDOA Based Moving Source Localization for Automatic Camera Steering", ["Sundar Harshavardhan", "Gokul Deepak Manavalan", "T. V. Sreenivas", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2016-575", 5, "interspeech", 2016]], "Shigeki Miyabe": [0, ["Multi-Talker Speech Recognition Based on Blind Source Separation with ad hoc Microphone Array Using Smartphones and Cloud Storage", ["Keiko Ochi", "Nobutaka Ono", "Shigeki Miyabe", "Shoji Makino"], "https://doi.org/10.21437/Interspeech.2016-758", 5, "interspeech", 2016]], "Shoji Makino": [0, ["Multi-Talker Speech Recognition Based on Blind Source Separation with ad hoc Microphone Array Using Smartphones and Cloud Storage", ["Keiko Ochi", "Nobutaka Ono", "Shigeki Miyabe", "Shoji Makino"], "https://doi.org/10.21437/Interspeech.2016-758", 5, "interspeech", 2016]], "Johannes Fahringer": [0, ["Phase-Aware Signal Processing for Automatic Speech Recognition", ["Johannes Fahringer", "Tobias Schrank", "Johannes Stahl", "Pejman Mowlaee", "Franz Pernkopf"], "https://doi.org/10.21437/Interspeech.2016-823", 5, "interspeech", 2016]], "Tobias Schrank": [0, ["Phase-Aware Signal Processing for Automatic Speech Recognition", ["Johannes Fahringer", "Tobias Schrank", "Johannes Stahl", "Pejman Mowlaee", "Franz Pernkopf"], "https://doi.org/10.21437/Interspeech.2016-823", 5, "interspeech", 2016]], "Johannes Stahl": [0, ["Phase-Aware Signal Processing for Automatic Speech Recognition", ["Johannes Fahringer", "Tobias Schrank", "Johannes Stahl", "Pejman Mowlaee", "Franz Pernkopf"], "https://doi.org/10.21437/Interspeech.2016-823", 5, "interspeech", 2016]], "Philip Weber": [0, ["Interpretation of Low Dimensional Neural Network Bottleneck Features in Terms of Human Perception and Production", ["Philip Weber", "Linxue Bai", "Martin J. Russell", "Peter Jancovic", "Stephen M. Houghton"], "https://doi.org/10.21437/Interspeech.2016-124", 5, "interspeech", 2016]], "Linxue Bai": [2.3632823697994354e-08, ["Interpretation of Low Dimensional Neural Network Bottleneck Features in Terms of Human Perception and Production", ["Philip Weber", "Linxue Bai", "Martin J. Russell", "Peter Jancovic", "Stephen M. Houghton"], "https://doi.org/10.21437/Interspeech.2016-124", 5, "interspeech", 2016]], "Martin J. Russell": [0, ["Interpretation of Low Dimensional Neural Network Bottleneck Features in Terms of Human Perception and Production", ["Philip Weber", "Linxue Bai", "Martin J. Russell", "Peter Jancovic", "Stephen M. Houghton"], "https://doi.org/10.21437/Interspeech.2016-124", 5, "interspeech", 2016]], "Stephen M. Houghton": [0, ["Interpretation of Low Dimensional Neural Network Bottleneck Features in Terms of Human Perception and Production", ["Philip Weber", "Linxue Bai", "Martin J. Russell", "Peter Jancovic", "Stephen M. Houghton"], "https://doi.org/10.21437/Interspeech.2016-124", 5, "interspeech", 2016]], "Shiliang Zhang": [0, ["Compact Feedforward Sequential Memory Networks for Large Vocabulary Continuous Speech Recognition", ["Shiliang Zhang", "Hui Jiang", "Shifu Xiong", "Si Wei", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-121", 5, "interspeech", 2016], ["Future Context Attention for Unidirectional LSTM Based Acoustic Model", ["Jian Tang", "Shiliang Zhang", "Si Wei", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-185", 5, "interspeech", 2016]], "Hui Jiang": [0, ["Compact Feedforward Sequential Memory Networks for Large Vocabulary Continuous Speech Recognition", ["Shiliang Zhang", "Hui Jiang", "Shifu Xiong", "Si Wei", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-121", 5, "interspeech", 2016]], "Shifu Xiong": [0, ["Compact Feedforward Sequential Memory Networks for Large Vocabulary Continuous Speech Recognition", ["Shiliang Zhang", "Hui Jiang", "Shifu Xiong", "Si Wei", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-121", 5, "interspeech", 2016]], "Si Wei": [0, ["Compact Feedforward Sequential Memory Networks for Large Vocabulary Continuous Speech Recognition", ["Shiliang Zhang", "Hui Jiang", "Shifu Xiong", "Si Wei", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-121", 5, "interspeech", 2016], ["Future Context Attention for Unidirectional LSTM Based Acoustic Model", ["Jian Tang", "Shiliang Zhang", "Si Wei", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2016-185", 5, "interspeech", 2016]], "Pei-Wen Huang": [0, ["Hybrid Accelerated Optimization for Speech Recognition", ["Jen-Tzung Chien", "Pei-Wen Huang", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2016-192", 5, "interspeech", 2016]], "Yajie Miao": [0, ["Open-Domain Audio-Visual Speech Recognition: A Deep Learning Approach", ["Yajie Miao", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2016-412", 5, "interspeech", 2016]], "Albert Zeyer": [0, ["Towards Online-Recognition with Deep Bidirectional LSTM Acoustic Models", ["Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2016-759", 5, "interspeech", 2016]], "Ralf Schluter": [0, ["Towards Online-Recognition with Deep Bidirectional LSTM Acoustic Models", ["Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2016-759", 5, "interspeech", 2016], ["LSTM, GRU, Highway and a Bit of Attention: An Empirical Overview for Language Modeling in Speech Recognition", ["Kazuki Irie", "Zoltan Tuske", "Tamer Alkhouli", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2016-491", 5, "interspeech", 2016]], "Hermann Ney": [0, ["Towards Online-Recognition with Deep Bidirectional LSTM Acoustic Models", ["Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2016-759", 5, "interspeech", 2016], ["LSTM, GRU, Highway and a Bit of Attention: An Empirical Overview for Language Modeling in Speech Recognition", ["Kazuki Irie", "Zoltan Tuske", "Tamer Alkhouli", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2016-491", 5, "interspeech", 2016]], "Yevgen Chebotar": [0, ["Distilling Knowledge from Ensembles of Neural Networks for Speech Recognition", ["Yevgen Chebotar", "Austin Waters"], "https://doi.org/10.21437/Interspeech.2016-1190", 5, "interspeech", 2016]], "Austin Waters": [0, ["Distilling Knowledge from Ensembles of Neural Networks for Speech Recognition", ["Yevgen Chebotar", "Austin Waters"], "https://doi.org/10.21437/Interspeech.2016-1190", 5, "interspeech", 2016]], "Pranay Dighe": [0, ["Low-Rank Representation of Nearest Neighbor Posterior Probabilities to Enhance DNN Based Acoustic Modeling", ["Gil Luyet", "Pranay Dighe", "Afsaneh Asaei", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2016-1279", 5, "interspeech", 2016]], "Hao Zheng": [0, ["Improving Large Vocabulary Accented Mandarin Speech Recognition with Attribute-Based I-Vectors", ["Hao Zheng", "Shanshan Zhang", "Liwei Qiao", "Jianping Li", "Wenju Liu"], "https://doi.org/10.21437/Interspeech.2016-378", 5, "interspeech", 2016]], "Shanshan Zhang": [0, ["Improving Large Vocabulary Accented Mandarin Speech Recognition with Attribute-Based I-Vectors", ["Hao Zheng", "Shanshan Zhang", "Liwei Qiao", "Jianping Li", "Wenju Liu"], "https://doi.org/10.21437/Interspeech.2016-378", 5, "interspeech", 2016]], "Liwei Qiao": [0, ["Improving Large Vocabulary Accented Mandarin Speech Recognition with Attribute-Based I-Vectors", ["Hao Zheng", "Shanshan Zhang", "Liwei Qiao", "Jianping Li", "Wenju Liu"], "https://doi.org/10.21437/Interspeech.2016-378", 5, "interspeech", 2016]], "Jianping Li": [0, ["Improving Large Vocabulary Accented Mandarin Speech Recognition with Attribute-Based I-Vectors", ["Hao Zheng", "Shanshan Zhang", "Liwei Qiao", "Jianping Li", "Wenju Liu"], "https://doi.org/10.21437/Interspeech.2016-378", 5, "interspeech", 2016]], "Wenju Liu": [0, ["Improving Large Vocabulary Accented Mandarin Speech Recognition with Attribute-Based I-Vectors", ["Hao Zheng", "Shanshan Zhang", "Liwei Qiao", "Jianping Li", "Wenju Liu"], "https://doi.org/10.21437/Interspeech.2016-378", 5, "interspeech", 2016]], "Syed Shahnawazuddin": [0, ["Pitch-Adaptive Front-End Features for Robust Children's ASR", ["Syed Shahnawazuddin", "Abhishek Dey", "Rohit Sinha"], "https://doi.org/10.21437/Interspeech.2016-1020", 5, "interspeech", 2016]], "Abhishek Dey": [0, ["Pitch-Adaptive Front-End Features for Robust Children's ASR", ["Syed Shahnawazuddin", "Abhishek Dey", "Rohit Sinha"], "https://doi.org/10.21437/Interspeech.2016-1020", 5, "interspeech", 2016]], "Miguel Angel del Agua": [0, ["ASR Confidence Estimation with Speaker-Adapted Recurrent Neural Networks", ["Miguel Angel del Agua", "Santiago Piqueras", "Adria Gimenez", "Alberto Sanchis", "Jorge Civera", "Alfons Juan"], "https://doi.org/10.21437/Interspeech.2016-1142", 5, "interspeech", 2016]], "Santiago Piqueras": [0, ["ASR Confidence Estimation with Speaker-Adapted Recurrent Neural Networks", ["Miguel Angel del Agua", "Santiago Piqueras", "Adria Gimenez", "Alberto Sanchis", "Jorge Civera", "Alfons Juan"], "https://doi.org/10.21437/Interspeech.2016-1142", 5, "interspeech", 2016]], "Adria Gimenez": [0, ["ASR Confidence Estimation with Speaker-Adapted Recurrent Neural Networks", ["Miguel Angel del Agua", "Santiago Piqueras", "Adria Gimenez", "Alberto Sanchis", "Jorge Civera", "Alfons Juan"], "https://doi.org/10.21437/Interspeech.2016-1142", 5, "interspeech", 2016]], "Alberto Sanchis": [0, ["ASR Confidence Estimation with Speaker-Adapted Recurrent Neural Networks", ["Miguel Angel del Agua", "Santiago Piqueras", "Adria Gimenez", "Alberto Sanchis", "Jorge Civera", "Alfons Juan"], "https://doi.org/10.21437/Interspeech.2016-1142", 5, "interspeech", 2016]], "Jorge Civera": [0, ["ASR Confidence Estimation with Speaker-Adapted Recurrent Neural Networks", ["Miguel Angel del Agua", "Santiago Piqueras", "Adria Gimenez", "Alberto Sanchis", "Jorge Civera", "Alfons Juan"], "https://doi.org/10.21437/Interspeech.2016-1142", 5, "interspeech", 2016]], "Alfons Juan": [0, ["ASR Confidence Estimation with Speaker-Adapted Recurrent Neural Networks", ["Miguel Angel del Agua", "Santiago Piqueras", "Adria Gimenez", "Alberto Sanchis", "Jorge Civera", "Alfons Juan"], "https://doi.org/10.21437/Interspeech.2016-1142", 5, "interspeech", 2016]], "Luis Fernando DHaro": [0, ["Automatic Correction of ASR Outputs by Using Machine Translation", ["Luis Fernando DHaro", "Rafael E. Banchs"], "https://doi.org/10.21437/Interspeech.2016-299", 5, "interspeech", 2016]], "Rafael E. Banchs": [0, ["Automatic Correction of ASR Outputs by Using Machine Translation", ["Luis Fernando DHaro", "Rafael E. Banchs"], "https://doi.org/10.21437/Interspeech.2016-299", 5, "interspeech", 2016]], "Murali Karthick Baskar": [0, ["DNNs for Unsupervised Extraction of Pseudo FMLLR Features Without Explicit Adaptation Data", ["Neethu Mariam Joy", "Murali Karthick Baskar", "Srinivasan Umesh", "Basil Abraham"], "https://doi.org/10.21437/Interspeech.2016-904", 5, "interspeech", 2016]], "Jahyun Goo": [0.9914836287498474, ["Speaker Normalization Through Feature Shifting of Linearly Transformed i-Vector", ["Jahyun Goo", "Younggwan Kim", "Hyungjun Lim", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2016-819", 5, "interspeech", 2016]], "Younggwan Kim": [0.9961809366941452, ["Speaker Normalization Through Feature Shifting of Linearly Transformed i-Vector", ["Jahyun Goo", "Younggwan Kim", "Hyungjun Lim", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2016-819", 5, "interspeech", 2016]], "Hyungjun Lim": [0.9916885942220688, ["Speaker Normalization Through Feature Shifting of Linearly Transformed i-Vector", ["Jahyun Goo", "Younggwan Kim", "Hyungjun Lim", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2016-819", 5, "interspeech", 2016]], "Mona T. Diab": [0, ["Computational Approaches to Linguistic Code Switching", ["Mona T. Diab", "Pascale Fung", "Julia Hirschberg", "Thamar Solorio"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs16.html", 0, "interspeech", 2016]], "Thamar Solorio": [0, ["Computational Approaches to Linguistic Code Switching", ["Mona T. Diab", "Pascale Fung", "Julia Hirschberg", "Thamar Solorio"], "http://www.isca-speech.org/archive/Interspeech_2016/abstracts/abs16.html", 0, "interspeech", 2016]], "Ebru Arisoy": [0, ["Compositional Neural Network Language Models for Agglutinative Languages", ["Ebru Arisoy", "Murat Saraclar"], "https://doi.org/10.21437/Interspeech.2016-1239", 5, "interspeech", 2016]], "Murat Saraclar": [0, ["Compositional Neural Network Language Models for Agglutinative Languages", ["Ebru Arisoy", "Murat Saraclar"], "https://doi.org/10.21437/Interspeech.2016-1239", 5, "interspeech", 2016]], "Babak Damavandi": [0, ["NN-Grams: Unifying Neural Network and n-Gram Language Models for Speech Recognition", ["Babak Damavandi", "Shankar Kumar", "Noam Shazeer", "Antoine Bruguier"], "https://doi.org/10.21437/Interspeech.2016-1295", 5, "interspeech", 2016]], "Shankar Kumar": [0, ["NN-Grams: Unifying Neural Network and n-Gram Language Models for Speech Recognition", ["Babak Damavandi", "Shankar Kumar", "Noam Shazeer", "Antoine Bruguier"], "https://doi.org/10.21437/Interspeech.2016-1295", 5, "interspeech", 2016]], "Noam Shazeer": [0, ["NN-Grams: Unifying Neural Network and n-Gram Language Models for Speech Recognition", ["Babak Damavandi", "Shankar Kumar", "Noam Shazeer", "Antoine Bruguier"], "https://doi.org/10.21437/Interspeech.2016-1295", 5, "interspeech", 2016]], "Md. Akmal Haidar": [0, ["Recurrent Neural Network Language Model with Incremental Updated Context Information Generated Using Bag-of-Words Representation", ["Md. Akmal Haidar", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2016-375", 5, "interspeech", 2016]], "Youssef Oualil": [0, ["Sequential Recurrent Neural Networks for Language Modeling", ["Youssef Oualil", "Clayton Greenberg", "Mittul Singh", "Dietrich Klakow"], "https://doi.org/10.21437/Interspeech.2016-422", 5, "interspeech", 2016]], "Clayton Greenberg": [0, ["Sequential Recurrent Neural Networks for Language Modeling", ["Youssef Oualil", "Clayton Greenberg", "Mittul Singh", "Dietrich Klakow"], "https://doi.org/10.21437/Interspeech.2016-422", 5, "interspeech", 2016]], "Mittul Singh": [0, ["Sequential Recurrent Neural Networks for Language Modeling", ["Youssef Oualil", "Clayton Greenberg", "Mittul Singh", "Dietrich Klakow"], "https://doi.org/10.21437/Interspeech.2016-422", 5, "interspeech", 2016]], "Dietrich Klakow": [0, ["Sequential Recurrent Neural Networks for Language Modeling", ["Youssef Oualil", "Clayton Greenberg", "Mittul Singh", "Dietrich Klakow"], "https://doi.org/10.21437/Interspeech.2016-422", 5, "interspeech", 2016]], "Michael Levit": [0, ["Word-Phrase-Entity Recurrent Neural Networks for Language Modeling", ["Michael Levit", "Sarangarajan Parthasarathy", "Shuangyu Chang"], "https://doi.org/10.21437/Interspeech.2016-44", 5, "interspeech", 2016]], "Sarangarajan Parthasarathy": [0, ["Word-Phrase-Entity Recurrent Neural Networks for Language Modeling", ["Michael Levit", "Sarangarajan Parthasarathy", "Shuangyu Chang"], "https://doi.org/10.21437/Interspeech.2016-44", 5, "interspeech", 2016]], "Kazuki Irie": [0, ["LSTM, GRU, Highway and a Bit of Attention: An Empirical Overview for Language Modeling in Speech Recognition", ["Kazuki Irie", "Zoltan Tuske", "Tamer Alkhouli", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2016-491", 5, "interspeech", 2016]], "Zoltan Tuske": [0, ["LSTM, GRU, Highway and a Bit of Attention: An Empirical Overview for Language Modeling in Speech Recognition", ["Kazuki Irie", "Zoltan Tuske", "Tamer Alkhouli", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2016-491", 5, "interspeech", 2016]], "Tamer Alkhouli": [0, ["LSTM, GRU, Highway and a Bit of Attention: An Empirical Overview for Language Modeling in Speech Recognition", ["Kazuki Irie", "Zoltan Tuske", "Tamer Alkhouli", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2016-491", 5, "interspeech", 2016]], "Amit Das": [0, ["Automatic Speech Recognition Using Probabilistic Transcriptions in Swahili, Amharic, and Dinka", ["Amit Das", "Preethi Jyothi", "Mark Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2016-657", 5, "interspeech", 2016], ["An Investigation on Training Deep Neural Networks Using Probabilistic Transcriptions", ["Amit Das", "Mark Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2016-655", 5, "interspeech", 2016]], "Preethi Jyothi": [0, ["Automatic Speech Recognition Using Probabilistic Transcriptions in Swahili, Amharic, and Dinka", ["Amit Das", "Preethi Jyothi", "Mark Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2016-657", 5, "interspeech", 2016]], "Mark Hasegawa-Johnson": [0, ["Automatic Speech Recognition Using Probabilistic Transcriptions in Swahili, Amharic, and Dinka", ["Amit Das", "Preethi Jyothi", "Mark Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2016-657", 5, "interspeech", 2016], ["An Investigation on Training Deep Neural Networks Using Probabilistic Transcriptions", ["Amit Das", "Mark Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2016-655", 5, "interspeech", 2016], ["Analysis of Mismatched Transcriptions Generated by Humans and Machines for Under-Resourced Languages", ["Van Hai Do", "Nancy F. Chen", "Boon Pang Lim", "Mark Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2016-736", 5, "interspeech", 2016]], "Sylvie Voisin": [0, ["Speed Perturbation and Vowel Duration Modeling for ASR in Hausa and Wolof Languages", ["Elodie Gauthier", "Laurent Besacier", "Sylvie Voisin"], "https://doi.org/10.21437/Interspeech.2016-461", 5, "interspeech", 2016]], "Charl Johannes van Heerden": [0, ["Improving the Lwazi ASR Baseline", ["Charl Johannes van Heerden", "Neil Kleynhans", "Marelie H. Davel"], "https://doi.org/10.21437/Interspeech.2016-1412", 5, "interspeech", 2016]], "Neil Kleynhans": [0, ["Improving the Lwazi ASR Baseline", ["Charl Johannes van Heerden", "Neil Kleynhans", "Marelie H. Davel"], "https://doi.org/10.21437/Interspeech.2016-1412", 5, "interspeech", 2016]], "Marelie H. Davel": [0, ["Improving the Lwazi ASR Baseline", ["Charl Johannes van Heerden", "Neil Kleynhans", "Marelie H. Davel"], "https://doi.org/10.21437/Interspeech.2016-1412", 5, "interspeech", 2016]], "Pierre Godard": [0, ["Preliminary Experiments on Unsupervised Word Discovery in Mboshi", ["Pierre Godard", "Gilles Adda", "Martine Adda-Decker", "Alexandre Allauzen", "Laurent Besacier", "Helene Bonneau-Maynard", "Guy-Noel Kouarata", "Kevin Loser", "Annie Rialland", "Francois Yvon"], "https://doi.org/10.21437/Interspeech.2016-886", 5, "interspeech", 2016]], "Alexandre Allauzen": [0, ["Preliminary Experiments on Unsupervised Word Discovery in Mboshi", ["Pierre Godard", "Gilles Adda", "Martine Adda-Decker", "Alexandre Allauzen", "Laurent Besacier", "Helene Bonneau-Maynard", "Guy-Noel Kouarata", "Kevin Loser", "Annie Rialland", "Francois Yvon"], "https://doi.org/10.21437/Interspeech.2016-886", 5, "interspeech", 2016]], "Helene Bonneau-Maynard": [0, ["Preliminary Experiments on Unsupervised Word Discovery in Mboshi", ["Pierre Godard", "Gilles Adda", "Martine Adda-Decker", "Alexandre Allauzen", "Laurent Besacier", "Helene Bonneau-Maynard", "Guy-Noel Kouarata", "Kevin Loser", "Annie Rialland", "Francois Yvon"], "https://doi.org/10.21437/Interspeech.2016-886", 5, "interspeech", 2016]], "Kevin Loser": [0, ["Preliminary Experiments on Unsupervised Word Discovery in Mboshi", ["Pierre Godard", "Gilles Adda", "Martine Adda-Decker", "Alexandre Allauzen", "Laurent Besacier", "Helene Bonneau-Maynard", "Guy-Noel Kouarata", "Kevin Loser", "Annie Rialland", "Francois Yvon"], "https://doi.org/10.21437/Interspeech.2016-886", 5, "interspeech", 2016]], "Francois Yvon": [0, ["Preliminary Experiments on Unsupervised Word Discovery in Mboshi", ["Pierre Godard", "Gilles Adda", "Martine Adda-Decker", "Alexandre Allauzen", "Laurent Besacier", "Helene Bonneau-Maynard", "Guy-Noel Kouarata", "Kevin Loser", "Annie Rialland", "Francois Yvon"], "https://doi.org/10.21437/Interspeech.2016-886", 5, "interspeech", 2016]], "Marco Vetter": [0, ["Unsupervised Phoneme Segmentation of Previously Unseen Languages", ["Marco Vetter", "Markus Muller", "Fatima Hamlaoui", "Graham Neubig", "Satoshi Nakamura", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-1440", 5, "interspeech", 2016]], "Fatima Hamlaoui": [0, ["Unsupervised Phoneme Segmentation of Previously Unseen Languages", ["Marco Vetter", "Markus Muller", "Fatima Hamlaoui", "Graham Neubig", "Satoshi Nakamura", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2016-1440", 5, "interspeech", 2016]], "Celine Manenti": [0, ["CNN-Based Phone Segmentation Experiments in a Less-Represented Language", ["Celine Manenti", "Thomas Pellegrini", "Julien Pinquier"], "https://doi.org/10.21437/Interspeech.2016-796", 5, "interspeech", 2016]], "Georg I. Schlunz": [0, ["Part-of-Speech Tagging and Chunking in Text-to-Speech Synthesis for South African Languages", ["Georg I. Schlunz", "Nkosikhona Dlamini", "Rynhardt P. Kruger"], "https://doi.org/10.21437/Interspeech.2016-1040", 5, "interspeech", 2016]], "Nkosikhona Dlamini": [0, ["Part-of-Speech Tagging and Chunking in Text-to-Speech Synthesis for South African Languages", ["Georg I. Schlunz", "Nkosikhona Dlamini", "Rynhardt P. Kruger"], "https://doi.org/10.21437/Interspeech.2016-1040", 5, "interspeech", 2016]], "Rynhardt P. Kruger": [0, ["Part-of-Speech Tagging and Chunking in Text-to-Speech Synthesis for South African Languages", ["Georg I. Schlunz", "Nkosikhona Dlamini", "Rynhardt P. Kruger"], "https://doi.org/10.21437/Interspeech.2016-1040", 5, "interspeech", 2016]], "Ewald van der Westhuizen": [0, ["The Effect of Postlexical Deletion on Automatic Speech Recognition in Fast Spontaneously Spoken Zulu", ["Ewald van der Westhuizen", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2016-820", 5, "interspeech", 2016]], "Thomas Niesler": [0, ["The Effect of Postlexical Deletion on Automatic Speech Recognition in Fast Spontaneously Spoken Zulu", ["Ewald van der Westhuizen", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2016-820", 5, "interspeech", 2016]], "Vikram Ramanarayanan": [0, ["A New Model of Speech Motor Control Based on Task Dynamics and State Feedback", ["Vikram Ramanarayanan", "Benjamin Parrell", "Louis Goldstein", "Srikantan S. Nagarajan", "John F. Houde"], "https://doi.org/10.21437/Interspeech.2016-1499", 5, "interspeech", 2016], ["Noise and Metadata Sensitive Bottleneck Features for Improving Speaker Recognition with Non-Native Speech Input", ["Yao Qian", "Jidong Tao", "David Suendermann-Oeft", "Keelan Evanini", "Alexei V. Ivanov", "Vikram Ramanarayanan"], "https://doi.org/10.21437/Interspeech.2016-548", 5, "interspeech", 2016]], "Benjamin Parrell": [0, ["A New Model of Speech Motor Control Based on Task Dynamics and State Feedback", ["Vikram Ramanarayanan", "Benjamin Parrell", "Louis Goldstein", "Srikantan S. Nagarajan", "John F. Houde"], "https://doi.org/10.21437/Interspeech.2016-1499", 5, "interspeech", 2016]], "Srikantan S. Nagarajan": [0, ["A New Model of Speech Motor Control Based on Task Dynamics and State Feedback", ["Vikram Ramanarayanan", "Benjamin Parrell", "Louis Goldstein", "Srikantan S. Nagarajan", "John F. Houde"], "https://doi.org/10.21437/Interspeech.2016-1499", 5, "interspeech", 2016]], "John F. Houde": [0, ["A New Model of Speech Motor Control Based on Task Dynamics and State Feedback", ["Vikram Ramanarayanan", "Benjamin Parrell", "Louis Goldstein", "Srikantan S. Nagarajan", "John F. Houde"], "https://doi.org/10.21437/Interspeech.2016-1499", 5, "interspeech", 2016]], "Saeed Dabbaghchian": [0, ["Using a Biomechanical Model and Articulatory Data for the Numerical Production of Vowels", ["Saeed Dabbaghchian", "Marc Arnela", "Olov Engwall", "Oriol Guasch", "Ian Stavness", "Pierre Badin"], "https://doi.org/10.21437/Interspeech.2016-1500", 5, "interspeech", 2016]], "Marc Arnela": [0, ["Using a Biomechanical Model and Articulatory Data for the Numerical Production of Vowels", ["Saeed Dabbaghchian", "Marc Arnela", "Olov Engwall", "Oriol Guasch", "Ian Stavness", "Pierre Badin"], "https://doi.org/10.21437/Interspeech.2016-1500", 5, "interspeech", 2016]], "Olov Engwall": [0, ["Using a Biomechanical Model and Articulatory Data for the Numerical Production of Vowels", ["Saeed Dabbaghchian", "Marc Arnela", "Olov Engwall", "Oriol Guasch", "Ian Stavness", "Pierre Badin"], "https://doi.org/10.21437/Interspeech.2016-1500", 5, "interspeech", 2016]], "Oriol Guasch": [0, ["Using a Biomechanical Model and Articulatory Data for the Numerical Production of Vowels", ["Saeed Dabbaghchian", "Marc Arnela", "Olov Engwall", "Oriol Guasch", "Ian Stavness", "Pierre Badin"], "https://doi.org/10.21437/Interspeech.2016-1500", 5, "interspeech", 2016]], "Ian Stavness": [0, ["Using a Biomechanical Model and Articulatory Data for the Numerical Production of Vowels", ["Saeed Dabbaghchian", "Marc Arnela", "Olov Engwall", "Oriol Guasch", "Ian Stavness", "Pierre Badin"], "https://doi.org/10.21437/Interspeech.2016-1500", 5, "interspeech", 2016]], "Wendan Guan": [0, ["A New Model for Acoustic Wave Propagation and Scattering in the Vocal Tract", ["Jianguo Wei", "Wendan Guan", "Darcy Q. Hou", "Dingyi Pan", "Wenhuan Lu", "Jianwu Dang"], "https://doi.org/10.21437/Interspeech.2016-1513", 5, "interspeech", 2016]], "Darcy Q. Hou": [0, ["A New Model for Acoustic Wave Propagation and Scattering in the Vocal Tract", ["Jianguo Wei", "Wendan Guan", "Darcy Q. Hou", "Dingyi Pan", "Wenhuan Lu", "Jianwu Dang"], "https://doi.org/10.21437/Interspeech.2016-1513", 5, "interspeech", 2016]], "Dingyi Pan": [0, ["A New Model for Acoustic Wave Propagation and Scattering in the Vocal Tract", ["Jianguo Wei", "Wendan Guan", "Darcy Q. Hou", "Dingyi Pan", "Wenhuan Lu", "Jianwu Dang"], "https://doi.org/10.21437/Interspeech.2016-1513", 5, "interspeech", 2016]], "Wenhuan Lu": [0, ["A New Model for Acoustic Wave Propagation and Scattering in the Vocal Tract", ["Jianguo Wei", "Wendan Guan", "Darcy Q. Hou", "Dingyi Pan", "Wenhuan Lu", "Jianwu Dang"], "https://doi.org/10.21437/Interspeech.2016-1513", 5, "interspeech", 2016]], "Andrew Szabados": [0, ["Uncontrolled Manifolds in Vowel Production: Assessment with a Biomechanical Model of the Tongue", ["Andrew Szabados", "Pascal Perrier"], "https://doi.org/10.21437/Interspeech.2016-1579", 5, "interspeech", 2016]], "Tsukasa Yoshinaga": [0, ["Experimental Validation of Sound Generated from Flow in Simplified Vocal Tract Model of Sibilant /s/", ["Tsukasa Yoshinaga", "Kazunori Nozaki", "Shigeo Wada"], "https://doi.org/10.21437/Interspeech.2016-1597", 4, "interspeech", 2016]], "Kazunori Nozaki": [0, ["Experimental Validation of Sound Generated from Flow in Simplified Vocal Tract Model of Sibilant /s/", ["Tsukasa Yoshinaga", "Kazunori Nozaki", "Shigeo Wada"], "https://doi.org/10.21437/Interspeech.2016-1597", 4, "interspeech", 2016]], "Shigeo Wada": [0, ["Experimental Validation of Sound Generated from Flow in Simplified Vocal Tract Model of Sibilant /s/", ["Tsukasa Yoshinaga", "Kazunori Nozaki", "Shigeo Wada"], "https://doi.org/10.21437/Interspeech.2016-1597", 4, "interspeech", 2016]], "Jean-Francois Patri": [0, ["Bayesian Modeling in Speech Motor Control: A Principled Structure for the Integration of Various Constraints", ["Jean-Francois Patri", "Pascal Perrier", "Julien Diard"], "https://doi.org/10.21437/Interspeech.2016-441", 5, "interspeech", 2016]], "Zixing Zhang": [0, ["Facing Realism in Spontaneous Emotion Recognition from Speech: Feature Enhancement by Autoencoder with LSTM Neural Networks", ["Zixing Zhang", "Fabien Ringeval", "Jing Han", "Jun Deng", "Erik Marchi", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-998", 5, "interspeech", 2016]], "Jing Han": [0.06778808869421482, ["Facing Realism in Spontaneous Emotion Recognition from Speech: Feature Enhancement by Autoencoder with LSTM Neural Networks", ["Zixing Zhang", "Fabien Ringeval", "Jing Han", "Jun Deng", "Erik Marchi", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2016-998", 5, "interspeech", 2016]], "Srinivas Parthasarathy": [0, ["Defining Emotionally Salient Regions Using Qualitative Agreement Method", ["Srinivas Parthasarathy", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2016-429", 5, "interspeech", 2016]], "Sayan Ghosh": [0, ["Representation Learning for Speech Emotion Recognition", ["Sayan Ghosh", "Eugene Laksana", "Louis-Philippe Morency", "Stefan Scherer"], "https://doi.org/10.21437/Interspeech.2016-692", 5, "interspeech", 2016]], "Eugene Laksana": [0, ["Representation Learning for Speech Emotion Recognition", ["Sayan Ghosh", "Eugene Laksana", "Louis-Philippe Morency", "Stefan Scherer"], "https://doi.org/10.21437/Interspeech.2016-692", 5, "interspeech", 2016]], "Louis-Philippe Morency": [0, ["Representation Learning for Speech Emotion Recognition", ["Sayan Ghosh", "Eugene Laksana", "Louis-Philippe Morency", "Stefan Scherer"], "https://doi.org/10.21437/Interspeech.2016-692", 5, "interspeech", 2016]], "Stefan Scherer": [0, ["Representation Learning for Speech Emotion Recognition", ["Sayan Ghosh", "Eugene Laksana", "Louis-Philippe Morency", "Stefan Scherer"], "https://doi.org/10.21437/Interspeech.2016-692", 5, "interspeech", 2016]], "Xingfeng Li": [0, ["Multilingual Speech Emotion Recognition System Based on a Three-Layer Model", ["Xingfeng Li", "Masato Akagi"], "https://doi.org/10.21437/Interspeech.2016-645", 5, "interspeech", 2016]], "Masato Akagi": [0, ["Multilingual Speech Emotion Recognition System Based on a Three-Layer Model", ["Xingfeng Li", "Masato Akagi"], "https://doi.org/10.21437/Interspeech.2016-645", 5, "interspeech", 2016]], "Ozlem Kalinli": [0, ["Analysis of Multi-Lingual Emotion Recognition Using Auditory Attention Features", ["Ozlem Kalinli"], "https://doi.org/10.21437/Interspeech.2016-1557", 5, "interspeech", 2016]], "Haytham M. Fayek": [0, ["On the Correlation and Transferability of Features Between Automatic Speech Recognition and Speech Emotion Recognition", ["Haytham M. Fayek", "Margaret Lech", "Lawrence Cavedon"], "https://doi.org/10.21437/Interspeech.2016-868", 5, "interspeech", 2016]], "Margaret Lech": [0, ["On the Correlation and Transferability of Features Between Automatic Speech Recognition and Speech Emotion Recognition", ["Haytham M. Fayek", "Margaret Lech", "Lawrence Cavedon"], "https://doi.org/10.21437/Interspeech.2016-868", 5, "interspeech", 2016]], "Lawrence Cavedon": [0, ["On the Correlation and Transferability of Features Between Automatic Speech Recognition and Speech Emotion Recognition", ["Haytham M. Fayek", "Margaret Lech", "Lawrence Cavedon"], "https://doi.org/10.21437/Interspeech.2016-868", 5, "interspeech", 2016]], "Giacomo Valenti": [0, ["On the Influence of Text Content on Pass-Phrase Strength for Short-Duration Text-Dependent Automatic Speaker Authentication", ["Giacomo Valenti", "Adrien Daniel", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2016-1115", 5, "interspeech", 2016]], "Adrien Daniel": [0, ["On the Influence of Text Content on Pass-Phrase Strength for Short-Duration Text-Dependent Automatic Speaker Authentication", ["Giacomo Valenti", "Adrien Daniel", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2016-1115", 5, "interspeech", 2016]], "Seyed Omid Sadjadi": [0, ["The IBM Speaker Recognition System: Recent Advances and Error Analysis", ["Seyed Omid Sadjadi", "Jason W. Pelecanos", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2016-1159", 5, "interspeech", 2016]], "Jason W. Pelecanos": [0, ["The IBM Speaker Recognition System: Recent Advances and Error Analysis", ["Seyed Omid Sadjadi", "Jason W. Pelecanos", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2016-1159", 5, "interspeech", 2016]], "Sriram Ganapathy": [0, ["The IBM Speaker Recognition System: Recent Advances and Error Analysis", ["Seyed Omid Sadjadi", "Jason W. Pelecanos", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2016-1159", 5, "interspeech", 2016], ["An Investigation on the Use of i-Vectors for Robust ASR", ["Dimitrios Dimitriadis", "Samuel Thomas", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2016-1482", 5, "interspeech", 2016]], "Fahimeh Bahmaninezhad": [0, ["Generalized Discriminant Analysis (GDA) for Improved i-Vector Based Speaker Recognition", ["Fahimeh Bahmaninezhad", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2016-1523", 5, "interspeech", 2016]], "Alexei V. Ivanov": [0, ["Noise and Metadata Sensitive Bottleneck Features for Improving Speaker Recognition with Non-Native Speech Input", ["Yao Qian", "Jidong Tao", "David Suendermann-Oeft", "Keelan Evanini", "Alexei V. Ivanov", "Vikram Ramanarayanan"], "https://doi.org/10.21437/Interspeech.2016-548", 5, "interspeech", 2016]], "Huy Phan": [0, ["Robust Audio Event Recognition with 1-Max Pooling Convolutional Neural Networks", ["Huy Phan", "Lars Hertel", "Marco Maass", "Alfred Mertins"], "https://doi.org/10.21437/Interspeech.2016-123", 5, "interspeech", 2016]], "Lars Hertel": [0, ["Robust Audio Event Recognition with 1-Max Pooling Convolutional Neural Networks", ["Huy Phan", "Lars Hertel", "Marco Maass", "Alfred Mertins"], "https://doi.org/10.21437/Interspeech.2016-123", 5, "interspeech", 2016]], "Marco Maass": [0, ["Robust Audio Event Recognition with 1-Max Pooling Convolutional Neural Networks", ["Huy Phan", "Lars Hertel", "Marco Maass", "Alfred Mertins"], "https://doi.org/10.21437/Interspeech.2016-123", 5, "interspeech", 2016]], "Alfred Mertins": [0, ["Robust Audio Event Recognition with 1-Max Pooling Convolutional Neural Networks", ["Huy Phan", "Lars Hertel", "Marco Maass", "Alfred Mertins"], "https://doi.org/10.21437/Interspeech.2016-123", 5, "interspeech", 2016]], "Giannis Karamanolakis": [0, ["Audio-Based Distributional Representations of Meaning Using a Fusion of Feature Encodings", ["Giannis Karamanolakis", "Elias Iosif", "Athanasia Zlatintsi", "Aggelos Pikrakis", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2016-839", 5, "interspeech", 2016]], "Athanasia Zlatintsi": [0, ["Audio-Based Distributional Representations of Meaning Using a Fusion of Feature Encodings", ["Giannis Karamanolakis", "Elias Iosif", "Athanasia Zlatintsi", "Aggelos Pikrakis", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2016-839", 5, "interspeech", 2016]], "Aggelos Pikrakis": [0, ["Audio-Based Distributional Representations of Meaning Using a Fusion of Feature Encodings", ["Giannis Karamanolakis", "Elias Iosif", "Athanasia Zlatintsi", "Aggelos Pikrakis", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2016-839", 5, "interspeech", 2016]], "Yuya Fujita": [0, ["Robust DNN-Based VAD Augmented with Phone Entropy Based Rejection of Background Speech", ["Yuya Fujita", "Ken-ichi Iso"], "https://doi.org/10.21437/Interspeech.2016-136", 5, "interspeech", 2016]], "Ken-ichi Iso": [0, ["Robust DNN-Based VAD Augmented with Phone Entropy Based Rejection of Background Speech", ["Yuya Fujita", "Ken-ichi Iso"], "https://doi.org/10.21437/Interspeech.2016-136", 5, "interspeech", 2016]], "Ruben Zazo": [0, ["Feature Learning with Raw-Waveform CLDNNs for Voice Activity Detection", ["Ruben Zazo", "Tara N. Sainath", "Gabor Simko", "Carolina Parada"], "https://doi.org/10.21437/Interspeech.2016-268", 5, "interspeech", 2016]], "Gabor Simko": [0, ["Feature Learning with Raw-Waveform CLDNNs for Voice Activity Detection", ["Ruben Zazo", "Tara N. Sainath", "Gabor Simko", "Carolina Parada"], "https://doi.org/10.21437/Interspeech.2016-268", 5, "interspeech", 2016]], "Carolina Parada": [0, ["Feature Learning with Raw-Waveform CLDNNs for Voice Activity Detection", ["Ruben Zazo", "Tara N. Sainath", "Gabor Simko", "Carolina Parada"], "https://doi.org/10.21437/Interspeech.2016-268", 5, "interspeech", 2016]], "Damianos Karakos": [0, ["Model Adaptation and Active Learning in the BBN Speech Activity Detection System for the DARPA RATS Program", ["Damianos Karakos", "Scott Novotney", "Le Zhang", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-603", 5, "interspeech", 2016]], "Scott Novotney": [0, ["Model Adaptation and Active Learning in the BBN Speech Activity Detection System for the DARPA RATS Program", ["Damianos Karakos", "Scott Novotney", "Le Zhang", "Richard M. Schwartz"], "https://doi.org/10.21437/Interspeech.2016-603", 5, "interspeech", 2016]], "Wen Wang": [7.306307452381589e-05, ["Fusion Strategies for Robust Speech Recognition and Keyword Spotting for Channel- and Noise-Degraded Speech", ["Vikramjit Mitra", "Julien van Hout", "Wen Wang", "Chris Bartels", "Horacio Franco", "Dimitra Vergyri", "Abeer Alwan", "Adam Janin", "John H. L. Hansen", "Richard M. Stern", "Abhijeet Sangwan", "Nelson Morgan"], "https://doi.org/10.21437/Interspeech.2016-279", 5, "interspeech", 2016]], "Adam Janin": [0, ["Fusion Strategies for Robust Speech Recognition and Keyword Spotting for Channel- and Noise-Degraded Speech", ["Vikramjit Mitra", "Julien van Hout", "Wen Wang", "Chris Bartels", "Horacio Franco", "Dimitra Vergyri", "Abeer Alwan", "Adam Janin", "John H. L. Hansen", "Richard M. Stern", "Abhijeet Sangwan", "Nelson Morgan"], "https://doi.org/10.21437/Interspeech.2016-279", 5, "interspeech", 2016]], "Nelson Morgan": [0, ["Fusion Strategies for Robust Speech Recognition and Keyword Spotting for Channel- and Noise-Degraded Speech", ["Vikramjit Mitra", "Julien van Hout", "Wen Wang", "Chris Bartels", "Horacio Franco", "Dimitra Vergyri", "Abeer Alwan", "Adam Janin", "John H. L. Hansen", "Richard M. Stern", "Abhijeet Sangwan", "Nelson Morgan"], "https://doi.org/10.21437/Interspeech.2016-279", 5, "interspeech", 2016]], "Naoki Sawada": [0, ["Recurrent Neural Network-Based Phoneme Sequence Estimation Using Multiple ASR Systems' Outputs for Spoken Term Detection", ["Naoki Sawada", "Hiromitsu Nishizaki"], "https://doi.org/10.21437/Interspeech.2016-337", 5, "interspeech", 2016]], "Hiromitsu Nishizaki": [0, ["Recurrent Neural Network-Based Phoneme Sequence Estimation Using Multiple ASR Systems' Outputs for Spoken Term Detection", ["Naoki Sawada", "Hiromitsu Nishizaki"], "https://doi.org/10.21437/Interspeech.2016-337", 5, "interspeech", 2016]], "Mark Kane": [0, ["Enhancing Data-Driven Phone Confusions Using Restricted Recognition", ["Mark Kane", "Julie Carson-Berndsen"], "https://doi.org/10.21437/Interspeech.2016-489", 5, "interspeech", 2016]], "Julie Carson-Berndsen": [0, ["Enhancing Data-Driven Phone Confusions Using Restricted Recognition", ["Mark Kane", "Julie Carson-Berndsen"], "https://doi.org/10.21437/Interspeech.2016-489", 5, "interspeech", 2016]], "Feng Rao": [0, ["Rapid Update of Multilingual Deep Neural Network for Low-Resource Keyword Search", ["Chongjia Ni", "Lei Wang", "Cheung-Chi Leung", "Feng Rao", "Li Lu", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-53", 5, "interspeech", 2016]], "Li Lu": [0, ["Rapid Update of Multilingual Deep Neural Network for Low-Resource Keyword Search", ["Chongjia Ni", "Lei Wang", "Cheung-Chi Leung", "Feng Rao", "Li Lu", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-53", 5, "interspeech", 2016]], "Jingyong Hou": [0, ["Toward High-Performance Language-Independent Query-by-Example Spoken Term Detection for MediaEval 2015: Post-Evaluation Analysis", ["Cheung-Chi Leung", "Lei Wang", "Haihua Xu", "Jingyong Hou", "Van Tung Pham", "Hang Lv", "Lei Xie", "Xiong Xiao", "Chongjia Ni", "Bin Ma", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-691", 5, "interspeech", 2016]], "Hang Lv": [0, ["Toward High-Performance Language-Independent Query-by-Example Spoken Term Detection for MediaEval 2015: Post-Evaluation Analysis", ["Cheung-Chi Leung", "Lei Wang", "Haihua Xu", "Jingyong Hou", "Van Tung Pham", "Hang Lv", "Lei Xie", "Xiong Xiao", "Chongjia Ni", "Bin Ma", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2016-691", 5, "interspeech", 2016]], "Tian Gao": [0, ["SNR-Based Progressive Learning of Deep Neural Network for Speech Enhancement", ["Tian Gao", "Jun Du", "Li-Rong Dai", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2016-224", 5, "interspeech", 2016]], "Jun Du": [0, ["SNR-Based Progressive Learning of Deep Neural Network for Speech Enhancement", ["Tian Gao", "Jun Du", "Li-Rong Dai", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2016-224", 5, "interspeech", 2016]], "Jishnu Sadasivan": [0, ["A Novel Risk-Estimation-Theoretic Framework for Speech Enhancement in Nonstationary and Non-Gaussian Noise Conditions", ["Jishnu Sadasivan", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2016-151", 5, "interspeech", 2016]], "Suman Samui": [0, ["Two-Stage Temporal Processing for Single-Channel Speech Enhancement", ["Suman Samui", "Indrajit Chakrabarti", "Soumya Kanti Ghosh"], "https://doi.org/10.21437/Interspeech.2016-307", 5, "interspeech", 2016]], "Indrajit Chakrabarti": [0, ["Two-Stage Temporal Processing for Single-Channel Speech Enhancement", ["Suman Samui", "Indrajit Chakrabarti", "Soumya Kanti Ghosh"], "https://doi.org/10.21437/Interspeech.2016-307", 5, "interspeech", 2016]], "Soumya Kanti Ghosh": [0, ["Two-Stage Temporal Processing for Single-Channel Speech Enhancement", ["Suman Samui", "Indrajit Chakrabarti", "Soumya Kanti Ghosh"], "https://doi.org/10.21437/Interspeech.2016-307", 5, "interspeech", 2016]], "Nazreen P. M.": [0, ["A Class-Specific Speech Enhancement for Phoneme Recognition: A Dictionary Learning Approach", ["Nazreen P. M.", "A. G. Ramakrishnan", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2016-236", 5, "interspeech", 2016]], "Shogo Seki": [0, ["Robust Example Search Using Bottleneck Features for Example-Based Speech Enhancement", ["Atsunori Ogawa", "Shogo Seki", "Keisuke Kinoshita", "Marc Delcroix", "Takuya Yoshioka", "Tomohiro Nakatani", "Kazuya Takeda"], "https://doi.org/10.21437/Interspeech.2016-671", 5, "interspeech", 2016]], "Kazuya Takeda": [0, ["Robust Example Search Using Bottleneck Features for Example-Based Speech Enhancement", ["Atsunori Ogawa", "Shogo Seki", "Keisuke Kinoshita", "Marc Delcroix", "Takuya Yoshioka", "Tomohiro Nakatani", "Kazuya Takeda"], "https://doi.org/10.21437/Interspeech.2016-671", 5, "interspeech", 2016]], "Anurag Kumar": [0, ["Speech Enhancement in Multiple-Noise Conditions Using Deep Neural Networks", ["Anurag Kumar", "Dinei A. F. Florencio"], "https://doi.org/10.21437/Interspeech.2016-88", 5, "interspeech", 2016]], "Dinei A. F. Florencio": [0, ["Speech Enhancement in Multiple-Noise Conditions Using Deep Neural Networks", ["Anurag Kumar", "Dinei A. F. Florencio"], "https://doi.org/10.21437/Interspeech.2016-88", 5, "interspeech", 2016]], "Li Li": [0, ["Semi-Supervised Joint Enhancement of Spectral and Cepstral Sequences of Noisy Speech", ["Li Li", "Hirokazu Kameoka", "Takuya Higuchi", "Hiroshi Saruwatari"], "https://doi.org/10.21437/Interspeech.2016-1286", 5, "interspeech", 2016]], "Takuya Higuchi": [0, ["Semi-Supervised Joint Enhancement of Spectral and Cepstral Sequences of Noisy Speech", ["Li Li", "Hirokazu Kameoka", "Takuya Higuchi", "Hiroshi Saruwatari"], "https://doi.org/10.21437/Interspeech.2016-1286", 5, "interspeech", 2016], ["Optimization of Speech Enhancement Front-End with Speech Recognition-Level Criterion", ["Takuya Higuchi", "Takuya Yoshioka", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2016-681", 5, "interspeech", 2016]], "Hiroshi Saruwatari": [0, ["Semi-Supervised Joint Enhancement of Spectral and Cepstral Sequences of Noisy Speech", ["Li Li", "Hirokazu Kameoka", "Takuya Higuchi", "Hiroshi Saruwatari"], "https://doi.org/10.21437/Interspeech.2016-1286", 5, "interspeech", 2016]], "Aleksej Chinaev": [0, ["A priori SNR Estimation Using a Generalized Decision Directed Approach", ["Aleksej Chinaev", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2016-474", 5, "interspeech", 2016]], "Szu-Wei Fu": [0, ["SNR-Aware Convolutional Neural Network Modeling for Speech Enhancement", ["Szu-Wei Fu", "Yu Tsao", "Xugang Lu"], "https://doi.org/10.21437/Interspeech.2016-211", 5, "interspeech", 2016]], "Bo Wu": [0.00013600734746432863, ["An Iterative Phase Recovery Framework with Phase Mask for Spectral Mapping with an Application to Speech Enhancement", ["Kehuang Li", "Bo Wu", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2016-494", 5, "interspeech", 2016]], "Bin Liu": [0, ["A Novel Research to Artificial Bandwidth Extension Based on Deep BLSTM Recurrent Neural Networks and Exemplar-Based Sparse Representation", ["Bin Liu", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2016-772", 5, "interspeech", 2016]], "Natalia A. Tomashenko": [0, ["On the Use of Gaussian Mixture Model Framework to Improve Speaker Adaptation of Deep Neural Network Acoustic Models", ["Natalia A. Tomashenko", "Yuri Y. Khokhlov", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2016-1230", 5, "interspeech", 2016]], "Yuri Y. Khokhlov": [0, ["On the Use of Gaussian Mixture Model Framework to Improve Speaker Adaptation of Deep Neural Network Acoustic Models", ["Natalia A. Tomashenko", "Yuri Y. Khokhlov", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2016-1230", 5, "interspeech", 2016]], "Bert Cranen": [0, ["Analytical Assessment of Dual-Stream Merging for Noise-Robust ASR", ["Louis ten Bosch", "Bert Cranen", "Yang Sun"], "https://doi.org/10.21437/Interspeech.2016-1050", 5, "interspeech", 2016]], "Yang Sun": [0.012746322434395552, ["Analytical Assessment of Dual-Stream Merging for Noise-Robust ASR", ["Louis ten Bosch", "Bert Cranen", "Yang Sun"], "https://doi.org/10.21437/Interspeech.2016-1050", 5, "interspeech", 2016]], "Erfan Loweimi": [0, ["Use of Generalised Nonlinearity in Vector Taylor Series Noise Compensation for Robust Speech Recognition", ["Erfan Loweimi", "Jon Barker", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-1028", 5, "interspeech", 2016]], "Masato Mimura": [0, ["Joint Optimization of Denoising Autoencoder and DNN Acoustic Model Based on Multi-Target Learning for Noisy Speech Recognition", ["Masato Mimura", "Shinsuke Sakai", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2016-388", 5, "interspeech", 2016]], "Shinsuke Sakai": [0, ["Joint Optimization of Denoising Autoencoder and DNN Acoustic Model Based on Multi-Target Learning for Noisy Speech Recognition", ["Masato Mimura", "Shinsuke Sakai", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2016-388", 5, "interspeech", 2016]], "Yusuke Fujita": [0, ["Data Augmentation Using Multi-Input Multi-Output Source Separation for Deep Neural Network Based Acoustic Modeling", ["Yusuke Fujita", "Ryoichi Takashima", "Takeshi Homma", "Masahito Togami"], "https://doi.org/10.21437/Interspeech.2016-733", 5, "interspeech", 2016]], "Ryoichi Takashima": [0, ["Data Augmentation Using Multi-Input Multi-Output Source Separation for Deep Neural Network Based Acoustic Modeling", ["Yusuke Fujita", "Ryoichi Takashima", "Takeshi Homma", "Masahito Togami"], "https://doi.org/10.21437/Interspeech.2016-733", 5, "interspeech", 2016]], "Takeshi Homma": [0, ["Data Augmentation Using Multi-Input Multi-Output Source Separation for Deep Neural Network Based Acoustic Modeling", ["Yusuke Fujita", "Ryoichi Takashima", "Takeshi Homma", "Masahito Togami"], "https://doi.org/10.21437/Interspeech.2016-733", 5, "interspeech", 2016]], "Masahito Togami": [0, ["Data Augmentation Using Multi-Input Multi-Output Source Separation for Deep Neural Network Based Acoustic Modeling", ["Yusuke Fujita", "Ryoichi Takashima", "Takeshi Homma", "Masahito Togami"], "https://doi.org/10.21437/Interspeech.2016-733", 5, "interspeech", 2016]], "Animesh Prasad": [0, ["Microphone Distance Adaptation Using Cluster Adaptive Training for Robust Far Field Speech Recognition", ["Animesh Prasad", "Khe Chai Sim"], "https://doi.org/10.21437/Interspeech.2016-738", 5, "interspeech", 2016]], "Dimitrios Dimitriadis": [0, ["An Investigation on the Use of i-Vectors for Robust ASR", ["Dimitrios Dimitriadis", "Samuel Thomas", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2016-1482", 5, "interspeech", 2016]], "Charles Fox": [0, ["The Sheffield Wargame Corpus - Day Two and Day Three", ["Yulan Liu", "Charles Fox", "Madina Hasan", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2016-98", 5, "interspeech", 2016]], "Suyoun Kim": [0.9995113462209702, ["Recurrent Models for Auditory Attention in Multi-Microphone Distant Speech Recognition", ["Suyoun Kim", "Ian R. Lane"], "https://doi.org/10.21437/Interspeech.2016-326", 5, "interspeech", 2016]], "Ian R. Lane": [0, ["Recurrent Models for Auditory Attention in Multi-Microphone Distant Speech Recognition", ["Suyoun Kim", "Ian R. Lane"], "https://doi.org/10.21437/Interspeech.2016-326", 5, "interspeech", 2016], ["Semi-Supervised Speaker Adaptation for In-Vehicle Speech Recognition with Deep Neural Networks", ["Wonkyum Lee", "Kyu J. Han", "Ian R. Lane"], "https://doi.org/10.21437/Interspeech.2016-1625", 5, "interspeech", 2016]], "Wonkyum Lee": [0.9962333291769028, ["Semi-Supervised Speaker Adaptation for In-Vehicle Speech Recognition with Deep Neural Networks", ["Wonkyum Lee", "Kyu J. Han", "Ian R. Lane"], "https://doi.org/10.21437/Interspeech.2016-1625", 5, "interspeech", 2016]], "Kyu J. Han": [0.11793997138738632, ["Semi-Supervised Speaker Adaptation for In-Vehicle Speech Recognition with Deep Neural Networks", ["Wonkyum Lee", "Kyu J. Han", "Ian R. Lane"], "https://doi.org/10.21437/Interspeech.2016-1625", 5, "interspeech", 2016]], "Yan Huang": [0, ["Semi-Supervised Training in Deep Learning Acoustic Model", ["Yan Huang", "Yongqiang Wang", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2016-1596", 5, "interspeech", 2016]], "Yongqiang Wang": [1.582059150351256e-08, ["Semi-Supervised Training in Deep Learning Acoustic Model", ["Yan Huang", "Yongqiang Wang", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2016-1596", 5, "interspeech", 2016]], "Yifan Gong": [0.00023316614533541724, ["Semi-Supervised Training in Deep Learning Acoustic Model", ["Yan Huang", "Yongqiang Wang", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2016-1596", 5, "interspeech", 2016]], "Kartik Audhkhasi": [0, ["Multilingual Data Selection for Low Resource Speech Recognition", ["Samuel Thomas", "Kartik Audhkhasi", "Jia Cui", "Brian Kingsbury", "Bhuvana Ramabhadran"], "https://doi.org/10.21437/Interspeech.2016-598", 5, "interspeech", 2016]], "Van Hai Do": [1.6532569979688105e-08, ["Analysis of Mismatched Transcriptions Generated by Humans and Machines for Under-Resourced Languages", ["Van Hai Do", "Nancy F. Chen", "Boon Pang Lim", "Mark Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2016-736", 5, "interspeech", 2016]], "Jan Nouza": [0, ["ASR for South Slavic Languages Developed in Almost Automated Way", ["Jan Nouza", "Radek Safarik", "Petr Cerva"], "https://doi.org/10.21437/Interspeech.2016-747", 5, "interspeech", 2016]], "Radek Safarik": [0, ["ASR for South Slavic Languages Developed in Almost Automated Way", ["Jan Nouza", "Radek Safarik", "Petr Cerva"], "https://doi.org/10.21437/Interspeech.2016-747", 5, "interspeech", 2016]], "Petr Cerva": [0, ["ASR for South Slavic Languages Developed in Almost Automated Way", ["Jan Nouza", "Radek Safarik", "Petr Cerva"], "https://doi.org/10.21437/Interspeech.2016-747", 5, "interspeech", 2016]], "Marzieh Razavi": [0, ["Improving Under-Resourced Language ASR Through Latent Subword Unit Space Discovery", ["Marzieh Razavi", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2016-1010", 5, "interspeech", 2016]]}